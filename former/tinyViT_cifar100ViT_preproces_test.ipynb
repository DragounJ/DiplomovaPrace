{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b80e8fe1",
   "metadata": {},
   "source": [
    "# Notebook pro trénink s destilací nad datasetem CIFAR100\n",
    "V tomto notebooku je trénován MobileNetV2 nad datasetem CIFAR100, jako učitelsý model je využíván finetunued ViT nad stejným datasetem. \n",
    "\n",
    "MobileNetV2 je používán s náhodnou inicializací, tréninkem pouze klasifikační hlavy inicializovaného (předtrénovaného nad ImageNetem) MobileNetuV2 a trénink celého modelu, taktéž inicializovaného. Tyto tři úlohy jsou trénovány bězným způsobem a také s pomocí destilace výše zmíněného modelu.  \n",
    "\n",
    "Při destilaci je využíváno předpočítaných logitů ze sešitu precompute_logits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d1c726",
   "metadata": {},
   "source": [
    "## Import knihoven a definice metod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7e7a26f-aa1f-4645-b3b3-4643ca8be2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, EarlyStoppingCallback, AutoModelForImageClassification, AutoImageProcessor\n",
    "from torch.utils.data import ConcatDataset\n",
    "import torch\n",
    "import base\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c86002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_part = base.get_dataset_part()\n",
    "DATASET = \"cifar100\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921fc223",
   "metadata": {},
   "source": [
    "Inicializovaný MobileNetV2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad6208b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29b9ceef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and will be used: NVIDIA A100 80GB PCIe MIG 2g.20gb\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and will be used:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eb90dc",
   "metadata": {},
   "source": [
    "Provedení transformací nad datasetem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b74ce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = base.base_transforms()\n",
    "\n",
    "train = base.CustomCIFAR100L(root=f\"{os.path.expanduser('~')}/data/100-logits\", dataset_part=dataset_part.TRAIN, transform=None)\n",
    "eval = base.CustomCIFAR100L(root=f\"{os.path.expanduser('~')}/data/100-logits\", dataset_part=dataset_part.EVAL, transform=None)\n",
    "test = base.CustomCIFAR100L(root=f\"{os.path.expanduser('~')}/data/100-logits\", dataset_part=dataset_part.TEST, transform=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a85914",
   "metadata": {},
   "source": [
    "### Standardní trénink náhodně inicializovaného modelu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c07c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of TimmWrapperForImageClassification were not initialized from the model checkpoint at timm/tiny_vit_5m_224.in1k and are newly initialized because the shapes did not match:\n",
      "- head.fc.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([100]) in the model instantiated\n",
      "- head.fc.weight: found shape torch.Size([1000, 320]) in the checkpoint and torch.Size([100, 320]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/vit-basetrain-model-transform\", logging_dir=f\"~/logs/{DATASET}/vit-basetrain-model-transform\", lr=0.0005, weight_decay=0.008, adam_beta1=.95, epochs=30)\n",
    "model = AutoModelForImageClassification.from_pretrained(\"timm/tiny_vit_5m_224.in1k\", num_labels=100, ignore_mismatched_sizes=True)\n",
    "processor = AutoImageProcessor.from_pretrained(\"timm/tiny_vit_5m_224.in1k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbd9c40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "def collate_fn(examples):\n",
    "    to_tensor = ToTensor()\n",
    "    pixel_values = torch.stack([to_tensor(example[\"pixel_values\"]) for example in examples])\n",
    "    labels = torch.tensor([example[\"labels\"] for example in examples])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc752b97-d843-4919-a0fc-066d192e037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    processing_class = processor,\n",
    "    data_collator = collate_fn,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97855619-93d5-4fc2-93d2-fee24c61b8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1566' max='9390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1566/9390 05:04 < 25:23, 5.14 it/s, Epoch 5/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.029200</td>\n",
       "      <td>2.310220</td>\n",
       "      <td>0.393100</td>\n",
       "      <td>0.418164</td>\n",
       "      <td>0.393100</td>\n",
       "      <td>0.375002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.900600</td>\n",
       "      <td>1.904595</td>\n",
       "      <td>0.481200</td>\n",
       "      <td>0.505944</td>\n",
       "      <td>0.481200</td>\n",
       "      <td>0.475442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.470900</td>\n",
       "      <td>1.786745</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>0.548163</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>0.513766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.158100</td>\n",
       "      <td>1.729847</td>\n",
       "      <td>0.535600</td>\n",
       "      <td>0.557527</td>\n",
       "      <td>0.535600</td>\n",
       "      <td>0.531547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.928300</td>\n",
       "      <td>1.722173</td>\n",
       "      <td>0.547600</td>\n",
       "      <td>0.568670</td>\n",
       "      <td>0.547600</td>\n",
       "      <td>0.544768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `save_pretrained` method is disabled for TimmWrapperImageProcessor. The image processor configuration is saved directly in `config.json` when `save_pretrained` is called for saving the model.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2548\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2541\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2542\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2543\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2544\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2546\u001b[0m )\n\u001b[1;32m   2547\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2548\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2551\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2552\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2553\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2554\u001b[0m ):\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2556\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3740\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3737\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   3738\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 3740\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3742\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:2325\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m learning_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_lomo_optimizer:\n\u001b[1;32m   2327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:818\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 818\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    819\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882ec503-b58f-418c-bc31-58a9efce7dbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b651751f-7022-4677-8059-11380670b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0225877",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/vit-basetrain_token.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d921c113",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9811bacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of TimmWrapperForImageClassification were not initialized from the model checkpoint at timm/tiny_vit_5m_224.in1k and are newly initialized because the shapes did not match:\n",
      "- head.fc.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([100]) in the model instantiated\n",
      "- head.fc.weight: found shape torch.Size([1000, 320]) in the checkpoint and torch.Size([100, 320]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "transform = base.base_transforms()\n",
    "\n",
    "train = base.CustomCIFAR100L(root=f\"{os.path.expanduser('~')}/data/100-logits\", dataset_part=dataset_part.TRAIN, transform=transform)\n",
    "eval = base.CustomCIFAR100L(root=f\"{os.path.expanduser('~')}/data/100-logits\", dataset_part=dataset_part.EVAL, transform=transform)\n",
    "test = base.CustomCIFAR100L(root=f\"{os.path.expanduser('~')}/data/100-logits\", dataset_part=dataset_part.TEST, transform=transform)\n",
    "\n",
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/vit-basetrain-token-transf\", logging_dir=f\"~/logs/{DATASET}/vit-basetrain-token-transf\", lr=0.0005, weight_decay=0.008, adam_beta1=.95, epochs=30)\n",
    "model = AutoModelForImageClassification.from_pretrained(\"timm/tiny_vit_5m_224.in1k\", num_labels=100, ignore_mismatched_sizes=True)\n",
    "processor = AutoImageProcessor.from_pretrained(\"timm/tiny_vit_5m_224.in1k\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d443e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    processing_class = processor,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff18e433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9390' max='9390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9390/9390 1:38:43, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.642100</td>\n",
       "      <td>1.027111</td>\n",
       "      <td>0.703100</td>\n",
       "      <td>0.723367</td>\n",
       "      <td>0.703100</td>\n",
       "      <td>0.700154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.763300</td>\n",
       "      <td>0.893031</td>\n",
       "      <td>0.741600</td>\n",
       "      <td>0.760275</td>\n",
       "      <td>0.741600</td>\n",
       "      <td>0.739986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.550800</td>\n",
       "      <td>0.869524</td>\n",
       "      <td>0.749900</td>\n",
       "      <td>0.774201</td>\n",
       "      <td>0.749900</td>\n",
       "      <td>0.749924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.421000</td>\n",
       "      <td>0.867980</td>\n",
       "      <td>0.760500</td>\n",
       "      <td>0.781796</td>\n",
       "      <td>0.760500</td>\n",
       "      <td>0.760626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.317200</td>\n",
       "      <td>0.838674</td>\n",
       "      <td>0.775800</td>\n",
       "      <td>0.787255</td>\n",
       "      <td>0.775800</td>\n",
       "      <td>0.775314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.255500</td>\n",
       "      <td>0.790946</td>\n",
       "      <td>0.787100</td>\n",
       "      <td>0.796470</td>\n",
       "      <td>0.787100</td>\n",
       "      <td>0.786925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.216600</td>\n",
       "      <td>0.823603</td>\n",
       "      <td>0.791200</td>\n",
       "      <td>0.803079</td>\n",
       "      <td>0.791200</td>\n",
       "      <td>0.791609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.162900</td>\n",
       "      <td>0.876584</td>\n",
       "      <td>0.788300</td>\n",
       "      <td>0.797620</td>\n",
       "      <td>0.788300</td>\n",
       "      <td>0.787960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.956399</td>\n",
       "      <td>0.779700</td>\n",
       "      <td>0.790966</td>\n",
       "      <td>0.779700</td>\n",
       "      <td>0.780496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.116900</td>\n",
       "      <td>0.903787</td>\n",
       "      <td>0.788500</td>\n",
       "      <td>0.798007</td>\n",
       "      <td>0.788500</td>\n",
       "      <td>0.788618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>0.916584</td>\n",
       "      <td>0.790400</td>\n",
       "      <td>0.798448</td>\n",
       "      <td>0.790400</td>\n",
       "      <td>0.790255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.921764</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.806317</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.799958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.070600</td>\n",
       "      <td>0.936064</td>\n",
       "      <td>0.799600</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.799600</td>\n",
       "      <td>0.799656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.064100</td>\n",
       "      <td>0.932954</td>\n",
       "      <td>0.800900</td>\n",
       "      <td>0.809126</td>\n",
       "      <td>0.800900</td>\n",
       "      <td>0.801228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.055800</td>\n",
       "      <td>0.976699</td>\n",
       "      <td>0.798600</td>\n",
       "      <td>0.807728</td>\n",
       "      <td>0.798600</td>\n",
       "      <td>0.799378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>0.984271</td>\n",
       "      <td>0.807200</td>\n",
       "      <td>0.816225</td>\n",
       "      <td>0.807200</td>\n",
       "      <td>0.808098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.976373</td>\n",
       "      <td>0.810400</td>\n",
       "      <td>0.817907</td>\n",
       "      <td>0.810400</td>\n",
       "      <td>0.811102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.029700</td>\n",
       "      <td>1.012874</td>\n",
       "      <td>0.807800</td>\n",
       "      <td>0.814088</td>\n",
       "      <td>0.807800</td>\n",
       "      <td>0.808199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>1.056953</td>\n",
       "      <td>0.804100</td>\n",
       "      <td>0.811958</td>\n",
       "      <td>0.804100</td>\n",
       "      <td>0.803972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>1.016065</td>\n",
       "      <td>0.814500</td>\n",
       "      <td>0.819339</td>\n",
       "      <td>0.814500</td>\n",
       "      <td>0.814034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>1.023126</td>\n",
       "      <td>0.814500</td>\n",
       "      <td>0.817781</td>\n",
       "      <td>0.814500</td>\n",
       "      <td>0.813632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>1.022999</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.824682</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.819761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.001988</td>\n",
       "      <td>0.825700</td>\n",
       "      <td>0.829317</td>\n",
       "      <td>0.825700</td>\n",
       "      <td>0.825996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.977232</td>\n",
       "      <td>0.829000</td>\n",
       "      <td>0.831546</td>\n",
       "      <td>0.829000</td>\n",
       "      <td>0.828853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.974232</td>\n",
       "      <td>0.831200</td>\n",
       "      <td>0.833184</td>\n",
       "      <td>0.831200</td>\n",
       "      <td>0.831151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.971277</td>\n",
       "      <td>0.832600</td>\n",
       "      <td>0.833915</td>\n",
       "      <td>0.832600</td>\n",
       "      <td>0.832275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.974123</td>\n",
       "      <td>0.834200</td>\n",
       "      <td>0.835542</td>\n",
       "      <td>0.834200</td>\n",
       "      <td>0.833905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.970459</td>\n",
       "      <td>0.833800</td>\n",
       "      <td>0.835130</td>\n",
       "      <td>0.833800</td>\n",
       "      <td>0.833515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.968622</td>\n",
       "      <td>0.833600</td>\n",
       "      <td>0.835047</td>\n",
       "      <td>0.833600</td>\n",
       "      <td>0.833393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.967838</td>\n",
       "      <td>0.833900</td>\n",
       "      <td>0.835115</td>\n",
       "      <td>0.833900</td>\n",
       "      <td>0.833607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9390, training_loss=0.1716814164552318, metrics={'train_runtime': 5929.021, 'train_samples_per_second': 202.394, 'train_steps_per_second': 1.584, 'total_flos': 5.5315759693824e+18, 'train_loss': 0.1716814164552318, 'epoch': 30.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3410ddc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimmWrapperForImageClassification(\n",
       "  (timm_model): TinyVit(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (conv1): ConvNorm(\n",
       "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (act): GELU(approximate='none')\n",
       "      (conv2): ConvNorm(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stages): Sequential(\n",
       "      (0): ConvLayer(\n",
       "        (blocks): Sequential(\n",
       "          (0): MBConv(\n",
       "            (conv1): ConvNorm(\n",
       "              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act1): GELU(approximate='none')\n",
       "            (conv2): ConvNorm(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act2): GELU(approximate='none')\n",
       "            (conv3): ConvNorm(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act3): GELU(approximate='none')\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (conv1): ConvNorm(\n",
       "              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act1): GELU(approximate='none')\n",
       "            (conv2): ConvNorm(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act2): GELU(approximate='none')\n",
       "            (conv3): ConvNorm(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act3): GELU(approximate='none')\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): TinyVitStage(\n",
       "        dim=128, depth=2\n",
       "        (downsample): PatchMerging(\n",
       "          (conv1): ConvNorm(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act1): GELU(approximate='none')\n",
       "          (conv2): ConvNorm(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act2): GELU(approximate='none')\n",
       "          (conv3): ConvNorm(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): TinyVitBlock(\n",
       "            dim=128, num_heads=4, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): TinyVitBlock(\n",
       "            dim=128, num_heads=4, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): TinyVitStage(\n",
       "        dim=160, depth=6\n",
       "        (downsample): PatchMerging(\n",
       "          (conv1): ConvNorm(\n",
       "            (conv): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act1): GELU(approximate='none')\n",
       "          (conv2): ConvNorm(\n",
       "            (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act2): GELU(approximate='none')\n",
       "          (conv3): ConvNorm(\n",
       "            (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (3): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (4): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (5): TinyVitBlock(\n",
       "            dim=160, num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): TinyVitStage(\n",
       "        dim=320, depth=2\n",
       "        (downsample): PatchMerging(\n",
       "          (conv1): ConvNorm(\n",
       "            (conv): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act1): GELU(approximate='none')\n",
       "          (conv2): ConvNorm(\n",
       "            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=320, bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (act2): GELU(approximate='none')\n",
       "          (conv3): ConvNorm(\n",
       "            (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): TinyVitBlock(\n",
       "            dim=320, num_heads=10, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=320, out_features=960, bias=True)\n",
       "              (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): TinyVitBlock(\n",
       "            dim=320, num_heads=10, window_size=7, mlp_ratio=4.0\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=320, out_features=960, bias=True)\n",
       "              (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): NormMlp(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "            (local_conv): ConvNorm(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): NormMlpClassifierHead(\n",
       "      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "      (norm): LayerNorm2d((320,), eps=1e-05, elementwise_affine=True)\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "      (pre_logits): Identity()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "      (fc): Linear(in_features=320, out_features=100, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d04c296e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='79' max='79' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [79/79 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9375255703926086,\n",
       " 'eval_accuracy': 0.8402,\n",
       " 'eval_precision': 0.8423099663864122,\n",
       " 'eval_recall': 0.8402,\n",
       " 'eval_f1': 0.8405098146032582,\n",
       " 'eval_runtime': 12.3538,\n",
       " 'eval_samples_per_second': 809.468,\n",
       " 'eval_steps_per_second': 6.395,\n",
       " 'epoch': 30.0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87594fbb",
   "metadata": {},
   "source": [
    "## Definice destilačního tréninku\n",
    "\n",
    "Třída, která upravuje hugging face trenéra pro destilaci znalostí. Nově pracuje s logity uloženými v datasetu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd84cda",
   "metadata": {},
   "source": [
    "### Trénink náhodně inicializovaného modelu s pomocí destilace znalostí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "24f990e8-d259-44c7-b85b-cca2f4f97a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aad7fa0f-f432-4e99-bb07-31951b7858f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of TimmWrapperForImageClassification were not initialized from the model checkpoint at timm/tiny_vit_5m_224.in1k and are newly initialized because the shapes did not match:\n",
      "- head.fc.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([100]) in the model instantiated\n",
      "- head.fc.weight: found shape torch.Size([1000, 320]) in the checkpoint and torch.Size([100, 320]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/vit-distilltrain\", logging_dir=f\"~/logs/{DATASET}/vit-distilltrain\", remove_unused_columns=False, epochs=30, lr=0.00047, weight_decay=0, adam_beta1=.9, lambda_param=1, temp=6)\n",
    "student_model = AutoModelForImageClassification.from_pretrained(\"timm/tiny_vit_5m_224.in1k\", num_labels=100, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43af926a-dba5-468f-9a48-c4c581e97893",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainer(\n",
    "    student_model=student_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    processing_class = processor,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "22a2fa47-1cf3-465c-aa7f-9b41b66846d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6490' max='9390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6490/9390 35:39 < 15:56, 3.03 it/s, Epoch 20.73/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.298900</td>\n",
       "      <td>0.831203</td>\n",
       "      <td>0.683800</td>\n",
       "      <td>0.731836</td>\n",
       "      <td>0.683800</td>\n",
       "      <td>0.685063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.662224</td>\n",
       "      <td>0.729600</td>\n",
       "      <td>0.753612</td>\n",
       "      <td>0.729600</td>\n",
       "      <td>0.730670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.453300</td>\n",
       "      <td>0.622127</td>\n",
       "      <td>0.755500</td>\n",
       "      <td>0.776564</td>\n",
       "      <td>0.755500</td>\n",
       "      <td>0.753489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.368500</td>\n",
       "      <td>0.563021</td>\n",
       "      <td>0.770700</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.770700</td>\n",
       "      <td>0.772211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.310300</td>\n",
       "      <td>0.546491</td>\n",
       "      <td>0.779300</td>\n",
       "      <td>0.799878</td>\n",
       "      <td>0.779300</td>\n",
       "      <td>0.779068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.262700</td>\n",
       "      <td>0.532122</td>\n",
       "      <td>0.782600</td>\n",
       "      <td>0.800717</td>\n",
       "      <td>0.782600</td>\n",
       "      <td>0.784513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.232000</td>\n",
       "      <td>0.495274</td>\n",
       "      <td>0.797000</td>\n",
       "      <td>0.812961</td>\n",
       "      <td>0.797000</td>\n",
       "      <td>0.799272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.203200</td>\n",
       "      <td>0.501735</td>\n",
       "      <td>0.795400</td>\n",
       "      <td>0.811297</td>\n",
       "      <td>0.795400</td>\n",
       "      <td>0.797779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>0.486403</td>\n",
       "      <td>0.797000</td>\n",
       "      <td>0.811036</td>\n",
       "      <td>0.797000</td>\n",
       "      <td>0.797992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.164500</td>\n",
       "      <td>0.481768</td>\n",
       "      <td>0.797900</td>\n",
       "      <td>0.809001</td>\n",
       "      <td>0.797900</td>\n",
       "      <td>0.798922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.452184</td>\n",
       "      <td>0.811500</td>\n",
       "      <td>0.823122</td>\n",
       "      <td>0.811500</td>\n",
       "      <td>0.813808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.137600</td>\n",
       "      <td>0.438851</td>\n",
       "      <td>0.815100</td>\n",
       "      <td>0.823559</td>\n",
       "      <td>0.815100</td>\n",
       "      <td>0.815763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.125400</td>\n",
       "      <td>0.422168</td>\n",
       "      <td>0.818700</td>\n",
       "      <td>0.827122</td>\n",
       "      <td>0.818700</td>\n",
       "      <td>0.819231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.114200</td>\n",
       "      <td>0.415929</td>\n",
       "      <td>0.821100</td>\n",
       "      <td>0.828424</td>\n",
       "      <td>0.821100</td>\n",
       "      <td>0.821512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.102300</td>\n",
       "      <td>0.398898</td>\n",
       "      <td>0.823800</td>\n",
       "      <td>0.835364</td>\n",
       "      <td>0.823800</td>\n",
       "      <td>0.825578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.383429</td>\n",
       "      <td>0.832100</td>\n",
       "      <td>0.841084</td>\n",
       "      <td>0.832100</td>\n",
       "      <td>0.833592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.081900</td>\n",
       "      <td>0.367584</td>\n",
       "      <td>0.835600</td>\n",
       "      <td>0.842364</td>\n",
       "      <td>0.835600</td>\n",
       "      <td>0.836567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.074300</td>\n",
       "      <td>0.356513</td>\n",
       "      <td>0.840300</td>\n",
       "      <td>0.846905</td>\n",
       "      <td>0.840300</td>\n",
       "      <td>0.841311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.356558</td>\n",
       "      <td>0.839500</td>\n",
       "      <td>0.847558</td>\n",
       "      <td>0.839500</td>\n",
       "      <td>0.840639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.063100</td>\n",
       "      <td>0.352872</td>\n",
       "      <td>0.837700</td>\n",
       "      <td>0.846143</td>\n",
       "      <td>0.837700</td>\n",
       "      <td>0.838799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2553\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2547\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2548\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2551\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2552\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2553\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2554\u001b[0m ):\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2556\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2557\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdb542b-ab09-419d-9094-9b2385e68d19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2ForImageClassification(\n",
       "  (mobilenet_v2): MobileNetV2Model(\n",
       "    (conv_stem): MobileNetV2Stem(\n",
       "      (first_conv): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (conv_3x3): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
       "        (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (reduce_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(16, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer): ModuleList(\n",
       "      (0): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3-4): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(64, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6-8): 3 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(64, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (9): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (10-11): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (12): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), groups=576, bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(160, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (13-14): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(160, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (15): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(320, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_1x1): MobileNetV2ConvLayer(\n",
       "      (convolution): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (normalization): BatchNorm2d(1280, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU6()\n",
       "    )\n",
       "    (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.8, inplace=True)\n",
       "  (classifier): Linear(in_features=1280, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9356e120-e435-44ff-91a1-2cac9facae31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='79' max='79' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [79/79 00:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.09884512424469,\n",
       " 'eval_accuracy': 0.5504,\n",
       " 'eval_precision': 0.5808980316978757,\n",
       " 'eval_recall': 0.5504,\n",
       " 'eval_f1': 0.5546805225416259,\n",
       " 'eval_runtime': 37.502,\n",
       " 'eval_samples_per_second': 266.653,\n",
       " 'eval_steps_per_second': 2.107,\n",
       " 'epoch': 30.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94621e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/vit-distilltrain.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
