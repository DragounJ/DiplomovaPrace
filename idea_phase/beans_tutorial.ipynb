{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3efcfa7e-c869-43c9-955f-0678e717c4cf",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in /opt/conda/lib/python3.11/site-packages (4.45.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (4.66.5)\n",
      "Collecting accelerate>=0.26.0 (from transformers[torch])\n",
      "  Obtaining dependency information for accelerate>=0.26.0 from https://files.pythonhosted.org/packages/2c/92/48aec3736ca778ffe5fa68e19e3c18917cba4de43fa46fe6176cccafe267/accelerate-1.0.1-py3-none-any.whl.metadata\n",
      "  Downloading accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (2.4.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.11/site-packages (from torch->transformers[torch]) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.6.77)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers[torch]) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers[torch]) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers[torch]) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
      "Downloading accelerate-1.0.1-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.9/330.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: accelerate\n",
      "Successfully installed accelerate-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "387e0d78-247b-4ca6-97c9-35ba745c5290",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 20:14:18.172618: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-11 20:14:18.200435: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-11 20:14:18.768788: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login, HfFolder\n",
    "from transformers import AutoTokenizer, TrainingArguments, Trainer, AutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from evaluate import load\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def20887-f71c-434c-a586-c792b7192946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"beans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9407b8f1-3884-4b62-bf17-9a6f7aea52ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "teacher_processor = AutoImageProcessor.from_pretrained(\"merve/beans-vit-224\")\n",
    "\n",
    "def process(examples):\n",
    "    processed_inputs = teacher_processor(examples[\"image\"])\n",
    "    return processed_inputs\n",
    "\n",
    "processed_datasets = dataset.map(process, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6d856dd-5cd3-43ee-b300-b96225bbdd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['image_file_path', 'image', 'labels', 'pixel_values'],\n",
      "    num_rows: 1034\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(processed_datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5b62d9d-2bcb-4743-959a-830b1b31d277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ImageDistilTrainer(Trainer):\n",
    "    def __init__(self, teacher_model=None, student_model=None, temperature=None, lambda_param=None,  *args, **kwargs):\n",
    "        super().__init__(model=student_model, *args, **kwargs)\n",
    "        self.teacher = teacher_model\n",
    "        self.student = student_model\n",
    "        self.loss_function = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.teacher.to(device)\n",
    "        self.teacher.eval()\n",
    "        self.temperature = temperature\n",
    "        self.lambda_param = lambda_param\n",
    "\n",
    "\n",
    "\n",
    "    def compute_loss(self, student, inputs, return_outputs=False):\n",
    "        student_output = self.student(**inputs)\n",
    "\n",
    "        with torch.no_grad():\n",
    "          teacher_output = self.teacher(**inputs)\n",
    "\n",
    "        # Compute soft targets for teacher and student\n",
    "        soft_teacher = F.softmax(teacher_output.logits / self.temperature, dim=-1)\n",
    "        soft_student = F.log_softmax(student_output.logits / self.temperature, dim=-1)\n",
    "\n",
    "        # Compute the loss\n",
    "        distillation_loss = self.loss_function(soft_student, soft_teacher) * (self.temperature ** 2)\n",
    "\n",
    "        # Compute the true label loss\n",
    "        student_target_loss = student_output.loss\n",
    "\n",
    "        # Calculate final loss\n",
    "        loss = (1. - self.lambda_param) * student_target_loss + self.lambda_param * distillation_loss\n",
    "        return (loss, student_output) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61b45de7-f19d-48f7-b23a-6df442185505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5e22d867b446c8aae1cf4b7b6eac46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4598c3c0-4ac1-42c5-b5b7-9d2723fb2a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification, MobileNetV2Config, MobileNetV2ForImageClassification\n",
    "repo_name = \"DistilationTest\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my-awesome-model\",\n",
    "    num_train_epochs=30,\n",
    "    fp16=True,\n",
    "    learning_rate=5e-5,\n",
    "    seed=42,\n",
    "    logging_dir=f\"{repo_name}/logs\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"tensorboard\",\n",
    "    push_to_hub=True,\n",
    "    hub_strategy=\"every_save\",\n",
    "    hub_model_id=repo_name,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    )\n",
    "\n",
    "num_labels = len(processed_datasets[\"train\"].features[\"labels\"].names)\n",
    "\n",
    "# initialize models\n",
    "teacher_model = AutoModelForImageClassification.from_pretrained(\n",
    "    \"merve/beans-vit-224\",\n",
    "    num_labels=num_labels,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "# training MobileNetV2 from scratch\n",
    "student_config = MobileNetV2Config()\n",
    "student_config.num_labels = num_labels\n",
    "student_model = MobileNetV2ForImageClassification(student_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10bb86e6-9041-4b1e-a46d-81f600141003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    acc = accuracy.compute(references=labels, predictions=np.argmax(predictions, axis=1))\n",
    "    return {\"accuracy\": acc[\"accuracy\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28de93c4-2580-40da-8fc4-a6251f9c83c0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()\n",
    "trainer = ImageDistilTrainer(\n",
    "    student_model=student_model,\n",
    "    teacher_model=teacher_model,\n",
    "    args=training_args,\n",
    "    train_dataset=processed_datasets[\"train\"],\n",
    "    eval_dataset=processed_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=teacher_processor,\n",
    "    compute_metrics=compute_metrics,\n",
    "    temperature = 5,\n",
    "    lambda_param = 0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43a681a1-97c0-4164-b796-85af696c4bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='510' max='510' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [510/510 43:34, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.883000</td>\n",
       "      <td>0.779409</td>\n",
       "      <td>0.406015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.841500</td>\n",
       "      <td>0.756176</td>\n",
       "      <td>0.511278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.776300</td>\n",
       "      <td>0.708210</td>\n",
       "      <td>0.563910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.748700</td>\n",
       "      <td>0.691835</td>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.682000</td>\n",
       "      <td>0.645402</td>\n",
       "      <td>0.601504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.632300</td>\n",
       "      <td>0.631559</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.614000</td>\n",
       "      <td>0.596645</td>\n",
       "      <td>0.661654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.567700</td>\n",
       "      <td>0.598456</td>\n",
       "      <td>0.586466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.538600</td>\n",
       "      <td>0.601588</td>\n",
       "      <td>0.601504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.516400</td>\n",
       "      <td>0.624563</td>\n",
       "      <td>0.616541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.486200</td>\n",
       "      <td>0.632727</td>\n",
       "      <td>0.609023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.463500</td>\n",
       "      <td>0.568847</td>\n",
       "      <td>0.639098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.438900</td>\n",
       "      <td>0.619604</td>\n",
       "      <td>0.593985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.411900</td>\n",
       "      <td>0.614225</td>\n",
       "      <td>0.639098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.415200</td>\n",
       "      <td>0.559443</td>\n",
       "      <td>0.661654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.373100</td>\n",
       "      <td>0.586346</td>\n",
       "      <td>0.639098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.381200</td>\n",
       "      <td>0.650307</td>\n",
       "      <td>0.601504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.367600</td>\n",
       "      <td>0.558895</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.345600</td>\n",
       "      <td>0.575285</td>\n",
       "      <td>0.654135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.342800</td>\n",
       "      <td>0.606935</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.335200</td>\n",
       "      <td>0.640607</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.330500</td>\n",
       "      <td>0.692291</td>\n",
       "      <td>0.586466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.302800</td>\n",
       "      <td>0.594675</td>\n",
       "      <td>0.593985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.301500</td>\n",
       "      <td>0.650484</td>\n",
       "      <td>0.616541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.313000</td>\n",
       "      <td>0.582605</td>\n",
       "      <td>0.691729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.287900</td>\n",
       "      <td>0.696263</td>\n",
       "      <td>0.593985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.285800</td>\n",
       "      <td>0.601210</td>\n",
       "      <td>0.676692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.273300</td>\n",
       "      <td>0.576041</td>\n",
       "      <td>0.691729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.283800</td>\n",
       "      <td>0.654895</td>\n",
       "      <td>0.624060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.291500</td>\n",
       "      <td>0.661489</td>\n",
       "      <td>0.624060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=510, training_loss=0.4610541250191483, metrics={'train_runtime': 2622.7706, 'train_samples_per_second': 11.827, 'train_steps_per_second': 0.194, 'total_flos': 6.24122679527424e+16, 'train_loss': 0.4610541250191483, 'epoch': 30.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5dfee5ed-aef8-4fef-9c2a-9bef374c040c",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2ForImageClassification(\n",
       "  (mobilenet_v2): MobileNetV2Model(\n",
       "    (conv_stem): MobileNetV2Stem(\n",
       "      (first_conv): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (conv_3x3): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
       "        (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (reduce_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(16, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer): ModuleList(\n",
       "      (0): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3-4): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(64, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6-8): 3 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(64, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (9): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (10-11): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (12): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), groups=576, bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(160, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (13-14): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(160, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (15): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(320, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_1x1): MobileNetV2ConvLayer(\n",
       "      (convolution): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (normalization): BatchNorm2d(1280, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU6()\n",
       "    )\n",
       "    (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.8, inplace=True)\n",
       "  (classifier): Linear(in_features=1280, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58ad6c4a-b355-481f-845e-edebc61980bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5066142082214355,\n",
       " 'eval_accuracy': 0.6875,\n",
       " 'eval_runtime': 9.7214,\n",
       " 'eval_samples_per_second': 13.167,\n",
       " 'eval_steps_per_second': 0.206,\n",
       " 'epoch': 30.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(processed_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "488d628e-9975-43d7-827e-829dbdc8e4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_config = MobileNetV2Config()\n",
    "base_config.num_labels = num_labels\n",
    "base_model = MobileNetV2ForImageClassification(base_config)\n",
    "repo_name = \"DistilationTestComparison\"\n",
    "argsv2 = TrainingArguments(\n",
    "    output_dir=\"my-awesome-model-base-v2\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    report_to=\"tensorboard\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    num_train_epochs=30,\n",
    "    fp16=True,\n",
    "    seed=42,\n",
    "    learning_rate = 5e-5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    logging_dir=f\"{repo_name}/logs\",\n",
    ")\n",
    "trainer_base = Trainer(\n",
    "    base_model,\n",
    "    argsv2,\n",
    "    train_dataset=processed_datasets[\"train\"],\n",
    "    eval_dataset=processed_datasets[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3c81f38-726c-4c36-aa74-d24fab3867d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='510' max='510' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [510/510 34:13, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.257800</td>\n",
       "      <td>1.105976</td>\n",
       "      <td>0.345865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.186700</td>\n",
       "      <td>1.080333</td>\n",
       "      <td>0.398496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.175800</td>\n",
       "      <td>1.079312</td>\n",
       "      <td>0.398496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.152900</td>\n",
       "      <td>1.048753</td>\n",
       "      <td>0.406015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.069800</td>\n",
       "      <td>1.016128</td>\n",
       "      <td>0.503759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.025200</td>\n",
       "      <td>0.972632</td>\n",
       "      <td>0.548872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.934900</td>\n",
       "      <td>1.025278</td>\n",
       "      <td>0.593985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.910500</td>\n",
       "      <td>1.022724</td>\n",
       "      <td>0.563910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.816400</td>\n",
       "      <td>1.049483</td>\n",
       "      <td>0.601504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.706200</td>\n",
       "      <td>1.254436</td>\n",
       "      <td>0.654135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.578400</td>\n",
       "      <td>1.203301</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.508200</td>\n",
       "      <td>1.085035</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.406400</td>\n",
       "      <td>1.114540</td>\n",
       "      <td>0.624060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>1.312841</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.275800</td>\n",
       "      <td>1.268624</td>\n",
       "      <td>0.624060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.216000</td>\n",
       "      <td>0.993654</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.221700</td>\n",
       "      <td>1.785806</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.184200</td>\n",
       "      <td>1.317857</td>\n",
       "      <td>0.601504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.127700</td>\n",
       "      <td>1.424345</td>\n",
       "      <td>0.586466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.109500</td>\n",
       "      <td>1.441403</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>2.161748</td>\n",
       "      <td>0.518797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.125500</td>\n",
       "      <td>1.638397</td>\n",
       "      <td>0.518797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.092400</td>\n",
       "      <td>2.142509</td>\n",
       "      <td>0.496241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.076700</td>\n",
       "      <td>1.706821</td>\n",
       "      <td>0.609023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.072700</td>\n",
       "      <td>1.891730</td>\n",
       "      <td>0.541353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.102300</td>\n",
       "      <td>2.162549</td>\n",
       "      <td>0.541353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.073700</td>\n",
       "      <td>1.508941</td>\n",
       "      <td>0.639098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.042400</td>\n",
       "      <td>1.389156</td>\n",
       "      <td>0.639098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>2.029588</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>1.556754</td>\n",
       "      <td>0.548872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=510, training_loss=0.4669638855784547, metrics={'train_runtime': 2060.3369, 'train_samples_per_second': 15.056, 'train_steps_per_second': 0.248, 'total_flos': 6.24122679527424e+16, 'train_loss': 0.4669638855784547, 'epoch': 30.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_base.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd8ddf21-81f9-458c-86dc-33a1674513cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2ForImageClassification(\n",
       "  (mobilenet_v2): MobileNetV2Model(\n",
       "    (conv_stem): MobileNetV2Stem(\n",
       "      (first_conv): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (conv_3x3): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
       "        (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (reduce_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(16, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer): ModuleList(\n",
       "      (0): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3-4): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(64, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6-8): 3 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(64, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (9): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (10-11): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (12): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), groups=576, bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(160, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (13-14): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(160, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (15): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(320, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_1x1): MobileNetV2ConvLayer(\n",
       "      (convolution): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (normalization): BatchNorm2d(1280, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU6()\n",
       "    )\n",
       "    (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.8, inplace=True)\n",
       "  (classifier): Linear(in_features=1280, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a8d5c0f-3a2b-4d15-963a-9783797910bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.299200177192688,\n",
       " 'eval_accuracy': 0.59375,\n",
       " 'eval_runtime': 7.5802,\n",
       " 'eval_samples_per_second': 16.886,\n",
       " 'eval_steps_per_second': 0.264,\n",
       " 'epoch': 30.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_base.evaluate(processed_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e7a26f-aa1f-4645-b3b3-4643ca8be2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
