{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Torchtext není k dispozici pro poslední verzi pytorch, budeme tedy využuívat něco jiného ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, BertForSequenceClassification, BertTokenizer, EarlyStoppingCallback\n",
    "from datasets import load_from_disk\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import base\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"trec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and will be used: NVIDIA A100 80GB PCIe MIG 2g.20gb\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and will be used:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_from_disk(f\"~/data/{DATASET}/train-logits_fine\")\n",
    "eval = load_from_disk(f\"~/data/{DATASET}/eval-logits_fine\")\n",
    "test = load_from_disk(f\"~/data/{DATASET}/test-logits_fine\")\n",
    "\n",
    "train_aug = load_from_disk(f\"~/data/{DATASET}/train-logits-augmented_fine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"ndavid/autotrain-trec-fine-bert-739422530\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the train dataset\")\n",
    "eval = eval.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the eval dataset\")\n",
    "test = test.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the test dataset\")\n",
    "\n",
    "train_aug = train_aug.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the augmented dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\", num_labels=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bert-base_fine\", logging_dir=f\"~/logs/{DATASET}/bert-base_fine\", batch_size=128, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [700/700 02:05, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.782000</td>\n",
       "      <td>3.659952</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.016891</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.599900</td>\n",
       "      <td>3.504540</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023548</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.463800</td>\n",
       "      <td>3.361355</td>\n",
       "      <td>0.239230</td>\n",
       "      <td>0.075162</td>\n",
       "      <td>0.038320</td>\n",
       "      <td>0.032300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.324800</td>\n",
       "      <td>3.230582</td>\n",
       "      <td>0.368469</td>\n",
       "      <td>0.068824</td>\n",
       "      <td>0.077057</td>\n",
       "      <td>0.063401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.223700</td>\n",
       "      <td>3.117347</td>\n",
       "      <td>0.401467</td>\n",
       "      <td>0.076742</td>\n",
       "      <td>0.086241</td>\n",
       "      <td>0.066248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.104000</td>\n",
       "      <td>3.015311</td>\n",
       "      <td>0.417965</td>\n",
       "      <td>0.093694</td>\n",
       "      <td>0.093164</td>\n",
       "      <td>0.073303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.003000</td>\n",
       "      <td>2.925939</td>\n",
       "      <td>0.429881</td>\n",
       "      <td>0.088959</td>\n",
       "      <td>0.100196</td>\n",
       "      <td>0.079902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.927400</td>\n",
       "      <td>2.845344</td>\n",
       "      <td>0.448213</td>\n",
       "      <td>0.085833</td>\n",
       "      <td>0.107519</td>\n",
       "      <td>0.084251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.845800</td>\n",
       "      <td>2.773612</td>\n",
       "      <td>0.455545</td>\n",
       "      <td>0.104410</td>\n",
       "      <td>0.111707</td>\n",
       "      <td>0.087127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.780600</td>\n",
       "      <td>2.710714</td>\n",
       "      <td>0.469294</td>\n",
       "      <td>0.104791</td>\n",
       "      <td>0.121830</td>\n",
       "      <td>0.097324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.725300</td>\n",
       "      <td>2.653377</td>\n",
       "      <td>0.472961</td>\n",
       "      <td>0.104718</td>\n",
       "      <td>0.123589</td>\n",
       "      <td>0.099525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.658700</td>\n",
       "      <td>2.604350</td>\n",
       "      <td>0.483043</td>\n",
       "      <td>0.105165</td>\n",
       "      <td>0.127507</td>\n",
       "      <td>0.102495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.628200</td>\n",
       "      <td>2.562277</td>\n",
       "      <td>0.487626</td>\n",
       "      <td>0.102196</td>\n",
       "      <td>0.130170</td>\n",
       "      <td>0.104431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.579700</td>\n",
       "      <td>2.526321</td>\n",
       "      <td>0.492209</td>\n",
       "      <td>0.105179</td>\n",
       "      <td>0.134252</td>\n",
       "      <td>0.108696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.549000</td>\n",
       "      <td>2.497067</td>\n",
       "      <td>0.499542</td>\n",
       "      <td>0.125246</td>\n",
       "      <td>0.137990</td>\n",
       "      <td>0.112234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.514600</td>\n",
       "      <td>2.473726</td>\n",
       "      <td>0.503208</td>\n",
       "      <td>0.146948</td>\n",
       "      <td>0.140334</td>\n",
       "      <td>0.115160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.484900</td>\n",
       "      <td>2.455923</td>\n",
       "      <td>0.508708</td>\n",
       "      <td>0.180354</td>\n",
       "      <td>0.144467</td>\n",
       "      <td>0.121660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.483200</td>\n",
       "      <td>2.443304</td>\n",
       "      <td>0.512374</td>\n",
       "      <td>0.180753</td>\n",
       "      <td>0.147412</td>\n",
       "      <td>0.125137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.476400</td>\n",
       "      <td>2.434930</td>\n",
       "      <td>0.515124</td>\n",
       "      <td>0.182165</td>\n",
       "      <td>0.149106</td>\n",
       "      <td>0.127665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.473400</td>\n",
       "      <td>2.432208</td>\n",
       "      <td>0.516040</td>\n",
       "      <td>0.182875</td>\n",
       "      <td>0.149101</td>\n",
       "      <td>0.127747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=700, training_loss=2.881428451538086, metrics={'train_runtime': 125.8131, 'train_samples_per_second': 693.251, 'train_steps_per_second': 5.564, 'total_flos': 65900954952000.0, 'train_loss': 2.881428451538086, 'epoch': 20.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-1): 2 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=128, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.5368008613586426,\n",
       " 'eval_accuracy': 0.566,\n",
       " 'eval_precision': 0.12189557405215357,\n",
       " 'eval_recall': 0.18359783242761965,\n",
       " 'eval_f1': 0.12798195561772654,\n",
       " 'eval_runtime': 3.129,\n",
       " 'eval_samples_per_second': 159.794,\n",
       " 'eval_steps_per_second': 1.278,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bert_fine.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "student_model = BertForSequenceClassification.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\", num_labels=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bert-distill_fine\", logging_dir=f\"~/logs/{DATASET}/bert-distill_fine\", remove_unused_columns=False, batch_size=128, epochs=20, temp=5, lambda_param=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainer(\n",
    "    student_model=student_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [700/700 02:07, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.407600</td>\n",
       "      <td>2.324112</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.294300</td>\n",
       "      <td>2.239185</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.221300</td>\n",
       "      <td>2.169806</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.153900</td>\n",
       "      <td>2.102734</td>\n",
       "      <td>0.293309</td>\n",
       "      <td>0.026650</td>\n",
       "      <td>0.052740</td>\n",
       "      <td>0.033642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.098000</td>\n",
       "      <td>2.039486</td>\n",
       "      <td>0.307058</td>\n",
       "      <td>0.035465</td>\n",
       "      <td>0.056396</td>\n",
       "      <td>0.034119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.033100</td>\n",
       "      <td>1.977010</td>\n",
       "      <td>0.337305</td>\n",
       "      <td>0.054202</td>\n",
       "      <td>0.063994</td>\n",
       "      <td>0.042839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.972500</td>\n",
       "      <td>1.914761</td>\n",
       "      <td>0.404216</td>\n",
       "      <td>0.078100</td>\n",
       "      <td>0.090593</td>\n",
       "      <td>0.071845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.917000</td>\n",
       "      <td>1.860798</td>\n",
       "      <td>0.430797</td>\n",
       "      <td>0.073561</td>\n",
       "      <td>0.100584</td>\n",
       "      <td>0.077952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.870100</td>\n",
       "      <td>1.811178</td>\n",
       "      <td>0.436297</td>\n",
       "      <td>0.068977</td>\n",
       "      <td>0.103844</td>\n",
       "      <td>0.079061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.825300</td>\n",
       "      <td>1.768889</td>\n",
       "      <td>0.461045</td>\n",
       "      <td>0.104244</td>\n",
       "      <td>0.117568</td>\n",
       "      <td>0.095030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.789400</td>\n",
       "      <td>1.731568</td>\n",
       "      <td>0.472044</td>\n",
       "      <td>0.103294</td>\n",
       "      <td>0.124511</td>\n",
       "      <td>0.101058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.747400</td>\n",
       "      <td>1.699237</td>\n",
       "      <td>0.482126</td>\n",
       "      <td>0.134850</td>\n",
       "      <td>0.136567</td>\n",
       "      <td>0.117486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.723600</td>\n",
       "      <td>1.672567</td>\n",
       "      <td>0.490376</td>\n",
       "      <td>0.132508</td>\n",
       "      <td>0.147450</td>\n",
       "      <td>0.125854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.693500</td>\n",
       "      <td>1.650252</td>\n",
       "      <td>0.501375</td>\n",
       "      <td>0.147680</td>\n",
       "      <td>0.154276</td>\n",
       "      <td>0.133710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.672200</td>\n",
       "      <td>1.631290</td>\n",
       "      <td>0.504125</td>\n",
       "      <td>0.141467</td>\n",
       "      <td>0.155137</td>\n",
       "      <td>0.132957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.653800</td>\n",
       "      <td>1.616730</td>\n",
       "      <td>0.505958</td>\n",
       "      <td>0.133455</td>\n",
       "      <td>0.156118</td>\n",
       "      <td>0.133811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.635900</td>\n",
       "      <td>1.605902</td>\n",
       "      <td>0.514207</td>\n",
       "      <td>0.156449</td>\n",
       "      <td>0.161289</td>\n",
       "      <td>0.139777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.634700</td>\n",
       "      <td>1.597566</td>\n",
       "      <td>0.518790</td>\n",
       "      <td>0.157763</td>\n",
       "      <td>0.163323</td>\n",
       "      <td>0.142364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.628200</td>\n",
       "      <td>1.592692</td>\n",
       "      <td>0.519707</td>\n",
       "      <td>0.157791</td>\n",
       "      <td>0.163777</td>\n",
       "      <td>0.142708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.625300</td>\n",
       "      <td>1.591055</td>\n",
       "      <td>0.519707</td>\n",
       "      <td>0.157597</td>\n",
       "      <td>0.163777</td>\n",
       "      <td>0.142613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=700, training_loss=1.8798588562011718, metrics={'train_runtime': 128.1475, 'train_samples_per_second': 680.622, 'train_steps_per_second': 5.462, 'total_flos': 65900954952000.0, 'train_loss': 1.8798588562011718, 'epoch': 20.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-1): 2 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=128, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.6074937582015991,\n",
       " 'eval_accuracy': 0.556,\n",
       " 'eval_precision': 0.16645158090077605,\n",
       " 'eval_recall': 0.20287909490037145,\n",
       " 'eval_f1': 0.15261276616621097,\n",
       " 'eval_runtime': 3.4842,\n",
       " 'eval_samples_per_second': 143.506,\n",
       " 'eval_steps_per_second': 1.148,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student_model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bert-distil_fine.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\", num_labels=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bert-base-aug_fine\", logging_dir=f\"~/logs/{DATASET}/bert-base-aug_fine\", batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_aug,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 4)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='5250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/5250 06:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.824100</td>\n",
       "      <td>2.136180</td>\n",
       "      <td>0.622365</td>\n",
       "      <td>0.301445</td>\n",
       "      <td>0.262651</td>\n",
       "      <td>0.258269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.602200</td>\n",
       "      <td>1.491287</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.410205</td>\n",
       "      <td>0.412482</td>\n",
       "      <td>0.392001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.054200</td>\n",
       "      <td>1.241309</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.446046</td>\n",
       "      <td>0.438159</td>\n",
       "      <td>0.419732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.769300</td>\n",
       "      <td>1.122047</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.481814</td>\n",
       "      <td>0.469729</td>\n",
       "      <td>0.456060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.598600</td>\n",
       "      <td>1.071303</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.491996</td>\n",
       "      <td>0.493517</td>\n",
       "      <td>0.483893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.491800</td>\n",
       "      <td>1.041133</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.522023</td>\n",
       "      <td>0.515877</td>\n",
       "      <td>0.511503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.418600</td>\n",
       "      <td>1.025562</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.517848</td>\n",
       "      <td>0.513470</td>\n",
       "      <td>0.508353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.374200</td>\n",
       "      <td>1.014744</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.533035</td>\n",
       "      <td>0.515185</td>\n",
       "      <td>0.509330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.342900</td>\n",
       "      <td>1.013984</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.534928</td>\n",
       "      <td>0.518609</td>\n",
       "      <td>0.512396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.329200</td>\n",
       "      <td>1.011537</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.556973</td>\n",
       "      <td>0.527321</td>\n",
       "      <td>0.524949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5250, training_loss=0.8805165405273437, metrics={'train_runtime': 361.447, 'train_samples_per_second': 1855.874, 'train_steps_per_second': 14.525, 'total_flos': 506837429280000.0, 'train_loss': 0.8805165405273437, 'epoch': 10.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-1): 2 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=128, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0670723915100098,\n",
       " 'eval_accuracy': 0.75,\n",
       " 'eval_precision': 0.495292131023191,\n",
       " 'eval_recall': 0.5526976371772174,\n",
       " 'eval_f1': 0.4961979675487844,\n",
       " 'eval_runtime': 3.236,\n",
       " 'eval_samples_per_second': 154.512,\n",
       " 'eval_steps_per_second': 1.236,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bert-base-aug_fine.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "student_model = BertForSequenceClassification.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\", num_labels=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bert-distill-aug_fine\", logging_dir=f\"~/logs/{DATASET}/bert-distill-aug_fine\", remove_unused_columns=False, batch_size=128, epochs=10, temp=5, lambda_param=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainer(\n",
    "    student_model=student_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_aug,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 4)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='5250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/5250 06:05, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.815600</td>\n",
       "      <td>1.408841</td>\n",
       "      <td>0.560953</td>\n",
       "      <td>0.202901</td>\n",
       "      <td>0.197673</td>\n",
       "      <td>0.172608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.082500</td>\n",
       "      <td>1.010816</td>\n",
       "      <td>0.705775</td>\n",
       "      <td>0.295062</td>\n",
       "      <td>0.315894</td>\n",
       "      <td>0.290770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.756300</td>\n",
       "      <td>0.858956</td>\n",
       "      <td>0.732356</td>\n",
       "      <td>0.430171</td>\n",
       "      <td>0.371395</td>\n",
       "      <td>0.359406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.588300</td>\n",
       "      <td>0.778024</td>\n",
       "      <td>0.743355</td>\n",
       "      <td>0.436063</td>\n",
       "      <td>0.402083</td>\n",
       "      <td>0.391438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.486100</td>\n",
       "      <td>0.734973</td>\n",
       "      <td>0.756187</td>\n",
       "      <td>0.448253</td>\n",
       "      <td>0.429689</td>\n",
       "      <td>0.418087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.420200</td>\n",
       "      <td>0.707767</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.494127</td>\n",
       "      <td>0.456463</td>\n",
       "      <td>0.455369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.373400</td>\n",
       "      <td>0.689448</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.476383</td>\n",
       "      <td>0.455588</td>\n",
       "      <td>0.450042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.679557</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.473426</td>\n",
       "      <td>0.457292</td>\n",
       "      <td>0.451839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.326600</td>\n",
       "      <td>0.676093</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.505999</td>\n",
       "      <td>0.469333</td>\n",
       "      <td>0.466900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.316400</td>\n",
       "      <td>0.672138</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.517882</td>\n",
       "      <td>0.477052</td>\n",
       "      <td>0.478183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5250, training_loss=0.6510405128115699, metrics={'train_runtime': 366.2537, 'train_samples_per_second': 1831.517, 'train_steps_per_second': 14.334, 'total_flos': 506837429280000.0, 'train_loss': 0.6510405128115699, 'epoch': 10.0})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-1): 2 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=128, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6992137432098389,\n",
       " 'eval_accuracy': 0.742,\n",
       " 'eval_precision': 0.4123024488061562,\n",
       " 'eval_recall': 0.48892849367182883,\n",
       " 'eval_f1': 0.4244696974848007,\n",
       " 'eval_runtime': 3.8399,\n",
       " 'eval_samples_per_second': 130.213,\n",
       " 'eval_steps_per_second': 1.042,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student_model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bert-distil-aug_fine.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 16.763MB.\n",
      "Total Trainable Params: 4392370.\n",
      "Average Inference Time on GPU: 2.739 ms\n",
      "Average Inference Time on CPU: 8.063 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch.utils.data import  DataLoader\n",
    "\n",
    "base.count_parameters(model)\n",
    "torch.cuda.synchronize() \n",
    "starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "device = \"cuda\"\n",
    "model.to(device)\n",
    "\n",
    "train.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"], device=\"cuda\")\n",
    "test_loader = DataLoader(train, batch_size=1, shuffle=False)\n",
    "\n",
    "timings = []\n",
    "\n",
    "\n",
    "\n",
    "for i, batch in enumerate(test_loader):\n",
    "    if i >= 1000:\n",
    "        break\n",
    "    torch.cuda.synchronize()\n",
    "    starter.record()\n",
    "    with torch.no_grad():\n",
    "        _ = model(**batch)\n",
    "    ender.record()\n",
    "    torch.cuda.synchronize()\n",
    "    timings.append(starter.elapsed_time(ender))\n",
    "\n",
    "print(f\"Average Inference Time on GPU: {sum(timings) / len(timings):.3f} ms\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "timings = []\n",
    "device = \"cpu\"\n",
    "model.to(device)\n",
    "train.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"], device=\"cpu\")\n",
    "test_loader = DataLoader(train, batch_size=1, shuffle=False)\n",
    "for i, batch in enumerate(test_loader):\n",
    "    if i >= 1000:\n",
    "        break\n",
    "    start_time = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        _ = model(**batch)\n",
    "    end_time = time.perf_counter()\n",
    "    timings.append((end_time - start_time)*1000)\n",
    "\n",
    "\n",
    "print(f\"Average Inference Time on CPU: {sum(timings) / len(timings):.3f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
