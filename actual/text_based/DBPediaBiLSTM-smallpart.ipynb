{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets, load_from_disk\n",
    "from transformers import BasicTokenizer, EarlyStoppingCallback, Trainer\n",
    "import kagglehub\n",
    "import torch\n",
    "import base\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.cache/kagglehub/datasets/thanakomsn/glove6b300dtxt/versions/1\n"
     ]
    }
   ],
   "source": [
    "#my_glove = kagglehub.dataset_download(\"takuok/glove840b300dtxt\")\n",
    "my_glove = kagglehub.dataset_download(\"thanakomsn/glove6b300dtxt\")\n",
    "print(my_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GLOVE_FILE = f\"{my_glove}/glove.840B.300d.txt\"\n",
    "GLOVE_FILE = f\"{my_glove}/glove.6B.300d.txt\"\n",
    "DATASET = \"dbpedia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_from_disk(f\"~/data/{DATASET}/train-logits\")\n",
    "eval_data = load_from_disk(f\"~/data/{DATASET}/eval-logits\")\n",
    "test_data = load_from_disk(f\"~/data/{DATASET}/test-logits\")\n",
    "\n",
    "data = train_data.train_test_split(test_size=0.1, seed=42, stratify_by_column=\"labels\")\n",
    "train_data = data[\"test\"]\n",
    "\n",
    "all_train_data = load_from_disk(f\"~/data/{DATASET}/train-logits-augmented\")\n",
    "data = all_train_data.train_test_split(test_size=0.1, seed=42, stratify_by_column=\"labels\")\n",
    "all_train_data = data[\"test\"]\n",
    "\n",
    "\n",
    "all_data = concatenate_datasets([load_from_disk(file) for file in [f\"~/data/{DATASET}/eval-logits\", f\"~/data/{DATASET}/test-logits\", f\"~/data/{DATASET}/train-logits-augmented\"]])\n",
    "tokenizer = BasicTokenizer(do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and will be used: NVIDIA A100 80GB PCIe MIG 2g.20gb\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and will be used:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m test_data_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m e: tokenizer\u001b[38;5;241m.\u001b[39mtokenize(e[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m\"\u001b[39m]), test_data))\n\u001b[1;32m      5\u001b[0m all_train_data_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m e: tokenizer\u001b[38;5;241m.\u001b[39mtokenize(e[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m\"\u001b[39m]), all_train_data))\n\u001b[0;32m----> 6\u001b[0m all_data_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msentence\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m      3\u001b[0m test_data_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m e: tokenizer\u001b[38;5;241m.\u001b[39mtokenize(e[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m\"\u001b[39m]), test_data))\n\u001b[1;32m      5\u001b[0m all_train_data_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m e: tokenizer\u001b[38;5;241m.\u001b[39mtokenize(e[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m\"\u001b[39m]), all_train_data))\n\u001b[0;32m----> 6\u001b[0m all_data_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m e: \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msentence\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, all_data))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/tokenization_bert.py:361\u001b[0m, in \u001b[0;36mBasicTokenizer.tokenize\u001b[0;34m(self, text, never_split)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrip_accents:\n\u001b[1;32m    360\u001b[0m             token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_strip_accents(token)\n\u001b[0;32m--> 361\u001b[0m     split_tokens\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_split_on_punc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnever_split\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    363\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m whitespace_tokenize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(split_tokens))\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_tokens\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data_tokens = list(map(lambda e: tokenizer.tokenize(e[\"sentence\"]), train_data))\n",
    "eval_data_tokens = list(map(lambda e: tokenizer.tokenize(e[\"sentence\"]), eval_data))\n",
    "test_data_tokens = list(map(lambda e: tokenizer.tokenize(e[\"sentence\"]), test_data))\n",
    "\n",
    "all_train_data_tokens = list(map(lambda e: tokenizer.tokenize(e[\"sentence\"]), all_train_data))\n",
    "all_data_tokens = list(map(lambda e: tokenizer.tokenize(e[\"sentence\"]), all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = base.get_vocab(all_data_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = dict(zip(vocab, range(len(vocab))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = base.get_embeddings_indeces(GLOVE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691158\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))\n",
    "num_tokens = len(vocab) + 2\n",
    "embedding_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 212978 words (478180) misses\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = base.get_embedding_matrix(num_tokens, embedding_dim, word_index, embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_index = list(map(lambda x: list(map(lambda y: word_index[y], x)),train_data_tokens))\n",
    "eval_data_index = list(map(lambda x: list(map(lambda y: word_index[y], x)),eval_data_tokens))\n",
    "test_data_index = list(map(lambda x: list(map(lambda y: word_index[y], x)),test_data_tokens))\n",
    "\n",
    "all_train_data_index = list(map(lambda x: list(map(lambda y: word_index[y], x)),all_train_data_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded_data = list(map(lambda x: base.padd(x,300), train_data_index))\n",
    "eval_padded_data = list(map(lambda x: base.padd(x,300), eval_data_index))\n",
    "test_padded_data = list(map(lambda x: base.padd(x,300), test_data_index))\n",
    "\n",
    "all_train_padded_data = list(map(lambda x: base.padd(x,300), all_train_data_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c67dbe42542e46d1b631a623cf0ae7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/44800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4a320fcb3d4d799024edf267fa09a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/87929 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = train_data.add_column(\"input_ids\", train_padded_data)\n",
    "eval_data = eval_data.add_column(\"input_ids\", eval_padded_data)\n",
    "test_data = test_data.add_column(\"input_ids\", test_padded_data)\n",
    "\n",
    "all_train_data = all_train_data.add_column(\"input_ids\", all_train_padded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = base.BiLSTMClassifier(embedding_matrix=embedding_matrix, embedding_dim=embedding_dim, fc_dim=400, hidden_dim=300, output_dim=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTMClassifier(\n",
      "  (embedding): Embedding(691160, 300)\n",
      "  (lstm): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
      "  (fc1): Linear(in_features=600, out_features=400, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc2): Linear(in_features=400, out_features=14, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bilstm-base-small\", logging_dir=f\"~/logs/{DATASET}/bilstm-base-small\", lr=.0001,  epochs=3, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2100' max='2100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2100/2100 02:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.751100</td>\n",
       "      <td>0.209696</td>\n",
       "      <td>0.939705</td>\n",
       "      <td>0.941527</td>\n",
       "      <td>0.939705</td>\n",
       "      <td>0.939795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.146500</td>\n",
       "      <td>0.112080</td>\n",
       "      <td>0.968179</td>\n",
       "      <td>0.968280</td>\n",
       "      <td>0.968179</td>\n",
       "      <td>0.968173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.098086</td>\n",
       "      <td>0.972473</td>\n",
       "      <td>0.972450</td>\n",
       "      <td>0.972473</td>\n",
       "      <td>0.972445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2100, training_loss=0.33268421718052454, metrics={'train_runtime': 133.3024, 'train_samples_per_second': 2016.468, 'train_steps_per_second': 15.754, 'total_flos': 0.0, 'train_loss': 0.33268421718052454, 'epoch': 3.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMClassifier(\n",
       "  (embedding): Embedding(691160, 300)\n",
       "  (lstm): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=600, out_features=400, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=400, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='547' max='547' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [547/547 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.0990210622549057,\n",
       " 'eval_accuracy': 0.9717142857142858,\n",
       " 'eval_precision': 0.9716920080249002,\n",
       " 'eval_recall': 0.9717142857142858,\n",
       " 'eval_f1': 0.9716787672081507,\n",
       " 'eval_runtime': 11.9081,\n",
       " 'eval_samples_per_second': 5878.362,\n",
       " 'eval_steps_per_second': 45.935,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bilstm-base-small.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = base.BiLSTMClassifier(embedding_matrix=embedding_matrix, embedding_dim=embedding_dim, fc_dim=400, hidden_dim=300, output_dim=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bilstm-distill-small\", remove_unused_columns=False, logging_dir=f\"~/logs/{DATASET}/bilstm-distill-small\", lr=.0001,  epochs=3, batch_size=128, lambda_param=.75, temp=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainer(\n",
    "    student_model=student_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1050' max='1050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1050/1050 01:46, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.415400</td>\n",
       "      <td>3.341083</td>\n",
       "      <td>0.786312</td>\n",
       "      <td>0.802289</td>\n",
       "      <td>0.786313</td>\n",
       "      <td>0.776738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.613000</td>\n",
       "      <td>1.986502</td>\n",
       "      <td>0.877768</td>\n",
       "      <td>0.880041</td>\n",
       "      <td>0.877768</td>\n",
       "      <td>0.875281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.765000</td>\n",
       "      <td>1.592329</td>\n",
       "      <td>0.895339</td>\n",
       "      <td>0.898132</td>\n",
       "      <td>0.895339</td>\n",
       "      <td>0.893522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1050, training_loss=3.2644549851190474, metrics={'train_runtime': 109.1124, 'train_samples_per_second': 1231.757, 'train_steps_per_second': 9.623, 'total_flos': 0.0, 'train_loss': 3.2644549851190474, 'epoch': 3.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMClassifier(\n",
       "  (embedding): Embedding(691160, 300)\n",
       "  (lstm): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=600, out_features=400, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=400, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='547' max='547' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [547/547 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.5967628955841064,\n",
       " 'eval_accuracy': 0.8956428571428572,\n",
       " 'eval_precision': 0.8982861081068234,\n",
       " 'eval_recall': 0.8956428571428571,\n",
       " 'eval_f1': 0.8939248319125565,\n",
       " 'eval_runtime': 12.5712,\n",
       " 'eval_samples_per_second': 5568.281,\n",
       " 'eval_steps_per_second': 43.512,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student_model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bilstm-distill-small.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = base.BiLSTMClassifier(embedding_matrix=embedding_matrix, embedding_dim=embedding_dim, fc_dim=400, hidden_dim=300, output_dim=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bilstm-base-aug-small\", logging_dir=f\"~/logs/{DATASET}/bilstm-base-aug-small\", lr=.0001,  epochs=3, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=all_train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20610' max='20610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20610/20610 23:39, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.060120</td>\n",
       "      <td>0.983232</td>\n",
       "      <td>0.983234</td>\n",
       "      <td>0.983232</td>\n",
       "      <td>0.983224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.076100</td>\n",
       "      <td>0.050490</td>\n",
       "      <td>0.985821</td>\n",
       "      <td>0.985832</td>\n",
       "      <td>0.985821</td>\n",
       "      <td>0.985816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.062100</td>\n",
       "      <td>0.047384</td>\n",
       "      <td>0.986777</td>\n",
       "      <td>0.986779</td>\n",
       "      <td>0.986777</td>\n",
       "      <td>0.986777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20610, training_loss=0.11540887454133308, metrics={'train_runtime': 1423.2056, 'train_samples_per_second': 1853.458, 'train_steps_per_second': 14.481, 'total_flos': 0.0, 'train_loss': 0.11540887454133308, 'epoch': 3.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMClassifier(\n",
       "  (embedding): Embedding(691160, 300)\n",
       "  (lstm): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=600, out_features=400, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=400, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='547' max='547' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [547/547 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.046175818890333176,\n",
       " 'eval_accuracy': 0.9867428571428571,\n",
       " 'eval_precision': 0.9867385036592475,\n",
       " 'eval_recall': 0.9867428571428573,\n",
       " 'eval_f1': 0.9867395869986717,\n",
       " 'eval_runtime': 21.7972,\n",
       " 'eval_samples_per_second': 3211.424,\n",
       " 'eval_steps_per_second': 25.095,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bilstm-base-aug-small.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = base.BiLSTMClassifier(embedding_matrix=embedding_matrix, embedding_dim=embedding_dim, fc_dim=400, hidden_dim=300, output_dim=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bilstm-distill-aug-small\", remove_unused_columns=False, logging_dir=f\"~/logs/{DATASET}/bilstm-distill-aug-small\", lr=.0001,  epochs=3, batch_size=128, lambda_param=.75, temp=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainer(\n",
    "    student_model=student_model,\n",
    "    args=training_args,\n",
    "    train_dataset=all_train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20610' max='20610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20610/20610 25:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.871700</td>\n",
       "      <td>0.168142</td>\n",
       "      <td>0.980518</td>\n",
       "      <td>0.980552</td>\n",
       "      <td>0.980518</td>\n",
       "      <td>0.980480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.241700</td>\n",
       "      <td>0.123618</td>\n",
       "      <td>0.983929</td>\n",
       "      <td>0.983950</td>\n",
       "      <td>0.983929</td>\n",
       "      <td>0.983908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.198400</td>\n",
       "      <td>0.107652</td>\n",
       "      <td>0.985446</td>\n",
       "      <td>0.985431</td>\n",
       "      <td>0.985446</td>\n",
       "      <td>0.985435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20610, training_loss=0.4372475081309134, metrics={'train_runtime': 1513.0336, 'train_samples_per_second': 1743.419, 'train_steps_per_second': 13.622, 'total_flos': 0.0, 'train_loss': 0.4372475081309134, 'epoch': 3.0})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMClassifier(\n",
       "  (embedding): Embedding(691160, 300)\n",
       "  (lstm): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=600, out_features=400, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=400, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='547' max='547' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [547/547 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.10681172460317612,\n",
       " 'eval_accuracy': 0.9854285714285714,\n",
       " 'eval_precision': 0.9854093760634609,\n",
       " 'eval_recall': 0.9854285714285714,\n",
       " 'eval_f1': 0.9854123976057806,\n",
       " 'eval_runtime': 23.2612,\n",
       " 'eval_samples_per_second': 3009.306,\n",
       " 'eval_steps_per_second': 23.516,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bilstm-distill-aug-small.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
