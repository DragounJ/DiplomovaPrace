{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Předzpracování datasetu SST2\n",
    "\n",
    "Tento notebook slouží k předzpracování datasetu SST2. Pro dataset jsou vytvořeny augmentované záznamy a předpočítány logity.\n",
    "Nejprve jsou načteny všechny potřebné knihovny včetně vlastní sbírky objektů a funkcí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk, Dataset, concatenate_datasets, ClassLabel, Features, Value, Sequence\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BasicTokenizer\n",
    "from torch.utils.data import  DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import copy\n",
    "import base\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ověření, že GPU je k dispozici a balíček torch je správně nakonfigurován."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and will be used: NVIDIA A100 80GB PCIe MIG 2g.20gb\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and will be used:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konfigurace augmentačních parametrů.\n",
    "Dataset se bude procházet pětkrát, každý token v záznamu bude na deset procent zamaskován a na třicet procent nahrazen jiným tokenem se stejným POS tagem. Po průchodu všech tokenů v záznamu může dojít s pravděpodobností dvacet procent ke zkrácení záznamu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_params = {\"n_iter\": 5, \"p_mask\":0.1, \"p_pos\": 0.3, \"p_ng\":0.2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Získání datasetu, základního tokenizeru a jeho použití nad datasetem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BasicTokenizer(do_lower_case=True)\n",
    "DATASET = \"sst2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_from_disk(f\"~/data/{DATASET}/train\")\n",
    "sentences = list(map(lambda e: e[\"sentence\"], train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Získání POS tagů jednotlivých tokenů v záznamech pro potřeby augmentace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag_word_map_list = base.get_pos_tag_word_map(sentences, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spuštění procesu augmentace s popsanými parametry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_datasets = base.get_augmented_dataset(augmentation_params, train_data, pos_tag_word_map_list, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Převedení nových záznamů do dataset objektu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c649e9b34e194f11a9d0387f13b56e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/53879 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb5a010708954b9abc3a7b1be9385fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/53879 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f9254568d3f444fa66cd8da989f44e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/53879 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8a1784f34c474b8248b3ed67562ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/53879 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13100e3b0b7c44af9f9e9c0bcb945899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/53879 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aug_datasets_formated = []\n",
    "ds_schema = Features({\n",
    "    \"idx\": Value(\"int32\"),\n",
    "    \"sentence\": Value(\"string\"),\n",
    "    \"label\": ClassLabel(names=[\"negative\", \"positive\"])\n",
    "})\n",
    "\n",
    "for iter in augmented_datasets:\n",
    "    dataset = Dataset.from_dict(iter)\n",
    "    dataset = dataset.cast(ds_schema)\n",
    "    aug_datasets_formated.append(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ověření efektu augmentace, zde např. zamaskované slovo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'idx': 6575, 'sentence': \"in reality it ' s [MASK] tough rock .\", 'label': 1}\n",
      "{'idx': 6575, 'sentence': \"in reality it 's one tough rock . \", 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "print(aug_datasets_formated[4][70])\n",
    "print(train_data[70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Načtení učitelského modelu a jeho tokenizeru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03fd5269f2eb41cab4344397111f256b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/879 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e94116df344187960a312dfce98e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "721f4360551143ed895be135fbb609bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"gchhablani/bert-base-cased-finetuned-sst2\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"gchhablani/bert-base-cased-finetuned-sst2\", num_labels=2)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "torch.save(model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/teacher.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Předzpracování trénovací části datasetu a výpočet logitů učitelským modelem. Vypočtené logity se přidávají jako nový sloupec datasetu, naopak se odstraňují záznamy ponechané po tokenizeru učitele, které dále nejsou třeba. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de43e4836d9a4d059a4065a75df04530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the provided dataset:   0%|          | 0/53879 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142621b2a47a4b60a424315f6ea4021c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating logits for given dataset:   0%|          | 0/421 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = base.prepare_dataset(train_data, tokenizer)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=False)\n",
    "train_logits = base.generate_logits(train_dataloader, model)\n",
    "train_dataset = train_dataset.add_column(\"logits\", train_logits)\n",
    "train_dataset = train_dataset.remove_columns([\"token_type_ids\", \"attention_mask\"])\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"logits\", \"labels\"], device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Výpočet správnosti učitelských predikcí nad trénovací částí datasetu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6226609e3d744a9ac64f8736c2a15b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating accuracy based on the saved logits:   0%|          | 0/53879 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for base dataset:  0.9888268156424581\n"
     ]
    }
   ],
   "source": [
    "print(base.check_acc(train_dataset, \"Accuracy for base dataset: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stejné kroky pro výpočet logitů jsou provedeny nad každou z pěti augmentovaných variant datasetu. Postupně je skrze záznamy iterováno. Dataset je nejprve tokenizován a následně je předán učitely k inferenci pro získání logitů, které jsou k datasetu uloženy. Odstraněny jsou poté nepotřebné pozůstatky tokenizace. V rámci průběhu zpracování rovnou dochází k filtraci augmentovaných záznamů dle popsaného mechanismu (notebook precompute_logits_10.ipynb).\n",
    "\n",
    "Takto zpracované datasety se postupně spojují do jednoho celku. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc789687a274335b8817cd29687a2e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing augmented datasets:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baeb34a246024056a8f35ff82b15167c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the provided dataset:   0%|          | 0/53879 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c500a40a6c4fa98c25a877dca9349c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating logits for given dataset:   0%|          | 0/421 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561778954e274d00898778d2d5326ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Removing entries from augmented dataset that are different from the base one - based on saved logits:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0013d5588f18405490caf9c6d5b99de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the provided dataset:   0%|          | 0/53879 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fef4c14c06e42538d781f8117de7fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating logits for given dataset:   0%|          | 0/421 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79de602dff242ee934ded623fefe7fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Removing entries from augmented dataset that are different from the base one - based on saved logits:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614b719699fe47249be5d3563ed48747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the provided dataset:   0%|          | 0/53879 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c74dc53b9c404abfc273ecfe4efa24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating logits for given dataset:   0%|          | 0/421 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64cc16a603b24b1c91b6c6e7bb1138f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Removing entries from augmented dataset that are different from the base one - based on saved logits:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a7523d17a843188b23f1649d2b44ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the provided dataset:   0%|          | 0/53879 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6f04e46f914cb092a440e2690367c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating logits for given dataset:   0%|          | 0/421 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba951b8f43714a74aa7e8126f0931de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Removing entries from augmented dataset that are different from the base one - based on saved logits:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf5458e66cd44c7bf3a132afe916d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the provided dataset:   0%|          | 0/53879 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b54bd8dce144f9888a38c09d5a5ab2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating logits for given dataset:   0%|          | 0/421 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "062c59103bb143dcbfa5f91edca7f084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Removing entries from augmented dataset that are different from the base one - based on saved logits:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aug_clean_datasets = []\n",
    "for dataset in tqdm(aug_datasets_formated, total=(len(aug_datasets_formated)), desc=\"Processing augmented datasets: \"):\n",
    "    aug_train_dataset = base.prepare_dataset(dataset, tokenizer)\n",
    "    aug_train_dataloader = DataLoader(aug_train_dataset, batch_size=128, shuffle=False)\n",
    "    aug_train_logits = base.generate_logits(aug_train_dataloader, model)\n",
    "    aug_train_dataset = aug_train_dataset.add_column(\"logits\", aug_train_logits)\n",
    "    aug_train_dataset = aug_train_dataset.remove_columns([\"token_type_ids\", \"attention_mask\"])\n",
    "    aug_train_dataset.set_format(type=\"torch\", columns=[\"logits\", \"labels\"], device=\"cpu\")\n",
    "\n",
    "    aug_train_dataset = base.remove_diff_pred_class(train_dataset, aug_train_dataset, pytorch_dataset=False)\n",
    "    \n",
    "    aug_train_dataset.reset_format()\n",
    "    aug_clean_datasets.extend(aug_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.reset_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ověření, že augmentované věty mají lehce posunutý význam (logity nejsou totožné)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First iter check\n",
      "{'idx': 20217, 'sentence': 'will be literally worth your time .', 'labels': 1, 'input_ids': [101, 1209, 1129, 6290, 3869, 1240, 1159, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'logits': [-4.896175384521484, 4.807943344116211]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89035948cba44f4b7fee6fa99e64b67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/53879 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'idx': 20217, 'sentence': 'will be well worth your time . ', 'labels': 1, 'input_ids': [101, 1209, 1129, 1218, 3869, 1240, 1159, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'logits': [-4.851616859436035, 4.748195171356201]}\n",
      "Second iter check\n",
      "{'idx': 30561, 'sentence': 'mr . man and [MASK] . [MASK] [MASK] strong and elysian performances , but', 'labels': 1, 'input_ids': [101, 182, 1197, 119, 1299, 1105, 103, 119, 103, 103, 2012, 1105, 8468, 6834, 1811, 3853, 117, 1133, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'logits': [-3.758352041244507, 3.7316389083862305]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "838123218d5a43ea844743388451ec13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/53879 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'idx': 30561, 'sentence': 'mr. wollter and ms. seldhal give strong and convincing performances , but ', 'labels': 1, 'input_ids': [101, 182, 1197, 119, 192, 12666, 2083, 1105, 182, 1116, 119, 14516, 5253, 7654, 1660, 2012, 1105, 13870, 3853, 117, 1133, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'logits': [-4.357180595397949, 4.360624313354492]}\n"
     ]
    }
   ],
   "source": [
    "print(\"First iter check\")\n",
    "print(aug_clean_datasets[1997])\n",
    "filtered_base = train_dataset.filter(lambda x: x[\"idx\"] == aug_clean_datasets[1997][\"idx\"])\n",
    "print(filtered_base[0])\n",
    "\n",
    "print(\"Second iter check\")\n",
    "print(aug_clean_datasets[66699])\n",
    "filtered_base = train_dataset.filter(lambda x: x[\"idx\"] == aug_clean_datasets[66699][\"idx\"])\n",
    "print(filtered_base[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'idx': Value(dtype='int32', id=None), 'sentence': Value(dtype='string', id=None), 'labels': ClassLabel(names=['negative', 'positive'], id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'logits': Sequence(feature=Value(dtype='float32', id=None), length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Převedení spojeného a zpracovaného augmentovaného datasetu do dataset objektu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35df17e9e71a49589dbe62a2832f48b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/239757 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_schema = Features({\n",
    "    \"idx\": Value(\"int32\"),\n",
    "    \"sentence\": Value(\"string\"),\n",
    "    \"labels\": ClassLabel(names=[\"negative\", \"positive\"]),\n",
    "    \"input_ids\": Sequence(feature=Value(dtype=\"int32\")),\n",
    "    \"logits\": Sequence(feature=Value(dtype=\"float32\")),\n",
    "})\n",
    "\n",
    "aug_dataset = Dataset.from_list(aug_clean_datasets)\n",
    "aug_dataset = aug_dataset.cast(ds_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_dataset.set_format(type=\"torch\", columns=[\"logits\", \"labels\"], device=\"cpu\")\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"logits\", \"labels\"], device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Výpočet správnosti nad zpracovanými datasety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d95deb4354740b189240f70fddd4b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating accuracy based on the saved logits:   0%|          | 0/53879 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for base dataset:  0.9888268156424581\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948df7400e514e5b89b3489b6ebdfa9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating accuracy based on the saved logits:   0%|          | 0/239757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for augmented dataset:  0.9903151941340608\n"
     ]
    }
   ],
   "source": [
    "print(base.check_acc(train_dataset, \"Accuracy for base dataset: \"))\n",
    "print(base.check_acc(aug_dataset, \"Accuracy for augmented dataset: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spojení původního a augmentovaného datasetu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_data = concatenate_datasets([train_dataset, aug_dataset])\n",
    "train_all_data.set_format(type=\"torch\", columns=[\"logits\", \"labels\"], device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Získání správnosti nad touto kombinací."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34d66d352674fb99518d5056e0ac740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating accuracy based on the saved logits:   0%|          | 0/293636 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for combined dataset:  0.9900420929313845\n"
     ]
    }
   ],
   "source": [
    "print(base.check_acc(train_all_data, \"Accuracy for combined dataset: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['idx', 'sentence', 'labels', 'input_ids', 'logits']\n"
     ]
    }
   ],
   "source": [
    "print(train_all_data.column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uložení zpracovaných datasetů na disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_data.reset_format()\n",
    "train_all_data = train_all_data.remove_columns([\"idx\", \"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18fd75a6d3f147c8b5ec821101d7c82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/293636 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_all_data.save_to_disk(f\"~/data/{DATASET}/train-logits-augmented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235cf1457bbb48d5982ffd980fac09ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/53879 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset.reset_format()\n",
    "train_dataset = train_dataset.remove_columns([\"idx\", \"input_ids\"])\n",
    "train_dataset.save_to_disk(f\"~/data/{DATASET}/train-logits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Načtení zbylých částí datasetu (validační, umělé testovací a původní testovací). Výpočet logitů je proveden pro každou z těchto částí stejným způsobem jako v příapdě trénovací části.\n",
    "\n",
    "Nejprve je část tokenizována učitelem a vložena do dataloaderu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269ecff175614e5180d70a9c92458196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the provided dataset:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_data = load_from_disk(f\"~/data/{DATASET}/eval\")\n",
    "eval_dataset = base.prepare_dataset(eval_data, tokenizer)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90fbebb9c9d7473f89ea9b1b39dfb592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the provided dataset:   0%|          | 0/13470 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data = load_from_disk(f\"~/data/{DATASET}/test\")\n",
    "test_dataset = base.prepare_dataset(test_data, tokenizer)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7835a2b78f254b50b7f5595c5657c11f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the provided dataset:   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_blank_data = load_from_disk(f\"~/data/{DATASET}/test-blank\")\n",
    "test_blank_dataset = base.prepare_dataset(test_blank_data, tokenizer)\n",
    "test_blank_dataloader = DataLoader(test_blank_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Následně jsou pro každou část spočteny logity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c5b1325f504807b5f53c0e780765b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating logits for given dataset:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54afdc2ddb564877a626b0bc2f999353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating logits for given dataset:   0%|          | 0/106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f3d6c552b04ccf890a02aa9f171748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating logits for given dataset:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_logits = base.generate_logits(eval_dataloader, model)\n",
    "test_logits = base.generate_logits(test_dataloader, model)\n",
    "test_blank_logits = base.generate_logits(test_blank_dataloader, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logity jsou přidány jako nový sloupec, odstraněny jsou již nepotřebné pozůstatky tokenizace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset.reset_format()\n",
    "eval_dataset = eval_dataset.add_column(\"logits\", eval_logits)\n",
    "eval_dataset = eval_dataset.remove_columns([\"idx\", \"token_type_ids\", \"input_ids\", \"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.reset_format()\n",
    "test_dataset = test_dataset.add_column(\"logits\", test_logits)\n",
    "test_dataset = test_dataset.remove_columns([\"idx\", \"token_type_ids\", \"input_ids\", \"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_blank_dataset.reset_format()\n",
    "test_blank_dataset = test_blank_dataset.add_column(\"logits\", test_blank_logits)\n",
    "test_blank_dataset = test_blank_dataset.remove_columns([\"idx\", \"token_type_ids\", \"input_ids\", \"attention_mask\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uložení dat na disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24860928857a4401a59f565c43da9426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb979e4083e4cd78d1129c8430591da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/13470 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de1bebb945545aa8d68d0a3c1d59583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_dataset.save_to_disk(f\"~/data/{DATASET}/eval-logits\")\n",
    "test_dataset.save_to_disk(f\"~/data/{DATASET}/test-logits\")\n",
    "test_blank_dataset.save_to_disk(f\"~/data/{DATASET}/test-blank-logits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vypočtení správnosti nad validační a umělou testovací částí datasetu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d000e9dad54d91acdd5e42b60008cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating accuracy based on the saved logits:   0%|          | 0/872 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for base eval dataset:  0.9231651376146789\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62cc4ab055c841a79688095974ab46e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating accuracy based on the saved logits:   0%|          | 0/13470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for base test dataset:  0.9896807720861173\n"
     ]
    }
   ],
   "source": [
    "eval_data = load_from_disk(f\"~/data/{DATASET}/eval-logits\")\n",
    "test_data = load_from_disk(f\"~/data/{DATASET}/test-logits\")\n",
    "\n",
    "eval_data.set_format(type=\"torch\", columns=[\"logits\", \"labels\"], device=\"cpu\")\n",
    "test_data.set_format(type=\"torch\", columns=[\"logits\", \"labels\"], device=\"cpu\")\n",
    "\n",
    "print(base.check_acc(eval_data, \"Accuracy for base eval dataset: \"))\n",
    "print(base.check_acc(test_data, \"Accuracy for base test dataset: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Výpočet výkonnostních metrik a velikosti u učitelského modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = base.prepare_dataset(train_data, tokenizer)\n",
    "\n",
    "train_data_gpu = copy.deepcopy(train_dataset)\n",
    "train_data_gpu.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"], device=\"cuda\")\n",
    "gpu_data_loader = DataLoader(train_data_gpu, batch_size=1, shuffle=False)\n",
    "\n",
    "train_data_cpu = copy.deepcopy(train_dataset)\n",
    "train_data_cpu.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"], device=\"cpu\")\n",
    "cpu_data_loader = DataLoader(train_data_cpu, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 413.185MB.\n",
      "Total Trainable Params: 108311810.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Modules</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert.embeddings.word_embeddings.weight</td>\n",
       "      <td>22268928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert.embeddings.position_embeddings.weight</td>\n",
       "      <td>393216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert.embeddings.token_type_embeddings.weight</td>\n",
       "      <td>1536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert.embeddings.LayerNorm.weight</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bert.embeddings.LayerNorm.bias</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>bert.encoder.layer.11.output.LayerNorm.bias</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>bert.pooler.dense.weight</td>\n",
       "      <td>589824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>bert.pooler.dense.bias</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>classifier.weight</td>\n",
       "      <td>1536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>classifier.bias</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Modules Parameters\n",
       "0          bert.embeddings.word_embeddings.weight   22268928\n",
       "1      bert.embeddings.position_embeddings.weight     393216\n",
       "2    bert.embeddings.token_type_embeddings.weight       1536\n",
       "3                bert.embeddings.LayerNorm.weight        768\n",
       "4                  bert.embeddings.LayerNorm.bias        768\n",
       "..                                            ...        ...\n",
       "196   bert.encoder.layer.11.output.LayerNorm.bias        768\n",
       "197                      bert.pooler.dense.weight     589824\n",
       "198                        bert.pooler.dense.bias        768\n",
       "199                             classifier.weight       1536\n",
       "200                               classifier.bias          2\n",
       "\n",
       "[201 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x79af91eeace0>\n",
      "self.infer_speed_comp()\n",
      "  50.36 ms\n",
      "  1 measurement, 1000 runs , 4 threads\n"
     ]
    }
   ],
   "source": [
    "cpu_benchmark = base.BenchMarkRunner(model, cpu_data_loader, \"cpu\", 1000)\n",
    "print(cpu_benchmark.run_benchmark())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x79b1100b7df0>\n",
      "self.infer_speed_comp()\n",
      "  6.02 ms\n",
      "  1 measurement, 1000 runs , 4 threads\n"
     ]
    }
   ],
   "source": [
    "gpu_benchmark = base.BenchMarkRunner(model, gpu_data_loader, \"cuda\", 1000)\n",
    "print(gpu_benchmark.run_benchmark())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.9895478534592006\n",
      "Accuracy: 0.9896807720861173\n",
      "Precision: 0.989232666017668\n",
      "Recall: 0.9898802736347267\n"
     ]
    }
   ],
   "source": [
    "base.get_scores(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
