{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk, Dataset, concatenate_datasets, ClassLabel, Features, Value, Sequence\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BasicTokenizer\n",
    "from torch.utils.data import  DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import base\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and will be used: NVIDIA A100 80GB PCIe MIG 2g.20gb\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and will be used:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_params = {\"n_iter\": 1, \"p_mask\":0.1, \"p_pos\": 0.3, \"p_ng\":0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BasicTokenizer(do_lower_case=True)\n",
    "DATASET = \"dbpedia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_from_disk(f\"~/data/{DATASET}/train\")\n",
    "sentences = list(map(lambda e: e[\"sentence\"], train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_lengths = [len(tokenizer.tokenize(sentence)) for sentence in sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_token_lengths = sorted(token_lengths, reverse=True)\n",
    "avg_tokens = np.mean(token_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1498, 1283, 1211, 989, 734, 655, 551, 516, 501, 433, 410, 394, 384, 364, 354, 338, 336, 331, 313, 311, 308, 307, 306, 301, 294]\n",
      "53.53230357142857\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "print(sorted_token_lengths[0:25])\n",
    "print(avg_tokens)\n",
    "print(sorted_token_lengths[-25:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag_word_map_list = base.get_pos_tag_word_map(sentences, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 8, 'sentence': ' Zarrin Darreh (Persian: زرين دره\\u200e also Romanized as Zarrīn Darreh) is a village in Chahriq Rural District Kuhsar District Salmas County West Azerbaijan Province Iran. At the 2006 census its population was 37 in 8 families.'}\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_datasets = base.get_augmented_dataset(augmentation_params, train_data, pos_tag_word_map_list, tokenizer=tokenizer, include_idx=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['label', 'sentence'])\n"
     ]
    }
   ],
   "source": [
    "print(augmented_datasets[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b430f61df56e4425abc380257556f2ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/448000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aug_datasets_formated = []\n",
    "ds_schema = Features({\n",
    "    \"sentence\": Value(\"string\"),\n",
    "    \"label\": ClassLabel(names=[\"Company\", \"EducationalInstitution\", \"Artist\", \"Athlete\", \"OfficeHolder\", \"MeanOfTransportation\", \"Building\", \"NaturalPlace\", \"Village\", \"Animal\", \"Plant\", \"Album\", \"Film\", \"WrittenWork\"])\n",
    "})\n",
    "\n",
    "for iter in augmented_datasets:\n",
    "    dataset = Dataset.from_dict(iter)\n",
    "    dataset = dataset.cast(ds_schema)\n",
    "    aug_datasets_formated.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': \"zarrin d ' alba : la : [MASK] is a zarrin as alba - zarrin - romaine ardeche in southeast france . the castle [MASK] [MASK] as a monument historique as 1939 by the french [MASK] of culture .\", 'label': 6}\n",
      "{'label': 6, 'sentence': \" Château d'Alba-la-Romaine is a château in Alba-la-Romaine Ardèche in southeast France.The castle is listed as a Monument historique since 1939 by the French Ministry of Culture.\"}\n"
     ]
    }
   ],
   "source": [
    "print(aug_datasets_formated[0][70])\n",
    "print(train_data[70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"fabriceyhc/bert-base-uncased-dbpedia_14\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"fabriceyhc/bert-base-uncased-dbpedia_14\", num_labels=14)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "torch.save(model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/teacher.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ce18baef87b4bea8c7554911179f4ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the provided dataset:   0%|          | 0/448000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e6dfdedd5f472599eb8bbcea8b8324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating logits for given dataset:   0%|          | 0/3500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = base.prepare_dataset(train_data, tokenizer)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=False)\n",
    "train_logits = base.generate_logits(train_dataloader, model)\n",
    "train_dataset = train_dataset.add_column(\"logits\", train_logits)\n",
    "train_dataset = train_dataset.remove_columns([\"token_type_ids\", \"attention_mask\", \"input_ids\"])\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"logits\", \"labels\"], device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2225f6b9e9a1457cbd52a44095c7c8b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating accuracy based on the saved logits:   0%|          | 0/448000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for base dataset:  0.9887633928571429\n"
     ]
    }
   ],
   "source": [
    "print(base.check_acc(train_dataset, \"Accuracy for base dataset: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc6c42281964b20a00ff223ab45e6a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing augmented datasets:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b5dd04bf294ce6b0f0dd61d9e772ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the provided dataset:   0%|          | 0/448000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ddc2aae86de41d589d78dc65307828b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating logits for given dataset:   0%|          | 0/3500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4f6e35e1664d06be882d9d0fe54bc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating accuracy based on the saved logits:   0%|          | 0/448000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for augmented dataset:  0.9572946428571428\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e3b2a3bce3947b5b1d68182349c1f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Removing entries from augmented dataset that are different from the base one - based on saved logits:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b881cf93ec59434fb663a654ed0bcdb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating accuracy based on the saved logits:   0%|          | 0/431575 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for filtered dataset:  0.9915008978740659\n"
     ]
    }
   ],
   "source": [
    "aug_clean_datasets = []\n",
    "for dataset in tqdm(aug_datasets_formated, total=(len(aug_datasets_formated)), desc=\"Processing augmented datasets: \"):\n",
    "    aug_train_dataset = base.prepare_dataset(dataset, tokenizer)\n",
    "    aug_train_dataloader = DataLoader(aug_train_dataset, batch_size=128, shuffle=False)\n",
    "    aug_train_logits = base.generate_logits(aug_train_dataloader, model)\n",
    "    aug_train_dataset = aug_train_dataset.add_column(\"logits\", aug_train_logits)\n",
    "    aug_train_dataset = aug_train_dataset.remove_columns([\"token_type_ids\", \"attention_mask\", \"input_ids\"])\n",
    "    aug_train_dataset.set_format(type=\"torch\", columns=[\"logits\", \"labels\"], device=\"cpu\")\n",
    "\n",
    "    print(base.check_acc(aug_train_dataset, \"Accuracy for augmented dataset: \"))\n",
    "\n",
    "    aug_train_dataset = base.remove_diff_pred_class(train_dataset, aug_train_dataset, pytorch_dataset=False)\n",
    "    \n",
    "    print(base.check_acc(aug_train_dataset, \"Accuracy for filtered dataset: \"))\n",
    "\n",
    "    aug_train_dataset.reset_format()\n",
    "    aug_clean_datasets.extend(aug_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': ClassLabel(names=['Company', 'EducationalInstitution', 'Artist', 'Athlete', 'OfficeHolder', 'MeanOfTransportation', 'Building', 'NaturalPlace', 'Village', 'Animal', 'Plant', 'Album', 'Film', 'WrittenWork'], id=None), 'sentence': Value(dtype='string', id=None), 'logits': Sequence(feature=Value(dtype='float32', id=None), length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7526a5714c6247a9ad08f3ee96a24ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/431575 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_schema = Features({\n",
    "    \"sentence\": Value(\"string\"),\n",
    "    \"labels\": ClassLabel(names=[\"Company\", \"EducationalInstitution\", \"Artist\", \"Athlete\", \"OfficeHolder\", \"MeanOfTransportation\", \"Building\", \"NaturalPlace\", \"Village\", \"Animal\", \"Plant\", \"Album\", \"Film\", \"WrittenWork\"]),\n",
    "    \"logits\": Sequence(feature=Value(dtype=\"float32\")),\n",
    "})\n",
    "\n",
    "aug_dataset = Dataset.from_list(aug_clean_datasets)\n",
    "aug_dataset = aug_dataset.cast(ds_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_dataset.set_format(type=\"torch\", columns=[\"logits\", \"labels\"], device=\"cpu\")\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"logits\", \"labels\"], device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351fdbfea5274112824ed58ffded3d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating accuracy based on the saved logits:   0%|          | 0/448000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for base dataset:  0.9887633928571429\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ffb1b37bf8f4742acf2e9019e44eea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating accuracy based on the saved logits:   0%|          | 0/431575 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for augmented dataset:  0.9915008978740659\n"
     ]
    }
   ],
   "source": [
    "print(base.check_acc(train_dataset, \"Accuracy for base dataset: \"))\n",
    "print(base.check_acc(aug_dataset, \"Accuracy for augmented dataset: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_data = concatenate_datasets([train_dataset, aug_dataset])\n",
    "train_all_data.set_format(type=\"torch\", columns=[\"logits\", \"labels\"], device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998b834d66624265a287354f0cdda238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating accuracy based on the saved logits:   0%|          | 0/879575 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for combined dataset:  0.9901065855668931\n"
     ]
    }
   ],
   "source": [
    "print(base.check_acc(train_all_data, \"Accuracy for combined dataset: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['labels', 'sentence', 'logits']\n"
     ]
    }
   ],
   "source": [
    "print(train_all_data.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_data.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b464758a9db14e04b4e95aab5e50349b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/879575 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_all_data.save_to_disk(f\"~/data/{DATASET}/train-logits-augmented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8cbc21a8d164f2c9f6f1248c8d8612e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/448000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset.reset_format()\n",
    "train_dataset.save_to_disk(f\"~/data/{DATASET}/train-logits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b15cbbf6ba4c1680d450504331dfa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the provided dataset:   0%|          | 0/112000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_data = load_from_disk(f\"~/data/{DATASET}/eval\")\n",
    "\n",
    "eval_dataset = base.prepare_dataset(eval_data, tokenizer)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe59beb59c14c3d9319baf4c45c3047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the provided dataset:   0%|          | 0/70000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data = load_from_disk(f\"~/data/{DATASET}/test\")\n",
    "\n",
    "test_dataset = base.prepare_dataset(test_data, tokenizer)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a488f404344896a5f0fff73d6a3c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating logits for given dataset:   0%|          | 0/875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c951db43a6524f12a9a8d6394bb77d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating logits for given dataset:   0%|          | 0/547 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_logits = base.generate_logits(eval_dataloader, model)\n",
    "test_logits = base.generate_logits(test_dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset.reset_format()\n",
    "eval_dataset = eval_dataset.add_column(\"logits\", eval_logits)\n",
    "eval_dataset = eval_dataset.remove_columns([\"token_type_ids\", \"input_ids\", \"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.reset_format()\n",
    "test_dataset = test_dataset.add_column(\"logits\", test_logits)\n",
    "test_dataset = test_dataset.remove_columns([\"token_type_ids\", \"input_ids\", \"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f088cd6032540ceba4c20b327b29494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/112000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd21ad3606e4c5ca1bf07e11fda085d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/70000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_dataset.save_to_disk(f\"~/data/{DATASET}/eval-logits\")\n",
    "test_dataset.save_to_disk(f\"~/data/{DATASET}/test-logits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e23b2d94c1614483ba9e0679aa6bb0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating accuracy based on the saved logits:   0%|          | 0/112000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for base eval dataset:  0.9881785714285715\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f9e676dfda14a4ba8c1dbd6b93417f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating accuracy based on the saved logits:   0%|          | 0/70000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for base test dataset:  0.9883285714285714\n"
     ]
    }
   ],
   "source": [
    "eval_data = load_from_disk(f\"~/data/{DATASET}/eval-logits\")\n",
    "test_data = load_from_disk(f\"~/data/{DATASET}/test-logits\")\n",
    "\n",
    "eval_data.set_format(type=\"torch\", columns=[\"logits\", \"labels\"], device=\"cpu\")\n",
    "test_data.set_format(type=\"torch\", columns=[\"logits\", \"labels\"], device=\"cpu\")\n",
    "\n",
    "print(base.check_acc(eval_data, \"Accuracy for base eval dataset: \"))\n",
    "print(base.check_acc(test_data, \"Accuracy for base test dataset: \"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
