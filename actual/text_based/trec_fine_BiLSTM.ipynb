{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets, load_from_disk\n",
    "from transformers import BasicTokenizer, EarlyStoppingCallback, Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "import kagglehub\n",
    "import torch\n",
    "import base\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.cache/kagglehub/datasets/thanakomsn/glove6b300dtxt/versions/1\n"
     ]
    }
   ],
   "source": [
    "my_glove = kagglehub.dataset_download(\"thanakomsn/glove6b300dtxt\")\n",
    "print(my_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_FILE = f\"{my_glove}/glove.6B.300d.txt\"\n",
    "DATASET = \"trec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_from_disk(f\"~/data/{DATASET}/train-logits_fine\")\n",
    "eval_data = load_from_disk(f\"~/data/{DATASET}/eval-logits_fine\")\n",
    "test_data = load_from_disk(f\"~/data/{DATASET}/test-logits_fine\")\n",
    "\n",
    "all_train_data = load_from_disk(f\"~/data/{DATASET}/train-logits-augmented_fine\")\n",
    "\n",
    "all_data = concatenate_datasets([load_from_disk(file) for file in [f\"~/data/{DATASET}/eval-logits_fine\", f\"~/data/{DATASET}/test-logits_fine\", f\"~/data/{DATASET}/train-logits-augmented_fine\"]])\n",
    "tokenizer = BasicTokenizer(do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and will be used: NVIDIA A100 80GB PCIe MIG 2g.20gb\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and will be used:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_tokens = list(map(lambda e: tokenizer.tokenize(e[\"sentence\"]), train_data))\n",
    "eval_data_tokens = list(map(lambda e: tokenizer.tokenize(e[\"sentence\"]), eval_data))\n",
    "test_data_tokens = list(map(lambda e: tokenizer.tokenize(e[\"sentence\"]), test_data))\n",
    "\n",
    "all_train_data_tokens = list(map(lambda e: tokenizer.tokenize(e[\"sentence\"]), all_train_data))\n",
    "\n",
    "all_data_tokens = list(map(lambda e: tokenizer.tokenize(e[\"sentence\"]), all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = base.get_vocab(all_data_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = dict(zip(vocab, range(len(vocab))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = base.get_embeddings_indeces(GLOVE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8766\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))\n",
    "num_tokens = len(vocab) + 2\n",
    "embedding_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 8551 words (215) misses\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = base.get_embedding_matrix(num_tokens, embedding_dim, word_index, embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_index = list(map(lambda x: list(map(lambda y: word_index[y], x)),train_data_tokens))\n",
    "eval_data_index = list(map(lambda x: list(map(lambda y: word_index[y], x)),eval_data_tokens))\n",
    "test_data_index = list(map(lambda x: list(map(lambda y: word_index[y], x)),test_data_tokens))\n",
    "\n",
    "all_train_data_index = list(map(lambda x: list(map(lambda y: word_index[y], x)),all_train_data_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded_data = list(map(lambda x: base.padd(x,60), train_data_index))\n",
    "eval_padded_data = list(map(lambda x: base.padd(x,60), eval_data_index))\n",
    "test_padded_data = list(map(lambda x: base.padd(x,60), test_data_index))\n",
    "\n",
    "all_train_padded_data = list(map(lambda x: base.padd(x,60), all_train_data_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.add_column(\"input_ids\", train_padded_data)\n",
    "eval_data = eval_data.add_column(\"input_ids\", eval_padded_data)\n",
    "test_data = test_data.add_column(\"input_ids\", test_padded_data)\n",
    "\n",
    "all_train_data = all_train_data.add_column(\"input_ids\", all_train_padded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gpu = copy.deepcopy(train_data)\n",
    "train_data_gpu.set_format(type=\"torch\", columns=[\"input_ids\"], device=\"cuda\")\n",
    "gpu_data_loader = DataLoader(train_data_gpu, batch_size=1, shuffle=False)\n",
    "\n",
    "train_data_cpu = copy.deepcopy(train_data)\n",
    "train_data_cpu.set_format(type=\"torch\", columns=[\"input_ids\"], device=\"cpu\")\n",
    "cpu_data_loader = DataLoader(train_data_cpu, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = base.BiLSTMClassifier(embedding_matrix=embedding_matrix, embedding_dim=embedding_dim, fc_dim=400, hidden_dim=300, output_dim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTMClassifier(\n",
      "  (embedding): Embedding(8768, 300)\n",
      "  (lstm): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
      "  (fc1): Linear(in_features=600, out_features=400, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc2): Linear(in_features=400, out_features=50, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bilstm-base_fine\", logging_dir=f\"~/logs/{DATASET}/bilstm-base_fine\", lr=.001,  epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/350 01:06, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.073900</td>\n",
       "      <td>2.503414</td>\n",
       "      <td>0.384051</td>\n",
       "      <td>0.073851</td>\n",
       "      <td>0.083262</td>\n",
       "      <td>0.058125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.164600</td>\n",
       "      <td>1.925456</td>\n",
       "      <td>0.534372</td>\n",
       "      <td>0.137764</td>\n",
       "      <td>0.156210</td>\n",
       "      <td>0.131718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.739700</td>\n",
       "      <td>1.590624</td>\n",
       "      <td>0.591201</td>\n",
       "      <td>0.241389</td>\n",
       "      <td>0.196628</td>\n",
       "      <td>0.192703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.387600</td>\n",
       "      <td>1.379046</td>\n",
       "      <td>0.653529</td>\n",
       "      <td>0.304337</td>\n",
       "      <td>0.265769</td>\n",
       "      <td>0.264644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.160800</td>\n",
       "      <td>1.252556</td>\n",
       "      <td>0.684693</td>\n",
       "      <td>0.352104</td>\n",
       "      <td>0.320205</td>\n",
       "      <td>0.319850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.961000</td>\n",
       "      <td>1.202357</td>\n",
       "      <td>0.696609</td>\n",
       "      <td>0.392709</td>\n",
       "      <td>0.365802</td>\n",
       "      <td>0.362126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.810100</td>\n",
       "      <td>1.203011</td>\n",
       "      <td>0.683776</td>\n",
       "      <td>0.414235</td>\n",
       "      <td>0.343203</td>\n",
       "      <td>0.355138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.735500</td>\n",
       "      <td>1.159855</td>\n",
       "      <td>0.701192</td>\n",
       "      <td>0.406064</td>\n",
       "      <td>0.392893</td>\n",
       "      <td>0.389383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.631100</td>\n",
       "      <td>1.167883</td>\n",
       "      <td>0.698442</td>\n",
       "      <td>0.422664</td>\n",
       "      <td>0.391569</td>\n",
       "      <td>0.396941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.562800</td>\n",
       "      <td>1.154422</td>\n",
       "      <td>0.701192</td>\n",
       "      <td>0.425888</td>\n",
       "      <td>0.394864</td>\n",
       "      <td>0.398052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=350, training_loss=1.3227099609375, metrics={'train_runtime': 66.8441, 'train_samples_per_second': 652.414, 'train_steps_per_second': 5.236, 'total_flos': 0.0, 'train_loss': 1.3227099609375, 'epoch': 10.0})"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMClassifier(\n",
       "  (embedding): Embedding(8768, 300)\n",
       "  (lstm): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=600, out_features=400, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=400, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0533905029296875,\n",
       " 'eval_accuracy': 0.712,\n",
       " 'eval_precision': 0.414032074537255,\n",
       " 'eval_recall': 0.4614954277729287,\n",
       " 'eval_f1': 0.4219846375382348,\n",
       " 'eval_runtime': 4.6833,\n",
       " 'eval_samples_per_second': 106.761,\n",
       " 'eval_steps_per_second': 0.854,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bilstm-base_fine.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 16.539MB.\n",
      "Total Trainable Params: 1705250.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Modules</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm.weight_ih_l0</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lstm.weight_hh_l0</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstm.bias_ih_l0</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lstm.bias_hh_l0</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lstm.weight_ih_l0_reverse</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lstm.weight_hh_l0_reverse</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lstm.bias_ih_l0_reverse</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lstm.bias_hh_l0_reverse</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fc1.weight</td>\n",
       "      <td>240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fc1.bias</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fc2.weight</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fc2.bias</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Modules Parameters\n",
       "0           lstm.weight_ih_l0     360000\n",
       "1           lstm.weight_hh_l0     360000\n",
       "2             lstm.bias_ih_l0       1200\n",
       "3             lstm.bias_hh_l0       1200\n",
       "4   lstm.weight_ih_l0_reverse     360000\n",
       "5   lstm.weight_hh_l0_reverse     360000\n",
       "6     lstm.bias_ih_l0_reverse       1200\n",
       "7     lstm.bias_hh_l0_reverse       1200\n",
       "8                  fc1.weight     240000\n",
       "9                    fc1.bias        400\n",
       "10                 fc2.weight      20000\n",
       "11                   fc2.bias         50"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x75e347187eb0>\n",
      "self.infer_speed_comp()\n",
      "  4.36 ms\n",
      "  1 measurement, 1000 runs , 6 threads\n"
     ]
    }
   ],
   "source": [
    "cpu_benchmark = base.BenchMarkRunner(model, cpu_data_loader, \"cpu\", 1000)\n",
    "print(cpu_benchmark.run_benchmark())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x75e345fb7f10>\n",
      "self.infer_speed_comp()\n",
      "  1.88 ms\n",
      "  1 measurement, 1000 runs , 6 threads\n"
     ]
    }
   ],
   "source": [
    "gpu_benchmark = base.BenchMarkRunner(model, gpu_data_loader, \"cuda\", 1000)\n",
    "print(gpu_benchmark.run_benchmark())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = base.BiLSTMClassifier(embedding_matrix=embedding_matrix, embedding_dim=embedding_dim, fc_dim=400, hidden_dim=300, output_dim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bilstm-distill_fine\", remove_unused_columns=False, logging_dir=f\"~/logs/{DATASET}/bilstm-distill_fine\", lr=.001,  epochs=10, batch_size=128, lambda_param=.4, temp=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainer(\n",
    "    student_model=student_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/350 01:04, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.699800</td>\n",
       "      <td>2.159288</td>\n",
       "      <td>0.384051</td>\n",
       "      <td>0.063069</td>\n",
       "      <td>0.081779</td>\n",
       "      <td>0.052825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.897800</td>\n",
       "      <td>1.693547</td>\n",
       "      <td>0.505958</td>\n",
       "      <td>0.114980</td>\n",
       "      <td>0.133844</td>\n",
       "      <td>0.108290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.581200</td>\n",
       "      <td>1.450519</td>\n",
       "      <td>0.562786</td>\n",
       "      <td>0.193427</td>\n",
       "      <td>0.173613</td>\n",
       "      <td>0.156870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.325700</td>\n",
       "      <td>1.280039</td>\n",
       "      <td>0.637947</td>\n",
       "      <td>0.273468</td>\n",
       "      <td>0.232180</td>\n",
       "      <td>0.222331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.135900</td>\n",
       "      <td>1.163610</td>\n",
       "      <td>0.668194</td>\n",
       "      <td>0.275144</td>\n",
       "      <td>0.266553</td>\n",
       "      <td>0.258865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.977900</td>\n",
       "      <td>1.101211</td>\n",
       "      <td>0.678277</td>\n",
       "      <td>0.301448</td>\n",
       "      <td>0.286788</td>\n",
       "      <td>0.282700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.860900</td>\n",
       "      <td>1.096320</td>\n",
       "      <td>0.671861</td>\n",
       "      <td>0.340059</td>\n",
       "      <td>0.283197</td>\n",
       "      <td>0.283167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.799700</td>\n",
       "      <td>1.036376</td>\n",
       "      <td>0.698442</td>\n",
       "      <td>0.365521</td>\n",
       "      <td>0.318395</td>\n",
       "      <td>0.318900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.731300</td>\n",
       "      <td>1.018743</td>\n",
       "      <td>0.699358</td>\n",
       "      <td>0.350070</td>\n",
       "      <td>0.321879</td>\n",
       "      <td>0.323286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.678400</td>\n",
       "      <td>1.006209</td>\n",
       "      <td>0.703025</td>\n",
       "      <td>0.381331</td>\n",
       "      <td>0.328636</td>\n",
       "      <td>0.329858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=350, training_loss=1.268863983154297, metrics={'train_runtime': 64.6098, 'train_samples_per_second': 674.975, 'train_steps_per_second': 5.417, 'total_flos': 0.0, 'train_loss': 1.268863983154297, 'epoch': 10.0})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMClassifier(\n",
       "  (embedding): Embedding(8768, 300)\n",
       "  (lstm): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=600, out_features=400, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=400, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9847412705421448,\n",
       " 'eval_accuracy': 0.706,\n",
       " 'eval_precision': 0.34694630717536823,\n",
       " 'eval_recall': 0.3712546955537928,\n",
       " 'eval_f1': 0.3264487866139811,\n",
       " 'eval_runtime': 4.7634,\n",
       " 'eval_samples_per_second': 104.967,\n",
       " 'eval_steps_per_second': 0.84,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student_model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bilstm-distill_fine.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 16.539MB.\n",
      "Total Trainable Params: 1705250.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Modules</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm.weight_ih_l0</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lstm.weight_hh_l0</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstm.bias_ih_l0</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lstm.bias_hh_l0</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lstm.weight_ih_l0_reverse</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lstm.weight_hh_l0_reverse</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lstm.bias_ih_l0_reverse</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lstm.bias_hh_l0_reverse</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fc1.weight</td>\n",
       "      <td>240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fc1.bias</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fc2.weight</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fc2.bias</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Modules Parameters\n",
       "0           lstm.weight_ih_l0     360000\n",
       "1           lstm.weight_hh_l0     360000\n",
       "2             lstm.bias_ih_l0       1200\n",
       "3             lstm.bias_hh_l0       1200\n",
       "4   lstm.weight_ih_l0_reverse     360000\n",
       "5   lstm.weight_hh_l0_reverse     360000\n",
       "6     lstm.bias_ih_l0_reverse       1200\n",
       "7     lstm.bias_hh_l0_reverse       1200\n",
       "8                  fc1.weight     240000\n",
       "9                    fc1.bias        400\n",
       "10                 fc2.weight      20000\n",
       "11                   fc2.bias         50"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.count_parameters(student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x75e3644016f0>\n",
      "self.infer_speed_comp()\n",
      "  4.59 ms\n",
      "  1 measurement, 1000 runs , 6 threads\n"
     ]
    }
   ],
   "source": [
    "cpu_benchmark = base.BenchMarkRunner(student_model, cpu_data_loader, \"cpu\", 1000)\n",
    "print(cpu_benchmark.run_benchmark())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x75e1cbc23d00>\n",
      "self.infer_speed_comp()\n",
      "  1.88 ms\n",
      "  1 measurement, 1000 runs , 6 threads\n"
     ]
    }
   ],
   "source": [
    "gpu_benchmark = base.BenchMarkRunner(student_model, gpu_data_loader, \"cuda\", 1000)\n",
    "print(gpu_benchmark.run_benchmark())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = base.BiLSTMClassifier(embedding_matrix=embedding_matrix, embedding_dim=embedding_dim, fc_dim=400, hidden_dim=300, output_dim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bilstm-base-aug_fine\", logging_dir=f\"~/logs/{DATASET}/bilstm-base-aug_fine\", lr=.001,  epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=all_train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 4)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='5250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/5250 02:03, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.045900</td>\n",
       "      <td>1.023053</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.635869</td>\n",
       "      <td>0.536293</td>\n",
       "      <td>0.552683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.177000</td>\n",
       "      <td>1.187909</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.691892</td>\n",
       "      <td>0.641475</td>\n",
       "      <td>0.650620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.055700</td>\n",
       "      <td>1.274335</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.723567</td>\n",
       "      <td>0.669486</td>\n",
       "      <td>0.686155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>1.442288</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.685190</td>\n",
       "      <td>0.649686</td>\n",
       "      <td>0.651868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>1.473755</td>\n",
       "      <td>0.812099</td>\n",
       "      <td>0.730327</td>\n",
       "      <td>0.689053</td>\n",
       "      <td>0.696772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.585668</td>\n",
       "      <td>0.805683</td>\n",
       "      <td>0.728329</td>\n",
       "      <td>0.681206</td>\n",
       "      <td>0.692194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.624400</td>\n",
       "      <td>0.814849</td>\n",
       "      <td>0.785707</td>\n",
       "      <td>0.684487</td>\n",
       "      <td>0.713712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.612765</td>\n",
       "      <td>0.814849</td>\n",
       "      <td>0.761628</td>\n",
       "      <td>0.692895</td>\n",
       "      <td>0.713338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.629979</td>\n",
       "      <td>0.817599</td>\n",
       "      <td>0.780827</td>\n",
       "      <td>0.704461</td>\n",
       "      <td>0.728280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.663172</td>\n",
       "      <td>0.815765</td>\n",
       "      <td>0.771773</td>\n",
       "      <td>0.693528</td>\n",
       "      <td>0.718780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5250, training_loss=0.13248115424598966, metrics={'train_runtime': 123.4803, 'train_samples_per_second': 5432.445, 'train_steps_per_second': 42.517, 'total_flos': 0.0, 'train_loss': 0.13248115424598966, 'epoch': 10.0})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMClassifier(\n",
       "  (embedding): Embedding(8768, 300)\n",
       "  (lstm): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=600, out_features=400, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=400, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.3135536909103394,\n",
       " 'eval_accuracy': 0.846,\n",
       " 'eval_precision': 0.7058719827930602,\n",
       " 'eval_recall': 0.7214950186575256,\n",
       " 'eval_f1': 0.6899065260384348,\n",
       " 'eval_runtime': 4.4088,\n",
       " 'eval_samples_per_second': 113.409,\n",
       " 'eval_steps_per_second': 0.907,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bilstm-base-aug_fine.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 16.539MB.\n",
      "Total Trainable Params: 1705250.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Modules</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm.weight_ih_l0</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lstm.weight_hh_l0</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstm.bias_ih_l0</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lstm.bias_hh_l0</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lstm.weight_ih_l0_reverse</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lstm.weight_hh_l0_reverse</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lstm.bias_ih_l0_reverse</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lstm.bias_hh_l0_reverse</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fc1.weight</td>\n",
       "      <td>240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fc1.bias</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fc2.weight</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fc2.bias</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Modules Parameters\n",
       "0           lstm.weight_ih_l0     360000\n",
       "1           lstm.weight_hh_l0     360000\n",
       "2             lstm.bias_ih_l0       1200\n",
       "3             lstm.bias_hh_l0       1200\n",
       "4   lstm.weight_ih_l0_reverse     360000\n",
       "5   lstm.weight_hh_l0_reverse     360000\n",
       "6     lstm.bias_ih_l0_reverse       1200\n",
       "7     lstm.bias_hh_l0_reverse       1200\n",
       "8                  fc1.weight     240000\n",
       "9                    fc1.bias        400\n",
       "10                 fc2.weight      20000\n",
       "11                   fc2.bias         50"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x75e1a4f0e530>\n",
      "self.infer_speed_comp()\n",
      "  4.94 ms\n",
      "  1 measurement, 1000 runs , 6 threads\n"
     ]
    }
   ],
   "source": [
    "cpu_benchmark = base.BenchMarkRunner(student_model, cpu_data_loader, \"cpu\", 1000)\n",
    "print(cpu_benchmark.run_benchmark())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x75e1a4f36b00>\n",
      "self.infer_speed_comp()\n",
      "  1.94 ms\n",
      "  1 measurement, 1000 runs , 6 threads\n"
     ]
    }
   ],
   "source": [
    "gpu_benchmark = base.BenchMarkRunner(student_model, gpu_data_loader, \"cuda\", 1000)\n",
    "print(gpu_benchmark.run_benchmark())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = base.BiLSTMClassifier(embedding_matrix=embedding_matrix, embedding_dim=embedding_dim, fc_dim=400, hidden_dim=300, output_dim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bilstm-distill-aug_fine\", remove_unused_columns=False, logging_dir=f\"~/logs/{DATASET}/bilstm-distill-aug_fine\", lr=0.0015, weight_decay=0.01, warmup_steps=45, adam_beta1=.95, epochs=30, batch_size=128, lambda_param=.9, temp=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainer(\n",
    "    student_model=student_model,\n",
    "    args=training_args,\n",
    "    train_dataset=all_train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8925' max='15750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8925/15750 03:41 < 02:49, 40.20 it/s, Epoch 17/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.831200</td>\n",
       "      <td>0.532684</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.402330</td>\n",
       "      <td>0.389453</td>\n",
       "      <td>0.384507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.182500</td>\n",
       "      <td>0.457369</td>\n",
       "      <td>0.814849</td>\n",
       "      <td>0.600572</td>\n",
       "      <td>0.528745</td>\n",
       "      <td>0.548273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.103900</td>\n",
       "      <td>0.428102</td>\n",
       "      <td>0.824931</td>\n",
       "      <td>0.671660</td>\n",
       "      <td>0.584802</td>\n",
       "      <td>0.611524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.082600</td>\n",
       "      <td>0.424568</td>\n",
       "      <td>0.826764</td>\n",
       "      <td>0.735698</td>\n",
       "      <td>0.650434</td>\n",
       "      <td>0.674225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.071700</td>\n",
       "      <td>0.427975</td>\n",
       "      <td>0.828598</td>\n",
       "      <td>0.772014</td>\n",
       "      <td>0.660684</td>\n",
       "      <td>0.695346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.066900</td>\n",
       "      <td>0.407494</td>\n",
       "      <td>0.838680</td>\n",
       "      <td>0.746627</td>\n",
       "      <td>0.650151</td>\n",
       "      <td>0.680647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.396718</td>\n",
       "      <td>0.842346</td>\n",
       "      <td>0.810542</td>\n",
       "      <td>0.679114</td>\n",
       "      <td>0.724032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.060900</td>\n",
       "      <td>0.401809</td>\n",
       "      <td>0.828598</td>\n",
       "      <td>0.788860</td>\n",
       "      <td>0.663020</td>\n",
       "      <td>0.704743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.394696</td>\n",
       "      <td>0.842346</td>\n",
       "      <td>0.794766</td>\n",
       "      <td>0.696065</td>\n",
       "      <td>0.731332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.055800</td>\n",
       "      <td>0.389493</td>\n",
       "      <td>0.846929</td>\n",
       "      <td>0.824274</td>\n",
       "      <td>0.697782</td>\n",
       "      <td>0.738985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>0.392499</td>\n",
       "      <td>0.846013</td>\n",
       "      <td>0.859183</td>\n",
       "      <td>0.727854</td>\n",
       "      <td>0.769883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.053000</td>\n",
       "      <td>0.380227</td>\n",
       "      <td>0.852429</td>\n",
       "      <td>0.849693</td>\n",
       "      <td>0.720053</td>\n",
       "      <td>0.765039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.051000</td>\n",
       "      <td>0.382105</td>\n",
       "      <td>0.841430</td>\n",
       "      <td>0.860090</td>\n",
       "      <td>0.720433</td>\n",
       "      <td>0.767430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>0.368525</td>\n",
       "      <td>0.846929</td>\n",
       "      <td>0.872221</td>\n",
       "      <td>0.727290</td>\n",
       "      <td>0.775990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.048700</td>\n",
       "      <td>0.373478</td>\n",
       "      <td>0.845096</td>\n",
       "      <td>0.851424</td>\n",
       "      <td>0.724333</td>\n",
       "      <td>0.765384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.047600</td>\n",
       "      <td>0.384567</td>\n",
       "      <td>0.838680</td>\n",
       "      <td>0.816115</td>\n",
       "      <td>0.706774</td>\n",
       "      <td>0.741801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.381309</td>\n",
       "      <td>0.842346</td>\n",
       "      <td>0.817002</td>\n",
       "      <td>0.698109</td>\n",
       "      <td>0.736176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8925, training_loss=0.11357396358201484, metrics={'train_runtime': 222.9195, 'train_samples_per_second': 9027.473, 'train_steps_per_second': 70.653, 'total_flos': 0.0, 'train_loss': 0.11357396358201484, 'epoch': 17.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMClassifier(\n",
       "  (embedding): Embedding(8768, 300)\n",
       "  (lstm): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=600, out_features=400, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=400, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2879835367202759,\n",
       " 'eval_accuracy': 0.84,\n",
       " 'eval_precision': 0.7659675748814134,\n",
       " 'eval_recall': 0.7009694424186768,\n",
       " 'eval_f1': 0.7021264683561136,\n",
       " 'eval_runtime': 6.3233,\n",
       " 'eval_samples_per_second': 79.073,\n",
       " 'eval_steps_per_second': 0.633,\n",
       " 'epoch': 17.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student_model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bilstm-distill-aug_fine.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 16.539MB.\n",
      "Total Trainable Params: 1705250.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Modules</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm.weight_ih_l0</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lstm.weight_hh_l0</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstm.bias_ih_l0</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lstm.bias_hh_l0</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lstm.weight_ih_l0_reverse</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lstm.weight_hh_l0_reverse</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lstm.bias_ih_l0_reverse</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lstm.bias_hh_l0_reverse</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fc1.weight</td>\n",
       "      <td>240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fc1.bias</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fc2.weight</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fc2.bias</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Modules Parameters\n",
       "0           lstm.weight_ih_l0     360000\n",
       "1           lstm.weight_hh_l0     360000\n",
       "2             lstm.bias_ih_l0       1200\n",
       "3             lstm.bias_hh_l0       1200\n",
       "4   lstm.weight_ih_l0_reverse     360000\n",
       "5   lstm.weight_hh_l0_reverse     360000\n",
       "6     lstm.bias_ih_l0_reverse       1200\n",
       "7     lstm.bias_hh_l0_reverse       1200\n",
       "8                  fc1.weight     240000\n",
       "9                    fc1.bias        400\n",
       "10                 fc2.weight      20000\n",
       "11                   fc2.bias         50"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.count_parameters(student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x75e34752c070>\n",
      "self.infer_speed_comp()\n",
      "  5.52 ms\n",
      "  1 measurement, 1000 runs , 6 threads\n"
     ]
    }
   ],
   "source": [
    "cpu_benchmark = base.BenchMarkRunner(student_model, cpu_data_loader, \"cpu\", 1000)\n",
    "print(cpu_benchmark.run_benchmark())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x75e346820b50>\n",
      "self.infer_speed_comp()\n",
      "  2.04 ms\n",
      "  1 measurement, 1000 runs , 6 threads\n"
     ]
    }
   ],
   "source": [
    "gpu_benchmark = base.BenchMarkRunner(student_model, gpu_data_loader, \"cuda\", 1000)\n",
    "print(gpu_benchmark.run_benchmark())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 16.539MB.\n",
      "Total Trainable Params: 1705250.\n",
      "Average Inference Time on GPU: 1.722 ms\n",
      "Average Inference Time on CPU: 4.301 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch.utils.data import  DataLoader\n",
    "\n",
    "base.count_parameters(model)\n",
    "torch.cuda.synchronize() \n",
    "starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "device = \"cuda\"\n",
    "model.to(device)\n",
    "\n",
    "train_data.set_format(type=\"torch\", columns=[\"input_ids\"], device=\"cuda\")\n",
    "test_loader = DataLoader(train_data, batch_size=1, shuffle=False)\n",
    "\n",
    "timings = []\n",
    "\n",
    "\n",
    "\n",
    "for i, batch in enumerate(test_loader):\n",
    "    if i >= 1000:\n",
    "        break\n",
    "    torch.cuda.synchronize()\n",
    "    starter.record()\n",
    "    with torch.no_grad():\n",
    "        _ = model(**batch)\n",
    "    ender.record()\n",
    "    torch.cuda.synchronize()\n",
    "    timings.append(starter.elapsed_time(ender))\n",
    "\n",
    "print(f\"Average Inference Time on GPU: {sum(timings) / len(timings):.3f} ms\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "timings = []\n",
    "device = \"cpu\"\n",
    "model.to(device)\n",
    "train_data.set_format(type=\"torch\", columns=[\"input_ids\"], device=\"cpu\")\n",
    "test_loader = DataLoader(train_data, batch_size=1, shuffle=False)\n",
    "for i, batch in enumerate(test_loader):\n",
    "    if i >= 1000:\n",
    "        break\n",
    "    start_time = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        _ = model(**batch)\n",
    "    end_time = time.perf_counter()\n",
    "    timings.append((end_time - start_time)*1000)\n",
    "\n",
    "\n",
    "print(f\"Average Inference Time on CPU: {sum(timings) / len(timings):.3f} ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
