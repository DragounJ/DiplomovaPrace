{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets, load_from_disk\n",
    "from transformers import BasicTokenizer, EarlyStoppingCallback, Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "import kagglehub\n",
    "import torch\n",
    "import base\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.cache/kagglehub/datasets/thanakomsn/glove6b300dtxt/versions/1\n"
     ]
    }
   ],
   "source": [
    "my_glove = kagglehub.dataset_download(\"thanakomsn/glove6b300dtxt\")\n",
    "print(my_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_FILE = f\"{my_glove}/glove.6B.300d.txt\"\n",
    "DATASET = \"trec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_from_disk(f\"~/data/{DATASET}/train-logits_fine\")\n",
    "eval_data = load_from_disk(f\"~/data/{DATASET}/eval-logits_fine\")\n",
    "test_data = load_from_disk(f\"~/data/{DATASET}/test-logits_fine\")\n",
    "\n",
    "all_train_data = load_from_disk(f\"~/data/{DATASET}/train-logits-augmented_fine\")\n",
    "\n",
    "all_data = concatenate_datasets([load_from_disk(file) for file in [f\"~/data/{DATASET}/eval-logits_fine\", f\"~/data/{DATASET}/test-logits_fine\", f\"~/data/{DATASET}/train-logits-augmented_fine\"]])\n",
    "tokenizer = BasicTokenizer(do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and will be used: NVIDIA H100 PCIe\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and will be used:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_tokens = list(map(lambda e: tokenizer.tokenize(e[\"sentence\"]), train_data))\n",
    "eval_data_tokens = list(map(lambda e: tokenizer.tokenize(e[\"sentence\"]), eval_data))\n",
    "test_data_tokens = list(map(lambda e: tokenizer.tokenize(e[\"sentence\"]), test_data))\n",
    "\n",
    "all_train_data_tokens = list(map(lambda e: tokenizer.tokenize(e[\"sentence\"]), all_train_data))\n",
    "\n",
    "all_data_tokens = list(map(lambda e: tokenizer.tokenize(e[\"sentence\"]), all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = base.get_vocab(all_data_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = dict(zip(vocab, range(len(vocab))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = base.get_embeddings_indeces(GLOVE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8766\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))\n",
    "num_tokens = len(vocab) + 2\n",
    "embedding_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 8551 words (215) misses\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = base.get_embedding_matrix(num_tokens, embedding_dim, word_index, embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_index = list(map(lambda x: list(map(lambda y: word_index[y], x)),train_data_tokens))\n",
    "eval_data_index = list(map(lambda x: list(map(lambda y: word_index[y], x)),eval_data_tokens))\n",
    "test_data_index = list(map(lambda x: list(map(lambda y: word_index[y], x)),test_data_tokens))\n",
    "\n",
    "all_train_data_index = list(map(lambda x: list(map(lambda y: word_index[y], x)),all_train_data_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded_data = list(map(lambda x: base.padd(x,60), train_data_index))\n",
    "eval_padded_data = list(map(lambda x: base.padd(x,60), eval_data_index))\n",
    "test_padded_data = list(map(lambda x: base.padd(x,60), test_data_index))\n",
    "\n",
    "all_train_padded_data = list(map(lambda x: base.padd(x,60), all_train_data_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.add_column(\"input_ids\", train_padded_data)\n",
    "eval_data = eval_data.add_column(\"input_ids\", eval_padded_data)\n",
    "test_data = test_data.add_column(\"input_ids\", test_padded_data)\n",
    "\n",
    "all_train_data = all_train_data.add_column(\"input_ids\", all_train_padded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gpu = copy.deepcopy(train_data)\n",
    "train_data_gpu.set_format(type=\"torch\", columns=[\"input_ids\"], device=\"cuda\")\n",
    "gpu_data_loader = DataLoader(train_data_gpu, batch_size=1, shuffle=False)\n",
    "\n",
    "train_data_cpu = copy.deepcopy(train_data)\n",
    "train_data_cpu.set_format(type=\"torch\", columns=[\"input_ids\"], device=\"cpu\")\n",
    "cpu_data_loader = DataLoader(train_data_cpu, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = base.BiLSTMClassifier(embedding_matrix=embedding_matrix, embedding_dim=embedding_dim, fc_dim=400, hidden_dim=300, output_dim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTMClassifier(\n",
      "  (embedding): Embedding(8768, 300)\n",
      "  (lstm): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
      "  (fc1): Linear(in_features=600, out_features=400, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc2): Linear(in_features=400, out_features=50, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bilstm-base_fine\", logging_dir=f\"~/logs/{DATASET}/bilstm-base_fine\", lr=.005, weight_decay = .002, warmup_steps = 2,  epochs=15, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='490' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [490/525 01:05 < 00:04, 7.47 it/s, Epoch 14/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.579600</td>\n",
       "      <td>1.895323</td>\n",
       "      <td>0.516957</td>\n",
       "      <td>0.201717</td>\n",
       "      <td>0.179139</td>\n",
       "      <td>0.166014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.497300</td>\n",
       "      <td>1.379462</td>\n",
       "      <td>0.666361</td>\n",
       "      <td>0.317662</td>\n",
       "      <td>0.299932</td>\n",
       "      <td>0.293096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.000400</td>\n",
       "      <td>1.157564</td>\n",
       "      <td>0.717690</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>0.371105</td>\n",
       "      <td>0.369859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.626000</td>\n",
       "      <td>1.080071</td>\n",
       "      <td>0.727773</td>\n",
       "      <td>0.550041</td>\n",
       "      <td>0.480927</td>\n",
       "      <td>0.492950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.352800</td>\n",
       "      <td>1.094388</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.599743</td>\n",
       "      <td>0.536896</td>\n",
       "      <td>0.554457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.171400</td>\n",
       "      <td>1.213981</td>\n",
       "      <td>0.778185</td>\n",
       "      <td>0.635408</td>\n",
       "      <td>0.606574</td>\n",
       "      <td>0.606317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>1.314857</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.672996</td>\n",
       "      <td>0.622436</td>\n",
       "      <td>0.635620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>1.415231</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.687267</td>\n",
       "      <td>0.628458</td>\n",
       "      <td>0.642874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>1.298808</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.700102</td>\n",
       "      <td>0.647338</td>\n",
       "      <td>0.660204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.380020</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.700119</td>\n",
       "      <td>0.642714</td>\n",
       "      <td>0.658627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.423399</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.715815</td>\n",
       "      <td>0.639387</td>\n",
       "      <td>0.660821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.440345</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.702664</td>\n",
       "      <td>0.638523</td>\n",
       "      <td>0.657081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.450448</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.691718</td>\n",
       "      <td>0.630614</td>\n",
       "      <td>0.648067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.455945</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.692867</td>\n",
       "      <td>0.633114</td>\n",
       "      <td>0.649855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=490, training_loss=0.4553474649862975, metrics={'train_runtime': 65.6674, 'train_samples_per_second': 996.156, 'train_steps_per_second': 7.995, 'total_flos': 0.0, 'train_loss': 0.4553474649862975, 'epoch': 14.0})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMClassifier(\n",
       "  (embedding): Embedding(8768, 300)\n",
       "  (lstm): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=600, out_features=400, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=400, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0148743391036987,\n",
       " 'eval_accuracy': 0.822,\n",
       " 'eval_precision': 0.7099063905070399,\n",
       " 'eval_recall': 0.6618411811215629,\n",
       " 'eval_f1': 0.666502175489911,\n",
       " 'eval_runtime': 3.3628,\n",
       " 'eval_samples_per_second': 148.688,\n",
       " 'eval_steps_per_second': 1.19,\n",
       " 'epoch': 14.0}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bilstm-base_fine.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 16.539MB.\n",
      "Total Trainable Params: 1705250.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Modules</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm.weight_ih_l0</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lstm.weight_hh_l0</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstm.bias_ih_l0</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lstm.bias_hh_l0</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lstm.weight_ih_l0_reverse</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lstm.weight_hh_l0_reverse</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lstm.bias_ih_l0_reverse</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lstm.bias_hh_l0_reverse</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fc1.weight</td>\n",
       "      <td>240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fc1.bias</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fc2.weight</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fc2.bias</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Modules Parameters\n",
       "0           lstm.weight_ih_l0     360000\n",
       "1           lstm.weight_hh_l0     360000\n",
       "2             lstm.bias_ih_l0       1200\n",
       "3             lstm.bias_hh_l0       1200\n",
       "4   lstm.weight_ih_l0_reverse     360000\n",
       "5   lstm.weight_hh_l0_reverse     360000\n",
       "6     lstm.bias_ih_l0_reverse       1200\n",
       "7     lstm.bias_hh_l0_reverse       1200\n",
       "8                  fc1.weight     240000\n",
       "9                    fc1.bias        400\n",
       "10                 fc2.weight      20000\n",
       "11                   fc2.bias         50"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x75183187f0a0>\n",
      "self.infer_speed_comp()\n",
      "  6.04 ms\n",
      "  1 measurement, 1000 runs , 4 threads\n"
     ]
    }
   ],
   "source": [
    "cpu_benchmark = base.BenchMarkRunner(model, cpu_data_loader, \"cpu\", 1000)\n",
    "print(cpu_benchmark.run_benchmark())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x75183182bdf0>\n",
      "self.infer_speed_comp()\n",
      "  2.16 ms\n",
      "  1 measurement, 1000 runs , 4 threads\n"
     ]
    }
   ],
   "source": [
    "gpu_benchmark = base.BenchMarkRunner(model, gpu_data_loader, \"cuda\", 1000)\n",
    "print(gpu_benchmark.run_benchmark())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = base.BiLSTMClassifier(embedding_matrix=embedding_matrix, embedding_dim=embedding_dim, fc_dim=400, hidden_dim=300, output_dim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bilstm-distill_fine\", remove_unused_columns=False, logging_dir=f\"~/logs/{DATASET}/bilstm-distill_fine\", lr=.005, weight_decay = 0.009, warmup_steps = 4, epochs=20, batch_size=128, lambda_param=.6, temp=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainer(\n",
    "    student_model=student_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='665' max='700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [665/700 01:28 < 00:04, 7.47 it/s, Epoch 19/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.589900</td>\n",
       "      <td>1.181036</td>\n",
       "      <td>0.474794</td>\n",
       "      <td>0.106221</td>\n",
       "      <td>0.123948</td>\n",
       "      <td>0.097965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.030100</td>\n",
       "      <td>0.888245</td>\n",
       "      <td>0.631531</td>\n",
       "      <td>0.234494</td>\n",
       "      <td>0.254940</td>\n",
       "      <td>0.235581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.727500</td>\n",
       "      <td>0.693991</td>\n",
       "      <td>0.718607</td>\n",
       "      <td>0.368497</td>\n",
       "      <td>0.360014</td>\n",
       "      <td>0.354463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.536800</td>\n",
       "      <td>0.619837</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.398146</td>\n",
       "      <td>0.394519</td>\n",
       "      <td>0.391347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.384800</td>\n",
       "      <td>0.557465</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.466319</td>\n",
       "      <td>0.443512</td>\n",
       "      <td>0.447690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.286900</td>\n",
       "      <td>0.557899</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.501812</td>\n",
       "      <td>0.452929</td>\n",
       "      <td>0.465692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.220800</td>\n",
       "      <td>0.513788</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.591454</td>\n",
       "      <td>0.522804</td>\n",
       "      <td>0.543003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.167400</td>\n",
       "      <td>0.510017</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.635664</td>\n",
       "      <td>0.558800</td>\n",
       "      <td>0.580133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.128300</td>\n",
       "      <td>0.495336</td>\n",
       "      <td>0.807516</td>\n",
       "      <td>0.661863</td>\n",
       "      <td>0.570878</td>\n",
       "      <td>0.601575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.103600</td>\n",
       "      <td>0.482070</td>\n",
       "      <td>0.815765</td>\n",
       "      <td>0.711728</td>\n",
       "      <td>0.635348</td>\n",
       "      <td>0.660211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.091700</td>\n",
       "      <td>0.483476</td>\n",
       "      <td>0.816682</td>\n",
       "      <td>0.714987</td>\n",
       "      <td>0.635774</td>\n",
       "      <td>0.661233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.085200</td>\n",
       "      <td>0.480401</td>\n",
       "      <td>0.819432</td>\n",
       "      <td>0.725496</td>\n",
       "      <td>0.649313</td>\n",
       "      <td>0.673704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.079800</td>\n",
       "      <td>0.481834</td>\n",
       "      <td>0.817599</td>\n",
       "      <td>0.735936</td>\n",
       "      <td>0.646208</td>\n",
       "      <td>0.677649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.075200</td>\n",
       "      <td>0.482341</td>\n",
       "      <td>0.818515</td>\n",
       "      <td>0.748756</td>\n",
       "      <td>0.667737</td>\n",
       "      <td>0.695404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.072600</td>\n",
       "      <td>0.483601</td>\n",
       "      <td>0.818515</td>\n",
       "      <td>0.757831</td>\n",
       "      <td>0.656593</td>\n",
       "      <td>0.690867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.069900</td>\n",
       "      <td>0.484931</td>\n",
       "      <td>0.826764</td>\n",
       "      <td>0.784146</td>\n",
       "      <td>0.685009</td>\n",
       "      <td>0.718419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.068700</td>\n",
       "      <td>0.480564</td>\n",
       "      <td>0.821265</td>\n",
       "      <td>0.757466</td>\n",
       "      <td>0.672685</td>\n",
       "      <td>0.701439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.480841</td>\n",
       "      <td>0.823098</td>\n",
       "      <td>0.779273</td>\n",
       "      <td>0.683711</td>\n",
       "      <td>0.715907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>0.481423</td>\n",
       "      <td>0.821265</td>\n",
       "      <td>0.758761</td>\n",
       "      <td>0.673214</td>\n",
       "      <td>0.702724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=665, training_loss=0.3081107985704465, metrics={'train_runtime': 88.9483, 'train_samples_per_second': 980.569, 'train_steps_per_second': 7.87, 'total_flos': 0.0, 'train_loss': 0.3081107985704465, 'epoch': 19.0})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMClassifier(\n",
       "  (embedding): Embedding(8768, 300)\n",
       "  (lstm): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=600, out_features=400, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=400, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.41698408126831055,\n",
       " 'eval_accuracy': 0.822,\n",
       " 'eval_precision': 0.7468531755825939,\n",
       " 'eval_recall': 0.6641065816458944,\n",
       " 'eval_f1': 0.6775623521158944,\n",
       " 'eval_runtime': 3.4288,\n",
       " 'eval_samples_per_second': 145.826,\n",
       " 'eval_steps_per_second': 1.167,\n",
       " 'epoch': 19.0}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student_model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bilstm-distill_fine.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 16.539MB.\n",
      "Total Trainable Params: 1705250.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Modules</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm.weight_ih_l0</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lstm.weight_hh_l0</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstm.bias_ih_l0</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lstm.bias_hh_l0</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lstm.weight_ih_l0_reverse</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lstm.weight_hh_l0_reverse</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lstm.bias_ih_l0_reverse</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lstm.bias_hh_l0_reverse</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fc1.weight</td>\n",
       "      <td>240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fc1.bias</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fc2.weight</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fc2.bias</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Modules Parameters\n",
       "0           lstm.weight_ih_l0     360000\n",
       "1           lstm.weight_hh_l0     360000\n",
       "2             lstm.bias_ih_l0       1200\n",
       "3             lstm.bias_hh_l0       1200\n",
       "4   lstm.weight_ih_l0_reverse     360000\n",
       "5   lstm.weight_hh_l0_reverse     360000\n",
       "6     lstm.bias_ih_l0_reverse       1200\n",
       "7     lstm.bias_hh_l0_reverse       1200\n",
       "8                  fc1.weight     240000\n",
       "9                    fc1.bias        400\n",
       "10                 fc2.weight      20000\n",
       "11                   fc2.bias         50"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.count_parameters(student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x75183187c1f0>\n",
      "self.infer_speed_comp()\n",
      "  3.33 ms\n",
      "  1 measurement, 1000 runs , 4 threads\n"
     ]
    }
   ],
   "source": [
    "cpu_benchmark = base.BenchMarkRunner(student_model, cpu_data_loader, \"cpu\", 1000)\n",
    "print(cpu_benchmark.run_benchmark())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7518319d5e40>\n",
      "self.infer_speed_comp()\n",
      "  1.83 ms\n",
      "  1 measurement, 1000 runs , 4 threads\n"
     ]
    }
   ],
   "source": [
    "gpu_benchmark = base.BenchMarkRunner(student_model, gpu_data_loader, \"cuda\", 1000)\n",
    "print(gpu_benchmark.run_benchmark())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = base.BiLSTMClassifier(embedding_matrix=embedding_matrix, embedding_dim=embedding_dim, fc_dim=400, hidden_dim=300, output_dim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bilstm-base-aug_fine\", logging_dir=f\"~/logs/{DATASET}/bilstm-base-aug_fine\", lr=.005,  epochs=20, weight_decay=0.009, warmup_steps=49, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=all_train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8891' max='10460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8891/10460 03:22 < 00:35, 43.85 it/s, Epoch 17/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.664400</td>\n",
       "      <td>1.046777</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.745181</td>\n",
       "      <td>0.692226</td>\n",
       "      <td>0.704679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.060500</td>\n",
       "      <td>1.180362</td>\n",
       "      <td>0.806599</td>\n",
       "      <td>0.751741</td>\n",
       "      <td>0.699872</td>\n",
       "      <td>0.704943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.029700</td>\n",
       "      <td>1.505155</td>\n",
       "      <td>0.805683</td>\n",
       "      <td>0.713317</td>\n",
       "      <td>0.686981</td>\n",
       "      <td>0.687996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>1.472180</td>\n",
       "      <td>0.820348</td>\n",
       "      <td>0.785614</td>\n",
       "      <td>0.720416</td>\n",
       "      <td>0.734060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.025100</td>\n",
       "      <td>1.732541</td>\n",
       "      <td>0.808433</td>\n",
       "      <td>0.793205</td>\n",
       "      <td>0.708483</td>\n",
       "      <td>0.734408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>1.702512</td>\n",
       "      <td>0.814849</td>\n",
       "      <td>0.748111</td>\n",
       "      <td>0.677796</td>\n",
       "      <td>0.697886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>1.795035</td>\n",
       "      <td>0.820348</td>\n",
       "      <td>0.810556</td>\n",
       "      <td>0.714336</td>\n",
       "      <td>0.741775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>1.755565</td>\n",
       "      <td>0.819432</td>\n",
       "      <td>0.781014</td>\n",
       "      <td>0.710225</td>\n",
       "      <td>0.729960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>1.878143</td>\n",
       "      <td>0.819432</td>\n",
       "      <td>0.813092</td>\n",
       "      <td>0.713920</td>\n",
       "      <td>0.745391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>1.901936</td>\n",
       "      <td>0.815765</td>\n",
       "      <td>0.795357</td>\n",
       "      <td>0.717573</td>\n",
       "      <td>0.742134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.826624</td>\n",
       "      <td>0.832264</td>\n",
       "      <td>0.788142</td>\n",
       "      <td>0.727369</td>\n",
       "      <td>0.748123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.917386</td>\n",
       "      <td>0.826764</td>\n",
       "      <td>0.774884</td>\n",
       "      <td>0.733032</td>\n",
       "      <td>0.742102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.986001</td>\n",
       "      <td>0.823098</td>\n",
       "      <td>0.781839</td>\n",
       "      <td>0.723370</td>\n",
       "      <td>0.740446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>2.056170</td>\n",
       "      <td>0.824931</td>\n",
       "      <td>0.793062</td>\n",
       "      <td>0.736708</td>\n",
       "      <td>0.752787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>2.033798</td>\n",
       "      <td>0.815765</td>\n",
       "      <td>0.762960</td>\n",
       "      <td>0.713618</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.006899</td>\n",
       "      <td>0.815765</td>\n",
       "      <td>0.759644</td>\n",
       "      <td>0.710496</td>\n",
       "      <td>0.724192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.000683</td>\n",
       "      <td>0.817599</td>\n",
       "      <td>0.763321</td>\n",
       "      <td>0.715187</td>\n",
       "      <td>0.727978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8891, training_loss=0.05143660313466874, metrics={'train_runtime': 202.976, 'train_samples_per_second': 6588.365, 'train_steps_per_second': 51.533, 'total_flos': 0.0, 'train_loss': 0.05143660313466874, 'epoch': 17.0})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMClassifier(\n",
       "  (embedding): Embedding(8768, 300)\n",
       "  (lstm): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=600, out_features=400, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=400, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.759264349937439,\n",
       " 'eval_accuracy': 0.836,\n",
       " 'eval_precision': 0.7059850941559144,\n",
       " 'eval_recall': 0.6690233050598904,\n",
       " 'eval_f1': 0.6735333580584322,\n",
       " 'eval_runtime': 3.1694,\n",
       " 'eval_samples_per_second': 157.76,\n",
       " 'eval_steps_per_second': 1.262,\n",
       " 'epoch': 17.0}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bilstm-base-aug_fine.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 16.539MB.\n",
      "Total Trainable Params: 1705250.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Modules</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm.weight_ih_l0</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lstm.weight_hh_l0</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstm.bias_ih_l0</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lstm.bias_hh_l0</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lstm.weight_ih_l0_reverse</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lstm.weight_hh_l0_reverse</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lstm.bias_ih_l0_reverse</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lstm.bias_hh_l0_reverse</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fc1.weight</td>\n",
       "      <td>240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fc1.bias</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fc2.weight</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fc2.bias</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Modules Parameters\n",
       "0           lstm.weight_ih_l0     360000\n",
       "1           lstm.weight_hh_l0     360000\n",
       "2             lstm.bias_ih_l0       1200\n",
       "3             lstm.bias_hh_l0       1200\n",
       "4   lstm.weight_ih_l0_reverse     360000\n",
       "5   lstm.weight_hh_l0_reverse     360000\n",
       "6     lstm.bias_ih_l0_reverse       1200\n",
       "7     lstm.bias_hh_l0_reverse       1200\n",
       "8                  fc1.weight     240000\n",
       "9                    fc1.bias        400\n",
       "10                 fc2.weight      20000\n",
       "11                   fc2.bias         50"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x75183182a3e0>\n",
      "self.infer_speed_comp()\n",
      "  6.05 ms\n",
      "  1 measurement, 1000 runs , 4 threads\n"
     ]
    }
   ],
   "source": [
    "cpu_benchmark = base.BenchMarkRunner(student_model, cpu_data_loader, \"cpu\", 1000)\n",
    "print(cpu_benchmark.run_benchmark())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7518319d5c00>\n",
      "self.infer_speed_comp()\n",
      "  2.14 ms\n",
      "  1 measurement, 1000 runs , 4 threads\n"
     ]
    }
   ],
   "source": [
    "gpu_benchmark = base.BenchMarkRunner(student_model, gpu_data_loader, \"cuda\", 1000)\n",
    "print(gpu_benchmark.run_benchmark())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = base.BiLSTMClassifier(embedding_matrix=embedding_matrix, embedding_dim=embedding_dim, fc_dim=400, hidden_dim=300, output_dim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bilstm-distill-aug_fine\", remove_unused_columns=False, logging_dir=f\"~/logs/{DATASET}/bilstm-distill-aug_fine\", lr=0.0045, weight_decay=0.01, warmup_steps=42, epochs=20, batch_size=128, lambda_param=.5, temp=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainer(\n",
    "    student_model=student_model,\n",
    "    args=training_args,\n",
    "    train_dataset=all_train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10460' max='10460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10460/10460 04:01, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.678300</td>\n",
       "      <td>0.621786</td>\n",
       "      <td>0.835930</td>\n",
       "      <td>0.819613</td>\n",
       "      <td>0.710978</td>\n",
       "      <td>0.747358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.150200</td>\n",
       "      <td>0.602439</td>\n",
       "      <td>0.829514</td>\n",
       "      <td>0.749696</td>\n",
       "      <td>0.674669</td>\n",
       "      <td>0.699273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.117000</td>\n",
       "      <td>0.609918</td>\n",
       "      <td>0.841430</td>\n",
       "      <td>0.825495</td>\n",
       "      <td>0.721298</td>\n",
       "      <td>0.753385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.106500</td>\n",
       "      <td>0.583910</td>\n",
       "      <td>0.835930</td>\n",
       "      <td>0.830465</td>\n",
       "      <td>0.709159</td>\n",
       "      <td>0.751163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.102400</td>\n",
       "      <td>0.623720</td>\n",
       "      <td>0.834097</td>\n",
       "      <td>0.805652</td>\n",
       "      <td>0.713997</td>\n",
       "      <td>0.745858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.099800</td>\n",
       "      <td>0.635390</td>\n",
       "      <td>0.824015</td>\n",
       "      <td>0.836893</td>\n",
       "      <td>0.710372</td>\n",
       "      <td>0.755673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.098500</td>\n",
       "      <td>0.625105</td>\n",
       "      <td>0.830431</td>\n",
       "      <td>0.804662</td>\n",
       "      <td>0.706594</td>\n",
       "      <td>0.738450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.095500</td>\n",
       "      <td>0.607409</td>\n",
       "      <td>0.834097</td>\n",
       "      <td>0.821349</td>\n",
       "      <td>0.725821</td>\n",
       "      <td>0.757971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.091700</td>\n",
       "      <td>0.613063</td>\n",
       "      <td>0.835930</td>\n",
       "      <td>0.827569</td>\n",
       "      <td>0.718591</td>\n",
       "      <td>0.757031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.568588</td>\n",
       "      <td>0.846013</td>\n",
       "      <td>0.836843</td>\n",
       "      <td>0.738641</td>\n",
       "      <td>0.771468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.087600</td>\n",
       "      <td>0.575317</td>\n",
       "      <td>0.842346</td>\n",
       "      <td>0.850937</td>\n",
       "      <td>0.745600</td>\n",
       "      <td>0.781095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.085500</td>\n",
       "      <td>0.571653</td>\n",
       "      <td>0.852429</td>\n",
       "      <td>0.831268</td>\n",
       "      <td>0.749710</td>\n",
       "      <td>0.776790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.084700</td>\n",
       "      <td>0.568337</td>\n",
       "      <td>0.856095</td>\n",
       "      <td>0.842382</td>\n",
       "      <td>0.747839</td>\n",
       "      <td>0.781255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.083500</td>\n",
       "      <td>0.575353</td>\n",
       "      <td>0.845096</td>\n",
       "      <td>0.833282</td>\n",
       "      <td>0.729455</td>\n",
       "      <td>0.763444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.082100</td>\n",
       "      <td>0.569896</td>\n",
       "      <td>0.851512</td>\n",
       "      <td>0.867570</td>\n",
       "      <td>0.739541</td>\n",
       "      <td>0.781856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.081000</td>\n",
       "      <td>0.583568</td>\n",
       "      <td>0.846013</td>\n",
       "      <td>0.858418</td>\n",
       "      <td>0.741178</td>\n",
       "      <td>0.780961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>0.575357</td>\n",
       "      <td>0.846929</td>\n",
       "      <td>0.856279</td>\n",
       "      <td>0.740792</td>\n",
       "      <td>0.781512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.079100</td>\n",
       "      <td>0.574685</td>\n",
       "      <td>0.849679</td>\n",
       "      <td>0.858244</td>\n",
       "      <td>0.744801</td>\n",
       "      <td>0.782857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.078100</td>\n",
       "      <td>0.571166</td>\n",
       "      <td>0.847846</td>\n",
       "      <td>0.866838</td>\n",
       "      <td>0.741493</td>\n",
       "      <td>0.784142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.077500</td>\n",
       "      <td>0.571238</td>\n",
       "      <td>0.843263</td>\n",
       "      <td>0.859777</td>\n",
       "      <td>0.742103</td>\n",
       "      <td>0.782066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10460, training_loss=0.12244620314063807, metrics={'train_runtime': 241.4593, 'train_samples_per_second': 5538.325, 'train_steps_per_second': 43.32, 'total_flos': 0.0, 'train_loss': 0.12244620314063807, 'epoch': 20.0})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMClassifier(\n",
       "  (embedding): Embedding(8768, 300)\n",
       "  (lstm): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=600, out_features=400, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=400, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.46995213627815247,\n",
       " 'eval_accuracy': 0.86,\n",
       " 'eval_precision': 0.8016732618616697,\n",
       " 'eval_recall': 0.7517333803440076,\n",
       " 'eval_f1': 0.7579899237628692,\n",
       " 'eval_runtime': 3.8775,\n",
       " 'eval_samples_per_second': 128.949,\n",
       " 'eval_steps_per_second': 1.032,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student_model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bilstm-distill-aug_fine.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 16.539MB.\n",
      "Total Trainable Params: 1705250.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Modules</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm.weight_ih_l0</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lstm.weight_hh_l0</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstm.bias_ih_l0</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lstm.bias_hh_l0</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lstm.weight_ih_l0_reverse</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lstm.weight_hh_l0_reverse</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lstm.bias_ih_l0_reverse</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lstm.bias_hh_l0_reverse</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fc1.weight</td>\n",
       "      <td>240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fc1.bias</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fc2.weight</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fc2.bias</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Modules Parameters\n",
       "0           lstm.weight_ih_l0     360000\n",
       "1           lstm.weight_hh_l0     360000\n",
       "2             lstm.bias_ih_l0       1200\n",
       "3             lstm.bias_hh_l0       1200\n",
       "4   lstm.weight_ih_l0_reverse     360000\n",
       "5   lstm.weight_hh_l0_reverse     360000\n",
       "6     lstm.bias_ih_l0_reverse       1200\n",
       "7     lstm.bias_hh_l0_reverse       1200\n",
       "8                  fc1.weight     240000\n",
       "9                    fc1.bias        400\n",
       "10                 fc2.weight      20000\n",
       "11                   fc2.bias         50"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.count_parameters(student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x75183187e3e0>\n",
      "self.infer_speed_comp()\n",
      "  5.39 ms\n",
      "  1 measurement, 1000 runs , 4 threads\n"
     ]
    }
   ],
   "source": [
    "cpu_benchmark = base.BenchMarkRunner(student_model, cpu_data_loader, \"cpu\", 1000)\n",
    "print(cpu_benchmark.run_benchmark())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x751831909b70>\n",
      "self.infer_speed_comp()\n",
      "  2.17 ms\n",
      "  1 measurement, 1000 runs , 4 threads\n"
     ]
    }
   ],
   "source": [
    "gpu_benchmark = base.BenchMarkRunner(student_model, gpu_data_loader, \"cuda\", 1000)\n",
    "print(gpu_benchmark.run_benchmark())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
