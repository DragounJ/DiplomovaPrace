{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7e7a26f-aa1f-4645-b3b3-4643ca8be2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, BertTokenizer, BertForSequenceClassification\n",
    "from datasets import load_from_disk\n",
    "import optuna\n",
    "import torch\n",
    "import math\n",
    "import base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29b9ceef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and will be used: NVIDIA A100 80GB PCIe MIG 1g.10gb\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and will be used:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26c9d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"sst2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14bfbf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_from_disk(f\"~/data/{DATASET}/train-logits\")\n",
    "eval_data = load_from_disk(f\"~/data/{DATASET}/eval-logits\")\n",
    "test_data = load_from_disk(f\"~/data/{DATASET}/test-logits\")\n",
    "\n",
    "all_train_data = load_from_disk(f\"~/data/{DATASET}/train-logits-augmented\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"ndavid/autotrain-trec-fine-bert-739422530\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bd0688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the train dataset\")\n",
    "eval = eval_data.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the eval dataset\")\n",
    "test = test_data.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the test dataset\")\n",
    "\n",
    "train_aug = all_train_data.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the augmented dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65e61bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01f8400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nápočet epoch na steps\n",
    "data_length = len(train_data)\n",
    "min_r = math.ceil(data_length/batch_size)*5\n",
    "max_r = math.ceil(data_length/batch_size)*num_epochs\n",
    "warm_up = math.ceil(data_length/batch_size/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3574e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_space(trial):\n",
    "    params =  {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 5e-4, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0, 1e-2, step=1e-3),\n",
    "        \"warmup_steps\" : trial.suggest_int(\"warmup_steps\", 0, warm_up)\n",
    "    }   \n",
    "    print(f\"Trial {trial.number} with params: {params}\")\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "174fff53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pruner = optuna.pruners.HyperbandPruner(min_resource=min_r, max_resource=max_r, reduction_factor=2, bootstrap_count=2)\n",
    "sampler = optuna.samplers.TPESampler(seed=42, multivariate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ba99151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Bert():\n",
    "    return BertForSequenceClassification.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a906d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4b4c462",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bert-base_hp-search\", logging_dir=f\"~/logs/{DATASET}/bert-base_hp-search\", epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc752b97-d843-4919-a0fc-066d192e037b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    model_init = lambda: get_Bert(),\n",
    ")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97855619-93d5-4fc2-93d2-fee24c61b8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 11:31:45,321] A new study created in memory with name: Test-base\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 with params: {'learning_rate': 4.3284502212938785e-05, 'weight_decay': 0.01, 'warmup_steps': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 06:43 < 03:21, 10.44 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.518900</td>\n",
       "      <td>0.461005</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793637</td>\n",
       "      <td>0.793340</td>\n",
       "      <td>0.793421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.362800</td>\n",
       "      <td>0.434238</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809585</td>\n",
       "      <td>0.809527</td>\n",
       "      <td>0.809552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.305700</td>\n",
       "      <td>0.436370</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815301</td>\n",
       "      <td>0.815326</td>\n",
       "      <td>0.815312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.272100</td>\n",
       "      <td>0.454227</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822380</td>\n",
       "      <td>0.821998</td>\n",
       "      <td>0.822101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.246200</td>\n",
       "      <td>0.441469</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810802</td>\n",
       "      <td>0.810906</td>\n",
       "      <td>0.810768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.227400</td>\n",
       "      <td>0.461721</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814494</td>\n",
       "      <td>0.814494</td>\n",
       "      <td>0.814220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.214000</td>\n",
       "      <td>0.481988</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813301</td>\n",
       "      <td>0.813326</td>\n",
       "      <td>0.813073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.202600</td>\n",
       "      <td>0.489547</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814175</td>\n",
       "      <td>0.814116</td>\n",
       "      <td>0.814141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.192200</td>\n",
       "      <td>0.500466</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.809646</td>\n",
       "      <td>0.809032</td>\n",
       "      <td>0.808444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.185200</td>\n",
       "      <td>0.505199</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816456</td>\n",
       "      <td>0.816536</td>\n",
       "      <td>0.816479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 11:38:30,533] Trial 0 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 with params: {'learning_rate': 0.00010401663679887307, 'weight_decay': 0.001, 'warmup_steps': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 03:28 < 06:56, 10.10 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.437000</td>\n",
       "      <td>0.433008</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.809646</td>\n",
       "      <td>0.809032</td>\n",
       "      <td>0.808444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.284100</td>\n",
       "      <td>0.453273</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.804788</td>\n",
       "      <td>0.803349</td>\n",
       "      <td>0.803506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.227700</td>\n",
       "      <td>0.459349</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820032</td>\n",
       "      <td>0.820125</td>\n",
       "      <td>0.819948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.194800</td>\n",
       "      <td>0.503375</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.827847</td>\n",
       "      <td>0.824914</td>\n",
       "      <td>0.825113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.171200</td>\n",
       "      <td>0.515211</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813504</td>\n",
       "      <td>0.813410</td>\n",
       "      <td>0.813071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 11:41:59,601] Trial 1 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 with params: {'learning_rate': 1.2551115172973821e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 06:37 < 03:19, 10.58 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.632800</td>\n",
       "      <td>0.560277</td>\n",
       "      <td>0.739679</td>\n",
       "      <td>0.739647</td>\n",
       "      <td>0.739444</td>\n",
       "      <td>0.739498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.493700</td>\n",
       "      <td>0.477547</td>\n",
       "      <td>0.779817</td>\n",
       "      <td>0.780281</td>\n",
       "      <td>0.780163</td>\n",
       "      <td>0.779812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.429600</td>\n",
       "      <td>0.461764</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791225</td>\n",
       "      <td>0.791298</td>\n",
       "      <td>0.791245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.397600</td>\n",
       "      <td>0.459046</td>\n",
       "      <td>0.785550</td>\n",
       "      <td>0.785693</td>\n",
       "      <td>0.785247</td>\n",
       "      <td>0.785345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.375700</td>\n",
       "      <td>0.452762</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793775</td>\n",
       "      <td>0.793256</td>\n",
       "      <td>0.793365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.357200</td>\n",
       "      <td>0.443788</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810802</td>\n",
       "      <td>0.810906</td>\n",
       "      <td>0.810768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.440710</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813220</td>\n",
       "      <td>0.813284</td>\n",
       "      <td>0.813071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.333400</td>\n",
       "      <td>0.440655</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809597</td>\n",
       "      <td>0.809695</td>\n",
       "      <td>0.809608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.324400</td>\n",
       "      <td>0.439242</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812032</td>\n",
       "      <td>0.811911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.317800</td>\n",
       "      <td>0.442916</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812010</td>\n",
       "      <td>0.811695</td>\n",
       "      <td>0.811784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 11:48:38,556] Trial 2 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 with params: {'learning_rate': 0.00015958573588141273, 'weight_decay': 0.0, 'warmup_steps': 42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 03:21 < 06:42, 10.45 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.415900</td>\n",
       "      <td>0.416100</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.808920</td>\n",
       "      <td>0.807032</td>\n",
       "      <td>0.806007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.252500</td>\n",
       "      <td>0.477402</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.809103</td>\n",
       "      <td>0.808022</td>\n",
       "      <td>0.808177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.196600</td>\n",
       "      <td>0.518501</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.816057</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.815355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.164200</td>\n",
       "      <td>0.537852</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812776</td>\n",
       "      <td>0.811400</td>\n",
       "      <td>0.811569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.140700</td>\n",
       "      <td>0.580719</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.803122</td>\n",
       "      <td>0.803065</td>\n",
       "      <td>0.802751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 11:52:00,636] Trial 3 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 with params: {'learning_rate': 0.00025959425503112657, 'weight_decay': 0.002, 'warmup_steps': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 06:41 < 03:20, 10.49 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>0.430053</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.801850</td>\n",
       "      <td>0.799150</td>\n",
       "      <td>0.797858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.223500</td>\n",
       "      <td>0.529651</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.809398</td>\n",
       "      <td>0.807938</td>\n",
       "      <td>0.808102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.168100</td>\n",
       "      <td>0.592634</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814269</td>\n",
       "      <td>0.814368</td>\n",
       "      <td>0.814211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.134800</td>\n",
       "      <td>0.574313</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812368</td>\n",
       "      <td>0.811526</td>\n",
       "      <td>0.811673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.111100</td>\n",
       "      <td>0.705184</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.802694</td>\n",
       "      <td>0.802770</td>\n",
       "      <td>0.802715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.092500</td>\n",
       "      <td>0.780370</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.797242</td>\n",
       "      <td>0.797266</td>\n",
       "      <td>0.797018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.077800</td>\n",
       "      <td>0.869577</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.796054</td>\n",
       "      <td>0.796097</td>\n",
       "      <td>0.795870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>0.830610</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793964</td>\n",
       "      <td>0.793172</td>\n",
       "      <td>0.793300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.060700</td>\n",
       "      <td>0.955186</td>\n",
       "      <td>0.785550</td>\n",
       "      <td>0.789908</td>\n",
       "      <td>0.786636</td>\n",
       "      <td>0.785121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.973840</td>\n",
       "      <td>0.785550</td>\n",
       "      <td>0.785862</td>\n",
       "      <td>0.785836</td>\n",
       "      <td>0.785550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 11:58:42,774] Trial 4 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 with params: {'learning_rate': 2.049268011541735e-05, 'weight_decay': 0.003, 'warmup_steps': 23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 03:20 < 06:40, 10.51 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.588800</td>\n",
       "      <td>0.494544</td>\n",
       "      <td>0.770642</td>\n",
       "      <td>0.771171</td>\n",
       "      <td>0.770144</td>\n",
       "      <td>0.770251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.434200</td>\n",
       "      <td>0.457863</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793519</td>\n",
       "      <td>0.793593</td>\n",
       "      <td>0.793539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.444194</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803977</td>\n",
       "      <td>0.804065</td>\n",
       "      <td>0.803893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.348100</td>\n",
       "      <td>0.448086</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.801577</td>\n",
       "      <td>0.799844</td>\n",
       "      <td>0.799995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.324500</td>\n",
       "      <td>0.440928</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813269</td>\n",
       "      <td>0.812779</td>\n",
       "      <td>0.812894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 12:02:04,453] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 with params: {'learning_rate': 5.4182823195332406e-05, 'weight_decay': 0.003, 'warmup_steps': 26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 09:59, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.497100</td>\n",
       "      <td>0.451238</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795817</td>\n",
       "      <td>0.795761</td>\n",
       "      <td>0.795785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.340900</td>\n",
       "      <td>0.430616</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809682</td>\n",
       "      <td>0.809779</td>\n",
       "      <td>0.809624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.283400</td>\n",
       "      <td>0.438365</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.249900</td>\n",
       "      <td>0.463810</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821197</td>\n",
       "      <td>0.820872</td>\n",
       "      <td>0.820965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.224300</td>\n",
       "      <td>0.453397</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812112</td>\n",
       "      <td>0.812158</td>\n",
       "      <td>0.811926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.206600</td>\n",
       "      <td>0.479937</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812416</td>\n",
       "      <td>0.812284</td>\n",
       "      <td>0.811923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.192900</td>\n",
       "      <td>0.501806</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814331</td>\n",
       "      <td>0.814410</td>\n",
       "      <td>0.814216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.182100</td>\n",
       "      <td>0.520086</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815489</td>\n",
       "      <td>0.815115</td>\n",
       "      <td>0.815215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.171900</td>\n",
       "      <td>0.532604</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810887</td>\n",
       "      <td>0.810200</td>\n",
       "      <td>0.809584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.164900</td>\n",
       "      <td>0.539663</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815319</td>\n",
       "      <td>0.815410</td>\n",
       "      <td>0.815338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.159500</td>\n",
       "      <td>0.544694</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.155200</td>\n",
       "      <td>0.548604</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814406</td>\n",
       "      <td>0.814452</td>\n",
       "      <td>0.814219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.152500</td>\n",
       "      <td>0.552781</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815390</td>\n",
       "      <td>0.815494</td>\n",
       "      <td>0.815355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.147600</td>\n",
       "      <td>0.566649</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816478</td>\n",
       "      <td>0.816578</td>\n",
       "      <td>0.816490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.146900</td>\n",
       "      <td>0.568085</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816620</td>\n",
       "      <td>0.816498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 12:12:05,814] Trial 6 finished with value: 0.8164983164983165 and parameters: {'learning_rate': 5.4182823195332406e-05, 'weight_decay': 0.003, 'warmup_steps': 26}. Best is trial 6 with value: 0.8164983164983165.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 with params: {'learning_rate': 1.7258215396625005e-05, 'weight_decay': 0.003, 'warmup_steps': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 03:21 < 06:42, 10.45 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.604600</td>\n",
       "      <td>0.512565</td>\n",
       "      <td>0.762615</td>\n",
       "      <td>0.763293</td>\n",
       "      <td>0.762051</td>\n",
       "      <td>0.762139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.452200</td>\n",
       "      <td>0.463292</td>\n",
       "      <td>0.786697</td>\n",
       "      <td>0.786637</td>\n",
       "      <td>0.786710</td>\n",
       "      <td>0.786657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.397100</td>\n",
       "      <td>0.450236</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795836</td>\n",
       "      <td>0.795929</td>\n",
       "      <td>0.795845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.365300</td>\n",
       "      <td>0.451116</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.796378</td>\n",
       "      <td>0.795424</td>\n",
       "      <td>0.795561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.342500</td>\n",
       "      <td>0.444939</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806462</td>\n",
       "      <td>0.805854</td>\n",
       "      <td>0.805978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 12:15:27,944] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 with params: {'learning_rate': 5.954553793888986e-05, 'weight_decay': 0.008, 'warmup_steps': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 03:21 < 06:44, 10.42 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.484300</td>\n",
       "      <td>0.447157</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.802686</td>\n",
       "      <td>0.802686</td>\n",
       "      <td>0.802686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.331600</td>\n",
       "      <td>0.430202</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811891</td>\n",
       "      <td>0.811990</td>\n",
       "      <td>0.811902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.274400</td>\n",
       "      <td>0.437524</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817631</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.241100</td>\n",
       "      <td>0.469189</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823871</td>\n",
       "      <td>0.822998</td>\n",
       "      <td>0.823156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.215600</td>\n",
       "      <td>0.460560</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811102</td>\n",
       "      <td>0.811074</td>\n",
       "      <td>0.810780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 12:18:50,743] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 with params: {'learning_rate': 7.475992999956501e-05, 'weight_decay': 0.006, 'warmup_steps': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 06:39 < 03:20, 10.52 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.462600</td>\n",
       "      <td>0.443429</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.801545</td>\n",
       "      <td>0.801518</td>\n",
       "      <td>0.801530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.311200</td>\n",
       "      <td>0.436101</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813041</td>\n",
       "      <td>0.812947</td>\n",
       "      <td>0.812985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>0.442275</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813078</td>\n",
       "      <td>0.812905</td>\n",
       "      <td>0.812965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.221100</td>\n",
       "      <td>0.482657</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.827840</td>\n",
       "      <td>0.826292</td>\n",
       "      <td>0.826488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.196500</td>\n",
       "      <td>0.478751</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812543</td>\n",
       "      <td>0.812326</td>\n",
       "      <td>0.811918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.179700</td>\n",
       "      <td>0.508953</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811330</td>\n",
       "      <td>0.811158</td>\n",
       "      <td>0.810774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.165200</td>\n",
       "      <td>0.546123</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812032</td>\n",
       "      <td>0.811911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.155600</td>\n",
       "      <td>0.570790</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816969</td>\n",
       "      <td>0.816115</td>\n",
       "      <td>0.816266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.145200</td>\n",
       "      <td>0.589826</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.807532</td>\n",
       "      <td>0.806780</td>\n",
       "      <td>0.806135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.138000</td>\n",
       "      <td>0.597323</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813009</td>\n",
       "      <td>0.813074</td>\n",
       "      <td>0.813032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 12:25:31,512] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 with params: {'learning_rate': 0.000247535485253281, 'weight_decay': 0.005, 'warmup_steps': 34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 03:21 < 06:44, 10.41 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.386100</td>\n",
       "      <td>0.421908</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.806888</td>\n",
       "      <td>0.804780</td>\n",
       "      <td>0.803682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.226800</td>\n",
       "      <td>0.521161</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809782</td>\n",
       "      <td>0.809358</td>\n",
       "      <td>0.809464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.171400</td>\n",
       "      <td>0.564505</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815799</td>\n",
       "      <td>0.815705</td>\n",
       "      <td>0.815365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.137000</td>\n",
       "      <td>0.598941</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814185</td>\n",
       "      <td>0.814284</td>\n",
       "      <td>0.814196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.114300</td>\n",
       "      <td>0.716075</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.797556</td>\n",
       "      <td>0.797392</td>\n",
       "      <td>0.797012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 12:28:54,548] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 with params: {'learning_rate': 4.640705568040428e-05, 'weight_decay': 0.007, 'warmup_steps': 42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 10:07, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>0.458557</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793637</td>\n",
       "      <td>0.793340</td>\n",
       "      <td>0.793421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.356400</td>\n",
       "      <td>0.432715</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808438</td>\n",
       "      <td>0.808527</td>\n",
       "      <td>0.808456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.298900</td>\n",
       "      <td>0.437386</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.265100</td>\n",
       "      <td>0.456671</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821197</td>\n",
       "      <td>0.820872</td>\n",
       "      <td>0.820965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.239200</td>\n",
       "      <td>0.444662</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814269</td>\n",
       "      <td>0.814368</td>\n",
       "      <td>0.814211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.220700</td>\n",
       "      <td>0.467614</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814494</td>\n",
       "      <td>0.814494</td>\n",
       "      <td>0.814220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.207300</td>\n",
       "      <td>0.488377</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809906</td>\n",
       "      <td>0.809906</td>\n",
       "      <td>0.809633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>0.498985</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814175</td>\n",
       "      <td>0.814116</td>\n",
       "      <td>0.814141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.185700</td>\n",
       "      <td>0.510463</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.813006</td>\n",
       "      <td>0.812453</td>\n",
       "      <td>0.811891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.178700</td>\n",
       "      <td>0.516075</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816456</td>\n",
       "      <td>0.816536</td>\n",
       "      <td>0.816479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.173400</td>\n",
       "      <td>0.520343</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814162</td>\n",
       "      <td>0.814242</td>\n",
       "      <td>0.814185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.169100</td>\n",
       "      <td>0.525807</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817808</td>\n",
       "      <td>0.817873</td>\n",
       "      <td>0.817658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.166300</td>\n",
       "      <td>0.527072</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814331</td>\n",
       "      <td>0.814410</td>\n",
       "      <td>0.814216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.161600</td>\n",
       "      <td>0.538247</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814185</td>\n",
       "      <td>0.814284</td>\n",
       "      <td>0.814196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.160700</td>\n",
       "      <td>0.539243</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814185</td>\n",
       "      <td>0.814284</td>\n",
       "      <td>0.814196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 12:39:03,289] Trial 11 finished with value: 0.8141957479047304 and parameters: {'learning_rate': 4.640705568040428e-05, 'weight_decay': 0.007, 'warmup_steps': 42}. Best is trial 6 with value: 0.8164983164983165.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 with params: {'learning_rate': 6.735226471879416e-05, 'weight_decay': 0.006, 'warmup_steps': 39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 03:21 < 06:44, 10.42 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.481200</td>\n",
       "      <td>0.444684</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805010</td>\n",
       "      <td>0.805107</td>\n",
       "      <td>0.805020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.320800</td>\n",
       "      <td>0.432085</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811891</td>\n",
       "      <td>0.811990</td>\n",
       "      <td>0.811902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.262900</td>\n",
       "      <td>0.439497</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816603</td>\n",
       "      <td>0.816284</td>\n",
       "      <td>0.816375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.229800</td>\n",
       "      <td>0.477914</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821839</td>\n",
       "      <td>0.820620</td>\n",
       "      <td>0.820795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.205000</td>\n",
       "      <td>0.472260</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811209</td>\n",
       "      <td>0.811116</td>\n",
       "      <td>0.810778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 12:42:26,096] Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13 with params: {'learning_rate': 1.3343699108210729e-05, 'weight_decay': 0.007, 'warmup_steps': 43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 06:43 < 03:22, 10.42 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.630600</td>\n",
       "      <td>0.553083</td>\n",
       "      <td>0.738532</td>\n",
       "      <td>0.738560</td>\n",
       "      <td>0.738234</td>\n",
       "      <td>0.738299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.486100</td>\n",
       "      <td>0.474523</td>\n",
       "      <td>0.784404</td>\n",
       "      <td>0.784668</td>\n",
       "      <td>0.784668</td>\n",
       "      <td>0.784404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.423500</td>\n",
       "      <td>0.459808</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793542</td>\n",
       "      <td>0.793635</td>\n",
       "      <td>0.793551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.391500</td>\n",
       "      <td>0.457392</td>\n",
       "      <td>0.786697</td>\n",
       "      <td>0.786880</td>\n",
       "      <td>0.786373</td>\n",
       "      <td>0.786477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.369300</td>\n",
       "      <td>0.451159</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793775</td>\n",
       "      <td>0.793256</td>\n",
       "      <td>0.793365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.350700</td>\n",
       "      <td>0.442237</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810858</td>\n",
       "      <td>0.810948</td>\n",
       "      <td>0.810774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.338700</td>\n",
       "      <td>0.439642</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808509</td>\n",
       "      <td>0.808611</td>\n",
       "      <td>0.808474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.326500</td>\n",
       "      <td>0.440044</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810715</td>\n",
       "      <td>0.810779</td>\n",
       "      <td>0.810738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.317500</td>\n",
       "      <td>0.438952</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813096</td>\n",
       "      <td>0.813200</td>\n",
       "      <td>0.813061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.310800</td>\n",
       "      <td>0.442824</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815425</td>\n",
       "      <td>0.815157</td>\n",
       "      <td>0.815238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 12:49:10,952] Trial 13 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 with params: {'learning_rate': 0.00010904880653392973, 'weight_decay': 0.003, 'warmup_steps': 25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 06:37 < 03:18, 10.59 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.438400</td>\n",
       "      <td>0.431211</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.805069</td>\n",
       "      <td>0.803528</td>\n",
       "      <td>0.802603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.280800</td>\n",
       "      <td>0.456231</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.807630</td>\n",
       "      <td>0.805517</td>\n",
       "      <td>0.805675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.223800</td>\n",
       "      <td>0.463777</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821150</td>\n",
       "      <td>0.821251</td>\n",
       "      <td>0.821092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.191100</td>\n",
       "      <td>0.511000</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.825064</td>\n",
       "      <td>0.822704</td>\n",
       "      <td>0.822902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>0.526253</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812200</td>\n",
       "      <td>0.812200</td>\n",
       "      <td>0.811927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.150300</td>\n",
       "      <td>0.566655</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.808244</td>\n",
       "      <td>0.807822</td>\n",
       "      <td>0.807314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.135200</td>\n",
       "      <td>0.636703</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805156</td>\n",
       "      <td>0.805233</td>\n",
       "      <td>0.805042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.125200</td>\n",
       "      <td>0.647055</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.813305</td>\n",
       "      <td>0.811274</td>\n",
       "      <td>0.811447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.114200</td>\n",
       "      <td>0.695792</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.799183</td>\n",
       "      <td>0.797771</td>\n",
       "      <td>0.796877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.107200</td>\n",
       "      <td>0.695591</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807401</td>\n",
       "      <td>0.807314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 12:55:49,186] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 with params: {'learning_rate': 4.211177033787934e-05, 'weight_decay': 0.002, 'warmup_steps': 40}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 10:05, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.523300</td>\n",
       "      <td>0.462096</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793586</td>\n",
       "      <td>0.793382</td>\n",
       "      <td>0.793447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.365700</td>\n",
       "      <td>0.434939</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809615</td>\n",
       "      <td>0.809485</td>\n",
       "      <td>0.809533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.308400</td>\n",
       "      <td>0.435718</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814158</td>\n",
       "      <td>0.814158</td>\n",
       "      <td>0.814158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.274900</td>\n",
       "      <td>0.453082</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820083</td>\n",
       "      <td>0.819704</td>\n",
       "      <td>0.819806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.249000</td>\n",
       "      <td>0.440047</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814326</td>\n",
       "      <td>0.814205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.459618</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813396</td>\n",
       "      <td>0.813368</td>\n",
       "      <td>0.813073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.216700</td>\n",
       "      <td>0.479535</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813220</td>\n",
       "      <td>0.813284</td>\n",
       "      <td>0.813071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.205200</td>\n",
       "      <td>0.485872</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815336</td>\n",
       "      <td>0.815242</td>\n",
       "      <td>0.815279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.194800</td>\n",
       "      <td>0.496923</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.809646</td>\n",
       "      <td>0.809032</td>\n",
       "      <td>0.808444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.187700</td>\n",
       "      <td>0.501373</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815303</td>\n",
       "      <td>0.815368</td>\n",
       "      <td>0.815326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>0.505470</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815336</td>\n",
       "      <td>0.815242</td>\n",
       "      <td>0.815279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.178200</td>\n",
       "      <td>0.510286</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816700</td>\n",
       "      <td>0.816747</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.175500</td>\n",
       "      <td>0.511703</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.170600</td>\n",
       "      <td>0.521665</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814162</td>\n",
       "      <td>0.814242</td>\n",
       "      <td>0.814185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.169700</td>\n",
       "      <td>0.522579</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816456</td>\n",
       "      <td>0.816536</td>\n",
       "      <td>0.816479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 13:05:55,755] Trial 15 finished with value: 0.8164790066294854 and parameters: {'learning_rate': 4.211177033787934e-05, 'weight_decay': 0.002, 'warmup_steps': 40}. Best is trial 6 with value: 0.8164983164983165.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16 with params: {'learning_rate': 2.253617142285837e-05, 'weight_decay': 0.002, 'warmup_steps': 38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 06:42 < 03:21, 10.47 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.582200</td>\n",
       "      <td>0.487769</td>\n",
       "      <td>0.782110</td>\n",
       "      <td>0.782283</td>\n",
       "      <td>0.781784</td>\n",
       "      <td>0.781885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.425300</td>\n",
       "      <td>0.455102</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793507</td>\n",
       "      <td>0.793551</td>\n",
       "      <td>0.793525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.370700</td>\n",
       "      <td>0.441400</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807524</td>\n",
       "      <td>0.807569</td>\n",
       "      <td>0.807338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.338500</td>\n",
       "      <td>0.446829</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.803715</td>\n",
       "      <td>0.802181</td>\n",
       "      <td>0.802336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.314500</td>\n",
       "      <td>0.438808</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815566</td>\n",
       "      <td>0.815073</td>\n",
       "      <td>0.815190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.294900</td>\n",
       "      <td>0.436247</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814185</td>\n",
       "      <td>0.814284</td>\n",
       "      <td>0.814196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.281700</td>\n",
       "      <td>0.439375</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810120</td>\n",
       "      <td>0.809990</td>\n",
       "      <td>0.809629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.269300</td>\n",
       "      <td>0.443794</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814153</td>\n",
       "      <td>0.814200</td>\n",
       "      <td>0.814172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>0.446034</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811102</td>\n",
       "      <td>0.811074</td>\n",
       "      <td>0.810780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.251800</td>\n",
       "      <td>0.449827</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815336</td>\n",
       "      <td>0.815242</td>\n",
       "      <td>0.815279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 13:12:38,954] Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17 with params: {'learning_rate': 7.03604506316601e-05, 'weight_decay': 0.003, 'warmup_steps': 35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 10:04, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.476400</td>\n",
       "      <td>0.444201</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.804987</td>\n",
       "      <td>0.805064</td>\n",
       "      <td>0.805009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.316800</td>\n",
       "      <td>0.433334</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813009</td>\n",
       "      <td>0.813074</td>\n",
       "      <td>0.813032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>0.440987</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816546</td>\n",
       "      <td>0.816326</td>\n",
       "      <td>0.816397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.226000</td>\n",
       "      <td>0.480724</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821839</td>\n",
       "      <td>0.820620</td>\n",
       "      <td>0.820795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.201400</td>\n",
       "      <td>0.476768</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810120</td>\n",
       "      <td>0.809990</td>\n",
       "      <td>0.809629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.184300</td>\n",
       "      <td>0.507897</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810247</td>\n",
       "      <td>0.810032</td>\n",
       "      <td>0.809624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.539020</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813220</td>\n",
       "      <td>0.813284</td>\n",
       "      <td>0.813071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.160200</td>\n",
       "      <td>0.562309</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816675</td>\n",
       "      <td>0.816241</td>\n",
       "      <td>0.816350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.149800</td>\n",
       "      <td>0.579975</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.804382</td>\n",
       "      <td>0.803402</td>\n",
       "      <td>0.802668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.142900</td>\n",
       "      <td>0.586653</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815319</td>\n",
       "      <td>0.815410</td>\n",
       "      <td>0.815338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.137400</td>\n",
       "      <td>0.598581</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819935</td>\n",
       "      <td>0.820041</td>\n",
       "      <td>0.819935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.132500</td>\n",
       "      <td>0.601457</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811102</td>\n",
       "      <td>0.811074</td>\n",
       "      <td>0.810780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.613733</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815390</td>\n",
       "      <td>0.815494</td>\n",
       "      <td>0.815355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.124900</td>\n",
       "      <td>0.631745</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813025</td>\n",
       "      <td>0.813116</td>\n",
       "      <td>0.813044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.124600</td>\n",
       "      <td>0.631531</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814185</td>\n",
       "      <td>0.814284</td>\n",
       "      <td>0.814196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 13:22:45,291] Trial 17 finished with value: 0.8141957479047304 and parameters: {'learning_rate': 7.03604506316601e-05, 'weight_decay': 0.003, 'warmup_steps': 35}. Best is trial 6 with value: 0.8164983164983165.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18 with params: {'learning_rate': 0.0002950137270531351, 'weight_decay': 0.01, 'warmup_steps': 15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 06:43 < 03:21, 10.43 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.372200</td>\n",
       "      <td>0.436959</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.807730</td>\n",
       "      <td>0.806822</td>\n",
       "      <td>0.806119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.217800</td>\n",
       "      <td>0.538754</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.807093</td>\n",
       "      <td>0.805643</td>\n",
       "      <td>0.805804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.162000</td>\n",
       "      <td>0.585874</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823443</td>\n",
       "      <td>0.823546</td>\n",
       "      <td>0.823386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.128100</td>\n",
       "      <td>0.627788</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806239</td>\n",
       "      <td>0.805980</td>\n",
       "      <td>0.806058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.736716</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.801201</td>\n",
       "      <td>0.800897</td>\n",
       "      <td>0.800442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.085800</td>\n",
       "      <td>0.830111</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.802890</td>\n",
       "      <td>0.802475</td>\n",
       "      <td>0.802577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.934850</td>\n",
       "      <td>0.790138</td>\n",
       "      <td>0.790670</td>\n",
       "      <td>0.790509</td>\n",
       "      <td>0.790131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.064700</td>\n",
       "      <td>0.872465</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798372</td>\n",
       "      <td>0.797845</td>\n",
       "      <td>0.797957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.055800</td>\n",
       "      <td>0.964403</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.793908</td>\n",
       "      <td>0.790141</td>\n",
       "      <td>0.788500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.048700</td>\n",
       "      <td>0.969067</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792454</td>\n",
       "      <td>0.792551</td>\n",
       "      <td>0.792418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 13:29:29,749] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 19 with params: {'learning_rate': 4.243886237843546e-05, 'weight_decay': 0.0, 'warmup_steps': 26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 06:46 < 03:23, 10.35 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.519300</td>\n",
       "      <td>0.461640</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792462</td>\n",
       "      <td>0.792214</td>\n",
       "      <td>0.792287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.364500</td>\n",
       "      <td>0.434751</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808451</td>\n",
       "      <td>0.808359</td>\n",
       "      <td>0.808395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.307700</td>\n",
       "      <td>0.436179</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814158</td>\n",
       "      <td>0.814158</td>\n",
       "      <td>0.814158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.274100</td>\n",
       "      <td>0.453622</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820083</td>\n",
       "      <td>0.819704</td>\n",
       "      <td>0.819806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.248200</td>\n",
       "      <td>0.440832</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813054</td>\n",
       "      <td>0.813158</td>\n",
       "      <td>0.813053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.229300</td>\n",
       "      <td>0.460210</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.216000</td>\n",
       "      <td>0.480182</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813220</td>\n",
       "      <td>0.813284</td>\n",
       "      <td>0.813071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.204500</td>\n",
       "      <td>0.487121</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815336</td>\n",
       "      <td>0.815242</td>\n",
       "      <td>0.815279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.194100</td>\n",
       "      <td>0.497982</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.808409</td>\n",
       "      <td>0.807864</td>\n",
       "      <td>0.807303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.187100</td>\n",
       "      <td>0.502386</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814153</td>\n",
       "      <td>0.814200</td>\n",
       "      <td>0.814172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 13:36:17,299] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 with params: {'learning_rate': 1.4635648999047601e-05, 'weight_decay': 0.006, 'warmup_steps': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 06:44 < 03:22, 10.39 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.617200</td>\n",
       "      <td>0.533641</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750444</td>\n",
       "      <td>0.749495</td>\n",
       "      <td>0.749573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.471000</td>\n",
       "      <td>0.469642</td>\n",
       "      <td>0.783257</td>\n",
       "      <td>0.783279</td>\n",
       "      <td>0.783373</td>\n",
       "      <td>0.783243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.413400</td>\n",
       "      <td>0.456280</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794676</td>\n",
       "      <td>0.794761</td>\n",
       "      <td>0.794692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.381900</td>\n",
       "      <td>0.455382</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.789363</td>\n",
       "      <td>0.788583</td>\n",
       "      <td>0.788706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.359700</td>\n",
       "      <td>0.448990</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798565</td>\n",
       "      <td>0.797760</td>\n",
       "      <td>0.797893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.341100</td>\n",
       "      <td>0.440347</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809597</td>\n",
       "      <td>0.809695</td>\n",
       "      <td>0.809608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.328900</td>\n",
       "      <td>0.438570</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809682</td>\n",
       "      <td>0.809779</td>\n",
       "      <td>0.809624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.316700</td>\n",
       "      <td>0.439671</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810715</td>\n",
       "      <td>0.810779</td>\n",
       "      <td>0.810738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.307400</td>\n",
       "      <td>0.439185</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812037</td>\n",
       "      <td>0.812116</td>\n",
       "      <td>0.811923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.300700</td>\n",
       "      <td>0.443231</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813192</td>\n",
       "      <td>0.812821</td>\n",
       "      <td>0.812920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 13:43:03,281] Trial 20 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 21 with params: {'learning_rate': 3.549077053310177e-05, 'weight_decay': 0.008, 'warmup_steps': 41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 10:03, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.539200</td>\n",
       "      <td>0.467534</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791227</td>\n",
       "      <td>0.791172</td>\n",
       "      <td>0.791195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.382100</td>\n",
       "      <td>0.439669</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803943</td>\n",
       "      <td>0.803686</td>\n",
       "      <td>0.803763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.325500</td>\n",
       "      <td>0.434552</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809737</td>\n",
       "      <td>0.809617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.292400</td>\n",
       "      <td>0.448834</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813269</td>\n",
       "      <td>0.812779</td>\n",
       "      <td>0.812894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.266700</td>\n",
       "      <td>0.435270</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813009</td>\n",
       "      <td>0.813074</td>\n",
       "      <td>0.813032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.247100</td>\n",
       "      <td>0.448982</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817808</td>\n",
       "      <td>0.817873</td>\n",
       "      <td>0.817658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.233800</td>\n",
       "      <td>0.463963</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.222100</td>\n",
       "      <td>0.468531</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.211500</td>\n",
       "      <td>0.477164</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814981</td>\n",
       "      <td>0.814663</td>\n",
       "      <td>0.814205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.204200</td>\n",
       "      <td>0.481366</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821059</td>\n",
       "      <td>0.820999</td>\n",
       "      <td>0.821025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.198900</td>\n",
       "      <td>0.483400</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818765</td>\n",
       "      <td>0.818704</td>\n",
       "      <td>0.818730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.194700</td>\n",
       "      <td>0.487338</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815445</td>\n",
       "      <td>0.815536</td>\n",
       "      <td>0.815361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.192200</td>\n",
       "      <td>0.488751</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821066</td>\n",
       "      <td>0.821167</td>\n",
       "      <td>0.821077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.187100</td>\n",
       "      <td>0.496257</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.186200</td>\n",
       "      <td>0.497205</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 13:53:07,870] Trial 21 finished with value: 0.8176065796760941 and parameters: {'learning_rate': 3.549077053310177e-05, 'weight_decay': 0.008, 'warmup_steps': 41}. Best is trial 21 with value: 0.8176065796760941.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 22 with params: {'learning_rate': 0.00016346269168385325, 'weight_decay': 0.009000000000000001, 'warmup_steps': 43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 06:42 < 03:21, 10.47 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.414600</td>\n",
       "      <td>0.415505</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.809940</td>\n",
       "      <td>0.808159</td>\n",
       "      <td>0.807168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.478353</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806801</td>\n",
       "      <td>0.805727</td>\n",
       "      <td>0.805880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.195100</td>\n",
       "      <td>0.522842</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814839</td>\n",
       "      <td>0.814621</td>\n",
       "      <td>0.814211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.162800</td>\n",
       "      <td>0.538862</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811872</td>\n",
       "      <td>0.810190</td>\n",
       "      <td>0.810361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.139100</td>\n",
       "      <td>0.587849</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.803023</td>\n",
       "      <td>0.803023</td>\n",
       "      <td>0.802752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.121000</td>\n",
       "      <td>0.630350</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.802279</td>\n",
       "      <td>0.802023</td>\n",
       "      <td>0.801593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.105700</td>\n",
       "      <td>0.731946</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809682</td>\n",
       "      <td>0.809779</td>\n",
       "      <td>0.809624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.095300</td>\n",
       "      <td>0.744622</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.807093</td>\n",
       "      <td>0.805643</td>\n",
       "      <td>0.805804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.085700</td>\n",
       "      <td>0.812466</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.795069</td>\n",
       "      <td>0.793266</td>\n",
       "      <td>0.792232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.079600</td>\n",
       "      <td>0.798995</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.800507</td>\n",
       "      <td>0.800602</td>\n",
       "      <td>0.800449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 13:59:50,900] Trial 22 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 23 with params: {'learning_rate': 6.51901776232881e-05, 'weight_decay': 0.002, 'warmup_steps': 42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 03:21 < 06:43, 10.44 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.484800</td>\n",
       "      <td>0.445062</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805010</td>\n",
       "      <td>0.805107</td>\n",
       "      <td>0.805020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.323800</td>\n",
       "      <td>0.431336</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810760</td>\n",
       "      <td>0.810863</td>\n",
       "      <td>0.810760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.265900</td>\n",
       "      <td>0.438527</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.818620</td>\n",
       "      <td>0.818692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.232700</td>\n",
       "      <td>0.475525</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821698</td>\n",
       "      <td>0.820662</td>\n",
       "      <td>0.820829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.207800</td>\n",
       "      <td>0.468937</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811007</td>\n",
       "      <td>0.811032</td>\n",
       "      <td>0.810780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 14:03:13,302] Trial 23 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 24 with params: {'learning_rate': 3.9182923462709525e-05, 'weight_decay': 0.007, 'warmup_steps': 29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 10:04, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.527300</td>\n",
       "      <td>0.464649</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792418</td>\n",
       "      <td>0.792256</td>\n",
       "      <td>0.792311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.372300</td>\n",
       "      <td>0.436934</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806239</td>\n",
       "      <td>0.805980</td>\n",
       "      <td>0.806058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.315600</td>\n",
       "      <td>0.435243</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810731</td>\n",
       "      <td>0.810821</td>\n",
       "      <td>0.810750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.451126</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818972</td>\n",
       "      <td>0.818536</td>\n",
       "      <td>0.818646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.256400</td>\n",
       "      <td>0.437978</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813025</td>\n",
       "      <td>0.813116</td>\n",
       "      <td>0.813044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.237100</td>\n",
       "      <td>0.455002</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814494</td>\n",
       "      <td>0.814494</td>\n",
       "      <td>0.814220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.223800</td>\n",
       "      <td>0.473219</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815596</td>\n",
       "      <td>0.815621</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.212300</td>\n",
       "      <td>0.478184</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814175</td>\n",
       "      <td>0.814116</td>\n",
       "      <td>0.814141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.201800</td>\n",
       "      <td>0.488377</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.815304</td>\n",
       "      <td>0.814747</td>\n",
       "      <td>0.814185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.194600</td>\n",
       "      <td>0.492344</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819889</td>\n",
       "      <td>0.819915</td>\n",
       "      <td>0.819901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.189300</td>\n",
       "      <td>0.495636</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.185100</td>\n",
       "      <td>0.500508</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.182500</td>\n",
       "      <td>0.501725</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817641</td>\n",
       "      <td>0.817746</td>\n",
       "      <td>0.817641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.177600</td>\n",
       "      <td>0.510692</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817597</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.176600</td>\n",
       "      <td>0.511462</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814153</td>\n",
       "      <td>0.814200</td>\n",
       "      <td>0.814172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 14:13:19,235] Trial 24 finished with value: 0.814172283698243 and parameters: {'learning_rate': 3.9182923462709525e-05, 'weight_decay': 0.007, 'warmup_steps': 29}. Best is trial 21 with value: 0.8176065796760941.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 with params: {'learning_rate': 0.0003026895453749053, 'weight_decay': 0.0, 'warmup_steps': 27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 03:20 < 06:41, 10.48 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.375300</td>\n",
       "      <td>0.435407</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.801850</td>\n",
       "      <td>0.799150</td>\n",
       "      <td>0.797858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.217100</td>\n",
       "      <td>0.541408</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810971</td>\n",
       "      <td>0.810485</td>\n",
       "      <td>0.810598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.160500</td>\n",
       "      <td>0.621798</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815390</td>\n",
       "      <td>0.815494</td>\n",
       "      <td>0.815355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.125900</td>\n",
       "      <td>0.610062</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810746</td>\n",
       "      <td>0.810653</td>\n",
       "      <td>0.810690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.102400</td>\n",
       "      <td>0.770615</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795981</td>\n",
       "      <td>0.796055</td>\n",
       "      <td>0.795867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 14:16:40,897] Trial 25 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 with params: {'learning_rate': 1.5421203730264887e-05, 'weight_decay': 0.01, 'warmup_steps': 42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 06:48 < 03:24, 10.29 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.619000</td>\n",
       "      <td>0.530811</td>\n",
       "      <td>0.754587</td>\n",
       "      <td>0.754947</td>\n",
       "      <td>0.754126</td>\n",
       "      <td>0.754213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.466900</td>\n",
       "      <td>0.467876</td>\n",
       "      <td>0.780963</td>\n",
       "      <td>0.780986</td>\n",
       "      <td>0.781079</td>\n",
       "      <td>0.780949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.408700</td>\n",
       "      <td>0.454543</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794676</td>\n",
       "      <td>0.794761</td>\n",
       "      <td>0.794692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.376800</td>\n",
       "      <td>0.453688</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791564</td>\n",
       "      <td>0.790919</td>\n",
       "      <td>0.791037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.354200</td>\n",
       "      <td>0.447563</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.800865</td>\n",
       "      <td>0.800055</td>\n",
       "      <td>0.800190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.335400</td>\n",
       "      <td>0.439212</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811891</td>\n",
       "      <td>0.811990</td>\n",
       "      <td>0.811902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.323000</td>\n",
       "      <td>0.437797</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808564</td>\n",
       "      <td>0.808653</td>\n",
       "      <td>0.808480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.310600</td>\n",
       "      <td>0.439416</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813009</td>\n",
       "      <td>0.813074</td>\n",
       "      <td>0.813032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.301200</td>\n",
       "      <td>0.439181</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812037</td>\n",
       "      <td>0.812116</td>\n",
       "      <td>0.811923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.294500</td>\n",
       "      <td>0.443126</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815489</td>\n",
       "      <td>0.815115</td>\n",
       "      <td>0.815215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 14:23:30,786] Trial 26 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 27 with params: {'learning_rate': 2.968297395257728e-05, 'weight_decay': 0.0, 'warmup_steps': 37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 10:09, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>0.472553</td>\n",
       "      <td>0.786697</td>\n",
       "      <td>0.786698</td>\n",
       "      <td>0.786499</td>\n",
       "      <td>0.786561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.398700</td>\n",
       "      <td>0.444844</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.800474</td>\n",
       "      <td>0.800265</td>\n",
       "      <td>0.800332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.343200</td>\n",
       "      <td>0.435863</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808632</td>\n",
       "      <td>0.808695</td>\n",
       "      <td>0.808484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.310600</td>\n",
       "      <td>0.446266</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816969</td>\n",
       "      <td>0.816115</td>\n",
       "      <td>0.816266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.285500</td>\n",
       "      <td>0.434920</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817631</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.265700</td>\n",
       "      <td>0.440511</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815445</td>\n",
       "      <td>0.815536</td>\n",
       "      <td>0.815361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.252300</td>\n",
       "      <td>0.450539</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810120</td>\n",
       "      <td>0.809990</td>\n",
       "      <td>0.809629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.240300</td>\n",
       "      <td>0.455377</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>0.460458</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.222300</td>\n",
       "      <td>0.465389</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.216900</td>\n",
       "      <td>0.466018</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.212600</td>\n",
       "      <td>0.468705</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815445</td>\n",
       "      <td>0.815536</td>\n",
       "      <td>0.815361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.210200</td>\n",
       "      <td>0.469946</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814185</td>\n",
       "      <td>0.814284</td>\n",
       "      <td>0.814196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.204900</td>\n",
       "      <td>0.475598</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.203800</td>\n",
       "      <td>0.476638</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 14:33:41,416] Trial 27 finished with value: 0.8210406668350594 and parameters: {'learning_rate': 2.968297395257728e-05, 'weight_decay': 0.0, 'warmup_steps': 37}. Best is trial 27 with value: 0.8210406668350594.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 28 with params: {'learning_rate': 2.3378491074230134e-05, 'weight_decay': 0.0, 'warmup_steps': 35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 10:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>0.485068</td>\n",
       "      <td>0.782110</td>\n",
       "      <td>0.782283</td>\n",
       "      <td>0.781784</td>\n",
       "      <td>0.781885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.421600</td>\n",
       "      <td>0.453978</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793507</td>\n",
       "      <td>0.793551</td>\n",
       "      <td>0.793525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.367000</td>\n",
       "      <td>0.440464</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808713</td>\n",
       "      <td>0.808737</td>\n",
       "      <td>0.808486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.334800</td>\n",
       "      <td>0.446589</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.804788</td>\n",
       "      <td>0.803349</td>\n",
       "      <td>0.803506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.310600</td>\n",
       "      <td>0.438215</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814307</td>\n",
       "      <td>0.813989</td>\n",
       "      <td>0.814079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.436528</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815348</td>\n",
       "      <td>0.815452</td>\n",
       "      <td>0.815347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.277800</td>\n",
       "      <td>0.440311</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811209</td>\n",
       "      <td>0.811116</td>\n",
       "      <td>0.810778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.265400</td>\n",
       "      <td>0.444888</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811863</td>\n",
       "      <td>0.811863</td>\n",
       "      <td>0.811863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>0.447509</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810007</td>\n",
       "      <td>0.809948</td>\n",
       "      <td>0.809632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.247800</td>\n",
       "      <td>0.451377</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817631</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.242100</td>\n",
       "      <td>0.450699</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817641</td>\n",
       "      <td>0.817746</td>\n",
       "      <td>0.817641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.237700</td>\n",
       "      <td>0.452584</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.235100</td>\n",
       "      <td>0.453809</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>0.456960</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817641</td>\n",
       "      <td>0.817746</td>\n",
       "      <td>0.817641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.228500</td>\n",
       "      <td>0.457556</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816620</td>\n",
       "      <td>0.816498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 14:43:55,170] Trial 28 finished with value: 0.8164983164983165 and parameters: {'learning_rate': 2.3378491074230134e-05, 'weight_decay': 0.0, 'warmup_steps': 35}. Best is trial 27 with value: 0.8210406668350594.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 29 with params: {'learning_rate': 5.987571743934924e-05, 'weight_decay': 0.006, 'warmup_steps': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 06:46 < 03:23, 10.34 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.486800</td>\n",
       "      <td>0.446797</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.804977</td>\n",
       "      <td>0.805022</td>\n",
       "      <td>0.804996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.331400</td>\n",
       "      <td>0.430145</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810760</td>\n",
       "      <td>0.810863</td>\n",
       "      <td>0.810760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.273800</td>\n",
       "      <td>0.437763</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816470</td>\n",
       "      <td>0.816410</td>\n",
       "      <td>0.816436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.240500</td>\n",
       "      <td>0.469815</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823756</td>\n",
       "      <td>0.823040</td>\n",
       "      <td>0.823185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.215100</td>\n",
       "      <td>0.461497</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811102</td>\n",
       "      <td>0.811074</td>\n",
       "      <td>0.810780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.197800</td>\n",
       "      <td>0.489110</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814981</td>\n",
       "      <td>0.814663</td>\n",
       "      <td>0.814205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.183900</td>\n",
       "      <td>0.513199</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818918</td>\n",
       "      <td>0.818999</td>\n",
       "      <td>0.818804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.173500</td>\n",
       "      <td>0.534864</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816759</td>\n",
       "      <td>0.816199</td>\n",
       "      <td>0.816324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.163200</td>\n",
       "      <td>0.549102</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.811287</td>\n",
       "      <td>0.810285</td>\n",
       "      <td>0.809552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.156300</td>\n",
       "      <td>0.555292</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814185</td>\n",
       "      <td>0.814284</td>\n",
       "      <td>0.814196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 14:50:43,090] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 with params: {'learning_rate': 2.1223336686458735e-05, 'weight_decay': 0.005, 'warmup_steps': 33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 10:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.587200</td>\n",
       "      <td>0.492097</td>\n",
       "      <td>0.775229</td>\n",
       "      <td>0.775663</td>\n",
       "      <td>0.774775</td>\n",
       "      <td>0.774887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.431000</td>\n",
       "      <td>0.456821</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794658</td>\n",
       "      <td>0.794719</td>\n",
       "      <td>0.794679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.376600</td>\n",
       "      <td>0.443130</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803977</td>\n",
       "      <td>0.804065</td>\n",
       "      <td>0.803893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.344600</td>\n",
       "      <td>0.447571</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.802820</td>\n",
       "      <td>0.800970</td>\n",
       "      <td>0.801122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.320800</td>\n",
       "      <td>0.440079</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814461</td>\n",
       "      <td>0.813905</td>\n",
       "      <td>0.814028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.301300</td>\n",
       "      <td>0.436148</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813025</td>\n",
       "      <td>0.813116</td>\n",
       "      <td>0.813044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.288300</td>\n",
       "      <td>0.438203</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811209</td>\n",
       "      <td>0.811116</td>\n",
       "      <td>0.810778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.275900</td>\n",
       "      <td>0.442337</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815301</td>\n",
       "      <td>0.815326</td>\n",
       "      <td>0.815312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.265600</td>\n",
       "      <td>0.444023</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812301</td>\n",
       "      <td>0.812242</td>\n",
       "      <td>0.811926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.258600</td>\n",
       "      <td>0.447878</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816501</td>\n",
       "      <td>0.816368</td>\n",
       "      <td>0.816417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.252800</td>\n",
       "      <td>0.446185</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819906</td>\n",
       "      <td>0.819999</td>\n",
       "      <td>0.819925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.248300</td>\n",
       "      <td>0.447778</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818856</td>\n",
       "      <td>0.818957</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.245600</td>\n",
       "      <td>0.448857</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.241000</td>\n",
       "      <td>0.451154</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819906</td>\n",
       "      <td>0.819999</td>\n",
       "      <td>0.819925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.239000</td>\n",
       "      <td>0.451722</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818772</td>\n",
       "      <td>0.818873</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 15:00:57,707] Trial 30 finished with value: 0.8187835072157246 and parameters: {'learning_rate': 2.1223336686458735e-05, 'weight_decay': 0.005, 'warmup_steps': 33}. Best is trial 27 with value: 0.8210406668350594.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 31 with params: {'learning_rate': 1.3271009826348826e-05, 'weight_decay': 0.003, 'warmup_steps': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 03:21 < 06:44, 10.42 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.629600</td>\n",
       "      <td>0.552509</td>\n",
       "      <td>0.738532</td>\n",
       "      <td>0.738560</td>\n",
       "      <td>0.738234</td>\n",
       "      <td>0.738299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.486200</td>\n",
       "      <td>0.474619</td>\n",
       "      <td>0.784404</td>\n",
       "      <td>0.784668</td>\n",
       "      <td>0.784668</td>\n",
       "      <td>0.784404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.423900</td>\n",
       "      <td>0.459902</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792382</td>\n",
       "      <td>0.792467</td>\n",
       "      <td>0.792398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.392000</td>\n",
       "      <td>0.457578</td>\n",
       "      <td>0.786697</td>\n",
       "      <td>0.786880</td>\n",
       "      <td>0.786373</td>\n",
       "      <td>0.786477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.369900</td>\n",
       "      <td>0.451298</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792668</td>\n",
       "      <td>0.792088</td>\n",
       "      <td>0.792201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 15:04:20,610] Trial 31 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 32 with params: {'learning_rate': 1.8537060185862908e-05, 'weight_decay': 0.005, 'warmup_steps': 27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 10:07, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.599500</td>\n",
       "      <td>0.505006</td>\n",
       "      <td>0.768349</td>\n",
       "      <td>0.768868</td>\n",
       "      <td>0.767850</td>\n",
       "      <td>0.767953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.444900</td>\n",
       "      <td>0.461033</td>\n",
       "      <td>0.790138</td>\n",
       "      <td>0.790071</td>\n",
       "      <td>0.790130</td>\n",
       "      <td>0.790091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.390100</td>\n",
       "      <td>0.447719</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798213</td>\n",
       "      <td>0.798308</td>\n",
       "      <td>0.798156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.358200</td>\n",
       "      <td>0.449569</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.797591</td>\n",
       "      <td>0.796550</td>\n",
       "      <td>0.796691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.335000</td>\n",
       "      <td>0.443253</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814461</td>\n",
       "      <td>0.813905</td>\n",
       "      <td>0.814028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.315900</td>\n",
       "      <td>0.436920</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815303</td>\n",
       "      <td>0.815368</td>\n",
       "      <td>0.815326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.303000</td>\n",
       "      <td>0.437180</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811007</td>\n",
       "      <td>0.811032</td>\n",
       "      <td>0.810780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.290600</td>\n",
       "      <td>0.440323</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811869</td>\n",
       "      <td>0.811947</td>\n",
       "      <td>0.811891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.280700</td>\n",
       "      <td>0.441264</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809906</td>\n",
       "      <td>0.809906</td>\n",
       "      <td>0.809633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.273800</td>\n",
       "      <td>0.445020</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815374</td>\n",
       "      <td>0.815200</td>\n",
       "      <td>0.815260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.267900</td>\n",
       "      <td>0.442024</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810731</td>\n",
       "      <td>0.810821</td>\n",
       "      <td>0.810750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.263300</td>\n",
       "      <td>0.443252</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813054</td>\n",
       "      <td>0.813158</td>\n",
       "      <td>0.813053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.260600</td>\n",
       "      <td>0.443793</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812032</td>\n",
       "      <td>0.811911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.256400</td>\n",
       "      <td>0.445569</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814153</td>\n",
       "      <td>0.814200</td>\n",
       "      <td>0.814172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.254100</td>\n",
       "      <td>0.445925</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816456</td>\n",
       "      <td>0.816536</td>\n",
       "      <td>0.816479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 15:14:29,580] Trial 32 finished with value: 0.8164790066294854 and parameters: {'learning_rate': 1.8537060185862908e-05, 'weight_decay': 0.005, 'warmup_steps': 27}. Best is trial 27 with value: 0.8210406668350594.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 33 with params: {'learning_rate': 4.795168759678875e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 40}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 06:42 < 03:21, 10.45 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.511600</td>\n",
       "      <td>0.457122</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793637</td>\n",
       "      <td>0.793340</td>\n",
       "      <td>0.793421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.353200</td>\n",
       "      <td>0.432191</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808438</td>\n",
       "      <td>0.808527</td>\n",
       "      <td>0.808456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.295600</td>\n",
       "      <td>0.437868</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.261900</td>\n",
       "      <td>0.458078</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820017</td>\n",
       "      <td>0.819746</td>\n",
       "      <td>0.819829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.236000</td>\n",
       "      <td>0.446449</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813096</td>\n",
       "      <td>0.813200</td>\n",
       "      <td>0.813061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.217700</td>\n",
       "      <td>0.470423</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814494</td>\n",
       "      <td>0.814494</td>\n",
       "      <td>0.814220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.204200</td>\n",
       "      <td>0.491395</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812301</td>\n",
       "      <td>0.812242</td>\n",
       "      <td>0.811926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.193000</td>\n",
       "      <td>0.503736</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815336</td>\n",
       "      <td>0.815242</td>\n",
       "      <td>0.815279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.182700</td>\n",
       "      <td>0.515613</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810708</td>\n",
       "      <td>0.810158</td>\n",
       "      <td>0.809597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.175700</td>\n",
       "      <td>0.521592</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816478</td>\n",
       "      <td>0.816578</td>\n",
       "      <td>0.816490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 15:21:13,247] Trial 33 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 34 with params: {'learning_rate': 4.762569890675935e-05, 'weight_decay': 0.004, 'warmup_steps': 26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 10:05, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.508800</td>\n",
       "      <td>0.456994</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792518</td>\n",
       "      <td>0.792172</td>\n",
       "      <td>0.792260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.353400</td>\n",
       "      <td>0.432231</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808438</td>\n",
       "      <td>0.808527</td>\n",
       "      <td>0.808456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.296200</td>\n",
       "      <td>0.437926</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.262600</td>\n",
       "      <td>0.457898</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820017</td>\n",
       "      <td>0.819746</td>\n",
       "      <td>0.819829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.236700</td>\n",
       "      <td>0.446094</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813096</td>\n",
       "      <td>0.813200</td>\n",
       "      <td>0.813061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.218400</td>\n",
       "      <td>0.469164</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813396</td>\n",
       "      <td>0.813368</td>\n",
       "      <td>0.813073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.204900</td>\n",
       "      <td>0.490271</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812301</td>\n",
       "      <td>0.812242</td>\n",
       "      <td>0.811926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.193700</td>\n",
       "      <td>0.502440</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816501</td>\n",
       "      <td>0.816368</td>\n",
       "      <td>0.816417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.183400</td>\n",
       "      <td>0.513555</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810708</td>\n",
       "      <td>0.810158</td>\n",
       "      <td>0.809597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.519685</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815319</td>\n",
       "      <td>0.815410</td>\n",
       "      <td>0.815338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.171100</td>\n",
       "      <td>0.524054</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816456</td>\n",
       "      <td>0.816536</td>\n",
       "      <td>0.816479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.166900</td>\n",
       "      <td>0.529153</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815445</td>\n",
       "      <td>0.815536</td>\n",
       "      <td>0.815361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.164100</td>\n",
       "      <td>0.530908</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814269</td>\n",
       "      <td>0.814368</td>\n",
       "      <td>0.814211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.159300</td>\n",
       "      <td>0.542661</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815319</td>\n",
       "      <td>0.815410</td>\n",
       "      <td>0.815338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.158400</td>\n",
       "      <td>0.543883</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816456</td>\n",
       "      <td>0.816536</td>\n",
       "      <td>0.816479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 15:31:20,164] Trial 34 finished with value: 0.8164790066294854 and parameters: {'learning_rate': 4.762569890675935e-05, 'weight_decay': 0.004, 'warmup_steps': 26}. Best is trial 27 with value: 0.8210406668350594.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 35 with params: {'learning_rate': 5.820403075952114e-05, 'weight_decay': 0.003, 'warmup_steps': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 06:41 < 03:20, 10.49 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.489300</td>\n",
       "      <td>0.447892</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.801536</td>\n",
       "      <td>0.801560</td>\n",
       "      <td>0.801547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.334000</td>\n",
       "      <td>0.430155</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811891</td>\n",
       "      <td>0.811990</td>\n",
       "      <td>0.811902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.276500</td>\n",
       "      <td>0.437776</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816470</td>\n",
       "      <td>0.816410</td>\n",
       "      <td>0.816436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.243200</td>\n",
       "      <td>0.468046</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821456</td>\n",
       "      <td>0.820746</td>\n",
       "      <td>0.820889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.217700</td>\n",
       "      <td>0.459060</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813396</td>\n",
       "      <td>0.813368</td>\n",
       "      <td>0.813073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.200300</td>\n",
       "      <td>0.486240</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813760</td>\n",
       "      <td>0.813495</td>\n",
       "      <td>0.813061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.186400</td>\n",
       "      <td>0.509586</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.175900</td>\n",
       "      <td>0.530453</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816675</td>\n",
       "      <td>0.816241</td>\n",
       "      <td>0.816350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.165600</td>\n",
       "      <td>0.544112</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.810032</td>\n",
       "      <td>0.809116</td>\n",
       "      <td>0.808413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.158700</td>\n",
       "      <td>0.550525</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813025</td>\n",
       "      <td>0.813116</td>\n",
       "      <td>0.813044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 15:38:02,225] Trial 35 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 36 with params: {'learning_rate': 0.0004180301872969493, 'weight_decay': 0.006, 'warmup_steps': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 06:42 < 03:21, 10.45 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.355300</td>\n",
       "      <td>0.435383</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.811740</td>\n",
       "      <td>0.810369</td>\n",
       "      <td>0.809512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.206100</td>\n",
       "      <td>0.601377</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.796505</td>\n",
       "      <td>0.795382</td>\n",
       "      <td>0.795523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>0.588913</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808509</td>\n",
       "      <td>0.808611</td>\n",
       "      <td>0.808474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.113200</td>\n",
       "      <td>0.648933</td>\n",
       "      <td>0.787844</td>\n",
       "      <td>0.788804</td>\n",
       "      <td>0.787246</td>\n",
       "      <td>0.787374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.090500</td>\n",
       "      <td>0.827626</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793586</td>\n",
       "      <td>0.793382</td>\n",
       "      <td>0.793447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.885744</td>\n",
       "      <td>0.787844</td>\n",
       "      <td>0.787795</td>\n",
       "      <td>0.787878</td>\n",
       "      <td>0.787810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.061800</td>\n",
       "      <td>0.902952</td>\n",
       "      <td>0.787844</td>\n",
       "      <td>0.788259</td>\n",
       "      <td>0.788173</td>\n",
       "      <td>0.787842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.053600</td>\n",
       "      <td>0.946650</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794681</td>\n",
       "      <td>0.794592</td>\n",
       "      <td>0.794627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>1.158072</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.798736</td>\n",
       "      <td>0.793729</td>\n",
       "      <td>0.791774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>1.076639</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.795390</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>0.794712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 15:44:45,757] Trial 36 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 37 with params: {'learning_rate': 1.795062715761262e-05, 'weight_decay': 0.006, 'warmup_steps': 35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 03:00 < 06:01, 11.66 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.604100</td>\n",
       "      <td>0.509395</td>\n",
       "      <td>0.767202</td>\n",
       "      <td>0.767776</td>\n",
       "      <td>0.766681</td>\n",
       "      <td>0.766782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.448700</td>\n",
       "      <td>0.462161</td>\n",
       "      <td>0.790138</td>\n",
       "      <td>0.790071</td>\n",
       "      <td>0.790130</td>\n",
       "      <td>0.790091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.393300</td>\n",
       "      <td>0.448929</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794705</td>\n",
       "      <td>0.794803</td>\n",
       "      <td>0.794703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.361400</td>\n",
       "      <td>0.450197</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.795289</td>\n",
       "      <td>0.794256</td>\n",
       "      <td>0.794394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.338400</td>\n",
       "      <td>0.443971</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808673</td>\n",
       "      <td>0.808190</td>\n",
       "      <td>0.808302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 15:47:47,363] Trial 37 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 38 with params: {'learning_rate': 2.428567376732491e-05, 'weight_decay': 0.0, 'warmup_steps': 43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:53, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.575900</td>\n",
       "      <td>0.482828</td>\n",
       "      <td>0.782110</td>\n",
       "      <td>0.782366</td>\n",
       "      <td>0.781742</td>\n",
       "      <td>0.781852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.418100</td>\n",
       "      <td>0.452714</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793507</td>\n",
       "      <td>0.793551</td>\n",
       "      <td>0.793525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.363300</td>\n",
       "      <td>0.439498</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809906</td>\n",
       "      <td>0.809906</td>\n",
       "      <td>0.809633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.331000</td>\n",
       "      <td>0.446303</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806940</td>\n",
       "      <td>0.805685</td>\n",
       "      <td>0.805843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.306600</td>\n",
       "      <td>0.437479</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816546</td>\n",
       "      <td>0.816326</td>\n",
       "      <td>0.816397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.286800</td>\n",
       "      <td>0.436833</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814326</td>\n",
       "      <td>0.814205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.273600</td>\n",
       "      <td>0.441461</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810120</td>\n",
       "      <td>0.809990</td>\n",
       "      <td>0.809629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.261300</td>\n",
       "      <td>0.446160</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813007</td>\n",
       "      <td>0.813031</td>\n",
       "      <td>0.813018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.250800</td>\n",
       "      <td>0.449175</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811330</td>\n",
       "      <td>0.811158</td>\n",
       "      <td>0.810774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.243600</td>\n",
       "      <td>0.453090</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.237900</td>\n",
       "      <td>0.452839</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818772</td>\n",
       "      <td>0.818873</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.233500</td>\n",
       "      <td>0.454906</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815514</td>\n",
       "      <td>0.815578</td>\n",
       "      <td>0.815365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.231000</td>\n",
       "      <td>0.456084</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.226000</td>\n",
       "      <td>0.459590</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818772</td>\n",
       "      <td>0.818873</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.224400</td>\n",
       "      <td>0.460236</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817641</td>\n",
       "      <td>0.817746</td>\n",
       "      <td>0.817641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 15:53:42,808] Trial 38 finished with value: 0.8176411246568802 and parameters: {'learning_rate': 2.428567376732491e-05, 'weight_decay': 0.0, 'warmup_steps': 43}. Best is trial 27 with value: 0.8210406668350594.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 39 with params: {'learning_rate': 1.0718747648822253e-05, 'weight_decay': 0.001, 'warmup_steps': 39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:53 < 01:56, 18.01 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.644100</td>\n",
       "      <td>0.584723</td>\n",
       "      <td>0.725917</td>\n",
       "      <td>0.725947</td>\n",
       "      <td>0.725594</td>\n",
       "      <td>0.725654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.518600</td>\n",
       "      <td>0.488497</td>\n",
       "      <td>0.782110</td>\n",
       "      <td>0.783127</td>\n",
       "      <td>0.782626</td>\n",
       "      <td>0.782069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.446700</td>\n",
       "      <td>0.467820</td>\n",
       "      <td>0.790138</td>\n",
       "      <td>0.790088</td>\n",
       "      <td>0.790172</td>\n",
       "      <td>0.790104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.413700</td>\n",
       "      <td>0.463598</td>\n",
       "      <td>0.785550</td>\n",
       "      <td>0.785693</td>\n",
       "      <td>0.785247</td>\n",
       "      <td>0.785345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.392000</td>\n",
       "      <td>0.457488</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792518</td>\n",
       "      <td>0.792172</td>\n",
       "      <td>0.792260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.373500</td>\n",
       "      <td>0.448136</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.799246</td>\n",
       "      <td>0.799307</td>\n",
       "      <td>0.799267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.362100</td>\n",
       "      <td>0.444314</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806270</td>\n",
       "      <td>0.806359</td>\n",
       "      <td>0.806186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.350400</td>\n",
       "      <td>0.442985</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810802</td>\n",
       "      <td>0.810906</td>\n",
       "      <td>0.810768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.341800</td>\n",
       "      <td>0.441009</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807449</td>\n",
       "      <td>0.807527</td>\n",
       "      <td>0.807335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.335200</td>\n",
       "      <td>0.443898</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809658</td>\n",
       "      <td>0.809443</td>\n",
       "      <td>0.809512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 15:57:37,451] Trial 39 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 40 with params: {'learning_rate': 1.9560937675681444e-05, 'weight_decay': 0.0, 'warmup_steps': 43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:54 < 01:57, 17.91 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.597200</td>\n",
       "      <td>0.500498</td>\n",
       "      <td>0.768349</td>\n",
       "      <td>0.768868</td>\n",
       "      <td>0.767850</td>\n",
       "      <td>0.767953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.439800</td>\n",
       "      <td>0.459567</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794676</td>\n",
       "      <td>0.794761</td>\n",
       "      <td>0.794692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.384800</td>\n",
       "      <td>0.445929</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803977</td>\n",
       "      <td>0.804065</td>\n",
       "      <td>0.803893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.352800</td>\n",
       "      <td>0.448701</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.799103</td>\n",
       "      <td>0.797592</td>\n",
       "      <td>0.797740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.329300</td>\n",
       "      <td>0.442103</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813269</td>\n",
       "      <td>0.812779</td>\n",
       "      <td>0.812894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.436626</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816456</td>\n",
       "      <td>0.816536</td>\n",
       "      <td>0.816479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.297100</td>\n",
       "      <td>0.437474</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808914</td>\n",
       "      <td>0.808822</td>\n",
       "      <td>0.808484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.284600</td>\n",
       "      <td>0.441031</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813009</td>\n",
       "      <td>0.813074</td>\n",
       "      <td>0.813032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.274600</td>\n",
       "      <td>0.442349</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812301</td>\n",
       "      <td>0.812242</td>\n",
       "      <td>0.811926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.267600</td>\n",
       "      <td>0.446031</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815336</td>\n",
       "      <td>0.815242</td>\n",
       "      <td>0.815279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 16:01:33,424] Trial 40 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 41 with params: {'learning_rate': 1.2431112024586663e-05, 'weight_decay': 0.0, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:01 < 02:00, 17.40 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.630700</td>\n",
       "      <td>0.558895</td>\n",
       "      <td>0.739679</td>\n",
       "      <td>0.739647</td>\n",
       "      <td>0.739444</td>\n",
       "      <td>0.739498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.493500</td>\n",
       "      <td>0.477738</td>\n",
       "      <td>0.782110</td>\n",
       "      <td>0.782469</td>\n",
       "      <td>0.782416</td>\n",
       "      <td>0.782109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.430200</td>\n",
       "      <td>0.462002</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792382</td>\n",
       "      <td>0.792467</td>\n",
       "      <td>0.792398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.398500</td>\n",
       "      <td>0.459454</td>\n",
       "      <td>0.785550</td>\n",
       "      <td>0.785693</td>\n",
       "      <td>0.785247</td>\n",
       "      <td>0.785345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.376600</td>\n",
       "      <td>0.453057</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793775</td>\n",
       "      <td>0.793256</td>\n",
       "      <td>0.793365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.358200</td>\n",
       "      <td>0.444075</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810802</td>\n",
       "      <td>0.810906</td>\n",
       "      <td>0.810768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.346500</td>\n",
       "      <td>0.440977</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813220</td>\n",
       "      <td>0.813284</td>\n",
       "      <td>0.813071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.334500</td>\n",
       "      <td>0.440877</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808438</td>\n",
       "      <td>0.808527</td>\n",
       "      <td>0.808456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.325600</td>\n",
       "      <td>0.439421</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811891</td>\n",
       "      <td>0.811990</td>\n",
       "      <td>0.811902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.319000</td>\n",
       "      <td>0.443096</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812010</td>\n",
       "      <td>0.811695</td>\n",
       "      <td>0.811784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 16:05:36,329] Trial 41 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 42 with params: {'learning_rate': 4.5074303476162835e-05, 'weight_decay': 0.0, 'warmup_steps': 33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:54 < 01:57, 17.93 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.515500</td>\n",
       "      <td>0.459516</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793637</td>\n",
       "      <td>0.793340</td>\n",
       "      <td>0.793421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.358900</td>\n",
       "      <td>0.433328</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810715</td>\n",
       "      <td>0.810779</td>\n",
       "      <td>0.810738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.301700</td>\n",
       "      <td>0.437077</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.268000</td>\n",
       "      <td>0.455695</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821197</td>\n",
       "      <td>0.820872</td>\n",
       "      <td>0.820965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.242100</td>\n",
       "      <td>0.443411</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813151</td>\n",
       "      <td>0.813242</td>\n",
       "      <td>0.813067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.223500</td>\n",
       "      <td>0.465024</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813396</td>\n",
       "      <td>0.813368</td>\n",
       "      <td>0.813073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.210100</td>\n",
       "      <td>0.485656</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811007</td>\n",
       "      <td>0.811032</td>\n",
       "      <td>0.810780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.198800</td>\n",
       "      <td>0.494939</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814158</td>\n",
       "      <td>0.814158</td>\n",
       "      <td>0.814158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.506061</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811772</td>\n",
       "      <td>0.811284</td>\n",
       "      <td>0.810750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.181400</td>\n",
       "      <td>0.511279</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816456</td>\n",
       "      <td>0.816536</td>\n",
       "      <td>0.816479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 16:09:32,270] Trial 42 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 43 with params: {'learning_rate': 3.472712926997433e-05, 'weight_decay': 0.001, 'warmup_steps': 43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:53, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.541700</td>\n",
       "      <td>0.467896</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792386</td>\n",
       "      <td>0.792298</td>\n",
       "      <td>0.792333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.384200</td>\n",
       "      <td>0.440298</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.802770</td>\n",
       "      <td>0.802560</td>\n",
       "      <td>0.802627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.327700</td>\n",
       "      <td>0.434538</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809737</td>\n",
       "      <td>0.809617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.294600</td>\n",
       "      <td>0.448246</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814377</td>\n",
       "      <td>0.813947</td>\n",
       "      <td>0.814055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.269000</td>\n",
       "      <td>0.434829</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811859</td>\n",
       "      <td>0.811905</td>\n",
       "      <td>0.811878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.249400</td>\n",
       "      <td>0.447569</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817808</td>\n",
       "      <td>0.817873</td>\n",
       "      <td>0.817658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.236000</td>\n",
       "      <td>0.461926</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815691</td>\n",
       "      <td>0.815663</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.224200</td>\n",
       "      <td>0.466492</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.213600</td>\n",
       "      <td>0.474600</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.816057</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.815355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.206400</td>\n",
       "      <td>0.478975</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822196</td>\n",
       "      <td>0.822167</td>\n",
       "      <td>0.822180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.201000</td>\n",
       "      <td>0.480772</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818765</td>\n",
       "      <td>0.818704</td>\n",
       "      <td>0.818730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.196800</td>\n",
       "      <td>0.484366</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815445</td>\n",
       "      <td>0.815536</td>\n",
       "      <td>0.815361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.194400</td>\n",
       "      <td>0.485768</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819906</td>\n",
       "      <td>0.819999</td>\n",
       "      <td>0.819925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.189200</td>\n",
       "      <td>0.493115</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.188300</td>\n",
       "      <td>0.494147</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 16:15:28,105] Trial 43 finished with value: 0.8176065796760941 and parameters: {'learning_rate': 3.472712926997433e-05, 'weight_decay': 0.001, 'warmup_steps': 43}. Best is trial 27 with value: 0.8210406668350594.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 44 with params: {'learning_rate': 5.969782925975992e-05, 'weight_decay': 0.0, 'warmup_steps': 40}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:55 < 01:57, 17.87 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.492000</td>\n",
       "      <td>0.447127</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807401</td>\n",
       "      <td>0.807314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.332000</td>\n",
       "      <td>0.430598</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810760</td>\n",
       "      <td>0.810863</td>\n",
       "      <td>0.810760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.274100</td>\n",
       "      <td>0.438239</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.240800</td>\n",
       "      <td>0.469760</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824962</td>\n",
       "      <td>0.824166</td>\n",
       "      <td>0.824319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.215400</td>\n",
       "      <td>0.461077</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813396</td>\n",
       "      <td>0.813368</td>\n",
       "      <td>0.813073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.198100</td>\n",
       "      <td>0.489548</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.816057</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.815355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.184200</td>\n",
       "      <td>0.512932</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.173600</td>\n",
       "      <td>0.534327</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814377</td>\n",
       "      <td>0.813947</td>\n",
       "      <td>0.814055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.549126</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.811081</td>\n",
       "      <td>0.810242</td>\n",
       "      <td>0.809569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.156400</td>\n",
       "      <td>0.555784</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810715</td>\n",
       "      <td>0.810779</td>\n",
       "      <td>0.810738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 16:19:24,484] Trial 44 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 45 with params: {'learning_rate': 2.3546370901208507e-05, 'weight_decay': 0.003, 'warmup_steps': 41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:54, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.578500</td>\n",
       "      <td>0.484808</td>\n",
       "      <td>0.782110</td>\n",
       "      <td>0.782283</td>\n",
       "      <td>0.781784</td>\n",
       "      <td>0.781885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.421100</td>\n",
       "      <td>0.453761</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793507</td>\n",
       "      <td>0.793551</td>\n",
       "      <td>0.793525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.440248</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808713</td>\n",
       "      <td>0.808737</td>\n",
       "      <td>0.808486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.334100</td>\n",
       "      <td>0.446458</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.804788</td>\n",
       "      <td>0.803349</td>\n",
       "      <td>0.803506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.309900</td>\n",
       "      <td>0.438000</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814307</td>\n",
       "      <td>0.813989</td>\n",
       "      <td>0.814079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.290100</td>\n",
       "      <td>0.436549</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816620</td>\n",
       "      <td>0.816498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.277000</td>\n",
       "      <td>0.440513</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811209</td>\n",
       "      <td>0.811116</td>\n",
       "      <td>0.810778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.264600</td>\n",
       "      <td>0.445129</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810723</td>\n",
       "      <td>0.810695</td>\n",
       "      <td>0.810708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.254200</td>\n",
       "      <td>0.447783</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810007</td>\n",
       "      <td>0.809948</td>\n",
       "      <td>0.809632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.247000</td>\n",
       "      <td>0.451682</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817631</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.241300</td>\n",
       "      <td>0.451115</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818772</td>\n",
       "      <td>0.818873</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.236800</td>\n",
       "      <td>0.453065</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>0.454261</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.229400</td>\n",
       "      <td>0.457429</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817612</td>\n",
       "      <td>0.817704</td>\n",
       "      <td>0.817632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.227700</td>\n",
       "      <td>0.458063</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817641</td>\n",
       "      <td>0.817746</td>\n",
       "      <td>0.817641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 16:25:20,258] Trial 45 finished with value: 0.8176411246568802 and parameters: {'learning_rate': 2.3546370901208507e-05, 'weight_decay': 0.003, 'warmup_steps': 41}. Best is trial 27 with value: 0.8210406668350594.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 46 with params: {'learning_rate': 1.4983957759694008e-05, 'weight_decay': 0.004, 'warmup_steps': 43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 01:57 < 03:55, 17.85 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.621600</td>\n",
       "      <td>0.535261</td>\n",
       "      <td>0.747706</td>\n",
       "      <td>0.748250</td>\n",
       "      <td>0.747158</td>\n",
       "      <td>0.747226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.470600</td>\n",
       "      <td>0.469100</td>\n",
       "      <td>0.782110</td>\n",
       "      <td>0.782158</td>\n",
       "      <td>0.782247</td>\n",
       "      <td>0.782100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.411600</td>\n",
       "      <td>0.455599</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.795887</td>\n",
       "      <td>0.795833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.379700</td>\n",
       "      <td>0.454390</td>\n",
       "      <td>0.790138</td>\n",
       "      <td>0.790369</td>\n",
       "      <td>0.789793</td>\n",
       "      <td>0.789905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.357200</td>\n",
       "      <td>0.448242</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.799662</td>\n",
       "      <td>0.798929</td>\n",
       "      <td>0.799058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 16:27:19,126] Trial 46 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 47 with params: {'learning_rate': 2.9399379535433413e-05, 'weight_decay': 0.005, 'warmup_steps': 39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:57, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.556400</td>\n",
       "      <td>0.472949</td>\n",
       "      <td>0.786697</td>\n",
       "      <td>0.786698</td>\n",
       "      <td>0.786499</td>\n",
       "      <td>0.786561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.399700</td>\n",
       "      <td>0.445148</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.800474</td>\n",
       "      <td>0.800265</td>\n",
       "      <td>0.800332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.344100</td>\n",
       "      <td>0.435993</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808632</td>\n",
       "      <td>0.808695</td>\n",
       "      <td>0.808484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.311600</td>\n",
       "      <td>0.446173</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816969</td>\n",
       "      <td>0.816115</td>\n",
       "      <td>0.816266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.286500</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817631</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.266600</td>\n",
       "      <td>0.440322</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815390</td>\n",
       "      <td>0.815494</td>\n",
       "      <td>0.815355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.253300</td>\n",
       "      <td>0.450002</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810120</td>\n",
       "      <td>0.809990</td>\n",
       "      <td>0.809629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.241300</td>\n",
       "      <td>0.454810</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.230600</td>\n",
       "      <td>0.459814</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814596</td>\n",
       "      <td>0.814536</td>\n",
       "      <td>0.814219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.223300</td>\n",
       "      <td>0.464673</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816447</td>\n",
       "      <td>0.816494</td>\n",
       "      <td>0.816466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.217800</td>\n",
       "      <td>0.465301</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.213500</td>\n",
       "      <td>0.467986</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815445</td>\n",
       "      <td>0.815536</td>\n",
       "      <td>0.815361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.211100</td>\n",
       "      <td>0.469159</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815348</td>\n",
       "      <td>0.815452</td>\n",
       "      <td>0.815347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.205900</td>\n",
       "      <td>0.474684</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816447</td>\n",
       "      <td>0.816494</td>\n",
       "      <td>0.816466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.204800</td>\n",
       "      <td>0.475734</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819889</td>\n",
       "      <td>0.819915</td>\n",
       "      <td>0.819901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 16:33:17,884] Trial 47 finished with value: 0.8199008365355143 and parameters: {'learning_rate': 2.9399379535433413e-05, 'weight_decay': 0.005, 'warmup_steps': 39}. Best is trial 27 with value: 0.8210406668350594.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 48 with params: {'learning_rate': 2.7666837299817864e-05, 'weight_decay': 0.003, 'warmup_steps': 43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:55, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.563100</td>\n",
       "      <td>0.475690</td>\n",
       "      <td>0.785550</td>\n",
       "      <td>0.785627</td>\n",
       "      <td>0.785289</td>\n",
       "      <td>0.785374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.405600</td>\n",
       "      <td>0.447385</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.800406</td>\n",
       "      <td>0.800349</td>\n",
       "      <td>0.800374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.350200</td>\n",
       "      <td>0.436906</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810926</td>\n",
       "      <td>0.810990</td>\n",
       "      <td>0.810778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.317800</td>\n",
       "      <td>0.446031</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811406</td>\n",
       "      <td>0.810316</td>\n",
       "      <td>0.810474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.292900</td>\n",
       "      <td>0.435561</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818796</td>\n",
       "      <td>0.818662</td>\n",
       "      <td>0.818712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.273000</td>\n",
       "      <td>0.439025</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815445</td>\n",
       "      <td>0.815536</td>\n",
       "      <td>0.815361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.259700</td>\n",
       "      <td>0.446847</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811330</td>\n",
       "      <td>0.811158</td>\n",
       "      <td>0.810774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.247500</td>\n",
       "      <td>0.451704</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818741</td>\n",
       "      <td>0.818788</td>\n",
       "      <td>0.818761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.236900</td>\n",
       "      <td>0.456035</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814711</td>\n",
       "      <td>0.814579</td>\n",
       "      <td>0.814216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.229600</td>\n",
       "      <td>0.460556</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.224100</td>\n",
       "      <td>0.461166</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819891</td>\n",
       "      <td>0.819957</td>\n",
       "      <td>0.819914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.219700</td>\n",
       "      <td>0.463622</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.217300</td>\n",
       "      <td>0.464725</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.212100</td>\n",
       "      <td>0.469687</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.818831</td>\n",
       "      <td>0.818773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.210900</td>\n",
       "      <td>0.470587</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817612</td>\n",
       "      <td>0.817704</td>\n",
       "      <td>0.817632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 16:39:14,695] Trial 48 finished with value: 0.8176315301415431 and parameters: {'learning_rate': 2.7666837299817864e-05, 'weight_decay': 0.003, 'warmup_steps': 43}. Best is trial 27 with value: 0.8210406668350594.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 49 with params: {'learning_rate': 2.9184668552378307e-05, 'weight_decay': 0.005, 'warmup_steps': 38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:54 < 01:57, 17.98 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.556900</td>\n",
       "      <td>0.473251</td>\n",
       "      <td>0.786697</td>\n",
       "      <td>0.786698</td>\n",
       "      <td>0.786499</td>\n",
       "      <td>0.786561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.400300</td>\n",
       "      <td>0.445422</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.799304</td>\n",
       "      <td>0.799139</td>\n",
       "      <td>0.799195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.344900</td>\n",
       "      <td>0.436097</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810926</td>\n",
       "      <td>0.810990</td>\n",
       "      <td>0.810778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.312400</td>\n",
       "      <td>0.446121</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816969</td>\n",
       "      <td>0.816115</td>\n",
       "      <td>0.816266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.287300</td>\n",
       "      <td>0.435072</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817631</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.267400</td>\n",
       "      <td>0.440115</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.254100</td>\n",
       "      <td>0.449617</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810120</td>\n",
       "      <td>0.809990</td>\n",
       "      <td>0.809629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.242000</td>\n",
       "      <td>0.454398</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.231400</td>\n",
       "      <td>0.459304</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814596</td>\n",
       "      <td>0.814536</td>\n",
       "      <td>0.814219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.224100</td>\n",
       "      <td>0.464199</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816447</td>\n",
       "      <td>0.816494</td>\n",
       "      <td>0.816466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 16:43:09,828] Trial 49 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 with params: {'learning_rate': 2.4578217928446838e-05, 'weight_decay': 0.004, 'warmup_steps': 34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:54, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.572800</td>\n",
       "      <td>0.481784</td>\n",
       "      <td>0.783257</td>\n",
       "      <td>0.783562</td>\n",
       "      <td>0.782868</td>\n",
       "      <td>0.782983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.416700</td>\n",
       "      <td>0.452318</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793507</td>\n",
       "      <td>0.793551</td>\n",
       "      <td>0.793525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.362000</td>\n",
       "      <td>0.439251</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810007</td>\n",
       "      <td>0.809948</td>\n",
       "      <td>0.809632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.329800</td>\n",
       "      <td>0.446351</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806940</td>\n",
       "      <td>0.805685</td>\n",
       "      <td>0.805843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.305400</td>\n",
       "      <td>0.437362</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816546</td>\n",
       "      <td>0.816326</td>\n",
       "      <td>0.816397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.285600</td>\n",
       "      <td>0.437069</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815348</td>\n",
       "      <td>0.815452</td>\n",
       "      <td>0.815347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.272400</td>\n",
       "      <td>0.441913</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.809168</td>\n",
       "      <td>0.808906</td>\n",
       "      <td>0.808474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.260100</td>\n",
       "      <td>0.446634</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813009</td>\n",
       "      <td>0.813074</td>\n",
       "      <td>0.813032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.249600</td>\n",
       "      <td>0.449821</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811330</td>\n",
       "      <td>0.811158</td>\n",
       "      <td>0.810774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.242400</td>\n",
       "      <td>0.453799</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.236700</td>\n",
       "      <td>0.453597</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818772</td>\n",
       "      <td>0.818873</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.232300</td>\n",
       "      <td>0.455716</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.229800</td>\n",
       "      <td>0.456873</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>0.460542</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818915</td>\n",
       "      <td>0.818792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.223200</td>\n",
       "      <td>0.461215</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818915</td>\n",
       "      <td>0.818792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 16:49:05,840] Trial 50 finished with value: 0.8187920875420875 and parameters: {'learning_rate': 2.4578217928446838e-05, 'weight_decay': 0.004, 'warmup_steps': 34}. Best is trial 27 with value: 0.8210406668350594.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 51 with params: {'learning_rate': 3.136836462081459e-05, 'weight_decay': 0.004, 'warmup_steps': 31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:06, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.548400</td>\n",
       "      <td>0.470644</td>\n",
       "      <td>0.787844</td>\n",
       "      <td>0.787869</td>\n",
       "      <td>0.787625</td>\n",
       "      <td>0.787696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.393300</td>\n",
       "      <td>0.443246</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798230</td>\n",
       "      <td>0.797929</td>\n",
       "      <td>0.798012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.337700</td>\n",
       "      <td>0.435284</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808632</td>\n",
       "      <td>0.808695</td>\n",
       "      <td>0.808484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.305000</td>\n",
       "      <td>0.446814</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814558</td>\n",
       "      <td>0.813863</td>\n",
       "      <td>0.814000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.279700</td>\n",
       "      <td>0.434833</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813007</td>\n",
       "      <td>0.813031</td>\n",
       "      <td>0.813018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.259900</td>\n",
       "      <td>0.442623</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.246600</td>\n",
       "      <td>0.454156</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814596</td>\n",
       "      <td>0.814536</td>\n",
       "      <td>0.814219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.234700</td>\n",
       "      <td>0.458957</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817597</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.224000</td>\n",
       "      <td>0.465062</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813504</td>\n",
       "      <td>0.813410</td>\n",
       "      <td>0.813071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.216700</td>\n",
       "      <td>0.469913</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.211300</td>\n",
       "      <td>0.470846</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815301</td>\n",
       "      <td>0.815326</td>\n",
       "      <td>0.815312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.207000</td>\n",
       "      <td>0.473905</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814269</td>\n",
       "      <td>0.814368</td>\n",
       "      <td>0.814211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.204600</td>\n",
       "      <td>0.474996</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815303</td>\n",
       "      <td>0.815368</td>\n",
       "      <td>0.815326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.199400</td>\n",
       "      <td>0.481222</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819901</td>\n",
       "      <td>0.819872</td>\n",
       "      <td>0.819886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.198400</td>\n",
       "      <td>0.482292</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822196</td>\n",
       "      <td>0.822167</td>\n",
       "      <td>0.822180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 16:55:14,295] Trial 51 finished with value: 0.8221801222215643 and parameters: {'learning_rate': 3.136836462081459e-05, 'weight_decay': 0.004, 'warmup_steps': 31}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 52 with params: {'learning_rate': 2.8888977110270142e-05, 'weight_decay': 0.005, 'warmup_steps': 33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:57, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.556700</td>\n",
       "      <td>0.473629</td>\n",
       "      <td>0.786697</td>\n",
       "      <td>0.786698</td>\n",
       "      <td>0.786499</td>\n",
       "      <td>0.786561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.401100</td>\n",
       "      <td>0.445797</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.799304</td>\n",
       "      <td>0.799139</td>\n",
       "      <td>0.799195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.345900</td>\n",
       "      <td>0.436319</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810926</td>\n",
       "      <td>0.810990</td>\n",
       "      <td>0.810778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.313400</td>\n",
       "      <td>0.446188</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815879</td>\n",
       "      <td>0.814947</td>\n",
       "      <td>0.815102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.288400</td>\n",
       "      <td>0.435290</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817631</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.268500</td>\n",
       "      <td>0.439916</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.255200</td>\n",
       "      <td>0.449115</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810120</td>\n",
       "      <td>0.809990</td>\n",
       "      <td>0.809629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.243100</td>\n",
       "      <td>0.453964</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.232500</td>\n",
       "      <td>0.458733</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815691</td>\n",
       "      <td>0.815663</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.225200</td>\n",
       "      <td>0.463485</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.219700</td>\n",
       "      <td>0.464111</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.215400</td>\n",
       "      <td>0.466708</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815445</td>\n",
       "      <td>0.815536</td>\n",
       "      <td>0.815361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.213000</td>\n",
       "      <td>0.467869</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815348</td>\n",
       "      <td>0.815452</td>\n",
       "      <td>0.815347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.207700</td>\n",
       "      <td>0.473264</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817597</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.206600</td>\n",
       "      <td>0.474169</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817597</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 17:01:13,783] Trial 52 finished with value: 0.817620015390383 and parameters: {'learning_rate': 2.8888977110270142e-05, 'weight_decay': 0.005, 'warmup_steps': 33}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 53 with params: {'learning_rate': 3.362759858007177e-05, 'weight_decay': 0.004, 'warmup_steps': 27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:56, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.541000</td>\n",
       "      <td>0.468698</td>\n",
       "      <td>0.790138</td>\n",
       "      <td>0.790122</td>\n",
       "      <td>0.789962</td>\n",
       "      <td>0.790016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.386600</td>\n",
       "      <td>0.441240</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.802770</td>\n",
       "      <td>0.802560</td>\n",
       "      <td>0.802627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.330800</td>\n",
       "      <td>0.434863</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808509</td>\n",
       "      <td>0.808611</td>\n",
       "      <td>0.808474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.297900</td>\n",
       "      <td>0.447875</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815657</td>\n",
       "      <td>0.815031</td>\n",
       "      <td>0.815163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.272400</td>\n",
       "      <td>0.435130</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813007</td>\n",
       "      <td>0.813031</td>\n",
       "      <td>0.813018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.252700</td>\n",
       "      <td>0.445937</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815596</td>\n",
       "      <td>0.815621</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.459545</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815691</td>\n",
       "      <td>0.815663</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.227600</td>\n",
       "      <td>0.464144</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.216900</td>\n",
       "      <td>0.471648</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812543</td>\n",
       "      <td>0.812326</td>\n",
       "      <td>0.811918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.209700</td>\n",
       "      <td>0.476051</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.204300</td>\n",
       "      <td>0.477549</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818765</td>\n",
       "      <td>0.818704</td>\n",
       "      <td>0.818730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.200100</td>\n",
       "      <td>0.481321</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815390</td>\n",
       "      <td>0.815494</td>\n",
       "      <td>0.815355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.197600</td>\n",
       "      <td>0.482335</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817612</td>\n",
       "      <td>0.817704</td>\n",
       "      <td>0.817632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.192400</td>\n",
       "      <td>0.489299</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819901</td>\n",
       "      <td>0.819872</td>\n",
       "      <td>0.819886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.191500</td>\n",
       "      <td>0.490320</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819901</td>\n",
       "      <td>0.819872</td>\n",
       "      <td>0.819886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 17:07:12,056] Trial 53 finished with value: 0.8198856721857136 and parameters: {'learning_rate': 3.362759858007177e-05, 'weight_decay': 0.004, 'warmup_steps': 27}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 54 with params: {'learning_rate': 3.2717712928282766e-05, 'weight_decay': 0.004, 'warmup_steps': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 01:57 < 03:55, 17.85 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.544700</td>\n",
       "      <td>0.469434</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.788957</td>\n",
       "      <td>0.788836</td>\n",
       "      <td>0.788880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.389400</td>\n",
       "      <td>0.442069</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.801647</td>\n",
       "      <td>0.801391</td>\n",
       "      <td>0.801467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.333500</td>\n",
       "      <td>0.434955</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810858</td>\n",
       "      <td>0.810948</td>\n",
       "      <td>0.810774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.300700</td>\n",
       "      <td>0.447320</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814558</td>\n",
       "      <td>0.813863</td>\n",
       "      <td>0.814000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.275300</td>\n",
       "      <td>0.434801</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813007</td>\n",
       "      <td>0.813031</td>\n",
       "      <td>0.813018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 17:09:10,908] Trial 54 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 55 with params: {'learning_rate': 2.436869330093948e-05, 'weight_decay': 0.004, 'warmup_steps': 26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:55, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.482045</td>\n",
       "      <td>0.783257</td>\n",
       "      <td>0.783562</td>\n",
       "      <td>0.782868</td>\n",
       "      <td>0.782983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.417200</td>\n",
       "      <td>0.452681</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793507</td>\n",
       "      <td>0.793551</td>\n",
       "      <td>0.793525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.362900</td>\n",
       "      <td>0.439539</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808713</td>\n",
       "      <td>0.808737</td>\n",
       "      <td>0.808486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.330700</td>\n",
       "      <td>0.446558</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806940</td>\n",
       "      <td>0.805685</td>\n",
       "      <td>0.805843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.306300</td>\n",
       "      <td>0.437634</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815425</td>\n",
       "      <td>0.815157</td>\n",
       "      <td>0.815238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.286600</td>\n",
       "      <td>0.436984</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815348</td>\n",
       "      <td>0.815452</td>\n",
       "      <td>0.815347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.273400</td>\n",
       "      <td>0.441620</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807952</td>\n",
       "      <td>0.807738</td>\n",
       "      <td>0.807330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.261100</td>\n",
       "      <td>0.446316</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813009</td>\n",
       "      <td>0.813074</td>\n",
       "      <td>0.813032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.250600</td>\n",
       "      <td>0.449399</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811330</td>\n",
       "      <td>0.811158</td>\n",
       "      <td>0.810774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.243400</td>\n",
       "      <td>0.453405</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.237700</td>\n",
       "      <td>0.453092</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818772</td>\n",
       "      <td>0.818873</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.233300</td>\n",
       "      <td>0.455157</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815514</td>\n",
       "      <td>0.815578</td>\n",
       "      <td>0.815365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.230800</td>\n",
       "      <td>0.456328</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.225800</td>\n",
       "      <td>0.459928</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.224200</td>\n",
       "      <td>0.460538</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 17:15:08,204] Trial 55 finished with value: 0.817648799542307 and parameters: {'learning_rate': 2.436869330093948e-05, 'weight_decay': 0.004, 'warmup_steps': 26}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 56 with params: {'learning_rate': 3.981577297029585e-05, 'weight_decay': 0.005, 'warmup_steps': 31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:56, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.526300</td>\n",
       "      <td>0.464097</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791290</td>\n",
       "      <td>0.791088</td>\n",
       "      <td>0.791151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.370800</td>\n",
       "      <td>0.436467</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806239</td>\n",
       "      <td>0.805980</td>\n",
       "      <td>0.806058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.314000</td>\n",
       "      <td>0.435319</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810731</td>\n",
       "      <td>0.810821</td>\n",
       "      <td>0.810750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.280600</td>\n",
       "      <td>0.451596</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818972</td>\n",
       "      <td>0.818536</td>\n",
       "      <td>0.818646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.254700</td>\n",
       "      <td>0.438374</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813025</td>\n",
       "      <td>0.813116</td>\n",
       "      <td>0.813044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.235600</td>\n",
       "      <td>0.455973</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815514</td>\n",
       "      <td>0.815578</td>\n",
       "      <td>0.815365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.222200</td>\n",
       "      <td>0.474640</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814494</td>\n",
       "      <td>0.814494</td>\n",
       "      <td>0.814220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.210700</td>\n",
       "      <td>0.479798</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813041</td>\n",
       "      <td>0.812947</td>\n",
       "      <td>0.812985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.200200</td>\n",
       "      <td>0.490143</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.813187</td>\n",
       "      <td>0.812495</td>\n",
       "      <td>0.811878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.193100</td>\n",
       "      <td>0.494180</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818741</td>\n",
       "      <td>0.818788</td>\n",
       "      <td>0.818761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.187800</td>\n",
       "      <td>0.497737</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819901</td>\n",
       "      <td>0.819872</td>\n",
       "      <td>0.819886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.183600</td>\n",
       "      <td>0.502499</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.180900</td>\n",
       "      <td>0.503753</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>0.512986</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815301</td>\n",
       "      <td>0.815326</td>\n",
       "      <td>0.815312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.513843</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813007</td>\n",
       "      <td>0.813031</td>\n",
       "      <td>0.813018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 17:21:06,598] Trial 56 finished with value: 0.8130180659572537 and parameters: {'learning_rate': 3.981577297029585e-05, 'weight_decay': 0.005, 'warmup_steps': 31}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 57 with params: {'learning_rate': 1.7967385120353152e-05, 'weight_decay': 0.003, 'warmup_steps': 29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:55 < 01:57, 17.90 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.602900</td>\n",
       "      <td>0.508787</td>\n",
       "      <td>0.767202</td>\n",
       "      <td>0.767776</td>\n",
       "      <td>0.766681</td>\n",
       "      <td>0.766782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.448400</td>\n",
       "      <td>0.462064</td>\n",
       "      <td>0.790138</td>\n",
       "      <td>0.790071</td>\n",
       "      <td>0.790130</td>\n",
       "      <td>0.790091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.393200</td>\n",
       "      <td>0.448863</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794705</td>\n",
       "      <td>0.794803</td>\n",
       "      <td>0.794703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.361300</td>\n",
       "      <td>0.450179</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.796378</td>\n",
       "      <td>0.795424</td>\n",
       "      <td>0.795561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.338300</td>\n",
       "      <td>0.443977</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808673</td>\n",
       "      <td>0.808190</td>\n",
       "      <td>0.808302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.319200</td>\n",
       "      <td>0.437155</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814162</td>\n",
       "      <td>0.814242</td>\n",
       "      <td>0.814185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.306400</td>\n",
       "      <td>0.437155</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811007</td>\n",
       "      <td>0.811032</td>\n",
       "      <td>0.810780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.294000</td>\n",
       "      <td>0.440080</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811869</td>\n",
       "      <td>0.811947</td>\n",
       "      <td>0.811891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.284200</td>\n",
       "      <td>0.440720</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808807</td>\n",
       "      <td>0.808780</td>\n",
       "      <td>0.808486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.277300</td>\n",
       "      <td>0.444543</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815374</td>\n",
       "      <td>0.815200</td>\n",
       "      <td>0.815260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 17:25:02,858] Trial 57 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 58 with params: {'learning_rate': 3.376913526648993e-05, 'weight_decay': 0.003, 'warmup_steps': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:53, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.541700</td>\n",
       "      <td>0.468589</td>\n",
       "      <td>0.790138</td>\n",
       "      <td>0.790122</td>\n",
       "      <td>0.789962</td>\n",
       "      <td>0.790016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.386400</td>\n",
       "      <td>0.441119</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.801647</td>\n",
       "      <td>0.801391</td>\n",
       "      <td>0.801467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.330400</td>\n",
       "      <td>0.434767</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808509</td>\n",
       "      <td>0.808611</td>\n",
       "      <td>0.808474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.297500</td>\n",
       "      <td>0.447824</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815657</td>\n",
       "      <td>0.815031</td>\n",
       "      <td>0.815163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.271900</td>\n",
       "      <td>0.434897</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813007</td>\n",
       "      <td>0.813031</td>\n",
       "      <td>0.813018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.252300</td>\n",
       "      <td>0.446059</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815596</td>\n",
       "      <td>0.815621</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.238900</td>\n",
       "      <td>0.459787</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.227100</td>\n",
       "      <td>0.464439</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.216500</td>\n",
       "      <td>0.471984</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812543</td>\n",
       "      <td>0.812326</td>\n",
       "      <td>0.811918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.209200</td>\n",
       "      <td>0.476445</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.203800</td>\n",
       "      <td>0.477885</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818765</td>\n",
       "      <td>0.818704</td>\n",
       "      <td>0.818730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.199600</td>\n",
       "      <td>0.481617</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814269</td>\n",
       "      <td>0.814368</td>\n",
       "      <td>0.814211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.197200</td>\n",
       "      <td>0.482706</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817612</td>\n",
       "      <td>0.817704</td>\n",
       "      <td>0.817632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.489693</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.191100</td>\n",
       "      <td>0.490707</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819889</td>\n",
       "      <td>0.819915</td>\n",
       "      <td>0.819901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 17:30:58,370] Trial 58 finished with value: 0.8199008365355143 and parameters: {'learning_rate': 3.376913526648993e-05, 'weight_decay': 0.003, 'warmup_steps': 32}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 59 with params: {'learning_rate': 2.579909624398062e-05, 'weight_decay': 0.003, 'warmup_steps': 33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:57, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.567800</td>\n",
       "      <td>0.479067</td>\n",
       "      <td>0.782110</td>\n",
       "      <td>0.782212</td>\n",
       "      <td>0.781826</td>\n",
       "      <td>0.781916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.412000</td>\n",
       "      <td>0.450574</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.796976</td>\n",
       "      <td>0.796887</td>\n",
       "      <td>0.796922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.357200</td>\n",
       "      <td>0.438286</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811102</td>\n",
       "      <td>0.811074</td>\n",
       "      <td>0.810780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.324900</td>\n",
       "      <td>0.446171</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810324</td>\n",
       "      <td>0.809148</td>\n",
       "      <td>0.809308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.300300</td>\n",
       "      <td>0.436677</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815374</td>\n",
       "      <td>0.815200</td>\n",
       "      <td>0.815260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.280400</td>\n",
       "      <td>0.437796</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816620</td>\n",
       "      <td>0.816498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.267200</td>\n",
       "      <td>0.443754</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810247</td>\n",
       "      <td>0.810032</td>\n",
       "      <td>0.809624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>0.448581</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.244400</td>\n",
       "      <td>0.452297</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812416</td>\n",
       "      <td>0.812284</td>\n",
       "      <td>0.811923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.237200</td>\n",
       "      <td>0.456422</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.231500</td>\n",
       "      <td>0.456668</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818772</td>\n",
       "      <td>0.818873</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.227200</td>\n",
       "      <td>0.458940</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.224700</td>\n",
       "      <td>0.460042</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.219600</td>\n",
       "      <td>0.464228</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818915</td>\n",
       "      <td>0.818792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.218100</td>\n",
       "      <td>0.464958</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818915</td>\n",
       "      <td>0.818792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 17:36:57,220] Trial 59 finished with value: 0.8187920875420875 and parameters: {'learning_rate': 2.579909624398062e-05, 'weight_decay': 0.003, 'warmup_steps': 33}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 60 with params: {'learning_rate': 6.710937090018343e-05, 'weight_decay': 0.004, 'warmup_steps': 31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:55, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.479500</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.803938</td>\n",
       "      <td>0.803868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.321000</td>\n",
       "      <td>0.431766</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811891</td>\n",
       "      <td>0.811990</td>\n",
       "      <td>0.811902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.263300</td>\n",
       "      <td>0.439349</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816603</td>\n",
       "      <td>0.816284</td>\n",
       "      <td>0.816375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.230100</td>\n",
       "      <td>0.477631</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822918</td>\n",
       "      <td>0.821788</td>\n",
       "      <td>0.821961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.205300</td>\n",
       "      <td>0.472177</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811209</td>\n",
       "      <td>0.811116</td>\n",
       "      <td>0.810778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.188200</td>\n",
       "      <td>0.502289</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811330</td>\n",
       "      <td>0.811158</td>\n",
       "      <td>0.810774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.174000</td>\n",
       "      <td>0.530678</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814406</td>\n",
       "      <td>0.814452</td>\n",
       "      <td>0.814219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.164000</td>\n",
       "      <td>0.554301</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815489</td>\n",
       "      <td>0.815115</td>\n",
       "      <td>0.815215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.153700</td>\n",
       "      <td>0.570594</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.806480</td>\n",
       "      <td>0.805654</td>\n",
       "      <td>0.804980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.146800</td>\n",
       "      <td>0.576663</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815319</td>\n",
       "      <td>0.815410</td>\n",
       "      <td>0.815338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.141300</td>\n",
       "      <td>0.587516</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819906</td>\n",
       "      <td>0.819999</td>\n",
       "      <td>0.819925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.136500</td>\n",
       "      <td>0.589740</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813396</td>\n",
       "      <td>0.813368</td>\n",
       "      <td>0.813073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.134000</td>\n",
       "      <td>0.600653</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>0.617965</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814185</td>\n",
       "      <td>0.814284</td>\n",
       "      <td>0.814196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>0.618127</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814185</td>\n",
       "      <td>0.814284</td>\n",
       "      <td>0.814196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 17:42:54,024] Trial 60 finished with value: 0.8141957479047304 and parameters: {'learning_rate': 6.710937090018343e-05, 'weight_decay': 0.004, 'warmup_steps': 31}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 61 with params: {'learning_rate': 3.332559849712927e-05, 'weight_decay': 0.003, 'warmup_steps': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 01:57 < 03:55, 17.88 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.543000</td>\n",
       "      <td>0.468911</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.788957</td>\n",
       "      <td>0.788836</td>\n",
       "      <td>0.788880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.387600</td>\n",
       "      <td>0.441489</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.801647</td>\n",
       "      <td>0.801391</td>\n",
       "      <td>0.801467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.331700</td>\n",
       "      <td>0.434822</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810802</td>\n",
       "      <td>0.810906</td>\n",
       "      <td>0.810768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.298800</td>\n",
       "      <td>0.447599</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814558</td>\n",
       "      <td>0.813863</td>\n",
       "      <td>0.814000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.273300</td>\n",
       "      <td>0.434854</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813007</td>\n",
       "      <td>0.813031</td>\n",
       "      <td>0.813018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 17:44:52,686] Trial 61 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 62 with params: {'learning_rate': 2.871282927455198e-05, 'weight_decay': 0.002, 'warmup_steps': 29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:54, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.556400</td>\n",
       "      <td>0.473863</td>\n",
       "      <td>0.785550</td>\n",
       "      <td>0.785573</td>\n",
       "      <td>0.785331</td>\n",
       "      <td>0.785401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.401600</td>\n",
       "      <td>0.446024</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.799304</td>\n",
       "      <td>0.799139</td>\n",
       "      <td>0.799195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.346400</td>\n",
       "      <td>0.436420</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810926</td>\n",
       "      <td>0.810990</td>\n",
       "      <td>0.810778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.314000</td>\n",
       "      <td>0.446224</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815879</td>\n",
       "      <td>0.814947</td>\n",
       "      <td>0.815102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.289000</td>\n",
       "      <td>0.435392</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817631</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.269200</td>\n",
       "      <td>0.439822</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.255900</td>\n",
       "      <td>0.448803</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810120</td>\n",
       "      <td>0.809990</td>\n",
       "      <td>0.809629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.243800</td>\n",
       "      <td>0.453665</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.233200</td>\n",
       "      <td>0.458371</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815799</td>\n",
       "      <td>0.815705</td>\n",
       "      <td>0.815365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.225900</td>\n",
       "      <td>0.463030</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.220300</td>\n",
       "      <td>0.463683</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.216000</td>\n",
       "      <td>0.466365</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815445</td>\n",
       "      <td>0.815536</td>\n",
       "      <td>0.815361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.213600</td>\n",
       "      <td>0.467392</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815348</td>\n",
       "      <td>0.815452</td>\n",
       "      <td>0.815347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.208400</td>\n",
       "      <td>0.472741</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817597</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.207200</td>\n",
       "      <td>0.473681</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817597</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 17:50:49,506] Trial 62 finished with value: 0.817620015390383 and parameters: {'learning_rate': 2.871282927455198e-05, 'weight_decay': 0.002, 'warmup_steps': 29}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 63 with params: {'learning_rate': 3.107537670155256e-05, 'weight_decay': 0.003, 'warmup_steps': 33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:54, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.549700</td>\n",
       "      <td>0.470949</td>\n",
       "      <td>0.787844</td>\n",
       "      <td>0.787869</td>\n",
       "      <td>0.787625</td>\n",
       "      <td>0.787696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>0.443536</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.799351</td>\n",
       "      <td>0.799097</td>\n",
       "      <td>0.799172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.338600</td>\n",
       "      <td>0.435385</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809818</td>\n",
       "      <td>0.809864</td>\n",
       "      <td>0.809632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.306000</td>\n",
       "      <td>0.446661</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814558</td>\n",
       "      <td>0.813863</td>\n",
       "      <td>0.814000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.280700</td>\n",
       "      <td>0.434796</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814158</td>\n",
       "      <td>0.814158</td>\n",
       "      <td>0.814158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.260900</td>\n",
       "      <td>0.442253</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.247500</td>\n",
       "      <td>0.453542</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814596</td>\n",
       "      <td>0.814536</td>\n",
       "      <td>0.814219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.235600</td>\n",
       "      <td>0.458304</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817597</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.464206</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813396</td>\n",
       "      <td>0.813368</td>\n",
       "      <td>0.813073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.217700</td>\n",
       "      <td>0.469138</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.212200</td>\n",
       "      <td>0.469978</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815301</td>\n",
       "      <td>0.815326</td>\n",
       "      <td>0.815312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.207900</td>\n",
       "      <td>0.472924</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815445</td>\n",
       "      <td>0.815536</td>\n",
       "      <td>0.815361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.205600</td>\n",
       "      <td>0.474062</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815303</td>\n",
       "      <td>0.815368</td>\n",
       "      <td>0.815326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.200300</td>\n",
       "      <td>0.480238</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819901</td>\n",
       "      <td>0.819872</td>\n",
       "      <td>0.819886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.199300</td>\n",
       "      <td>0.481296</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822196</td>\n",
       "      <td>0.822167</td>\n",
       "      <td>0.822180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 17:56:45,539] Trial 63 finished with value: 0.8221801222215643 and parameters: {'learning_rate': 3.107537670155256e-05, 'weight_decay': 0.003, 'warmup_steps': 33}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 64 with params: {'learning_rate': 2.090646578509708e-05, 'weight_decay': 0.006, 'warmup_steps': 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:57 < 01:58, 17.72 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.585800</td>\n",
       "      <td>0.492517</td>\n",
       "      <td>0.774083</td>\n",
       "      <td>0.774567</td>\n",
       "      <td>0.773607</td>\n",
       "      <td>0.773718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.431900</td>\n",
       "      <td>0.457258</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793519</td>\n",
       "      <td>0.793593</td>\n",
       "      <td>0.793539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>0.443590</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.802862</td>\n",
       "      <td>0.802938</td>\n",
       "      <td>0.802748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.346100</td>\n",
       "      <td>0.447914</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.802820</td>\n",
       "      <td>0.800970</td>\n",
       "      <td>0.801122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.322400</td>\n",
       "      <td>0.440599</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814461</td>\n",
       "      <td>0.813905</td>\n",
       "      <td>0.814028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.303000</td>\n",
       "      <td>0.436237</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814162</td>\n",
       "      <td>0.814242</td>\n",
       "      <td>0.814185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.438029</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809906</td>\n",
       "      <td>0.809906</td>\n",
       "      <td>0.809633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.277600</td>\n",
       "      <td>0.442098</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815301</td>\n",
       "      <td>0.815326</td>\n",
       "      <td>0.815312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.267500</td>\n",
       "      <td>0.443647</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811102</td>\n",
       "      <td>0.811074</td>\n",
       "      <td>0.810780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.260400</td>\n",
       "      <td>0.447448</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815336</td>\n",
       "      <td>0.815242</td>\n",
       "      <td>0.815279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 18:00:44,113] Trial 64 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 65 with params: {'learning_rate': 3.386295106767767e-05, 'weight_decay': 0.004, 'warmup_steps': 31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1685' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1685/6315 01:31 < 04:11, 18.43 it/s, Epoch 4/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.541200</td>\n",
       "      <td>0.468485</td>\n",
       "      <td>0.790138</td>\n",
       "      <td>0.790122</td>\n",
       "      <td>0.789962</td>\n",
       "      <td>0.790016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.386100</td>\n",
       "      <td>0.441030</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.802770</td>\n",
       "      <td>0.802560</td>\n",
       "      <td>0.802627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.330100</td>\n",
       "      <td>0.434750</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808509</td>\n",
       "      <td>0.808611</td>\n",
       "      <td>0.808474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.297200</td>\n",
       "      <td>0.447862</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816759</td>\n",
       "      <td>0.816199</td>\n",
       "      <td>0.816324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 66 with params: {'learning_rate': 2.5587190033751624e-05, 'weight_decay': 0.002, 'warmup_steps': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:57, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.568400</td>\n",
       "      <td>0.479461</td>\n",
       "      <td>0.780963</td>\n",
       "      <td>0.781097</td>\n",
       "      <td>0.780658</td>\n",
       "      <td>0.780753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.412700</td>\n",
       "      <td>0.450851</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.796976</td>\n",
       "      <td>0.796887</td>\n",
       "      <td>0.796922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.358000</td>\n",
       "      <td>0.438461</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811102</td>\n",
       "      <td>0.811074</td>\n",
       "      <td>0.810780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.325700</td>\n",
       "      <td>0.446264</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810324</td>\n",
       "      <td>0.809148</td>\n",
       "      <td>0.809308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.301200</td>\n",
       "      <td>0.436794</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817669</td>\n",
       "      <td>0.817494</td>\n",
       "      <td>0.817555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.281300</td>\n",
       "      <td>0.437674</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816620</td>\n",
       "      <td>0.816498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.268100</td>\n",
       "      <td>0.443414</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811464</td>\n",
       "      <td>0.811200</td>\n",
       "      <td>0.810768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.255800</td>\n",
       "      <td>0.448193</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.245300</td>\n",
       "      <td>0.451845</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812416</td>\n",
       "      <td>0.812284</td>\n",
       "      <td>0.811923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.238100</td>\n",
       "      <td>0.455943</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.456088</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818772</td>\n",
       "      <td>0.818873</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.458365</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.225500</td>\n",
       "      <td>0.459458</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.220500</td>\n",
       "      <td>0.463578</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.219000</td>\n",
       "      <td>0.464264</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 18:08:43,577] Trial 66 finished with value: 0.817648799542307 and parameters: {'learning_rate': 2.5587190033751624e-05, 'weight_decay': 0.002, 'warmup_steps': 32}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 67 with params: {'learning_rate': 1.409348001376769e-05, 'weight_decay': 0.001, 'warmup_steps': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 01:56 < 03:53, 18.00 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.623300</td>\n",
       "      <td>0.541714</td>\n",
       "      <td>0.739679</td>\n",
       "      <td>0.739862</td>\n",
       "      <td>0.739275</td>\n",
       "      <td>0.739349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.477200</td>\n",
       "      <td>0.471520</td>\n",
       "      <td>0.784404</td>\n",
       "      <td>0.784452</td>\n",
       "      <td>0.784542</td>\n",
       "      <td>0.784393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.417600</td>\n",
       "      <td>0.457742</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793519</td>\n",
       "      <td>0.793593</td>\n",
       "      <td>0.793539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.385900</td>\n",
       "      <td>0.456086</td>\n",
       "      <td>0.787844</td>\n",
       "      <td>0.788162</td>\n",
       "      <td>0.787457</td>\n",
       "      <td>0.787576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.363600</td>\n",
       "      <td>0.449761</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.800865</td>\n",
       "      <td>0.800055</td>\n",
       "      <td>0.800190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 18:10:41,538] Trial 67 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 68 with params: {'learning_rate': 4.190275252502407e-05, 'weight_decay': 0.006, 'warmup_steps': 40}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:55 < 01:57, 17.88 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.523800</td>\n",
       "      <td>0.462264</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793586</td>\n",
       "      <td>0.793382</td>\n",
       "      <td>0.793447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.366200</td>\n",
       "      <td>0.435045</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809615</td>\n",
       "      <td>0.809485</td>\n",
       "      <td>0.809533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.308900</td>\n",
       "      <td>0.435625</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814158</td>\n",
       "      <td>0.814158</td>\n",
       "      <td>0.814158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.275400</td>\n",
       "      <td>0.452895</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817864</td>\n",
       "      <td>0.817368</td>\n",
       "      <td>0.817486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.249500</td>\n",
       "      <td>0.439845</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814326</td>\n",
       "      <td>0.814205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.230500</td>\n",
       "      <td>0.459278</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814494</td>\n",
       "      <td>0.814494</td>\n",
       "      <td>0.814220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.217200</td>\n",
       "      <td>0.479056</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813220</td>\n",
       "      <td>0.813284</td>\n",
       "      <td>0.813071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.205700</td>\n",
       "      <td>0.485231</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815336</td>\n",
       "      <td>0.815242</td>\n",
       "      <td>0.815279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.195300</td>\n",
       "      <td>0.496226</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.809646</td>\n",
       "      <td>0.809032</td>\n",
       "      <td>0.808444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.188200</td>\n",
       "      <td>0.500687</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815303</td>\n",
       "      <td>0.815368</td>\n",
       "      <td>0.815326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 18:14:37,999] Trial 68 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 69 with params: {'learning_rate': 0.00046740581144500315, 'weight_decay': 0.007, 'warmup_steps': 34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:56 < 01:58, 17.78 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.362300</td>\n",
       "      <td>0.440969</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817641</td>\n",
       "      <td>0.817746</td>\n",
       "      <td>0.817641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.204100</td>\n",
       "      <td>0.570821</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806562</td>\n",
       "      <td>0.805812</td>\n",
       "      <td>0.805947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.145800</td>\n",
       "      <td>0.644113</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.796472</td>\n",
       "      <td>0.796266</td>\n",
       "      <td>0.795862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.109400</td>\n",
       "      <td>0.697168</td>\n",
       "      <td>0.779817</td>\n",
       "      <td>0.780809</td>\n",
       "      <td>0.779195</td>\n",
       "      <td>0.779305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>0.874891</td>\n",
       "      <td>0.787844</td>\n",
       "      <td>0.788510</td>\n",
       "      <td>0.787331</td>\n",
       "      <td>0.787461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.879289</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.796484</td>\n",
       "      <td>0.793961</td>\n",
       "      <td>0.794075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.974065</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.795567</td>\n",
       "      <td>0.794172</td>\n",
       "      <td>0.794313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.050400</td>\n",
       "      <td>0.912168</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806156</td>\n",
       "      <td>0.806064</td>\n",
       "      <td>0.806101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.042800</td>\n",
       "      <td>1.072344</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.792900</td>\n",
       "      <td>0.790014</td>\n",
       "      <td>0.788631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>1.132572</td>\n",
       "      <td>0.783257</td>\n",
       "      <td>0.783207</td>\n",
       "      <td>0.783289</td>\n",
       "      <td>0.783222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 18:18:35,808] Trial 69 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 70 with params: {'learning_rate': 0.0003432306292766826, 'weight_decay': 0.004, 'warmup_steps': 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:56 < 01:58, 17.77 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.366500</td>\n",
       "      <td>0.454334</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.810244</td>\n",
       "      <td>0.809158</td>\n",
       "      <td>0.808395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.212200</td>\n",
       "      <td>0.567160</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807417</td>\n",
       "      <td>0.807106</td>\n",
       "      <td>0.807193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.155900</td>\n",
       "      <td>0.617009</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809743</td>\n",
       "      <td>0.809822</td>\n",
       "      <td>0.809629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.120800</td>\n",
       "      <td>0.662873</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.800762</td>\n",
       "      <td>0.800097</td>\n",
       "      <td>0.800222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.097000</td>\n",
       "      <td>0.773072</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793548</td>\n",
       "      <td>0.793424</td>\n",
       "      <td>0.793469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>0.872373</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.800507</td>\n",
       "      <td>0.800602</td>\n",
       "      <td>0.800449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.066300</td>\n",
       "      <td>0.959243</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.795887</td>\n",
       "      <td>0.795833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.057900</td>\n",
       "      <td>0.953465</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803943</td>\n",
       "      <td>0.803686</td>\n",
       "      <td>0.803763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.048600</td>\n",
       "      <td>1.093834</td>\n",
       "      <td>0.787844</td>\n",
       "      <td>0.792570</td>\n",
       "      <td>0.788972</td>\n",
       "      <td>0.787374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>1.074588</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.795261</td>\n",
       "      <td>0.795098</td>\n",
       "      <td>0.794718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 18:22:33,719] Trial 70 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 71 with params: {'learning_rate': 3.70477842852424e-05, 'weight_decay': 0.002, 'warmup_steps': 33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:59, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.533400</td>\n",
       "      <td>0.466521</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792386</td>\n",
       "      <td>0.792298</td>\n",
       "      <td>0.792333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.377700</td>\n",
       "      <td>0.438512</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803896</td>\n",
       "      <td>0.803728</td>\n",
       "      <td>0.803785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.321200</td>\n",
       "      <td>0.434854</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811891</td>\n",
       "      <td>0.811990</td>\n",
       "      <td>0.811902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.288000</td>\n",
       "      <td>0.449769</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815566</td>\n",
       "      <td>0.815073</td>\n",
       "      <td>0.815190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.262200</td>\n",
       "      <td>0.436541</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814153</td>\n",
       "      <td>0.814200</td>\n",
       "      <td>0.814172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.242800</td>\n",
       "      <td>0.451848</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816700</td>\n",
       "      <td>0.816747</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.229500</td>\n",
       "      <td>0.468203</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.217800</td>\n",
       "      <td>0.472620</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.207200</td>\n",
       "      <td>0.482228</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.814070</td>\n",
       "      <td>0.813579</td>\n",
       "      <td>0.813044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.200100</td>\n",
       "      <td>0.486196</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819901</td>\n",
       "      <td>0.819872</td>\n",
       "      <td>0.819886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.194700</td>\n",
       "      <td>0.488776</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822196</td>\n",
       "      <td>0.822167</td>\n",
       "      <td>0.822180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.190500</td>\n",
       "      <td>0.493340</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818856</td>\n",
       "      <td>0.818957</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.494655</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818772</td>\n",
       "      <td>0.818873</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.182900</td>\n",
       "      <td>0.502762</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.182000</td>\n",
       "      <td>0.503528</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815303</td>\n",
       "      <td>0.815368</td>\n",
       "      <td>0.815326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 18:28:34,481] Trial 71 finished with value: 0.8153259275336583 and parameters: {'learning_rate': 3.70477842852424e-05, 'weight_decay': 0.002, 'warmup_steps': 33}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 72 with params: {'learning_rate': 4.785297222553491e-05, 'weight_decay': 0.004, 'warmup_steps': 39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:01, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.511500</td>\n",
       "      <td>0.457178</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793637</td>\n",
       "      <td>0.793340</td>\n",
       "      <td>0.793421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.353400</td>\n",
       "      <td>0.432194</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808438</td>\n",
       "      <td>0.808527</td>\n",
       "      <td>0.808456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.295800</td>\n",
       "      <td>0.437873</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.262100</td>\n",
       "      <td>0.457996</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820017</td>\n",
       "      <td>0.819746</td>\n",
       "      <td>0.819829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>0.446349</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813096</td>\n",
       "      <td>0.813200</td>\n",
       "      <td>0.813061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.217900</td>\n",
       "      <td>0.470142</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814494</td>\n",
       "      <td>0.814494</td>\n",
       "      <td>0.814220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.204500</td>\n",
       "      <td>0.491116</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812301</td>\n",
       "      <td>0.812242</td>\n",
       "      <td>0.811926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.193200</td>\n",
       "      <td>0.503337</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815336</td>\n",
       "      <td>0.815242</td>\n",
       "      <td>0.815279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.182900</td>\n",
       "      <td>0.515180</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810708</td>\n",
       "      <td>0.810158</td>\n",
       "      <td>0.809597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.175900</td>\n",
       "      <td>0.521199</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816478</td>\n",
       "      <td>0.816578</td>\n",
       "      <td>0.816490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.170600</td>\n",
       "      <td>0.525049</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815303</td>\n",
       "      <td>0.815368</td>\n",
       "      <td>0.815326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.166300</td>\n",
       "      <td>0.530629</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814331</td>\n",
       "      <td>0.814410</td>\n",
       "      <td>0.814216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.163500</td>\n",
       "      <td>0.531992</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814269</td>\n",
       "      <td>0.814368</td>\n",
       "      <td>0.814211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.158800</td>\n",
       "      <td>0.543690</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815319</td>\n",
       "      <td>0.815410</td>\n",
       "      <td>0.815338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.157900</td>\n",
       "      <td>0.544831</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816456</td>\n",
       "      <td>0.816536</td>\n",
       "      <td>0.816479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 18:34:37,264] Trial 72 finished with value: 0.8164790066294854 and parameters: {'learning_rate': 4.785297222553491e-05, 'weight_decay': 0.004, 'warmup_steps': 39}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 73 with params: {'learning_rate': 2.654871957864928e-05, 'weight_decay': 0.003, 'warmup_steps': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:55, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.564700</td>\n",
       "      <td>0.477491</td>\n",
       "      <td>0.784404</td>\n",
       "      <td>0.784510</td>\n",
       "      <td>0.784121</td>\n",
       "      <td>0.784212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.409200</td>\n",
       "      <td>0.449304</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.796976</td>\n",
       "      <td>0.796887</td>\n",
       "      <td>0.796922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.354300</td>\n",
       "      <td>0.437786</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812112</td>\n",
       "      <td>0.812158</td>\n",
       "      <td>0.811926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.322000</td>\n",
       "      <td>0.446165</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810324</td>\n",
       "      <td>0.809148</td>\n",
       "      <td>0.809308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.297300</td>\n",
       "      <td>0.436290</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817721</td>\n",
       "      <td>0.817452</td>\n",
       "      <td>0.817534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.277400</td>\n",
       "      <td>0.438303</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.264200</td>\n",
       "      <td>0.444988</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810247</td>\n",
       "      <td>0.810032</td>\n",
       "      <td>0.809624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.252000</td>\n",
       "      <td>0.449904</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817597</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.241400</td>\n",
       "      <td>0.453835</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813626</td>\n",
       "      <td>0.813452</td>\n",
       "      <td>0.813067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.234100</td>\n",
       "      <td>0.458088</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819889</td>\n",
       "      <td>0.819915</td>\n",
       "      <td>0.819901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.228500</td>\n",
       "      <td>0.458456</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.818831</td>\n",
       "      <td>0.818773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.224100</td>\n",
       "      <td>0.460880</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815514</td>\n",
       "      <td>0.815578</td>\n",
       "      <td>0.815365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.221700</td>\n",
       "      <td>0.461950</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.216500</td>\n",
       "      <td>0.466478</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818915</td>\n",
       "      <td>0.818792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.215200</td>\n",
       "      <td>0.467296</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818915</td>\n",
       "      <td>0.818792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 18:40:34,152] Trial 73 finished with value: 0.8187920875420875 and parameters: {'learning_rate': 2.654871957864928e-05, 'weight_decay': 0.003, 'warmup_steps': 32}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 74 with params: {'learning_rate': 4.1363313232318837e-05, 'weight_decay': 0.002, 'warmup_steps': 23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:57 < 01:58, 17.75 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.521000</td>\n",
       "      <td>0.462433</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794758</td>\n",
       "      <td>0.794508</td>\n",
       "      <td>0.794582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.366900</td>\n",
       "      <td>0.435432</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809615</td>\n",
       "      <td>0.809485</td>\n",
       "      <td>0.809533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.310200</td>\n",
       "      <td>0.435801</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814158</td>\n",
       "      <td>0.814158</td>\n",
       "      <td>0.814158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.276700</td>\n",
       "      <td>0.452832</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818972</td>\n",
       "      <td>0.818536</td>\n",
       "      <td>0.818646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.250800</td>\n",
       "      <td>0.439882</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813054</td>\n",
       "      <td>0.813158</td>\n",
       "      <td>0.813053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.231800</td>\n",
       "      <td>0.458313</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815596</td>\n",
       "      <td>0.815621</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.218500</td>\n",
       "      <td>0.477805</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813220</td>\n",
       "      <td>0.813284</td>\n",
       "      <td>0.813071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.207000</td>\n",
       "      <td>0.483900</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814206</td>\n",
       "      <td>0.814073</td>\n",
       "      <td>0.814122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.196600</td>\n",
       "      <td>0.494657</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.809646</td>\n",
       "      <td>0.809032</td>\n",
       "      <td>0.808444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.189500</td>\n",
       "      <td>0.498777</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814153</td>\n",
       "      <td>0.814200</td>\n",
       "      <td>0.814172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 18:44:32,358] Trial 74 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 75 with params: {'learning_rate': 2.1035077926232735e-05, 'weight_decay': 0.004, 'warmup_steps': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 01:57 < 03:55, 17.84 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.587900</td>\n",
       "      <td>0.492804</td>\n",
       "      <td>0.772936</td>\n",
       "      <td>0.773361</td>\n",
       "      <td>0.772480</td>\n",
       "      <td>0.772590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.431900</td>\n",
       "      <td>0.457139</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793519</td>\n",
       "      <td>0.793593</td>\n",
       "      <td>0.793539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.377500</td>\n",
       "      <td>0.443387</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.802862</td>\n",
       "      <td>0.802938</td>\n",
       "      <td>0.802748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.345500</td>\n",
       "      <td>0.447666</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.801577</td>\n",
       "      <td>0.799844</td>\n",
       "      <td>0.799995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.321800</td>\n",
       "      <td>0.440299</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813358</td>\n",
       "      <td>0.812737</td>\n",
       "      <td>0.812866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 18:46:31,377] Trial 75 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 76 with params: {'learning_rate': 5.765910166226165e-05, 'weight_decay': 0.003, 'warmup_steps': 30}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:57 < 01:58, 17.73 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.492600</td>\n",
       "      <td>0.448336</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803834</td>\n",
       "      <td>0.803896</td>\n",
       "      <td>0.803855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.335100</td>\n",
       "      <td>0.430408</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811891</td>\n",
       "      <td>0.811990</td>\n",
       "      <td>0.811902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.277400</td>\n",
       "      <td>0.438178</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.244000</td>\n",
       "      <td>0.467539</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821356</td>\n",
       "      <td>0.820788</td>\n",
       "      <td>0.820916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.218500</td>\n",
       "      <td>0.458223</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813396</td>\n",
       "      <td>0.813368</td>\n",
       "      <td>0.813073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.201100</td>\n",
       "      <td>0.485894</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814839</td>\n",
       "      <td>0.814621</td>\n",
       "      <td>0.814211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.187300</td>\n",
       "      <td>0.508494</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815514</td>\n",
       "      <td>0.815578</td>\n",
       "      <td>0.815365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.176600</td>\n",
       "      <td>0.529123</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815489</td>\n",
       "      <td>0.815115</td>\n",
       "      <td>0.815215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.542994</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.812132</td>\n",
       "      <td>0.811369</td>\n",
       "      <td>0.810724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.159500</td>\n",
       "      <td>0.549670</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814185</td>\n",
       "      <td>0.814284</td>\n",
       "      <td>0.814196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 18:50:29,733] Trial 76 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 77 with params: {'learning_rate': 2.8245230488944487e-05, 'weight_decay': 0.003, 'warmup_steps': 34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:55, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.559100</td>\n",
       "      <td>0.474684</td>\n",
       "      <td>0.786697</td>\n",
       "      <td>0.786747</td>\n",
       "      <td>0.786457</td>\n",
       "      <td>0.786536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.403300</td>\n",
       "      <td>0.446562</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798138</td>\n",
       "      <td>0.798013</td>\n",
       "      <td>0.798059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.348100</td>\n",
       "      <td>0.436653</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808632</td>\n",
       "      <td>0.808695</td>\n",
       "      <td>0.808484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.315700</td>\n",
       "      <td>0.446182</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813708</td>\n",
       "      <td>0.812611</td>\n",
       "      <td>0.812772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.290700</td>\n",
       "      <td>0.435445</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817631</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.270900</td>\n",
       "      <td>0.439415</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.257600</td>\n",
       "      <td>0.447902</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810120</td>\n",
       "      <td>0.809990</td>\n",
       "      <td>0.809629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.245500</td>\n",
       "      <td>0.452843</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.234800</td>\n",
       "      <td>0.457314</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814711</td>\n",
       "      <td>0.814579</td>\n",
       "      <td>0.814216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.227500</td>\n",
       "      <td>0.461963</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.222000</td>\n",
       "      <td>0.462532</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.217700</td>\n",
       "      <td>0.465125</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.215300</td>\n",
       "      <td>0.466190</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815348</td>\n",
       "      <td>0.815452</td>\n",
       "      <td>0.815347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.471381</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816456</td>\n",
       "      <td>0.816536</td>\n",
       "      <td>0.816479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.208800</td>\n",
       "      <td>0.472278</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815319</td>\n",
       "      <td>0.815410</td>\n",
       "      <td>0.815338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 18:56:26,507] Trial 77 finished with value: 0.8153375871244556 and parameters: {'learning_rate': 2.8245230488944487e-05, 'weight_decay': 0.003, 'warmup_steps': 34}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 78 with params: {'learning_rate': 0.00015823988166036246, 'weight_decay': 0.008, 'warmup_steps': 24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 01:57 < 03:55, 17.84 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.411600</td>\n",
       "      <td>0.416075</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.811228</td>\n",
       "      <td>0.809327</td>\n",
       "      <td>0.808302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.252700</td>\n",
       "      <td>0.475163</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.803284</td>\n",
       "      <td>0.802307</td>\n",
       "      <td>0.802452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.197000</td>\n",
       "      <td>0.517512</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813504</td>\n",
       "      <td>0.813410</td>\n",
       "      <td>0.813071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.533794</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814669</td>\n",
       "      <td>0.813821</td>\n",
       "      <td>0.813970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.141400</td>\n",
       "      <td>0.587866</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.799852</td>\n",
       "      <td>0.799686</td>\n",
       "      <td>0.799305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 18:58:25,500] Trial 78 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 79 with params: {'learning_rate': 4.7117596993793786e-05, 'weight_decay': 0.005, 'warmup_steps': 23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:55, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.509000</td>\n",
       "      <td>0.457438</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792518</td>\n",
       "      <td>0.792172</td>\n",
       "      <td>0.792260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.354300</td>\n",
       "      <td>0.432411</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808438</td>\n",
       "      <td>0.808527</td>\n",
       "      <td>0.808456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.297300</td>\n",
       "      <td>0.437813</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.263600</td>\n",
       "      <td>0.457513</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820017</td>\n",
       "      <td>0.819746</td>\n",
       "      <td>0.819829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.237700</td>\n",
       "      <td>0.445571</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813096</td>\n",
       "      <td>0.813200</td>\n",
       "      <td>0.813061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.219400</td>\n",
       "      <td>0.468162</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813396</td>\n",
       "      <td>0.813368</td>\n",
       "      <td>0.813073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.206000</td>\n",
       "      <td>0.489231</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812301</td>\n",
       "      <td>0.812242</td>\n",
       "      <td>0.811926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.194700</td>\n",
       "      <td>0.500913</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816501</td>\n",
       "      <td>0.816368</td>\n",
       "      <td>0.816417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.184400</td>\n",
       "      <td>0.511840</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810708</td>\n",
       "      <td>0.810158</td>\n",
       "      <td>0.809597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.177400</td>\n",
       "      <td>0.517801</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816478</td>\n",
       "      <td>0.816578</td>\n",
       "      <td>0.816490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>0.522285</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814162</td>\n",
       "      <td>0.814242</td>\n",
       "      <td>0.814185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.167900</td>\n",
       "      <td>0.527342</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.165100</td>\n",
       "      <td>0.529027</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813151</td>\n",
       "      <td>0.813242</td>\n",
       "      <td>0.813067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.160300</td>\n",
       "      <td>0.540623</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815319</td>\n",
       "      <td>0.815410</td>\n",
       "      <td>0.815338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.159400</td>\n",
       "      <td>0.541788</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816456</td>\n",
       "      <td>0.816536</td>\n",
       "      <td>0.816479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 19:04:22,601] Trial 79 finished with value: 0.8164790066294854 and parameters: {'learning_rate': 4.7117596993793786e-05, 'weight_decay': 0.005, 'warmup_steps': 23}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 80 with params: {'learning_rate': 2.663337414236467e-05, 'weight_decay': 0.0, 'warmup_steps': 30}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:54, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.564000</td>\n",
       "      <td>0.477305</td>\n",
       "      <td>0.784404</td>\n",
       "      <td>0.784510</td>\n",
       "      <td>0.784121</td>\n",
       "      <td>0.784212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.408800</td>\n",
       "      <td>0.449155</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.796976</td>\n",
       "      <td>0.796887</td>\n",
       "      <td>0.796922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.354000</td>\n",
       "      <td>0.437743</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812112</td>\n",
       "      <td>0.812158</td>\n",
       "      <td>0.811926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.321700</td>\n",
       "      <td>0.446264</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810324</td>\n",
       "      <td>0.809148</td>\n",
       "      <td>0.809308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.296900</td>\n",
       "      <td>0.436296</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817721</td>\n",
       "      <td>0.817452</td>\n",
       "      <td>0.817534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.277100</td>\n",
       "      <td>0.438375</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.263800</td>\n",
       "      <td>0.445138</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810247</td>\n",
       "      <td>0.810032</td>\n",
       "      <td>0.809624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.251600</td>\n",
       "      <td>0.450059</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817597</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.241100</td>\n",
       "      <td>0.453966</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813626</td>\n",
       "      <td>0.813452</td>\n",
       "      <td>0.813067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.233800</td>\n",
       "      <td>0.458288</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819889</td>\n",
       "      <td>0.819915</td>\n",
       "      <td>0.819901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.228200</td>\n",
       "      <td>0.458667</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.818831</td>\n",
       "      <td>0.818773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.223800</td>\n",
       "      <td>0.461161</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815514</td>\n",
       "      <td>0.815578</td>\n",
       "      <td>0.815365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.221400</td>\n",
       "      <td>0.462208</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.216200</td>\n",
       "      <td>0.466766</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818915</td>\n",
       "      <td>0.818792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.214900</td>\n",
       "      <td>0.467600</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818915</td>\n",
       "      <td>0.818792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 19:10:18,476] Trial 80 finished with value: 0.8187920875420875 and parameters: {'learning_rate': 2.663337414236467e-05, 'weight_decay': 0.0, 'warmup_steps': 30}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 81 with params: {'learning_rate': 1.382966814410927e-05, 'weight_decay': 0.01, 'warmup_steps': 15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:58, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.624100</td>\n",
       "      <td>0.543986</td>\n",
       "      <td>0.739679</td>\n",
       "      <td>0.739793</td>\n",
       "      <td>0.739318</td>\n",
       "      <td>0.739391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.479400</td>\n",
       "      <td>0.472371</td>\n",
       "      <td>0.783257</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.783415</td>\n",
       "      <td>0.783250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.419400</td>\n",
       "      <td>0.458358</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792364</td>\n",
       "      <td>0.792424</td>\n",
       "      <td>0.792385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.387700</td>\n",
       "      <td>0.456583</td>\n",
       "      <td>0.786697</td>\n",
       "      <td>0.786965</td>\n",
       "      <td>0.786331</td>\n",
       "      <td>0.786444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.365600</td>\n",
       "      <td>0.450269</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798565</td>\n",
       "      <td>0.797760</td>\n",
       "      <td>0.797893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.347000</td>\n",
       "      <td>0.441444</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813096</td>\n",
       "      <td>0.813200</td>\n",
       "      <td>0.813061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.335000</td>\n",
       "      <td>0.439136</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812032</td>\n",
       "      <td>0.811911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.322800</td>\n",
       "      <td>0.439853</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810715</td>\n",
       "      <td>0.810779</td>\n",
       "      <td>0.810738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.313700</td>\n",
       "      <td>0.438984</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813096</td>\n",
       "      <td>0.813200</td>\n",
       "      <td>0.813061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.307000</td>\n",
       "      <td>0.442954</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816603</td>\n",
       "      <td>0.816284</td>\n",
       "      <td>0.816375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.301300</td>\n",
       "      <td>0.438579</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814162</td>\n",
       "      <td>0.814242</td>\n",
       "      <td>0.814185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.296400</td>\n",
       "      <td>0.439277</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814162</td>\n",
       "      <td>0.814242</td>\n",
       "      <td>0.814185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.293500</td>\n",
       "      <td>0.438311</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815390</td>\n",
       "      <td>0.815494</td>\n",
       "      <td>0.815355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.289900</td>\n",
       "      <td>0.439936</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813009</td>\n",
       "      <td>0.813074</td>\n",
       "      <td>0.813032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.287700</td>\n",
       "      <td>0.439920</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816478</td>\n",
       "      <td>0.816578</td>\n",
       "      <td>0.816490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 19:16:18,326] Trial 81 finished with value: 0.8164896275602275 and parameters: {'learning_rate': 1.382966814410927e-05, 'weight_decay': 0.01, 'warmup_steps': 15}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 82 with params: {'learning_rate': 0.0002891902282670203, 'weight_decay': 0.0, 'warmup_steps': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 01:57 < 03:55, 17.84 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.370100</td>\n",
       "      <td>0.432953</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.805429</td>\n",
       "      <td>0.804528</td>\n",
       "      <td>0.803825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.218800</td>\n",
       "      <td>0.540377</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.806192</td>\n",
       "      <td>0.804433</td>\n",
       "      <td>0.804593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.163100</td>\n",
       "      <td>0.584140</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813007</td>\n",
       "      <td>0.813031</td>\n",
       "      <td>0.813018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.129200</td>\n",
       "      <td>0.582015</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809782</td>\n",
       "      <td>0.809358</td>\n",
       "      <td>0.809464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.761585</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798348</td>\n",
       "      <td>0.798392</td>\n",
       "      <td>0.798164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 19:18:17,385] Trial 82 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 83 with params: {'learning_rate': 1.1683809439115933e-05, 'weight_decay': 0.003, 'warmup_steps': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:56 < 01:58, 17.76 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.638300</td>\n",
       "      <td>0.571767</td>\n",
       "      <td>0.731651</td>\n",
       "      <td>0.731667</td>\n",
       "      <td>0.731351</td>\n",
       "      <td>0.731413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.504700</td>\n",
       "      <td>0.482058</td>\n",
       "      <td>0.780963</td>\n",
       "      <td>0.781612</td>\n",
       "      <td>0.781374</td>\n",
       "      <td>0.780949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.437200</td>\n",
       "      <td>0.464365</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792382</td>\n",
       "      <td>0.792467</td>\n",
       "      <td>0.792398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.404900</td>\n",
       "      <td>0.460940</td>\n",
       "      <td>0.785550</td>\n",
       "      <td>0.785693</td>\n",
       "      <td>0.785247</td>\n",
       "      <td>0.785345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.383100</td>\n",
       "      <td>0.454782</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792518</td>\n",
       "      <td>0.792172</td>\n",
       "      <td>0.792260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.364600</td>\n",
       "      <td>0.445663</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805010</td>\n",
       "      <td>0.805107</td>\n",
       "      <td>0.805020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.353000</td>\n",
       "      <td>0.442175</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809743</td>\n",
       "      <td>0.809822</td>\n",
       "      <td>0.809629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.341100</td>\n",
       "      <td>0.441560</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808438</td>\n",
       "      <td>0.808527</td>\n",
       "      <td>0.808456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.332300</td>\n",
       "      <td>0.439794</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808564</td>\n",
       "      <td>0.808653</td>\n",
       "      <td>0.808480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.325700</td>\n",
       "      <td>0.443173</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809658</td>\n",
       "      <td>0.809443</td>\n",
       "      <td>0.809512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 19:22:15,414] Trial 83 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 84 with params: {'learning_rate': 2.407908508263029e-05, 'weight_decay': 0.003, 'warmup_steps': 31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:59 < 01:59, 17.56 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.574200</td>\n",
       "      <td>0.482962</td>\n",
       "      <td>0.783257</td>\n",
       "      <td>0.783562</td>\n",
       "      <td>0.782868</td>\n",
       "      <td>0.782983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.418500</td>\n",
       "      <td>0.453025</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793507</td>\n",
       "      <td>0.793551</td>\n",
       "      <td>0.793525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.364100</td>\n",
       "      <td>0.439748</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808713</td>\n",
       "      <td>0.808737</td>\n",
       "      <td>0.808486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.331900</td>\n",
       "      <td>0.446513</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806940</td>\n",
       "      <td>0.805685</td>\n",
       "      <td>0.805843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.307600</td>\n",
       "      <td>0.437754</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815425</td>\n",
       "      <td>0.815157</td>\n",
       "      <td>0.815238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.287800</td>\n",
       "      <td>0.436803</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815348</td>\n",
       "      <td>0.815452</td>\n",
       "      <td>0.815347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.274600</td>\n",
       "      <td>0.441214</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810120</td>\n",
       "      <td>0.809990</td>\n",
       "      <td>0.809629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.262300</td>\n",
       "      <td>0.445844</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814153</td>\n",
       "      <td>0.814200</td>\n",
       "      <td>0.814172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.251900</td>\n",
       "      <td>0.448855</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812416</td>\n",
       "      <td>0.812284</td>\n",
       "      <td>0.811923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.244700</td>\n",
       "      <td>0.452729</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 19:26:16,155] Trial 84 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 85 with params: {'learning_rate': 3.830978114707282e-05, 'weight_decay': 0.003, 'warmup_steps': 35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:55, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.530800</td>\n",
       "      <td>0.465640</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792418</td>\n",
       "      <td>0.792256</td>\n",
       "      <td>0.792311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.374600</td>\n",
       "      <td>0.437550</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805066</td>\n",
       "      <td>0.804854</td>\n",
       "      <td>0.804922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.435030</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810731</td>\n",
       "      <td>0.810821</td>\n",
       "      <td>0.810750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.284500</td>\n",
       "      <td>0.450596</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818972</td>\n",
       "      <td>0.818536</td>\n",
       "      <td>0.818646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.258700</td>\n",
       "      <td>0.437287</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814162</td>\n",
       "      <td>0.814242</td>\n",
       "      <td>0.814185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.453880</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816700</td>\n",
       "      <td>0.816747</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.226100</td>\n",
       "      <td>0.471408</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815596</td>\n",
       "      <td>0.815621</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.214500</td>\n",
       "      <td>0.476020</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813017</td>\n",
       "      <td>0.812989</td>\n",
       "      <td>0.813002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.203900</td>\n",
       "      <td>0.486037</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.815304</td>\n",
       "      <td>0.814747</td>\n",
       "      <td>0.814185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.196800</td>\n",
       "      <td>0.489988</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.191500</td>\n",
       "      <td>0.492880</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.187200</td>\n",
       "      <td>0.497802</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.184700</td>\n",
       "      <td>0.499007</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817641</td>\n",
       "      <td>0.817746</td>\n",
       "      <td>0.817641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.179700</td>\n",
       "      <td>0.507635</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816447</td>\n",
       "      <td>0.816494</td>\n",
       "      <td>0.816466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.178700</td>\n",
       "      <td>0.508446</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814162</td>\n",
       "      <td>0.814242</td>\n",
       "      <td>0.814185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 19:32:13,257] Trial 85 finished with value: 0.814184994212354 and parameters: {'learning_rate': 3.830978114707282e-05, 'weight_decay': 0.003, 'warmup_steps': 35}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 86 with params: {'learning_rate': 2.1100268354513166e-05, 'weight_decay': 0.004, 'warmup_steps': 37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 01:55 < 03:52, 18.13 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.588600</td>\n",
       "      <td>0.492891</td>\n",
       "      <td>0.772936</td>\n",
       "      <td>0.773361</td>\n",
       "      <td>0.772480</td>\n",
       "      <td>0.772590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.431800</td>\n",
       "      <td>0.457034</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793519</td>\n",
       "      <td>0.793593</td>\n",
       "      <td>0.793539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.377200</td>\n",
       "      <td>0.443332</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.802862</td>\n",
       "      <td>0.802938</td>\n",
       "      <td>0.802748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.345100</td>\n",
       "      <td>0.447571</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.801577</td>\n",
       "      <td>0.799844</td>\n",
       "      <td>0.799995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.321400</td>\n",
       "      <td>0.440224</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813358</td>\n",
       "      <td>0.812737</td>\n",
       "      <td>0.812866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 19:34:10,300] Trial 86 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 87 with params: {'learning_rate': 2.067709333338839e-05, 'weight_decay': 0.003, 'warmup_steps': 23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:53 < 01:56, 17.99 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.587900</td>\n",
       "      <td>0.493754</td>\n",
       "      <td>0.772936</td>\n",
       "      <td>0.773361</td>\n",
       "      <td>0.772480</td>\n",
       "      <td>0.772590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.433300</td>\n",
       "      <td>0.457592</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793519</td>\n",
       "      <td>0.793593</td>\n",
       "      <td>0.793539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.379100</td>\n",
       "      <td>0.443941</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.802862</td>\n",
       "      <td>0.802938</td>\n",
       "      <td>0.802748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.347200</td>\n",
       "      <td>0.447988</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.800338</td>\n",
       "      <td>0.798718</td>\n",
       "      <td>0.798867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.323600</td>\n",
       "      <td>0.440758</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813358</td>\n",
       "      <td>0.812737</td>\n",
       "      <td>0.812866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.304200</td>\n",
       "      <td>0.436286</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815319</td>\n",
       "      <td>0.815410</td>\n",
       "      <td>0.815338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.291200</td>\n",
       "      <td>0.437865</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809906</td>\n",
       "      <td>0.809906</td>\n",
       "      <td>0.809633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.278800</td>\n",
       "      <td>0.441884</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814153</td>\n",
       "      <td>0.814200</td>\n",
       "      <td>0.814172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.268600</td>\n",
       "      <td>0.443306</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811102</td>\n",
       "      <td>0.811074</td>\n",
       "      <td>0.810780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.261500</td>\n",
       "      <td>0.447166</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815336</td>\n",
       "      <td>0.815242</td>\n",
       "      <td>0.815279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 19:38:05,193] Trial 87 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 88 with params: {'learning_rate': 3.738633777325785e-05, 'weight_decay': 0.003, 'warmup_steps': 28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:51, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.531400</td>\n",
       "      <td>0.466259</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793548</td>\n",
       "      <td>0.793424</td>\n",
       "      <td>0.793469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.376700</td>\n",
       "      <td>0.438252</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803896</td>\n",
       "      <td>0.803728</td>\n",
       "      <td>0.803785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.320300</td>\n",
       "      <td>0.434995</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810731</td>\n",
       "      <td>0.810821</td>\n",
       "      <td>0.810750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.287000</td>\n",
       "      <td>0.450015</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816675</td>\n",
       "      <td>0.816241</td>\n",
       "      <td>0.816350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.261200</td>\n",
       "      <td>0.436892</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814153</td>\n",
       "      <td>0.814200</td>\n",
       "      <td>0.814172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.241900</td>\n",
       "      <td>0.452412</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816700</td>\n",
       "      <td>0.816747</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.228500</td>\n",
       "      <td>0.469227</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815596</td>\n",
       "      <td>0.815621</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.216900</td>\n",
       "      <td>0.473605</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813017</td>\n",
       "      <td>0.812989</td>\n",
       "      <td>0.813002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.206400</td>\n",
       "      <td>0.483233</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.813006</td>\n",
       "      <td>0.812453</td>\n",
       "      <td>0.811891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.199200</td>\n",
       "      <td>0.487167</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819901</td>\n",
       "      <td>0.819872</td>\n",
       "      <td>0.819886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.193800</td>\n",
       "      <td>0.489918</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.189600</td>\n",
       "      <td>0.494711</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818856</td>\n",
       "      <td>0.818957</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.187100</td>\n",
       "      <td>0.495910</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818772</td>\n",
       "      <td>0.818873</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.182100</td>\n",
       "      <td>0.504209</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.181100</td>\n",
       "      <td>0.504957</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816447</td>\n",
       "      <td>0.816494</td>\n",
       "      <td>0.816466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 19:43:58,485] Trial 88 finished with value: 0.8164664530353019 and parameters: {'learning_rate': 3.738633777325785e-05, 'weight_decay': 0.003, 'warmup_steps': 28}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 89 with params: {'learning_rate': 2.0626243186970018e-05, 'weight_decay': 0.006, 'warmup_steps': 28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 01:55 < 03:51, 18.20 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.589100</td>\n",
       "      <td>0.494258</td>\n",
       "      <td>0.771789</td>\n",
       "      <td>0.772265</td>\n",
       "      <td>0.771312</td>\n",
       "      <td>0.771421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.433700</td>\n",
       "      <td>0.457681</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793519</td>\n",
       "      <td>0.793593</td>\n",
       "      <td>0.793539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.379400</td>\n",
       "      <td>0.444012</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.802862</td>\n",
       "      <td>0.802938</td>\n",
       "      <td>0.802748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.347400</td>\n",
       "      <td>0.447971</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.800512</td>\n",
       "      <td>0.798676</td>\n",
       "      <td>0.798823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.323800</td>\n",
       "      <td>0.440743</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813358</td>\n",
       "      <td>0.812737</td>\n",
       "      <td>0.812866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 19:45:54,982] Trial 89 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 90 with params: {'learning_rate': 3.6994363225924204e-05, 'weight_decay': 0.005, 'warmup_steps': 37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:54, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.534400</td>\n",
       "      <td>0.466592</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791253</td>\n",
       "      <td>0.791130</td>\n",
       "      <td>0.791175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>0.438515</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803896</td>\n",
       "      <td>0.803728</td>\n",
       "      <td>0.803785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.321400</td>\n",
       "      <td>0.434774</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811891</td>\n",
       "      <td>0.811990</td>\n",
       "      <td>0.811902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.288100</td>\n",
       "      <td>0.449790</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815566</td>\n",
       "      <td>0.815073</td>\n",
       "      <td>0.815190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.262300</td>\n",
       "      <td>0.436336</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815303</td>\n",
       "      <td>0.815368</td>\n",
       "      <td>0.815326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.242900</td>\n",
       "      <td>0.451768</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816700</td>\n",
       "      <td>0.816747</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.229600</td>\n",
       "      <td>0.468076</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.217900</td>\n",
       "      <td>0.472469</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.207400</td>\n",
       "      <td>0.482031</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.814070</td>\n",
       "      <td>0.813579</td>\n",
       "      <td>0.813044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.200200</td>\n",
       "      <td>0.486111</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819901</td>\n",
       "      <td>0.819872</td>\n",
       "      <td>0.819886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.194800</td>\n",
       "      <td>0.488588</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822196</td>\n",
       "      <td>0.822167</td>\n",
       "      <td>0.822180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.190600</td>\n",
       "      <td>0.493061</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818856</td>\n",
       "      <td>0.818957</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.188100</td>\n",
       "      <td>0.494431</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818772</td>\n",
       "      <td>0.818873</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.183100</td>\n",
       "      <td>0.502566</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816447</td>\n",
       "      <td>0.816494</td>\n",
       "      <td>0.816466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.182100</td>\n",
       "      <td>0.503374</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815303</td>\n",
       "      <td>0.815368</td>\n",
       "      <td>0.815326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 19:51:51,081] Trial 90 finished with value: 0.8153259275336583 and parameters: {'learning_rate': 3.6994363225924204e-05, 'weight_decay': 0.005, 'warmup_steps': 37}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 91 with params: {'learning_rate': 1.5775528862129258e-05, 'weight_decay': 0.0, 'warmup_steps': 28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:54, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.614800</td>\n",
       "      <td>0.525890</td>\n",
       "      <td>0.758028</td>\n",
       "      <td>0.758816</td>\n",
       "      <td>0.757420</td>\n",
       "      <td>0.757491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.463300</td>\n",
       "      <td>0.466767</td>\n",
       "      <td>0.784404</td>\n",
       "      <td>0.784368</td>\n",
       "      <td>0.784457</td>\n",
       "      <td>0.784375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.406200</td>\n",
       "      <td>0.453582</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795836</td>\n",
       "      <td>0.795929</td>\n",
       "      <td>0.795845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.374400</td>\n",
       "      <td>0.453174</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.789363</td>\n",
       "      <td>0.788583</td>\n",
       "      <td>0.788706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.351900</td>\n",
       "      <td>0.447031</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.803166</td>\n",
       "      <td>0.802349</td>\n",
       "      <td>0.802486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.333000</td>\n",
       "      <td>0.438821</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810731</td>\n",
       "      <td>0.810821</td>\n",
       "      <td>0.810750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.320600</td>\n",
       "      <td>0.437651</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808564</td>\n",
       "      <td>0.808653</td>\n",
       "      <td>0.808480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.308200</td>\n",
       "      <td>0.439416</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811859</td>\n",
       "      <td>0.811905</td>\n",
       "      <td>0.811878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.298800</td>\n",
       "      <td>0.439371</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810926</td>\n",
       "      <td>0.810990</td>\n",
       "      <td>0.810778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.292000</td>\n",
       "      <td>0.443306</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816603</td>\n",
       "      <td>0.816284</td>\n",
       "      <td>0.816375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.286200</td>\n",
       "      <td>0.439203</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811869</td>\n",
       "      <td>0.811947</td>\n",
       "      <td>0.811891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.281400</td>\n",
       "      <td>0.440092</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811869</td>\n",
       "      <td>0.811947</td>\n",
       "      <td>0.811891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.278600</td>\n",
       "      <td>0.439759</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810760</td>\n",
       "      <td>0.810863</td>\n",
       "      <td>0.810760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.274800</td>\n",
       "      <td>0.441416</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813009</td>\n",
       "      <td>0.813074</td>\n",
       "      <td>0.813032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.272500</td>\n",
       "      <td>0.441611</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813009</td>\n",
       "      <td>0.813074</td>\n",
       "      <td>0.813032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 19:57:47,499] Trial 91 finished with value: 0.8130318396769336 and parameters: {'learning_rate': 1.5775528862129258e-05, 'weight_decay': 0.0, 'warmup_steps': 28}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 92 with params: {'learning_rate': 2.7062569698455856e-05, 'weight_decay': 0.0, 'warmup_steps': 33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:53, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.563100</td>\n",
       "      <td>0.476596</td>\n",
       "      <td>0.784404</td>\n",
       "      <td>0.784510</td>\n",
       "      <td>0.784121</td>\n",
       "      <td>0.784212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.407400</td>\n",
       "      <td>0.448453</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.797009</td>\n",
       "      <td>0.796845</td>\n",
       "      <td>0.796901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.352400</td>\n",
       "      <td>0.437409</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812037</td>\n",
       "      <td>0.812116</td>\n",
       "      <td>0.811923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.446181</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.809244</td>\n",
       "      <td>0.807980</td>\n",
       "      <td>0.808141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.295200</td>\n",
       "      <td>0.436029</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817721</td>\n",
       "      <td>0.817452</td>\n",
       "      <td>0.817534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.275400</td>\n",
       "      <td>0.438646</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.262100</td>\n",
       "      <td>0.445885</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811330</td>\n",
       "      <td>0.811158</td>\n",
       "      <td>0.810774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.249900</td>\n",
       "      <td>0.450792</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818741</td>\n",
       "      <td>0.818788</td>\n",
       "      <td>0.818761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.454841</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813626</td>\n",
       "      <td>0.813452</td>\n",
       "      <td>0.813067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.232100</td>\n",
       "      <td>0.459208</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.226500</td>\n",
       "      <td>0.459716</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819891</td>\n",
       "      <td>0.819957</td>\n",
       "      <td>0.819914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.222100</td>\n",
       "      <td>0.462248</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815514</td>\n",
       "      <td>0.815578</td>\n",
       "      <td>0.815365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.219700</td>\n",
       "      <td>0.463248</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.214500</td>\n",
       "      <td>0.467955</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817641</td>\n",
       "      <td>0.817746</td>\n",
       "      <td>0.817641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.213200</td>\n",
       "      <td>0.468833</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817641</td>\n",
       "      <td>0.817746</td>\n",
       "      <td>0.817641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 20:03:42,756] Trial 92 finished with value: 0.8176411246568802 and parameters: {'learning_rate': 2.7062569698455856e-05, 'weight_decay': 0.0, 'warmup_steps': 33}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 93 with params: {'learning_rate': 2.1207807932658264e-05, 'weight_decay': 0.0, 'warmup_steps': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:56, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.587100</td>\n",
       "      <td>0.492110</td>\n",
       "      <td>0.775229</td>\n",
       "      <td>0.775663</td>\n",
       "      <td>0.774775</td>\n",
       "      <td>0.774887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.431100</td>\n",
       "      <td>0.456833</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794658</td>\n",
       "      <td>0.794719</td>\n",
       "      <td>0.794679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.376700</td>\n",
       "      <td>0.443147</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803977</td>\n",
       "      <td>0.804065</td>\n",
       "      <td>0.803893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.344600</td>\n",
       "      <td>0.447551</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.802820</td>\n",
       "      <td>0.800970</td>\n",
       "      <td>0.801122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.320900</td>\n",
       "      <td>0.440116</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814461</td>\n",
       "      <td>0.813905</td>\n",
       "      <td>0.814028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.301400</td>\n",
       "      <td>0.436171</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814162</td>\n",
       "      <td>0.814242</td>\n",
       "      <td>0.814185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.288400</td>\n",
       "      <td>0.438172</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810007</td>\n",
       "      <td>0.809948</td>\n",
       "      <td>0.809632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.275900</td>\n",
       "      <td>0.442331</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815301</td>\n",
       "      <td>0.815326</td>\n",
       "      <td>0.815312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.265700</td>\n",
       "      <td>0.443997</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812301</td>\n",
       "      <td>0.812242</td>\n",
       "      <td>0.811926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.258600</td>\n",
       "      <td>0.447875</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816501</td>\n",
       "      <td>0.816368</td>\n",
       "      <td>0.816417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.252900</td>\n",
       "      <td>0.446145</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819906</td>\n",
       "      <td>0.819999</td>\n",
       "      <td>0.819925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.248400</td>\n",
       "      <td>0.447758</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818856</td>\n",
       "      <td>0.818957</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.245700</td>\n",
       "      <td>0.448826</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.241100</td>\n",
       "      <td>0.451107</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819906</td>\n",
       "      <td>0.819999</td>\n",
       "      <td>0.819925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.239100</td>\n",
       "      <td>0.451662</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819935</td>\n",
       "      <td>0.820041</td>\n",
       "      <td>0.819935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 20:09:40,998] Trial 93 finished with value: 0.8199349469882402 and parameters: {'learning_rate': 2.1207807932658264e-05, 'weight_decay': 0.0, 'warmup_steps': 32}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 94 with params: {'learning_rate': 1.9690163329695552e-05, 'weight_decay': 0.0, 'warmup_steps': 35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:54 < 01:57, 17.93 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.595100</td>\n",
       "      <td>0.499160</td>\n",
       "      <td>0.768349</td>\n",
       "      <td>0.768868</td>\n",
       "      <td>0.767850</td>\n",
       "      <td>0.767953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.438800</td>\n",
       "      <td>0.459230</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795836</td>\n",
       "      <td>0.795929</td>\n",
       "      <td>0.795845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.384100</td>\n",
       "      <td>0.445647</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803977</td>\n",
       "      <td>0.804065</td>\n",
       "      <td>0.803893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.352100</td>\n",
       "      <td>0.448586</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.798031</td>\n",
       "      <td>0.796424</td>\n",
       "      <td>0.796569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.328700</td>\n",
       "      <td>0.441891</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814377</td>\n",
       "      <td>0.813947</td>\n",
       "      <td>0.814055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.309400</td>\n",
       "      <td>0.436532</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815319</td>\n",
       "      <td>0.815410</td>\n",
       "      <td>0.815338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.296400</td>\n",
       "      <td>0.437490</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808914</td>\n",
       "      <td>0.808822</td>\n",
       "      <td>0.808484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.283900</td>\n",
       "      <td>0.441123</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813009</td>\n",
       "      <td>0.813074</td>\n",
       "      <td>0.813032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.273900</td>\n",
       "      <td>0.442405</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811209</td>\n",
       "      <td>0.811116</td>\n",
       "      <td>0.810778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.266900</td>\n",
       "      <td>0.446125</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814206</td>\n",
       "      <td>0.814073</td>\n",
       "      <td>0.814122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 20:13:36,801] Trial 94 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 95 with params: {'learning_rate': 2.1208717836239785e-05, 'weight_decay': 0.003, 'warmup_steps': 35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:53 < 01:56, 18.03 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.587700</td>\n",
       "      <td>0.492297</td>\n",
       "      <td>0.774083</td>\n",
       "      <td>0.774459</td>\n",
       "      <td>0.773649</td>\n",
       "      <td>0.773759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.431200</td>\n",
       "      <td>0.456868</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794658</td>\n",
       "      <td>0.794719</td>\n",
       "      <td>0.794679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.376700</td>\n",
       "      <td>0.443168</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803977</td>\n",
       "      <td>0.804065</td>\n",
       "      <td>0.803893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.344600</td>\n",
       "      <td>0.447544</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.802820</td>\n",
       "      <td>0.800970</td>\n",
       "      <td>0.801122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.320900</td>\n",
       "      <td>0.440108</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814461</td>\n",
       "      <td>0.813905</td>\n",
       "      <td>0.814028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.301400</td>\n",
       "      <td>0.436185</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813025</td>\n",
       "      <td>0.813116</td>\n",
       "      <td>0.813044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.288300</td>\n",
       "      <td>0.438197</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811209</td>\n",
       "      <td>0.811116</td>\n",
       "      <td>0.810778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.275900</td>\n",
       "      <td>0.442336</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815301</td>\n",
       "      <td>0.815326</td>\n",
       "      <td>0.815312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.265700</td>\n",
       "      <td>0.444023</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811102</td>\n",
       "      <td>0.811074</td>\n",
       "      <td>0.810780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.258600</td>\n",
       "      <td>0.447838</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815336</td>\n",
       "      <td>0.815242</td>\n",
       "      <td>0.815279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 20:17:32,534] Trial 95 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 96 with params: {'learning_rate': 3.417395370091366e-05, 'weight_decay': 0.002, 'warmup_steps': 35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 01:55 < 03:51, 18.19 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.541300</td>\n",
       "      <td>0.468289</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792386</td>\n",
       "      <td>0.792298</td>\n",
       "      <td>0.792333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.385400</td>\n",
       "      <td>0.440732</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.802770</td>\n",
       "      <td>0.802560</td>\n",
       "      <td>0.802627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.329200</td>\n",
       "      <td>0.434684</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808509</td>\n",
       "      <td>0.808611</td>\n",
       "      <td>0.808474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.296300</td>\n",
       "      <td>0.448025</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815566</td>\n",
       "      <td>0.815073</td>\n",
       "      <td>0.815190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.270700</td>\n",
       "      <td>0.434939</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813007</td>\n",
       "      <td>0.813031</td>\n",
       "      <td>0.813018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 20:19:29,064] Trial 96 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 97 with params: {'learning_rate': 2.554508127002213e-05, 'weight_decay': 0.004, 'warmup_steps': 28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:50, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.567700</td>\n",
       "      <td>0.479440</td>\n",
       "      <td>0.780963</td>\n",
       "      <td>0.781097</td>\n",
       "      <td>0.780658</td>\n",
       "      <td>0.780753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.412700</td>\n",
       "      <td>0.450978</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795817</td>\n",
       "      <td>0.795761</td>\n",
       "      <td>0.795785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.358200</td>\n",
       "      <td>0.438557</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811102</td>\n",
       "      <td>0.811074</td>\n",
       "      <td>0.810780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.325900</td>\n",
       "      <td>0.446329</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810324</td>\n",
       "      <td>0.809148</td>\n",
       "      <td>0.809308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.301300</td>\n",
       "      <td>0.436866</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817669</td>\n",
       "      <td>0.817494</td>\n",
       "      <td>0.817555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.281500</td>\n",
       "      <td>0.437699</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815348</td>\n",
       "      <td>0.815452</td>\n",
       "      <td>0.815347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.268300</td>\n",
       "      <td>0.443353</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811464</td>\n",
       "      <td>0.811200</td>\n",
       "      <td>0.810768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.256100</td>\n",
       "      <td>0.448222</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.245500</td>\n",
       "      <td>0.451770</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812416</td>\n",
       "      <td>0.812284</td>\n",
       "      <td>0.811923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.238300</td>\n",
       "      <td>0.455874</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.232600</td>\n",
       "      <td>0.456046</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818772</td>\n",
       "      <td>0.818873</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.228200</td>\n",
       "      <td>0.458310</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.225800</td>\n",
       "      <td>0.459416</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.220700</td>\n",
       "      <td>0.463478</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.219200</td>\n",
       "      <td>0.464197</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 20:25:21,408] Trial 97 finished with value: 0.817648799542307 and parameters: {'learning_rate': 2.554508127002213e-05, 'weight_decay': 0.004, 'warmup_steps': 28}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 98 with params: {'learning_rate': 0.00036979530813873037, 'weight_decay': 0.009000000000000001, 'warmup_steps': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:55 < 01:57, 17.91 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.356100</td>\n",
       "      <td>0.429779</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810541</td>\n",
       "      <td>0.810116</td>\n",
       "      <td>0.809608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.209600</td>\n",
       "      <td>0.574433</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.804788</td>\n",
       "      <td>0.803349</td>\n",
       "      <td>0.803506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.153400</td>\n",
       "      <td>0.600963</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806301</td>\n",
       "      <td>0.805938</td>\n",
       "      <td>0.806033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.119100</td>\n",
       "      <td>0.645975</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795843</td>\n",
       "      <td>0.795719</td>\n",
       "      <td>0.795764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.095000</td>\n",
       "      <td>0.798493</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794681</td>\n",
       "      <td>0.794592</td>\n",
       "      <td>0.794627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.077900</td>\n",
       "      <td>0.915139</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798230</td>\n",
       "      <td>0.797929</td>\n",
       "      <td>0.798012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>0.904904</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795817</td>\n",
       "      <td>0.795761</td>\n",
       "      <td>0.795785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.936535</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795803</td>\n",
       "      <td>0.795803</td>\n",
       "      <td>0.795803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>1.027001</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.801351</td>\n",
       "      <td>0.800939</td>\n",
       "      <td>0.800432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.043100</td>\n",
       "      <td>1.021904</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.788920</td>\n",
       "      <td>0.788920</td>\n",
       "      <td>0.788920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 20:29:17,562] Trial 98 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 99 with params: {'learning_rate': 5.9614195699865725e-05, 'weight_decay': 0.002, 'warmup_steps': 31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:53 < 01:56, 18.03 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.489900</td>\n",
       "      <td>0.447069</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807401</td>\n",
       "      <td>0.807314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.332000</td>\n",
       "      <td>0.430503</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810760</td>\n",
       "      <td>0.810863</td>\n",
       "      <td>0.810760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.274200</td>\n",
       "      <td>0.438109</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816470</td>\n",
       "      <td>0.816410</td>\n",
       "      <td>0.816436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.240900</td>\n",
       "      <td>0.469831</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824962</td>\n",
       "      <td>0.824166</td>\n",
       "      <td>0.824319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.215500</td>\n",
       "      <td>0.461188</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813396</td>\n",
       "      <td>0.813368</td>\n",
       "      <td>0.813073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.198200</td>\n",
       "      <td>0.489267</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.816057</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.815355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.184300</td>\n",
       "      <td>0.512759</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818918</td>\n",
       "      <td>0.818999</td>\n",
       "      <td>0.818804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.173800</td>\n",
       "      <td>0.534339</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814377</td>\n",
       "      <td>0.813947</td>\n",
       "      <td>0.814055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.163600</td>\n",
       "      <td>0.548799</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.810032</td>\n",
       "      <td>0.809116</td>\n",
       "      <td>0.808413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.156600</td>\n",
       "      <td>0.555231</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810715</td>\n",
       "      <td>0.810779</td>\n",
       "      <td>0.810738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 20:33:11,852] Trial 99 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 with params: {'learning_rate': 1.6789879334421116e-05, 'weight_decay': 0.005, 'warmup_steps': 38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 01:56 < 03:53, 18.01 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.610900</td>\n",
       "      <td>0.518269</td>\n",
       "      <td>0.758028</td>\n",
       "      <td>0.758561</td>\n",
       "      <td>0.757504</td>\n",
       "      <td>0.757591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.456400</td>\n",
       "      <td>0.464492</td>\n",
       "      <td>0.786697</td>\n",
       "      <td>0.786661</td>\n",
       "      <td>0.786752</td>\n",
       "      <td>0.786669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.451349</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795836</td>\n",
       "      <td>0.795929</td>\n",
       "      <td>0.795845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.368100</td>\n",
       "      <td>0.451606</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.796378</td>\n",
       "      <td>0.795424</td>\n",
       "      <td>0.795561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.345300</td>\n",
       "      <td>0.445475</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.804163</td>\n",
       "      <td>0.803559</td>\n",
       "      <td>0.803682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 20:35:10,139] Trial 100 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 101 with params: {'learning_rate': 3.8465371212942565e-05, 'weight_decay': 0.0, 'warmup_steps': 35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:55, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.530400</td>\n",
       "      <td>0.465492</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792418</td>\n",
       "      <td>0.792256</td>\n",
       "      <td>0.792311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.374200</td>\n",
       "      <td>0.437415</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805066</td>\n",
       "      <td>0.804854</td>\n",
       "      <td>0.804922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.317500</td>\n",
       "      <td>0.435095</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810731</td>\n",
       "      <td>0.810821</td>\n",
       "      <td>0.810750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.284100</td>\n",
       "      <td>0.450706</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818972</td>\n",
       "      <td>0.818536</td>\n",
       "      <td>0.818646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.258300</td>\n",
       "      <td>0.437386</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814162</td>\n",
       "      <td>0.814242</td>\n",
       "      <td>0.814185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.239000</td>\n",
       "      <td>0.454104</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815596</td>\n",
       "      <td>0.815621</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.225700</td>\n",
       "      <td>0.471792</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815596</td>\n",
       "      <td>0.815621</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.214100</td>\n",
       "      <td>0.476417</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814158</td>\n",
       "      <td>0.814158</td>\n",
       "      <td>0.814158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.203500</td>\n",
       "      <td>0.486491</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.815304</td>\n",
       "      <td>0.814747</td>\n",
       "      <td>0.814185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.196400</td>\n",
       "      <td>0.490416</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.191100</td>\n",
       "      <td>0.493460</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818741</td>\n",
       "      <td>0.818788</td>\n",
       "      <td>0.818761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.186800</td>\n",
       "      <td>0.498272</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.184300</td>\n",
       "      <td>0.499527</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817641</td>\n",
       "      <td>0.817746</td>\n",
       "      <td>0.817641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.179300</td>\n",
       "      <td>0.508262</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817597</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.178300</td>\n",
       "      <td>0.509007</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814162</td>\n",
       "      <td>0.814242</td>\n",
       "      <td>0.814185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 20:41:06,803] Trial 101 finished with value: 0.814184994212354 and parameters: {'learning_rate': 3.8465371212942565e-05, 'weight_decay': 0.0, 'warmup_steps': 35}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 102 with params: {'learning_rate': 2.9414531729427016e-05, 'weight_decay': 0.0, 'warmup_steps': 24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:53 < 01:57, 17.98 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.553000</td>\n",
       "      <td>0.472815</td>\n",
       "      <td>0.786697</td>\n",
       "      <td>0.786698</td>\n",
       "      <td>0.786499</td>\n",
       "      <td>0.786561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.399100</td>\n",
       "      <td>0.445273</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.800474</td>\n",
       "      <td>0.800265</td>\n",
       "      <td>0.800332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.344000</td>\n",
       "      <td>0.436113</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808632</td>\n",
       "      <td>0.808695</td>\n",
       "      <td>0.808484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.311600</td>\n",
       "      <td>0.446433</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816969</td>\n",
       "      <td>0.816115</td>\n",
       "      <td>0.816266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.286500</td>\n",
       "      <td>0.435293</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817631</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.266700</td>\n",
       "      <td>0.440527</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815390</td>\n",
       "      <td>0.815494</td>\n",
       "      <td>0.815355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.253300</td>\n",
       "      <td>0.450143</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810120</td>\n",
       "      <td>0.809990</td>\n",
       "      <td>0.809629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.241300</td>\n",
       "      <td>0.455028</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818741</td>\n",
       "      <td>0.818788</td>\n",
       "      <td>0.818761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.230700</td>\n",
       "      <td>0.460056</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814494</td>\n",
       "      <td>0.814494</td>\n",
       "      <td>0.814220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.223400</td>\n",
       "      <td>0.464775</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815301</td>\n",
       "      <td>0.815326</td>\n",
       "      <td>0.815312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 20:45:01,699] Trial 102 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 103 with params: {'learning_rate': 2.5418705508557885e-05, 'weight_decay': 0.0, 'warmup_steps': 28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:50, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.568200</td>\n",
       "      <td>0.479704</td>\n",
       "      <td>0.780963</td>\n",
       "      <td>0.781097</td>\n",
       "      <td>0.780658</td>\n",
       "      <td>0.780753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.413200</td>\n",
       "      <td>0.451122</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794661</td>\n",
       "      <td>0.794635</td>\n",
       "      <td>0.794647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.358700</td>\n",
       "      <td>0.438666</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811102</td>\n",
       "      <td>0.811074</td>\n",
       "      <td>0.810780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.326400</td>\n",
       "      <td>0.446326</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810324</td>\n",
       "      <td>0.809148</td>\n",
       "      <td>0.809308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.301900</td>\n",
       "      <td>0.436971</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817669</td>\n",
       "      <td>0.817494</td>\n",
       "      <td>0.817555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.282100</td>\n",
       "      <td>0.437582</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815348</td>\n",
       "      <td>0.815452</td>\n",
       "      <td>0.815347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.268800</td>\n",
       "      <td>0.443166</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811464</td>\n",
       "      <td>0.811200</td>\n",
       "      <td>0.810768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.256600</td>\n",
       "      <td>0.447990</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.246100</td>\n",
       "      <td>0.451527</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812416</td>\n",
       "      <td>0.812284</td>\n",
       "      <td>0.811923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.238800</td>\n",
       "      <td>0.455611</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.233100</td>\n",
       "      <td>0.455636</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817641</td>\n",
       "      <td>0.817746</td>\n",
       "      <td>0.817641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.228800</td>\n",
       "      <td>0.457931</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.226300</td>\n",
       "      <td>0.459089</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.221200</td>\n",
       "      <td>0.463128</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.219700</td>\n",
       "      <td>0.463818</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 20:50:53,790] Trial 103 finished with value: 0.817648799542307 and parameters: {'learning_rate': 2.5418705508557885e-05, 'weight_decay': 0.0, 'warmup_steps': 28}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 104 with params: {'learning_rate': 2.2451250620334333e-05, 'weight_decay': 0.001, 'warmup_steps': 29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:54 < 01:57, 17.97 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.580800</td>\n",
       "      <td>0.487619</td>\n",
       "      <td>0.782110</td>\n",
       "      <td>0.782283</td>\n",
       "      <td>0.781784</td>\n",
       "      <td>0.781885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.425300</td>\n",
       "      <td>0.455184</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793507</td>\n",
       "      <td>0.793551</td>\n",
       "      <td>0.793525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.371000</td>\n",
       "      <td>0.441533</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807524</td>\n",
       "      <td>0.807569</td>\n",
       "      <td>0.807338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.338900</td>\n",
       "      <td>0.447018</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.803715</td>\n",
       "      <td>0.802181</td>\n",
       "      <td>0.802336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.314900</td>\n",
       "      <td>0.438973</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815566</td>\n",
       "      <td>0.815073</td>\n",
       "      <td>0.815190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.295300</td>\n",
       "      <td>0.436292</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814185</td>\n",
       "      <td>0.814284</td>\n",
       "      <td>0.814196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.439290</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811209</td>\n",
       "      <td>0.811116</td>\n",
       "      <td>0.810778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.269800</td>\n",
       "      <td>0.443735</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815301</td>\n",
       "      <td>0.815326</td>\n",
       "      <td>0.815312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.259500</td>\n",
       "      <td>0.445885</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811102</td>\n",
       "      <td>0.811074</td>\n",
       "      <td>0.810780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.252300</td>\n",
       "      <td>0.449736</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815336</td>\n",
       "      <td>0.815242</td>\n",
       "      <td>0.815279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 20:54:48,832] Trial 104 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 105 with params: {'learning_rate': 8.347446557533028e-05, 'weight_decay': 0.01, 'warmup_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:53 < 01:56, 18.01 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.453700</td>\n",
       "      <td>0.440061</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806215</td>\n",
       "      <td>0.806317</td>\n",
       "      <td>0.806180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.301900</td>\n",
       "      <td>0.441227</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816546</td>\n",
       "      <td>0.816326</td>\n",
       "      <td>0.816397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.244800</td>\n",
       "      <td>0.446615</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818741</td>\n",
       "      <td>0.818788</td>\n",
       "      <td>0.818761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.212000</td>\n",
       "      <td>0.488520</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.824852</td>\n",
       "      <td>0.822746</td>\n",
       "      <td>0.822944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.187700</td>\n",
       "      <td>0.488432</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813626</td>\n",
       "      <td>0.813452</td>\n",
       "      <td>0.813067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.519623</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811464</td>\n",
       "      <td>0.811200</td>\n",
       "      <td>0.810768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.156100</td>\n",
       "      <td>0.562707</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813054</td>\n",
       "      <td>0.813158</td>\n",
       "      <td>0.813053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.146600</td>\n",
       "      <td>0.587983</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.816155</td>\n",
       "      <td>0.814863</td>\n",
       "      <td>0.815034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.136100</td>\n",
       "      <td>0.611294</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.809646</td>\n",
       "      <td>0.809032</td>\n",
       "      <td>0.808444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>0.620272</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814185</td>\n",
       "      <td>0.814284</td>\n",
       "      <td>0.814196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 20:58:43,398] Trial 105 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 106 with params: {'learning_rate': 1.508409012592342e-05, 'weight_decay': 0.002, 'warmup_steps': 34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 01:56 < 03:52, 18.10 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.619700</td>\n",
       "      <td>0.533125</td>\n",
       "      <td>0.753440</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.752957</td>\n",
       "      <td>0.753043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.469200</td>\n",
       "      <td>0.468693</td>\n",
       "      <td>0.782110</td>\n",
       "      <td>0.782158</td>\n",
       "      <td>0.782247</td>\n",
       "      <td>0.782100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.410800</td>\n",
       "      <td>0.455293</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.795887</td>\n",
       "      <td>0.795833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.379000</td>\n",
       "      <td>0.454265</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791564</td>\n",
       "      <td>0.790919</td>\n",
       "      <td>0.791037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.356600</td>\n",
       "      <td>0.448068</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.799662</td>\n",
       "      <td>0.798929</td>\n",
       "      <td>0.799058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 21:00:40,497] Trial 106 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 107 with params: {'learning_rate': 0.00010121968952843504, 'weight_decay': 0.006, 'warmup_steps': 33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:53 < 01:56, 18.00 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.446100</td>\n",
       "      <td>0.432898</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.806684</td>\n",
       "      <td>0.805696</td>\n",
       "      <td>0.804963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.286900</td>\n",
       "      <td>0.452148</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810472</td>\n",
       "      <td>0.809106</td>\n",
       "      <td>0.809271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.229500</td>\n",
       "      <td>0.458867</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824564</td>\n",
       "      <td>0.824672</td>\n",
       "      <td>0.824530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.196600</td>\n",
       "      <td>0.504587</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.826332</td>\n",
       "      <td>0.823830</td>\n",
       "      <td>0.824030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.173200</td>\n",
       "      <td>0.516701</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811209</td>\n",
       "      <td>0.811116</td>\n",
       "      <td>0.810778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.155900</td>\n",
       "      <td>0.555492</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.806111</td>\n",
       "      <td>0.805570</td>\n",
       "      <td>0.805009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.140800</td>\n",
       "      <td>0.613808</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809743</td>\n",
       "      <td>0.809822</td>\n",
       "      <td>0.809629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.131100</td>\n",
       "      <td>0.629267</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819690</td>\n",
       "      <td>0.818283</td>\n",
       "      <td>0.818463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.120100</td>\n",
       "      <td>0.669681</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.802522</td>\n",
       "      <td>0.801191</td>\n",
       "      <td>0.800332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.112900</td>\n",
       "      <td>0.674922</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808467</td>\n",
       "      <td>0.808569</td>\n",
       "      <td>0.808466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 21:04:35,375] Trial 107 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 108 with params: {'learning_rate': 1.0134376014913452e-05, 'weight_decay': 0.0, 'warmup_steps': 35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:55 < 01:57, 17.86 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.646700</td>\n",
       "      <td>0.591629</td>\n",
       "      <td>0.715596</td>\n",
       "      <td>0.715898</td>\n",
       "      <td>0.715080</td>\n",
       "      <td>0.715111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.527300</td>\n",
       "      <td>0.493249</td>\n",
       "      <td>0.782110</td>\n",
       "      <td>0.783474</td>\n",
       "      <td>0.782710</td>\n",
       "      <td>0.782037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.453000</td>\n",
       "      <td>0.470218</td>\n",
       "      <td>0.786697</td>\n",
       "      <td>0.786661</td>\n",
       "      <td>0.786752</td>\n",
       "      <td>0.786669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.419400</td>\n",
       "      <td>0.465414</td>\n",
       "      <td>0.784404</td>\n",
       "      <td>0.784510</td>\n",
       "      <td>0.784121</td>\n",
       "      <td>0.784212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.397800</td>\n",
       "      <td>0.459419</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.789105</td>\n",
       "      <td>0.788709</td>\n",
       "      <td>0.788803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.379300</td>\n",
       "      <td>0.449806</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798106</td>\n",
       "      <td>0.798181</td>\n",
       "      <td>0.798127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.368000</td>\n",
       "      <td>0.445850</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805094</td>\n",
       "      <td>0.805191</td>\n",
       "      <td>0.805037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.356400</td>\n",
       "      <td>0.444096</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806215</td>\n",
       "      <td>0.806317</td>\n",
       "      <td>0.806180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.347900</td>\n",
       "      <td>0.441973</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808564</td>\n",
       "      <td>0.808653</td>\n",
       "      <td>0.808480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.341300</td>\n",
       "      <td>0.444519</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805024</td>\n",
       "      <td>0.804896</td>\n",
       "      <td>0.804943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 21:08:41,880] Trial 108 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 109 with params: {'learning_rate': 2.4585844678745737e-05, 'weight_decay': 0.001, 'warmup_steps': 34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:52, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.572800</td>\n",
       "      <td>0.481803</td>\n",
       "      <td>0.783257</td>\n",
       "      <td>0.783562</td>\n",
       "      <td>0.782868</td>\n",
       "      <td>0.782983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.416600</td>\n",
       "      <td>0.452319</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793507</td>\n",
       "      <td>0.793551</td>\n",
       "      <td>0.793525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.362000</td>\n",
       "      <td>0.439284</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810007</td>\n",
       "      <td>0.809948</td>\n",
       "      <td>0.809632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.329800</td>\n",
       "      <td>0.446339</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806940</td>\n",
       "      <td>0.805685</td>\n",
       "      <td>0.805843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.305400</td>\n",
       "      <td>0.437367</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816546</td>\n",
       "      <td>0.816326</td>\n",
       "      <td>0.816397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.285600</td>\n",
       "      <td>0.437052</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815348</td>\n",
       "      <td>0.815452</td>\n",
       "      <td>0.815347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.272400</td>\n",
       "      <td>0.441903</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.809168</td>\n",
       "      <td>0.808906</td>\n",
       "      <td>0.808474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.260100</td>\n",
       "      <td>0.446635</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813009</td>\n",
       "      <td>0.813074</td>\n",
       "      <td>0.813032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.249600</td>\n",
       "      <td>0.449817</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811330</td>\n",
       "      <td>0.811158</td>\n",
       "      <td>0.810774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.242400</td>\n",
       "      <td>0.453799</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.236700</td>\n",
       "      <td>0.453621</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818772</td>\n",
       "      <td>0.818873</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.232300</td>\n",
       "      <td>0.455734</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>0.456884</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>0.460517</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818915</td>\n",
       "      <td>0.818792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.223200</td>\n",
       "      <td>0.461197</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818915</td>\n",
       "      <td>0.818792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 21:14:36,362] Trial 109 finished with value: 0.8187920875420875 and parameters: {'learning_rate': 2.4585844678745737e-05, 'weight_decay': 0.001, 'warmup_steps': 34}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 110 with params: {'learning_rate': 5.596988913048012e-05, 'weight_decay': 0.003, 'warmup_steps': 11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 01:55 < 03:52, 18.13 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.490500</td>\n",
       "      <td>0.449712</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798097</td>\n",
       "      <td>0.798097</td>\n",
       "      <td>0.798097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.430156</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811891</td>\n",
       "      <td>0.811990</td>\n",
       "      <td>0.811902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.280300</td>\n",
       "      <td>0.437697</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816470</td>\n",
       "      <td>0.816410</td>\n",
       "      <td>0.816436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.246900</td>\n",
       "      <td>0.465516</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820162</td>\n",
       "      <td>0.819662</td>\n",
       "      <td>0.819781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.221200</td>\n",
       "      <td>0.455572</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811102</td>\n",
       "      <td>0.811074</td>\n",
       "      <td>0.810780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 21:16:33,270] Trial 110 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 111 with params: {'learning_rate': 2.5991571071450347e-05, 'weight_decay': 0.0, 'warmup_steps': 33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:51, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.567000</td>\n",
       "      <td>0.478673</td>\n",
       "      <td>0.783257</td>\n",
       "      <td>0.783395</td>\n",
       "      <td>0.782952</td>\n",
       "      <td>0.783049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.411200</td>\n",
       "      <td>0.450264</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.796976</td>\n",
       "      <td>0.796887</td>\n",
       "      <td>0.796922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.356500</td>\n",
       "      <td>0.438159</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812200</td>\n",
       "      <td>0.812200</td>\n",
       "      <td>0.811927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.324100</td>\n",
       "      <td>0.446202</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810324</td>\n",
       "      <td>0.809148</td>\n",
       "      <td>0.809308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.299500</td>\n",
       "      <td>0.436584</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815374</td>\n",
       "      <td>0.815200</td>\n",
       "      <td>0.815260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.279700</td>\n",
       "      <td>0.437929</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.266400</td>\n",
       "      <td>0.444074</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810247</td>\n",
       "      <td>0.810032</td>\n",
       "      <td>0.809624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.254200</td>\n",
       "      <td>0.448930</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.243600</td>\n",
       "      <td>0.452684</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812416</td>\n",
       "      <td>0.812284</td>\n",
       "      <td>0.811923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.236400</td>\n",
       "      <td>0.456870</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.230700</td>\n",
       "      <td>0.457134</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818772</td>\n",
       "      <td>0.818873</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.226400</td>\n",
       "      <td>0.459441</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.223900</td>\n",
       "      <td>0.460565</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.218800</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821066</td>\n",
       "      <td>0.821167</td>\n",
       "      <td>0.821077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.217400</td>\n",
       "      <td>0.465554</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819935</td>\n",
       "      <td>0.820041</td>\n",
       "      <td>0.819935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 21:22:25,659] Trial 111 finished with value: 0.8199349469882402 and parameters: {'learning_rate': 2.5991571071450347e-05, 'weight_decay': 0.0, 'warmup_steps': 33}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 112 with params: {'learning_rate': 2.784460988800823e-05, 'weight_decay': 0.0, 'warmup_steps': 33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:53, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.560300</td>\n",
       "      <td>0.475297</td>\n",
       "      <td>0.786697</td>\n",
       "      <td>0.786747</td>\n",
       "      <td>0.786457</td>\n",
       "      <td>0.786536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.404600</td>\n",
       "      <td>0.447200</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.799271</td>\n",
       "      <td>0.799181</td>\n",
       "      <td>0.799217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.349500</td>\n",
       "      <td>0.436890</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809818</td>\n",
       "      <td>0.809864</td>\n",
       "      <td>0.809632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.317100</td>\n",
       "      <td>0.446170</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811406</td>\n",
       "      <td>0.810316</td>\n",
       "      <td>0.810474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.292200</td>\n",
       "      <td>0.435647</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817631</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.272400</td>\n",
       "      <td>0.439192</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.259100</td>\n",
       "      <td>0.447198</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810120</td>\n",
       "      <td>0.809990</td>\n",
       "      <td>0.809629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.247000</td>\n",
       "      <td>0.452121</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.236300</td>\n",
       "      <td>0.456482</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813626</td>\n",
       "      <td>0.813452</td>\n",
       "      <td>0.813067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.229100</td>\n",
       "      <td>0.460976</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.223500</td>\n",
       "      <td>0.461573</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819891</td>\n",
       "      <td>0.819957</td>\n",
       "      <td>0.819914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.219200</td>\n",
       "      <td>0.464184</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.216700</td>\n",
       "      <td>0.465173</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.211500</td>\n",
       "      <td>0.470251</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817612</td>\n",
       "      <td>0.817704</td>\n",
       "      <td>0.817632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.210300</td>\n",
       "      <td>0.471162</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816478</td>\n",
       "      <td>0.816578</td>\n",
       "      <td>0.816490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 21:28:20,289] Trial 112 finished with value: 0.8164896275602275 and parameters: {'learning_rate': 2.784460988800823e-05, 'weight_decay': 0.0, 'warmup_steps': 33}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 113 with params: {'learning_rate': 0.00018984118670607364, 'weight_decay': 0.002, 'warmup_steps': 35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:52 < 01:56, 18.09 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.402400</td>\n",
       "      <td>0.413423</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.804598</td>\n",
       "      <td>0.803444</td>\n",
       "      <td>0.802648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.241500</td>\n",
       "      <td>0.486022</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806462</td>\n",
       "      <td>0.805854</td>\n",
       "      <td>0.805978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.186200</td>\n",
       "      <td>0.539477</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810388</td>\n",
       "      <td>0.810074</td>\n",
       "      <td>0.809617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.153400</td>\n",
       "      <td>0.540024</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.816011</td>\n",
       "      <td>0.814905</td>\n",
       "      <td>0.815069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.130100</td>\n",
       "      <td>0.626151</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.804443</td>\n",
       "      <td>0.804275</td>\n",
       "      <td>0.803893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.111600</td>\n",
       "      <td>0.661120</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.801064</td>\n",
       "      <td>0.800855</td>\n",
       "      <td>0.800449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.096100</td>\n",
       "      <td>0.790847</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.801064</td>\n",
       "      <td>0.800855</td>\n",
       "      <td>0.800449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.085900</td>\n",
       "      <td>0.769886</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.801647</td>\n",
       "      <td>0.801391</td>\n",
       "      <td>0.801467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.076700</td>\n",
       "      <td>0.849715</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.799428</td>\n",
       "      <td>0.797813</td>\n",
       "      <td>0.796851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.833328</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.803122</td>\n",
       "      <td>0.803065</td>\n",
       "      <td>0.802751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 21:32:13,782] Trial 113 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 114 with params: {'learning_rate': 4.783249558891983e-05, 'weight_decay': 0.005, 'warmup_steps': 31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:53 < 01:56, 18.06 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.509600</td>\n",
       "      <td>0.456938</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792518</td>\n",
       "      <td>0.792172</td>\n",
       "      <td>0.792260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.353100</td>\n",
       "      <td>0.432165</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808438</td>\n",
       "      <td>0.808527</td>\n",
       "      <td>0.808456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.295800</td>\n",
       "      <td>0.437943</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.262100</td>\n",
       "      <td>0.457993</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820017</td>\n",
       "      <td>0.819746</td>\n",
       "      <td>0.819829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>0.446272</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813096</td>\n",
       "      <td>0.813200</td>\n",
       "      <td>0.813061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>0.469829</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813396</td>\n",
       "      <td>0.813368</td>\n",
       "      <td>0.813073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.204500</td>\n",
       "      <td>0.490826</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812301</td>\n",
       "      <td>0.812242</td>\n",
       "      <td>0.811926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.193300</td>\n",
       "      <td>0.503114</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816501</td>\n",
       "      <td>0.816368</td>\n",
       "      <td>0.816417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.183000</td>\n",
       "      <td>0.514520</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810708</td>\n",
       "      <td>0.810158</td>\n",
       "      <td>0.809597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>0.520582</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815319</td>\n",
       "      <td>0.815410</td>\n",
       "      <td>0.815338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 21:36:07,805] Trial 114 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 115 with params: {'learning_rate': 3.110981689709106e-05, 'weight_decay': 0.0, 'warmup_steps': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:54, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.549400</td>\n",
       "      <td>0.470924</td>\n",
       "      <td>0.787844</td>\n",
       "      <td>0.787869</td>\n",
       "      <td>0.787625</td>\n",
       "      <td>0.787696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.394100</td>\n",
       "      <td>0.443486</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798230</td>\n",
       "      <td>0.797929</td>\n",
       "      <td>0.798012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.338500</td>\n",
       "      <td>0.435365</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809818</td>\n",
       "      <td>0.809864</td>\n",
       "      <td>0.809632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.446667</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814558</td>\n",
       "      <td>0.813863</td>\n",
       "      <td>0.814000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.280600</td>\n",
       "      <td>0.434825</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814158</td>\n",
       "      <td>0.814158</td>\n",
       "      <td>0.814158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.260800</td>\n",
       "      <td>0.442310</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.247400</td>\n",
       "      <td>0.453602</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814596</td>\n",
       "      <td>0.814536</td>\n",
       "      <td>0.814219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.235500</td>\n",
       "      <td>0.458381</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817597</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>0.464298</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813396</td>\n",
       "      <td>0.813368</td>\n",
       "      <td>0.813073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.217600</td>\n",
       "      <td>0.469251</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.212100</td>\n",
       "      <td>0.470034</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815301</td>\n",
       "      <td>0.815326</td>\n",
       "      <td>0.815312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.207800</td>\n",
       "      <td>0.473005</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814331</td>\n",
       "      <td>0.814410</td>\n",
       "      <td>0.814216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.205500</td>\n",
       "      <td>0.474184</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815303</td>\n",
       "      <td>0.815368</td>\n",
       "      <td>0.815326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.200200</td>\n",
       "      <td>0.480331</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819901</td>\n",
       "      <td>0.819872</td>\n",
       "      <td>0.819886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.199200</td>\n",
       "      <td>0.481412</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822196</td>\n",
       "      <td>0.822167</td>\n",
       "      <td>0.822180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 21:42:03,911] Trial 115 finished with value: 0.8221801222215643 and parameters: {'learning_rate': 3.110981689709106e-05, 'weight_decay': 0.0, 'warmup_steps': 32}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 116 with params: {'learning_rate': 3.568543861233653e-05, 'weight_decay': 0.002, 'warmup_steps': 36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 01:58 < 03:56, 17.78 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>0.467358</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791227</td>\n",
       "      <td>0.791172</td>\n",
       "      <td>0.791195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.381400</td>\n",
       "      <td>0.439503</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805066</td>\n",
       "      <td>0.804854</td>\n",
       "      <td>0.804922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.434675</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809737</td>\n",
       "      <td>0.809617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.291800</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813269</td>\n",
       "      <td>0.812779</td>\n",
       "      <td>0.812894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.266100</td>\n",
       "      <td>0.435561</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813009</td>\n",
       "      <td>0.813074</td>\n",
       "      <td>0.813032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 21:44:03,602] Trial 116 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 117 with params: {'learning_rate': 3.540275970611972e-05, 'weight_decay': 0.004, 'warmup_steps': 26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:54, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.536000</td>\n",
       "      <td>0.467445</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791227</td>\n",
       "      <td>0.791172</td>\n",
       "      <td>0.791195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.381800</td>\n",
       "      <td>0.439820</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805066</td>\n",
       "      <td>0.804854</td>\n",
       "      <td>0.804922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.325700</td>\n",
       "      <td>0.434792</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808509</td>\n",
       "      <td>0.808611</td>\n",
       "      <td>0.808474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.292700</td>\n",
       "      <td>0.448866</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813269</td>\n",
       "      <td>0.812779</td>\n",
       "      <td>0.812894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.267000</td>\n",
       "      <td>0.435738</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811859</td>\n",
       "      <td>0.811905</td>\n",
       "      <td>0.811878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.247400</td>\n",
       "      <td>0.448993</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817808</td>\n",
       "      <td>0.817873</td>\n",
       "      <td>0.817658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.234100</td>\n",
       "      <td>0.463959</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.222400</td>\n",
       "      <td>0.468423</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.211800</td>\n",
       "      <td>0.477033</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814981</td>\n",
       "      <td>0.814663</td>\n",
       "      <td>0.814205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.204600</td>\n",
       "      <td>0.481232</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819926</td>\n",
       "      <td>0.819830</td>\n",
       "      <td>0.819869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.199200</td>\n",
       "      <td>0.483260</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818765</td>\n",
       "      <td>0.818704</td>\n",
       "      <td>0.818730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.195000</td>\n",
       "      <td>0.487589</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815445</td>\n",
       "      <td>0.815536</td>\n",
       "      <td>0.815361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.488747</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821066</td>\n",
       "      <td>0.821167</td>\n",
       "      <td>0.821077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.187400</td>\n",
       "      <td>0.496296</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.186400</td>\n",
       "      <td>0.497101</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 21:50:00,407] Trial 117 finished with value: 0.8176065796760941 and parameters: {'learning_rate': 3.540275970611972e-05, 'weight_decay': 0.004, 'warmup_steps': 26}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 118 with params: {'learning_rate': 3.6664026396879975e-05, 'weight_decay': 0.0, 'warmup_steps': 34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:57, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.534600</td>\n",
       "      <td>0.466775</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793522</td>\n",
       "      <td>0.793466</td>\n",
       "      <td>0.793490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.378800</td>\n",
       "      <td>0.438809</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805066</td>\n",
       "      <td>0.804854</td>\n",
       "      <td>0.804922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.322300</td>\n",
       "      <td>0.434800</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810731</td>\n",
       "      <td>0.810821</td>\n",
       "      <td>0.810750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.289100</td>\n",
       "      <td>0.449569</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815566</td>\n",
       "      <td>0.815073</td>\n",
       "      <td>0.815190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.263300</td>\n",
       "      <td>0.436220</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814153</td>\n",
       "      <td>0.814200</td>\n",
       "      <td>0.814172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.243800</td>\n",
       "      <td>0.451206</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816700</td>\n",
       "      <td>0.816747</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.230500</td>\n",
       "      <td>0.467198</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815596</td>\n",
       "      <td>0.815621</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.218800</td>\n",
       "      <td>0.471650</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.208300</td>\n",
       "      <td>0.480996</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.814070</td>\n",
       "      <td>0.813579</td>\n",
       "      <td>0.813044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.201100</td>\n",
       "      <td>0.484998</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819901</td>\n",
       "      <td>0.819872</td>\n",
       "      <td>0.819886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.487462</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822196</td>\n",
       "      <td>0.822167</td>\n",
       "      <td>0.822180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.191500</td>\n",
       "      <td>0.491883</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819977</td>\n",
       "      <td>0.820083</td>\n",
       "      <td>0.819943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.189000</td>\n",
       "      <td>0.493179</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818772</td>\n",
       "      <td>0.818873</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.183900</td>\n",
       "      <td>0.501240</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.183000</td>\n",
       "      <td>0.502011</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816447</td>\n",
       "      <td>0.816494</td>\n",
       "      <td>0.816466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 21:55:59,123] Trial 118 finished with value: 0.8164664530353019 and parameters: {'learning_rate': 3.6664026396879975e-05, 'weight_decay': 0.0, 'warmup_steps': 34}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 119 with params: {'learning_rate': 8.728609309231897e-05, 'weight_decay': 0.01, 'warmup_steps': 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 01:57 < 03:56, 17.83 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.454100</td>\n",
       "      <td>0.437882</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808807</td>\n",
       "      <td>0.808780</td>\n",
       "      <td>0.808486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.298400</td>\n",
       "      <td>0.440995</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814307</td>\n",
       "      <td>0.813989</td>\n",
       "      <td>0.814079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.241000</td>\n",
       "      <td>0.449521</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819889</td>\n",
       "      <td>0.819915</td>\n",
       "      <td>0.819901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.492893</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.828644</td>\n",
       "      <td>0.826124</td>\n",
       "      <td>0.826330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.184300</td>\n",
       "      <td>0.494556</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808807</td>\n",
       "      <td>0.808780</td>\n",
       "      <td>0.808486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 21:57:57,920] Trial 119 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 120 with params: {'learning_rate': 3.6086783836865125e-05, 'weight_decay': 0.004, 'warmup_steps': 37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:56, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.536700</td>\n",
       "      <td>0.467097</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791227</td>\n",
       "      <td>0.791172</td>\n",
       "      <td>0.791195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.380300</td>\n",
       "      <td>0.439158</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803943</td>\n",
       "      <td>0.803686</td>\n",
       "      <td>0.803763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.323900</td>\n",
       "      <td>0.434668</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810760</td>\n",
       "      <td>0.810863</td>\n",
       "      <td>0.810760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.290700</td>\n",
       "      <td>0.449132</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814461</td>\n",
       "      <td>0.813905</td>\n",
       "      <td>0.814028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.265000</td>\n",
       "      <td>0.435782</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813009</td>\n",
       "      <td>0.813074</td>\n",
       "      <td>0.813032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.245400</td>\n",
       "      <td>0.450149</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817808</td>\n",
       "      <td>0.817873</td>\n",
       "      <td>0.817658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.232100</td>\n",
       "      <td>0.465590</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.220400</td>\n",
       "      <td>0.470093</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.209800</td>\n",
       "      <td>0.479200</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.813537</td>\n",
       "      <td>0.813053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.202600</td>\n",
       "      <td>0.483287</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818765</td>\n",
       "      <td>0.818704</td>\n",
       "      <td>0.818730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.197300</td>\n",
       "      <td>0.485466</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821059</td>\n",
       "      <td>0.820999</td>\n",
       "      <td>0.821025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.193000</td>\n",
       "      <td>0.489672</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.190600</td>\n",
       "      <td>0.491035</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819906</td>\n",
       "      <td>0.819999</td>\n",
       "      <td>0.819925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.185500</td>\n",
       "      <td>0.498870</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.184600</td>\n",
       "      <td>0.499703</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 22:03:55,324] Trial 120 finished with value: 0.8176065796760941 and parameters: {'learning_rate': 3.6086783836865125e-05, 'weight_decay': 0.004, 'warmup_steps': 37}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 121 with params: {'learning_rate': 6.745912212460918e-05, 'weight_decay': 0.0, 'warmup_steps': 26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 01:59 < 03:58, 17.67 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.477800</td>\n",
       "      <td>0.444211</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.801557</td>\n",
       "      <td>0.801644</td>\n",
       "      <td>0.801574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.320500</td>\n",
       "      <td>0.431584</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814185</td>\n",
       "      <td>0.814284</td>\n",
       "      <td>0.814196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.262800</td>\n",
       "      <td>0.439411</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816603</td>\n",
       "      <td>0.816284</td>\n",
       "      <td>0.816375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>0.477796</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822918</td>\n",
       "      <td>0.821788</td>\n",
       "      <td>0.821961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.204900</td>\n",
       "      <td>0.472604</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811209</td>\n",
       "      <td>0.811116</td>\n",
       "      <td>0.810778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 22:05:55,817] Trial 121 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 122 with params: {'learning_rate': 3.6369044045644285e-05, 'weight_decay': 0.0, 'warmup_steps': 28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:53, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.533900</td>\n",
       "      <td>0.466882</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793522</td>\n",
       "      <td>0.793466</td>\n",
       "      <td>0.793490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.379300</td>\n",
       "      <td>0.439036</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805066</td>\n",
       "      <td>0.804854</td>\n",
       "      <td>0.804922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.323000</td>\n",
       "      <td>0.434829</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810731</td>\n",
       "      <td>0.810821</td>\n",
       "      <td>0.810750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.289900</td>\n",
       "      <td>0.449443</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814461</td>\n",
       "      <td>0.813905</td>\n",
       "      <td>0.814028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.264100</td>\n",
       "      <td>0.436229</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813009</td>\n",
       "      <td>0.813074</td>\n",
       "      <td>0.813032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.244700</td>\n",
       "      <td>0.450657</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817808</td>\n",
       "      <td>0.817873</td>\n",
       "      <td>0.817658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.231300</td>\n",
       "      <td>0.466508</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815596</td>\n",
       "      <td>0.815621</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.219700</td>\n",
       "      <td>0.470887</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.209100</td>\n",
       "      <td>0.479994</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812839</td>\n",
       "      <td>0.812411</td>\n",
       "      <td>0.811902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.201900</td>\n",
       "      <td>0.484045</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819901</td>\n",
       "      <td>0.819872</td>\n",
       "      <td>0.819886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.196500</td>\n",
       "      <td>0.486527</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821059</td>\n",
       "      <td>0.820999</td>\n",
       "      <td>0.821025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.192300</td>\n",
       "      <td>0.491024</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818856</td>\n",
       "      <td>0.818957</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.189800</td>\n",
       "      <td>0.492236</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818772</td>\n",
       "      <td>0.818873</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.184800</td>\n",
       "      <td>0.500101</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.183800</td>\n",
       "      <td>0.500921</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 22:11:50,433] Trial 122 finished with value: 0.8176065796760941 and parameters: {'learning_rate': 3.6369044045644285e-05, 'weight_decay': 0.0, 'warmup_steps': 28}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 123 with params: {'learning_rate': 3.507714164620168e-05, 'weight_decay': 0.0, 'warmup_steps': 37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 01:57 < 03:54, 17.95 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.539400</td>\n",
       "      <td>0.467765</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791227</td>\n",
       "      <td>0.791172</td>\n",
       "      <td>0.791195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.383000</td>\n",
       "      <td>0.439981</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.802770</td>\n",
       "      <td>0.802560</td>\n",
       "      <td>0.802627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.326700</td>\n",
       "      <td>0.434591</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809737</td>\n",
       "      <td>0.809617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.293600</td>\n",
       "      <td>0.448530</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813269</td>\n",
       "      <td>0.812779</td>\n",
       "      <td>0.812894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.267900</td>\n",
       "      <td>0.435216</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811859</td>\n",
       "      <td>0.811905</td>\n",
       "      <td>0.811878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 22:13:48,561] Trial 123 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 124 with params: {'learning_rate': 2.103136890071569e-05, 'weight_decay': 0.001, 'warmup_steps': 33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:52 < 01:56, 18.08 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.588100</td>\n",
       "      <td>0.492888</td>\n",
       "      <td>0.772936</td>\n",
       "      <td>0.773361</td>\n",
       "      <td>0.772480</td>\n",
       "      <td>0.772590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>0.457140</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793519</td>\n",
       "      <td>0.793593</td>\n",
       "      <td>0.793539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.377500</td>\n",
       "      <td>0.443415</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.802862</td>\n",
       "      <td>0.802938</td>\n",
       "      <td>0.802748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.345500</td>\n",
       "      <td>0.447673</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.801577</td>\n",
       "      <td>0.799844</td>\n",
       "      <td>0.799995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.321800</td>\n",
       "      <td>0.440283</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813358</td>\n",
       "      <td>0.812737</td>\n",
       "      <td>0.812866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.302300</td>\n",
       "      <td>0.436236</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814162</td>\n",
       "      <td>0.814242</td>\n",
       "      <td>0.814185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.289300</td>\n",
       "      <td>0.438108</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810007</td>\n",
       "      <td>0.809948</td>\n",
       "      <td>0.809632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.276800</td>\n",
       "      <td>0.442203</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815301</td>\n",
       "      <td>0.815326</td>\n",
       "      <td>0.815312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.266700</td>\n",
       "      <td>0.443770</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811102</td>\n",
       "      <td>0.811074</td>\n",
       "      <td>0.810780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.259600</td>\n",
       "      <td>0.447597</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815336</td>\n",
       "      <td>0.815242</td>\n",
       "      <td>0.815279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 22:17:42,231] Trial 124 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 125 with params: {'learning_rate': 3.1133499157296776e-05, 'weight_decay': 0.006, 'warmup_steps': 43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:50, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.551900</td>\n",
       "      <td>0.470887</td>\n",
       "      <td>0.787844</td>\n",
       "      <td>0.787869</td>\n",
       "      <td>0.787625</td>\n",
       "      <td>0.787696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.443398</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.799351</td>\n",
       "      <td>0.799097</td>\n",
       "      <td>0.799172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.338500</td>\n",
       "      <td>0.435269</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809818</td>\n",
       "      <td>0.809864</td>\n",
       "      <td>0.809632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.305800</td>\n",
       "      <td>0.446480</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814558</td>\n",
       "      <td>0.813863</td>\n",
       "      <td>0.814000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.280500</td>\n",
       "      <td>0.434486</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814158</td>\n",
       "      <td>0.814158</td>\n",
       "      <td>0.814158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.260700</td>\n",
       "      <td>0.442040</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.247300</td>\n",
       "      <td>0.453321</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814596</td>\n",
       "      <td>0.814536</td>\n",
       "      <td>0.814219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.235400</td>\n",
       "      <td>0.458171</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817597</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.224700</td>\n",
       "      <td>0.463904</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813396</td>\n",
       "      <td>0.813368</td>\n",
       "      <td>0.813073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.217400</td>\n",
       "      <td>0.469145</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.212000</td>\n",
       "      <td>0.469783</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815301</td>\n",
       "      <td>0.815326</td>\n",
       "      <td>0.815312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.207700</td>\n",
       "      <td>0.472484</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815445</td>\n",
       "      <td>0.815536</td>\n",
       "      <td>0.815361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.205300</td>\n",
       "      <td>0.473953</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815303</td>\n",
       "      <td>0.815368</td>\n",
       "      <td>0.815326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.200100</td>\n",
       "      <td>0.480046</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821059</td>\n",
       "      <td>0.820999</td>\n",
       "      <td>0.821025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.199100</td>\n",
       "      <td>0.481182</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822196</td>\n",
       "      <td>0.822167</td>\n",
       "      <td>0.822180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 22:23:34,561] Trial 125 finished with value: 0.8221801222215643 and parameters: {'learning_rate': 3.1133499157296776e-05, 'weight_decay': 0.006, 'warmup_steps': 43}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 126 with params: {'learning_rate': 2.478204720478304e-05, 'weight_decay': 0.006, 'warmup_steps': 43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:51, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.573900</td>\n",
       "      <td>0.481560</td>\n",
       "      <td>0.783257</td>\n",
       "      <td>0.783562</td>\n",
       "      <td>0.782868</td>\n",
       "      <td>0.782983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.416200</td>\n",
       "      <td>0.452020</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793507</td>\n",
       "      <td>0.793551</td>\n",
       "      <td>0.793525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.361300</td>\n",
       "      <td>0.439044</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811102</td>\n",
       "      <td>0.811074</td>\n",
       "      <td>0.810780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.328900</td>\n",
       "      <td>0.446238</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806940</td>\n",
       "      <td>0.805685</td>\n",
       "      <td>0.805843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.304500</td>\n",
       "      <td>0.437131</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816546</td>\n",
       "      <td>0.816326</td>\n",
       "      <td>0.816397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.284700</td>\n",
       "      <td>0.437147</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814326</td>\n",
       "      <td>0.814205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.271400</td>\n",
       "      <td>0.442141</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.809168</td>\n",
       "      <td>0.808906</td>\n",
       "      <td>0.808474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.259100</td>\n",
       "      <td>0.446949</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813007</td>\n",
       "      <td>0.813031</td>\n",
       "      <td>0.813018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.248600</td>\n",
       "      <td>0.450106</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812416</td>\n",
       "      <td>0.812284</td>\n",
       "      <td>0.811923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.241400</td>\n",
       "      <td>0.454144</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.235700</td>\n",
       "      <td>0.454065</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818772</td>\n",
       "      <td>0.818873</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.231300</td>\n",
       "      <td>0.456146</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.228800</td>\n",
       "      <td>0.457344</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.223800</td>\n",
       "      <td>0.461132</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817641</td>\n",
       "      <td>0.817746</td>\n",
       "      <td>0.817641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.222200</td>\n",
       "      <td>0.461769</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818915</td>\n",
       "      <td>0.818792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 22:29:27,560] Trial 126 finished with value: 0.8187920875420875 and parameters: {'learning_rate': 2.478204720478304e-05, 'weight_decay': 0.006, 'warmup_steps': 43}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 127 with params: {'learning_rate': 4.9384195689829555e-05, 'weight_decay': 0.007, 'warmup_steps': 42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:54 < 01:57, 17.97 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.509400</td>\n",
       "      <td>0.455836</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793586</td>\n",
       "      <td>0.793382</td>\n",
       "      <td>0.793447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.350400</td>\n",
       "      <td>0.431778</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807401</td>\n",
       "      <td>0.807314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.292700</td>\n",
       "      <td>0.438199</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818741</td>\n",
       "      <td>0.818788</td>\n",
       "      <td>0.818761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>0.459368</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818900</td>\n",
       "      <td>0.818578</td>\n",
       "      <td>0.818670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.233100</td>\n",
       "      <td>0.447995</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813096</td>\n",
       "      <td>0.813200</td>\n",
       "      <td>0.813061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.215000</td>\n",
       "      <td>0.472983</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813504</td>\n",
       "      <td>0.813410</td>\n",
       "      <td>0.813071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.201500</td>\n",
       "      <td>0.494087</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814406</td>\n",
       "      <td>0.814452</td>\n",
       "      <td>0.814219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.190300</td>\n",
       "      <td>0.507903</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813078</td>\n",
       "      <td>0.812905</td>\n",
       "      <td>0.812965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.520159</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.809646</td>\n",
       "      <td>0.809032</td>\n",
       "      <td>0.808444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.173000</td>\n",
       "      <td>0.526531</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816478</td>\n",
       "      <td>0.816578</td>\n",
       "      <td>0.816490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 22:33:22,701] Trial 127 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 128 with params: {'learning_rate': 1.675581520520653e-05, 'weight_decay': 0.008, 'warmup_steps': 38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 01:57 < 03:55, 17.91 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>0.518525</td>\n",
       "      <td>0.758028</td>\n",
       "      <td>0.758561</td>\n",
       "      <td>0.757504</td>\n",
       "      <td>0.757591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.456700</td>\n",
       "      <td>0.464551</td>\n",
       "      <td>0.785550</td>\n",
       "      <td>0.785531</td>\n",
       "      <td>0.785626</td>\n",
       "      <td>0.785528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.400200</td>\n",
       "      <td>0.451412</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795836</td>\n",
       "      <td>0.795929</td>\n",
       "      <td>0.795845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.368300</td>\n",
       "      <td>0.451676</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.796378</td>\n",
       "      <td>0.795424</td>\n",
       "      <td>0.795561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.345500</td>\n",
       "      <td>0.445533</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.804163</td>\n",
       "      <td>0.803559</td>\n",
       "      <td>0.803682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 22:35:21,377] Trial 128 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 129 with params: {'learning_rate': 2.324199421340565e-05, 'weight_decay': 0.005, 'warmup_steps': 36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:54, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.578800</td>\n",
       "      <td>0.485470</td>\n",
       "      <td>0.780963</td>\n",
       "      <td>0.781174</td>\n",
       "      <td>0.780616</td>\n",
       "      <td>0.780721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.422200</td>\n",
       "      <td>0.454197</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793507</td>\n",
       "      <td>0.793551</td>\n",
       "      <td>0.793525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.367600</td>\n",
       "      <td>0.440611</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808713</td>\n",
       "      <td>0.808737</td>\n",
       "      <td>0.808486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.335400</td>\n",
       "      <td>0.446603</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.804788</td>\n",
       "      <td>0.803349</td>\n",
       "      <td>0.803506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.311300</td>\n",
       "      <td>0.438323</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815489</td>\n",
       "      <td>0.815115</td>\n",
       "      <td>0.815215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.291600</td>\n",
       "      <td>0.436427</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815348</td>\n",
       "      <td>0.815452</td>\n",
       "      <td>0.815347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.278400</td>\n",
       "      <td>0.440158</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811209</td>\n",
       "      <td>0.811116</td>\n",
       "      <td>0.810778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.266000</td>\n",
       "      <td>0.444715</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813007</td>\n",
       "      <td>0.813031</td>\n",
       "      <td>0.813018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.255700</td>\n",
       "      <td>0.447230</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811102</td>\n",
       "      <td>0.811074</td>\n",
       "      <td>0.810780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.248500</td>\n",
       "      <td>0.451100</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817631</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.242700</td>\n",
       "      <td>0.450398</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818772</td>\n",
       "      <td>0.818873</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.238300</td>\n",
       "      <td>0.452293</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.235700</td>\n",
       "      <td>0.453435</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.230900</td>\n",
       "      <td>0.456574</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817641</td>\n",
       "      <td>0.817746</td>\n",
       "      <td>0.817641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.229100</td>\n",
       "      <td>0.457178</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817641</td>\n",
       "      <td>0.817746</td>\n",
       "      <td>0.817641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 22:41:17,619] Trial 129 finished with value: 0.8176411246568802 and parameters: {'learning_rate': 2.324199421340565e-05, 'weight_decay': 0.005, 'warmup_steps': 36}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 130 with params: {'learning_rate': 3.2574657703616324e-05, 'weight_decay': 0.006, 'warmup_steps': 41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:54, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.547200</td>\n",
       "      <td>0.469488</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.788957</td>\n",
       "      <td>0.788836</td>\n",
       "      <td>0.788880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.390100</td>\n",
       "      <td>0.442151</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.801600</td>\n",
       "      <td>0.801433</td>\n",
       "      <td>0.801490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.334000</td>\n",
       "      <td>0.434867</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810858</td>\n",
       "      <td>0.810948</td>\n",
       "      <td>0.810774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.301200</td>\n",
       "      <td>0.447096</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815762</td>\n",
       "      <td>0.814989</td>\n",
       "      <td>0.815133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.275700</td>\n",
       "      <td>0.434517</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814153</td>\n",
       "      <td>0.814200</td>\n",
       "      <td>0.814172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.256000</td>\n",
       "      <td>0.444036</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815445</td>\n",
       "      <td>0.815536</td>\n",
       "      <td>0.815361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.242600</td>\n",
       "      <td>0.456621</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815691</td>\n",
       "      <td>0.815663</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.230700</td>\n",
       "      <td>0.461342</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.220100</td>\n",
       "      <td>0.467998</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813626</td>\n",
       "      <td>0.813452</td>\n",
       "      <td>0.813067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.212800</td>\n",
       "      <td>0.473104</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818741</td>\n",
       "      <td>0.818788</td>\n",
       "      <td>0.818761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.207400</td>\n",
       "      <td>0.474041</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.203200</td>\n",
       "      <td>0.477041</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813220</td>\n",
       "      <td>0.813284</td>\n",
       "      <td>0.813071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.200800</td>\n",
       "      <td>0.478476</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817612</td>\n",
       "      <td>0.817704</td>\n",
       "      <td>0.817632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.195500</td>\n",
       "      <td>0.485068</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.194600</td>\n",
       "      <td>0.486179</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822196</td>\n",
       "      <td>0.822167</td>\n",
       "      <td>0.822180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 22:47:14,269] Trial 130 finished with value: 0.8221801222215643 and parameters: {'learning_rate': 3.2574657703616324e-05, 'weight_decay': 0.006, 'warmup_steps': 41}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 131 with params: {'learning_rate': 3.015518420993117e-05, 'weight_decay': 0.005, 'warmup_steps': 39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:55, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.554000</td>\n",
       "      <td>0.471978</td>\n",
       "      <td>0.786697</td>\n",
       "      <td>0.786698</td>\n",
       "      <td>0.786499</td>\n",
       "      <td>0.786561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.397300</td>\n",
       "      <td>0.444352</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.800474</td>\n",
       "      <td>0.800265</td>\n",
       "      <td>0.800332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.341600</td>\n",
       "      <td>0.435671</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808632</td>\n",
       "      <td>0.808695</td>\n",
       "      <td>0.808484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.309000</td>\n",
       "      <td>0.446306</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815762</td>\n",
       "      <td>0.814989</td>\n",
       "      <td>0.815133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.283800</td>\n",
       "      <td>0.434780</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816470</td>\n",
       "      <td>0.816410</td>\n",
       "      <td>0.816436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.264000</td>\n",
       "      <td>0.441010</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815445</td>\n",
       "      <td>0.815536</td>\n",
       "      <td>0.815361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.250600</td>\n",
       "      <td>0.451416</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812416</td>\n",
       "      <td>0.812284</td>\n",
       "      <td>0.811923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.238700</td>\n",
       "      <td>0.456255</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818741</td>\n",
       "      <td>0.818788</td>\n",
       "      <td>0.818761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.461590</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815596</td>\n",
       "      <td>0.815621</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.220700</td>\n",
       "      <td>0.466621</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.215200</td>\n",
       "      <td>0.467155</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815301</td>\n",
       "      <td>0.815326</td>\n",
       "      <td>0.815312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.211000</td>\n",
       "      <td>0.469909</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814269</td>\n",
       "      <td>0.814368</td>\n",
       "      <td>0.814211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.208600</td>\n",
       "      <td>0.471184</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814162</td>\n",
       "      <td>0.814242</td>\n",
       "      <td>0.814185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.203300</td>\n",
       "      <td>0.476986</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.202200</td>\n",
       "      <td>0.478090</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819889</td>\n",
       "      <td>0.819915</td>\n",
       "      <td>0.819901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 22:53:11,695] Trial 131 finished with value: 0.8199008365355143 and parameters: {'learning_rate': 3.015518420993117e-05, 'weight_decay': 0.005, 'warmup_steps': 39}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 132 with params: {'learning_rate': 3.205322751680535e-05, 'weight_decay': 0.008, 'warmup_steps': 34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:54, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.547100</td>\n",
       "      <td>0.469950</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.788957</td>\n",
       "      <td>0.788836</td>\n",
       "      <td>0.788880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.391400</td>\n",
       "      <td>0.442609</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.801600</td>\n",
       "      <td>0.801433</td>\n",
       "      <td>0.801490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.335600</td>\n",
       "      <td>0.435035</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809743</td>\n",
       "      <td>0.809822</td>\n",
       "      <td>0.809629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.302800</td>\n",
       "      <td>0.447013</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814558</td>\n",
       "      <td>0.813863</td>\n",
       "      <td>0.814000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.277400</td>\n",
       "      <td>0.434711</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813007</td>\n",
       "      <td>0.813031</td>\n",
       "      <td>0.813018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.257700</td>\n",
       "      <td>0.443486</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.244300</td>\n",
       "      <td>0.455689</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815691</td>\n",
       "      <td>0.815663</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.460342</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.221800</td>\n",
       "      <td>0.466852</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813504</td>\n",
       "      <td>0.813410</td>\n",
       "      <td>0.813071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.214500</td>\n",
       "      <td>0.471754</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819889</td>\n",
       "      <td>0.819915</td>\n",
       "      <td>0.819901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.209100</td>\n",
       "      <td>0.472675</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.204800</td>\n",
       "      <td>0.475775</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813220</td>\n",
       "      <td>0.813284</td>\n",
       "      <td>0.813071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.202400</td>\n",
       "      <td>0.476988</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816478</td>\n",
       "      <td>0.816578</td>\n",
       "      <td>0.816490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.197200</td>\n",
       "      <td>0.483490</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822196</td>\n",
       "      <td>0.822167</td>\n",
       "      <td>0.822180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.196200</td>\n",
       "      <td>0.484525</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822196</td>\n",
       "      <td>0.822167</td>\n",
       "      <td>0.822180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 22:59:08,179] Trial 132 finished with value: 0.8221801222215643 and parameters: {'learning_rate': 3.205322751680535e-05, 'weight_decay': 0.008, 'warmup_steps': 34}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 133 with params: {'learning_rate': 2.8472404006122218e-05, 'weight_decay': 0.005, 'warmup_steps': 40}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:52, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.559700</td>\n",
       "      <td>0.474390</td>\n",
       "      <td>0.786697</td>\n",
       "      <td>0.786747</td>\n",
       "      <td>0.786457</td>\n",
       "      <td>0.786536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.402800</td>\n",
       "      <td>0.446279</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798138</td>\n",
       "      <td>0.798013</td>\n",
       "      <td>0.798059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.347300</td>\n",
       "      <td>0.436461</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810926</td>\n",
       "      <td>0.810990</td>\n",
       "      <td>0.810778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.314900</td>\n",
       "      <td>0.446089</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814793</td>\n",
       "      <td>0.813779</td>\n",
       "      <td>0.813937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.289900</td>\n",
       "      <td>0.435286</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817631</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.439543</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.256700</td>\n",
       "      <td>0.448250</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811330</td>\n",
       "      <td>0.811158</td>\n",
       "      <td>0.810774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.244600</td>\n",
       "      <td>0.453150</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.457704</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815799</td>\n",
       "      <td>0.815705</td>\n",
       "      <td>0.815365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.462460</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.221100</td>\n",
       "      <td>0.463054</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.216800</td>\n",
       "      <td>0.465597</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.214400</td>\n",
       "      <td>0.466746</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815348</td>\n",
       "      <td>0.815452</td>\n",
       "      <td>0.815347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.209200</td>\n",
       "      <td>0.471949</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816456</td>\n",
       "      <td>0.816536</td>\n",
       "      <td>0.816479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.472932</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817597</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 23:05:02,710] Trial 133 finished with value: 0.817620015390383 and parameters: {'learning_rate': 2.8472404006122218e-05, 'weight_decay': 0.005, 'warmup_steps': 40}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 134 with params: {'learning_rate': 2.3868971651215053e-05, 'weight_decay': 0.008, 'warmup_steps': 30}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 05:55, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.574900</td>\n",
       "      <td>0.483439</td>\n",
       "      <td>0.780963</td>\n",
       "      <td>0.781174</td>\n",
       "      <td>0.780616</td>\n",
       "      <td>0.780721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.419400</td>\n",
       "      <td>0.453342</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793507</td>\n",
       "      <td>0.793551</td>\n",
       "      <td>0.793525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.364900</td>\n",
       "      <td>0.439996</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808713</td>\n",
       "      <td>0.808737</td>\n",
       "      <td>0.808486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.332700</td>\n",
       "      <td>0.446572</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806940</td>\n",
       "      <td>0.805685</td>\n",
       "      <td>0.805843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.308500</td>\n",
       "      <td>0.437864</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814307</td>\n",
       "      <td>0.813989</td>\n",
       "      <td>0.814079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.288800</td>\n",
       "      <td>0.436699</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817641</td>\n",
       "      <td>0.817746</td>\n",
       "      <td>0.817641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.275600</td>\n",
       "      <td>0.440943</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810120</td>\n",
       "      <td>0.809990</td>\n",
       "      <td>0.809629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.263300</td>\n",
       "      <td>0.445615</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811859</td>\n",
       "      <td>0.811905</td>\n",
       "      <td>0.811878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.252800</td>\n",
       "      <td>0.448429</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812416</td>\n",
       "      <td>0.812284</td>\n",
       "      <td>0.811923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.245600</td>\n",
       "      <td>0.452311</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816470</td>\n",
       "      <td>0.816410</td>\n",
       "      <td>0.816436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.239900</td>\n",
       "      <td>0.451904</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818772</td>\n",
       "      <td>0.818873</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.235500</td>\n",
       "      <td>0.453843</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815514</td>\n",
       "      <td>0.815578</td>\n",
       "      <td>0.815365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.232900</td>\n",
       "      <td>0.455017</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.458382</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819935</td>\n",
       "      <td>0.820041</td>\n",
       "      <td>0.819935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.226400</td>\n",
       "      <td>0.459018</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816620</td>\n",
       "      <td>0.816498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 23:11:00,047] Trial 134 finished with value: 0.8164983164983165 and parameters: {'learning_rate': 2.3868971651215053e-05, 'weight_decay': 0.008, 'warmup_steps': 30}. Best is trial 51 with value: 0.8221801222215643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 135 with params: {'learning_rate': 3.586785103475273e-05, 'weight_decay': 0.008, 'warmup_steps': 36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 01:57 < 03:55, 17.86 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.537100</td>\n",
       "      <td>0.467289</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791227</td>\n",
       "      <td>0.791172</td>\n",
       "      <td>0.791195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.380900</td>\n",
       "      <td>0.439347</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803943</td>\n",
       "      <td>0.803686</td>\n",
       "      <td>0.803763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.324500</td>\n",
       "      <td>0.434667</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809737</td>\n",
       "      <td>0.809617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.291300</td>\n",
       "      <td>0.449042</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814461</td>\n",
       "      <td>0.813905</td>\n",
       "      <td>0.814028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.265600</td>\n",
       "      <td>0.435645</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813009</td>\n",
       "      <td>0.813074</td>\n",
       "      <td>0.813032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 23:12:58,824] Trial 135 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 136 with params: {'learning_rate': 4.1541758803203886e-05, 'weight_decay': 0.006, 'warmup_steps': 42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 03:56 < 01:58, 17.79 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.525100</td>\n",
       "      <td>0.462584</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793586</td>\n",
       "      <td>0.793382</td>\n",
       "      <td>0.793447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.367100</td>\n",
       "      <td>0.435251</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808487</td>\n",
       "      <td>0.808316</td>\n",
       "      <td>0.808375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.309800</td>\n",
       "      <td>0.435461</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813007</td>\n",
       "      <td>0.813031</td>\n",
       "      <td>0.813018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.276200</td>\n",
       "      <td>0.452654</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817864</td>\n",
       "      <td>0.817368</td>\n",
       "      <td>0.817486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.250300</td>\n",
       "      <td>0.439476</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814326</td>\n",
       "      <td>0.814205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.231300</td>\n",
       "      <td>0.458634</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815596</td>\n",
       "      <td>0.815621</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>0.478250</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812112</td>\n",
       "      <td>0.812158</td>\n",
       "      <td>0.811926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.206500</td>\n",
       "      <td>0.484210</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814206</td>\n",
       "      <td>0.814073</td>\n",
       "      <td>0.814122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.196100</td>\n",
       "      <td>0.495094</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.809646</td>\n",
       "      <td>0.809032</td>\n",
       "      <td>0.808444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.189000</td>\n",
       "      <td>0.499519</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815303</td>\n",
       "      <td>0.815368</td>\n",
       "      <td>0.815326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 23:16:56,525] Trial 136 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 137 with params: {'learning_rate': 3.225367657608565e-05, 'weight_decay': 0.007, 'warmup_steps': 43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1800' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1800/6315 01:40 < 04:11, 17.94 it/s, Epoch 4.27/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.548600</td>\n",
       "      <td>0.469761</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.788957</td>\n",
       "      <td>0.788836</td>\n",
       "      <td>0.788880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.391100</td>\n",
       "      <td>0.442409</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.801600</td>\n",
       "      <td>0.801433</td>\n",
       "      <td>0.801490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.335000</td>\n",
       "      <td>0.434901</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810926</td>\n",
       "      <td>0.810990</td>\n",
       "      <td>0.810778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.302200</td>\n",
       "      <td>0.446904</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815762</td>\n",
       "      <td>0.814989</td>\n",
       "      <td>0.815133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-03-28 23:18:37,897] Trial 137 failed with parameters: {'learning_rate': 3.225367657608565e-05, 'weight_decay': 0.007, 'warmup_steps': 43} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/transformers/integrations/integration_utils.py\", line 250, in _objective\n",
      "    trainer.train(resume_from_checkpoint=checkpoint, trial=trial)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2241, in train\n",
      "    return inner_training_loop(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2548, in _inner_training_loop\n",
      "    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 3698, in training_step\n",
      "    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 3759, in compute_loss\n",
      "    outputs = model(**inputs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\", line 819, in forward\n",
      "    return model_forward(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\", line 807, in __call__\n",
      "    return convert_to_fp32(self.model_forward(*args, **kwargs))\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py\", line 44, in decorate_autocast\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\", line 1673, in forward\n",
      "    outputs = self.bert(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\", line 1142, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\", line 695, in forward\n",
      "    layer_outputs = layer_module(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\", line 585, in forward\n",
      "    self_attention_outputs = self.attention(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\", line 524, in forward\n",
      "    attention_output = self.output(self_outputs[0], hidden_states)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\", line 467, in forward\n",
      "    hidden_states = self.dropout(hidden_states)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/dropout.py\", line 70, in forward\n",
      "    return F.dropout(input, self.p, self.training, self.inplace)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\", line 1425, in dropout\n",
      "    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "KeyboardInterrupt\n",
      "[W 2025-03-28 23:18:37,903] Trial 137 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparameter_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptuna\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhp_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhp_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_objective\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_f1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpruner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpruner\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTest-base\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3588\u001b[0m, in \u001b[0;36mTrainer.hyperparameter_search\u001b[0;34m(self, hp_space, compute_objective, n_trials, direction, backend, hp_name, **kwargs)\u001b[0m\n\u001b[1;32m   3585\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhp_name \u001b[38;5;241m=\u001b[39m hp_name\n\u001b[1;32m   3586\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_objective \u001b[38;5;241m=\u001b[39m default_compute_objective \u001b[38;5;28;01mif\u001b[39;00m compute_objective \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m compute_objective\n\u001b[0;32m-> 3588\u001b[0m best_run \u001b[38;5;241m=\u001b[39m \u001b[43mbackend_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3590\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhp_search_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_run\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/hyperparameter_search.py:72\u001b[0m, in \u001b[0;36mOptunaBackend.run\u001b[0;34m(self, trainer, n_trials, direction, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer, n_trials: \u001b[38;5;28mint\u001b[39m, direction: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_hp_search_optuna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/integrations/integration_utils.py:268\u001b[0m, in \u001b[0;36mrun_hp_search_optuna\u001b[0;34m(trainer, n_trials, direction, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m direction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m directions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m direction\n\u001b[1;32m    267\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39mdirection, directions\u001b[38;5;241m=\u001b[39mdirections, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 268\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_objective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m study\u001b[38;5;241m.\u001b[39m_is_multi_objective():\n\u001b[1;32m    270\u001b[0m     best_trial \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_trial\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/integrations/integration_utils.py:250\u001b[0m, in \u001b[0;36mrun_hp_search_optuna.<locals>._objective\u001b[0;34m(trial, checkpoint_dir)\u001b[0m\n\u001b[1;32m    248\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mtrain(resume_from_checkpoint\u001b[38;5;241m=\u001b[39mcheckpoint, trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 250\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# If there hasn't been any evaluation during the training loop.\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2548\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2541\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2542\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2543\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2544\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2546\u001b[0m )\n\u001b[1;32m   2547\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2548\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2551\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2552\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2553\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2554\u001b[0m ):\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2556\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3698\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3695\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3697\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3698\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3700\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3703\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3704\u001b[0m ):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3759\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3757\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3758\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[0;32m-> 3759\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3760\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3761\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py:819\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py:807\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 807\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:44\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py:1673\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1665\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1666\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1667\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1668\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1669\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1671\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1673\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1674\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1679\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1680\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1681\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1683\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1685\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1687\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py:1142\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1142\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1155\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    686\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m         output_attentions,\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    575\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    584\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py:524\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    507\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    514\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    515\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[1;32m    516\u001b[0m         hidden_states,\n\u001b[1;32m    517\u001b[0m         attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m         output_attentions,\n\u001b[1;32m    523\u001b[0m     )\n\u001b[0;32m--> 524\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py:467\u001b[0m, in \u001b[0;36mBertSelfOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    466\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m--> 467\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/dropout.py:70\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1425\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m-> 1425\u001b[0m     _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1426\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_trial = trainer.hyperparameter_search(\n",
    "    direction=\"maximize\",\n",
    "    backend=\"optuna\",\n",
    "    hp_space=hp_space,\n",
    "    compute_objective=lambda metrics: metrics[\"eval_f1\"],\n",
    "    pruner=pruner,\n",
    "    sampler=sampler,\n",
    "    study_name=\"Test-base\",\n",
    "    n_trials=150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43d41e6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_trial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbest_trial\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_trial' is not defined"
     ]
    }
   ],
   "source": [
    "print(best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff001c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f49758d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bert-distill_hp-search\", logging_dir=f\"~/logs/{DATASET}/bert-distill_hp-search\", remove_unused_columns=False, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb876364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_space(trial):\n",
    "    params =  {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 5e-4, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0, 1e-2, step=1e-3),\n",
    "        \"warmup_steps\" : trial.suggest_int(\"warmup_steps\", 0, warm_up),\n",
    "        \"lambda_param\": trial.suggest_float(\"lambda_param\",0,1,step=.1),\n",
    "        \"temperature\": trial.suggest_float(\"temperature\", 2,7, step=.5)\n",
    "    }\n",
    "    print(f\"Trial {trial.number} with params: {params}\")\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6858ab65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pruner = optuna.pruners.HyperbandPruner(min_resource=min_r, max_resource=max_r, reduction_factor=2, bootstrap_count=2)\n",
    "sampler = optuna.samplers.TPESampler(seed=42, multivariate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "511a945b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer = base.DistilTrainer(\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    model_init = lambda: get_Bert(),\n",
    ")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7091f8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 00:46:31,583] A new study created in memory with name: Distilation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 with params: {'learning_rate': 4.3284502212938785e-05, 'weight_decay': 0.01, 'warmup_steps': 32, 'lambda_param': 0.6000000000000001, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:07 < 02:03, 17.00 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.642600</td>\n",
       "      <td>1.794711</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795997</td>\n",
       "      <td>0.795592</td>\n",
       "      <td>0.795690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.683600</td>\n",
       "      <td>1.584951</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.796962</td>\n",
       "      <td>0.795256</td>\n",
       "      <td>0.795397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.307100</td>\n",
       "      <td>1.489271</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809575</td>\n",
       "      <td>0.809653</td>\n",
       "      <td>0.809597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.098600</td>\n",
       "      <td>1.506980</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812163</td>\n",
       "      <td>0.811611</td>\n",
       "      <td>0.811732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.957400</td>\n",
       "      <td>1.476046</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817612</td>\n",
       "      <td>0.817704</td>\n",
       "      <td>0.817632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.867000</td>\n",
       "      <td>1.505150</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815445</td>\n",
       "      <td>0.815536</td>\n",
       "      <td>0.815361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.798300</td>\n",
       "      <td>1.563696</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814494</td>\n",
       "      <td>0.814494</td>\n",
       "      <td>0.814220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.748800</td>\n",
       "      <td>1.550323</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814206</td>\n",
       "      <td>0.814073</td>\n",
       "      <td>0.814122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.705200</td>\n",
       "      <td>1.591043</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820280</td>\n",
       "      <td>0.820251</td>\n",
       "      <td>0.819954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.673100</td>\n",
       "      <td>1.564754</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821035</td>\n",
       "      <td>0.821083</td>\n",
       "      <td>0.821055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 00:50:40,600] Trial 0 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 with params: {'learning_rate': 1.8408992080552506e-05, 'weight_decay': 0.0, 'warmup_steps': 38, 'lambda_param': 0.6000000000000001, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 02:01 < 04:03, 17.28 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.080500</td>\n",
       "      <td>2.287992</td>\n",
       "      <td>0.753440</td>\n",
       "      <td>0.753954</td>\n",
       "      <td>0.752915</td>\n",
       "      <td>0.752996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.309700</td>\n",
       "      <td>1.842736</td>\n",
       "      <td>0.790138</td>\n",
       "      <td>0.790360</td>\n",
       "      <td>0.790383</td>\n",
       "      <td>0.790137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.900700</td>\n",
       "      <td>1.710683</td>\n",
       "      <td>0.785550</td>\n",
       "      <td>0.785693</td>\n",
       "      <td>0.785247</td>\n",
       "      <td>0.785345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.665800</td>\n",
       "      <td>1.638088</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.797470</td>\n",
       "      <td>0.796592</td>\n",
       "      <td>0.796727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.504100</td>\n",
       "      <td>1.580291</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.801111</td>\n",
       "      <td>0.799971</td>\n",
       "      <td>0.800118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 00:52:43,528] Trial 1 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 with params: {'learning_rate': 1.0838581269344744e-05, 'weight_decay': 0.01, 'warmup_steps': 36, 'lambda_param': 0.2, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:07 < 02:03, 17.01 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.222300</td>\n",
       "      <td>2.680268</td>\n",
       "      <td>0.699541</td>\n",
       "      <td>0.704751</td>\n",
       "      <td>0.697925</td>\n",
       "      <td>0.696450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.762800</td>\n",
       "      <td>2.163054</td>\n",
       "      <td>0.774083</td>\n",
       "      <td>0.775514</td>\n",
       "      <td>0.774701</td>\n",
       "      <td>0.773997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.315900</td>\n",
       "      <td>1.913745</td>\n",
       "      <td>0.779817</td>\n",
       "      <td>0.779753</td>\n",
       "      <td>0.779700</td>\n",
       "      <td>0.779723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.053500</td>\n",
       "      <td>1.810596</td>\n",
       "      <td>0.782110</td>\n",
       "      <td>0.782212</td>\n",
       "      <td>0.781826</td>\n",
       "      <td>0.781916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.887500</td>\n",
       "      <td>1.757589</td>\n",
       "      <td>0.785550</td>\n",
       "      <td>0.786079</td>\n",
       "      <td>0.785078</td>\n",
       "      <td>0.785204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.757700</td>\n",
       "      <td>1.687925</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792386</td>\n",
       "      <td>0.792298</td>\n",
       "      <td>0.792333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.670900</td>\n",
       "      <td>1.646094</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798112</td>\n",
       "      <td>0.798055</td>\n",
       "      <td>0.798079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.584700</td>\n",
       "      <td>1.619272</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803943</td>\n",
       "      <td>0.803686</td>\n",
       "      <td>0.803763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.526000</td>\n",
       "      <td>1.588411</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809585</td>\n",
       "      <td>0.809527</td>\n",
       "      <td>0.809552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.475800</td>\n",
       "      <td>1.579802</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.804163</td>\n",
       "      <td>0.803559</td>\n",
       "      <td>0.803682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 00:56:52,009] Trial 2 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 with params: {'learning_rate': 2.049268011541735e-05, 'weight_decay': 0.003, 'warmup_steps': 23, 'lambda_param': 0.4, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 02:01 < 04:03, 17.30 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.027100</td>\n",
       "      <td>2.196694</td>\n",
       "      <td>0.764908</td>\n",
       "      <td>0.765599</td>\n",
       "      <td>0.764345</td>\n",
       "      <td>0.764437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.216600</td>\n",
       "      <td>1.798141</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795971</td>\n",
       "      <td>0.795854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.823000</td>\n",
       "      <td>1.669979</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792587</td>\n",
       "      <td>0.792130</td>\n",
       "      <td>0.792232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.591000</td>\n",
       "      <td>1.609500</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.801254</td>\n",
       "      <td>0.799928</td>\n",
       "      <td>0.800079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.429400</td>\n",
       "      <td>1.552029</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806801</td>\n",
       "      <td>0.805727</td>\n",
       "      <td>0.805880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 00:58:54,657] Trial 3 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 with params: {'learning_rate': 0.00010952662748632558, 'weight_decay': 0.001, 'warmup_steps': 12, 'lambda_param': 0.4, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:05 < 02:02, 17.17 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.100900</td>\n",
       "      <td>1.555274</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811611</td>\n",
       "      <td>0.811242</td>\n",
       "      <td>0.810760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.128500</td>\n",
       "      <td>1.496460</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.816271</td>\n",
       "      <td>0.813442</td>\n",
       "      <td>0.813607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.830100</td>\n",
       "      <td>1.510520</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824620</td>\n",
       "      <td>0.824714</td>\n",
       "      <td>0.824536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.682200</td>\n",
       "      <td>1.574678</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.813433</td>\n",
       "      <td>0.809895</td>\n",
       "      <td>0.810024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.582200</td>\n",
       "      <td>1.635830</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819574</td>\n",
       "      <td>0.819251</td>\n",
       "      <td>0.818792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.518700</td>\n",
       "      <td>1.672433</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.813537</td>\n",
       "      <td>0.813053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.456100</td>\n",
       "      <td>1.759406</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809575</td>\n",
       "      <td>0.809653</td>\n",
       "      <td>0.809597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.422100</td>\n",
       "      <td>1.776611</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816759</td>\n",
       "      <td>0.816199</td>\n",
       "      <td>0.816324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.384400</td>\n",
       "      <td>1.817057</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.815682</td>\n",
       "      <td>0.814831</td>\n",
       "      <td>0.814158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.360500</td>\n",
       "      <td>1.841853</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809597</td>\n",
       "      <td>0.809695</td>\n",
       "      <td>0.809608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 01:03:00,838] Trial 4 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 with params: {'learning_rate': 0.0002157696745589684, 'weight_decay': 0.002, 'warmup_steps': 22, 'lambda_param': 0.6000000000000001, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:04 < 02:02, 17.21 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.778900</td>\n",
       "      <td>1.454532</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.807131</td>\n",
       "      <td>0.805780</td>\n",
       "      <td>0.804922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.868400</td>\n",
       "      <td>1.631527</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805267</td>\n",
       "      <td>0.804728</td>\n",
       "      <td>0.804845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.623200</td>\n",
       "      <td>1.742539</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.488200</td>\n",
       "      <td>1.685785</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.813115</td>\n",
       "      <td>0.811316</td>\n",
       "      <td>0.811489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.399500</td>\n",
       "      <td>1.845138</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810120</td>\n",
       "      <td>0.809990</td>\n",
       "      <td>0.809629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.337200</td>\n",
       "      <td>1.892421</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812112</td>\n",
       "      <td>0.812158</td>\n",
       "      <td>0.811926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.288600</td>\n",
       "      <td>2.149883</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.796756</td>\n",
       "      <td>0.796350</td>\n",
       "      <td>0.795845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.253300</td>\n",
       "      <td>2.016313</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.803938</td>\n",
       "      <td>0.803868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.227500</td>\n",
       "      <td>2.023047</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.805232</td>\n",
       "      <td>0.804486</td>\n",
       "      <td>0.803841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.208500</td>\n",
       "      <td>2.033162</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.803023</td>\n",
       "      <td>0.803023</td>\n",
       "      <td>0.802752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 01:07:06,593] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 with params: {'learning_rate': 0.00010769622478263136, 'weight_decay': 0.001, 'warmup_steps': 2, 'lambda_param': 1.0, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:06 < 02:03, 17.09 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.092500</td>\n",
       "      <td>1.556024</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812543</td>\n",
       "      <td>0.812326</td>\n",
       "      <td>0.811918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.135100</td>\n",
       "      <td>1.505002</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.818835</td>\n",
       "      <td>0.815694</td>\n",
       "      <td>0.815859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.836600</td>\n",
       "      <td>1.505569</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825798</td>\n",
       "      <td>0.825673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.688300</td>\n",
       "      <td>1.577069</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.813711</td>\n",
       "      <td>0.809853</td>\n",
       "      <td>0.809968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.588300</td>\n",
       "      <td>1.628784</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821727</td>\n",
       "      <td>0.821504</td>\n",
       "      <td>0.821092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.524700</td>\n",
       "      <td>1.674820</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811330</td>\n",
       "      <td>0.811158</td>\n",
       "      <td>0.810774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.462700</td>\n",
       "      <td>1.757227</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810731</td>\n",
       "      <td>0.810821</td>\n",
       "      <td>0.810750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.427900</td>\n",
       "      <td>1.771350</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820083</td>\n",
       "      <td>0.819704</td>\n",
       "      <td>0.819806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.389800</td>\n",
       "      <td>1.811973</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.814432</td>\n",
       "      <td>0.813663</td>\n",
       "      <td>0.813018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.366400</td>\n",
       "      <td>1.835226</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807401</td>\n",
       "      <td>0.807314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 01:11:13,879] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 with params: {'learning_rate': 0.000236288641842364, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.7000000000000001, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:05 < 02:02, 17.12 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.704100</td>\n",
       "      <td>1.477922</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.808655</td>\n",
       "      <td>0.806990</td>\n",
       "      <td>0.806033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.839500</td>\n",
       "      <td>1.642049</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.801864</td>\n",
       "      <td>0.801265</td>\n",
       "      <td>0.801386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.596700</td>\n",
       "      <td>1.788315</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821727</td>\n",
       "      <td>0.821504</td>\n",
       "      <td>0.821092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.461300</td>\n",
       "      <td>1.739623</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805066</td>\n",
       "      <td>0.804854</td>\n",
       "      <td>0.804922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.378900</td>\n",
       "      <td>1.873778</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.813187</td>\n",
       "      <td>0.812495</td>\n",
       "      <td>0.811878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.315700</td>\n",
       "      <td>1.982722</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810802</td>\n",
       "      <td>0.810906</td>\n",
       "      <td>0.810768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.272200</td>\n",
       "      <td>2.123283</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.801831</td>\n",
       "      <td>0.801854</td>\n",
       "      <td>0.801605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.238800</td>\n",
       "      <td>1.989539</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806215</td>\n",
       "      <td>0.806317</td>\n",
       "      <td>0.806180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.212900</td>\n",
       "      <td>2.052866</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805794</td>\n",
       "      <td>0.805485</td>\n",
       "      <td>0.805029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.197900</td>\n",
       "      <td>2.046692</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.799335</td>\n",
       "      <td>0.799434</td>\n",
       "      <td>0.799299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 01:15:21,100] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 with params: {'learning_rate': 1.6119044727609182e-05, 'weight_decay': 0.005, 'warmup_steps': 1, 'lambda_param': 1.0, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 02:03 < 04:06, 17.07 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.111000</td>\n",
       "      <td>2.374848</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750174</td>\n",
       "      <td>0.749621</td>\n",
       "      <td>0.749704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.408700</td>\n",
       "      <td>1.899731</td>\n",
       "      <td>0.784404</td>\n",
       "      <td>0.784668</td>\n",
       "      <td>0.784668</td>\n",
       "      <td>0.784404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.992600</td>\n",
       "      <td>1.756433</td>\n",
       "      <td>0.784404</td>\n",
       "      <td>0.784510</td>\n",
       "      <td>0.784121</td>\n",
       "      <td>0.784212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.756800</td>\n",
       "      <td>1.676793</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.796264</td>\n",
       "      <td>0.795466</td>\n",
       "      <td>0.795596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.596800</td>\n",
       "      <td>1.619456</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.795567</td>\n",
       "      <td>0.794172</td>\n",
       "      <td>0.794313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 01:17:25,445] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 with params: {'learning_rate': 0.00013353819088790598, 'weight_decay': 0.003, 'warmup_steps': 22, 'lambda_param': 0.6000000000000001, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:06 < 02:03, 17.04 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.014000</td>\n",
       "      <td>1.519257</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.806611</td>\n",
       "      <td>0.804738</td>\n",
       "      <td>0.803711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.036400</td>\n",
       "      <td>1.495800</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.809099</td>\n",
       "      <td>0.806601</td>\n",
       "      <td>0.806754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.760500</td>\n",
       "      <td>1.571663</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.825932</td>\n",
       "      <td>0.825135</td>\n",
       "      <td>0.824489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.616400</td>\n",
       "      <td>1.588069</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.808500</td>\n",
       "      <td>0.806727</td>\n",
       "      <td>0.806891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.522900</td>\n",
       "      <td>1.715670</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.810244</td>\n",
       "      <td>0.809158</td>\n",
       "      <td>0.808395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.456400</td>\n",
       "      <td>1.751974</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.809314</td>\n",
       "      <td>0.808948</td>\n",
       "      <td>0.808466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.397700</td>\n",
       "      <td>1.896207</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805417</td>\n",
       "      <td>0.805359</td>\n",
       "      <td>0.805045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.361500</td>\n",
       "      <td>1.881999</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812259</td>\n",
       "      <td>0.811569</td>\n",
       "      <td>0.811704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.328200</td>\n",
       "      <td>1.908619</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.811081</td>\n",
       "      <td>0.810242</td>\n",
       "      <td>0.809569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.308000</td>\n",
       "      <td>1.891332</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807281</td>\n",
       "      <td>0.807359</td>\n",
       "      <td>0.807303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 01:21:33,454] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 with params: {'learning_rate': 6.725268184578669e-05, 'weight_decay': 0.01, 'warmup_steps': 22, 'lambda_param': 0.7000000000000001, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:20, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.382000</td>\n",
       "      <td>1.655543</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794658</td>\n",
       "      <td>0.794719</td>\n",
       "      <td>0.794679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.402600</td>\n",
       "      <td>1.473135</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.801600</td>\n",
       "      <td>0.801433</td>\n",
       "      <td>0.801490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.047500</td>\n",
       "      <td>1.466806</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.874600</td>\n",
       "      <td>1.544127</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.827161</td>\n",
       "      <td>0.825040</td>\n",
       "      <td>0.825243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.754200</td>\n",
       "      <td>1.520280</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823443</td>\n",
       "      <td>0.823546</td>\n",
       "      <td>0.823386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.684200</td>\n",
       "      <td>1.549699</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819302</td>\n",
       "      <td>0.819167</td>\n",
       "      <td>0.818804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.619600</td>\n",
       "      <td>1.611278</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819901</td>\n",
       "      <td>0.819872</td>\n",
       "      <td>0.819886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.578200</td>\n",
       "      <td>1.631200</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821270</td>\n",
       "      <td>0.820830</td>\n",
       "      <td>0.820942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.537700</td>\n",
       "      <td>1.648224</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821871</td>\n",
       "      <td>0.821546</td>\n",
       "      <td>0.821086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.511900</td>\n",
       "      <td>1.642475</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819891</td>\n",
       "      <td>0.819957</td>\n",
       "      <td>0.819914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.492000</td>\n",
       "      <td>1.685744</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.473200</td>\n",
       "      <td>1.701575</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.459200</td>\n",
       "      <td>1.700829</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824478</td>\n",
       "      <td>0.824503</td>\n",
       "      <td>0.824489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.444400</td>\n",
       "      <td>1.707744</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823387</td>\n",
       "      <td>0.823251</td>\n",
       "      <td>0.823302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.441300</td>\n",
       "      <td>1.705968</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823335</td>\n",
       "      <td>0.823335</td>\n",
       "      <td>0.823335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 01:27:56,322] Trial 10 finished with value: 0.8233350172602509 and parameters: {'learning_rate': 6.725268184578669e-05, 'weight_decay': 0.01, 'warmup_steps': 22, 'lambda_param': 0.7000000000000001, 'temperature': 3.0}. Best is trial 10 with value: 0.8233350172602509.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 with params: {'learning_rate': 6.678376660461166e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 33, 'lambda_param': 0.6000000000000001, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:07, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.401100</td>\n",
       "      <td>1.661617</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.796952</td>\n",
       "      <td>0.797013</td>\n",
       "      <td>0.796973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.410200</td>\n",
       "      <td>1.475374</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.801647</td>\n",
       "      <td>0.801391</td>\n",
       "      <td>0.801467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.052000</td>\n",
       "      <td>1.468499</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819901</td>\n",
       "      <td>0.819872</td>\n",
       "      <td>0.819886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.877800</td>\n",
       "      <td>1.541198</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.828213</td>\n",
       "      <td>0.826208</td>\n",
       "      <td>0.826413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.757300</td>\n",
       "      <td>1.524844</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823506</td>\n",
       "      <td>0.823588</td>\n",
       "      <td>0.823391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.686900</td>\n",
       "      <td>1.551840</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819302</td>\n",
       "      <td>0.819167</td>\n",
       "      <td>0.818804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.622000</td>\n",
       "      <td>1.609382</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.580300</td>\n",
       "      <td>1.630996</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820083</td>\n",
       "      <td>0.819704</td>\n",
       "      <td>0.819806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.539900</td>\n",
       "      <td>1.649663</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819731</td>\n",
       "      <td>0.819294</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.513800</td>\n",
       "      <td>1.643704</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819891</td>\n",
       "      <td>0.819957</td>\n",
       "      <td>0.819914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.494100</td>\n",
       "      <td>1.686119</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819926</td>\n",
       "      <td>0.819830</td>\n",
       "      <td>0.819869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.475200</td>\n",
       "      <td>1.704794</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.461100</td>\n",
       "      <td>1.703419</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824479</td>\n",
       "      <td>0.824545</td>\n",
       "      <td>0.824502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.446500</td>\n",
       "      <td>1.710557</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824556</td>\n",
       "      <td>0.824377</td>\n",
       "      <td>0.824439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.443200</td>\n",
       "      <td>1.709570</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821035</td>\n",
       "      <td>0.821083</td>\n",
       "      <td>0.821055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 01:34:05,320] Trial 11 finished with value: 0.8210547917094193 and parameters: {'learning_rate': 6.678376660461166e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 33, 'lambda_param': 0.6000000000000001, 'temperature': 2.5}. Best is trial 10 with value: 0.8233350172602509.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 with params: {'learning_rate': 6.373988700422221e-05, 'weight_decay': 0.008, 'warmup_steps': 16, 'lambda_param': 0.9, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:08, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.405400</td>\n",
       "      <td>1.672864</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.796976</td>\n",
       "      <td>0.796887</td>\n",
       "      <td>0.796922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.434200</td>\n",
       "      <td>1.482393</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805066</td>\n",
       "      <td>0.804854</td>\n",
       "      <td>0.804922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.075300</td>\n",
       "      <td>1.469367</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814175</td>\n",
       "      <td>0.814116</td>\n",
       "      <td>0.814141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.898500</td>\n",
       "      <td>1.537092</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.828213</td>\n",
       "      <td>0.826208</td>\n",
       "      <td>0.826413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.775500</td>\n",
       "      <td>1.508390</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822270</td>\n",
       "      <td>0.822377</td>\n",
       "      <td>0.822236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.704200</td>\n",
       "      <td>1.539149</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822575</td>\n",
       "      <td>0.822546</td>\n",
       "      <td>0.822247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.639300</td>\n",
       "      <td>1.597134</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819926</td>\n",
       "      <td>0.819830</td>\n",
       "      <td>0.819869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.597200</td>\n",
       "      <td>1.616172</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820162</td>\n",
       "      <td>0.819662</td>\n",
       "      <td>0.819781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.556100</td>\n",
       "      <td>1.629522</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821597</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.821097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.529800</td>\n",
       "      <td>1.624816</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819891</td>\n",
       "      <td>0.819957</td>\n",
       "      <td>0.819914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.509900</td>\n",
       "      <td>1.666828</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819926</td>\n",
       "      <td>0.819830</td>\n",
       "      <td>0.819869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.491300</td>\n",
       "      <td>1.683380</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817890</td>\n",
       "      <td>0.817915</td>\n",
       "      <td>0.817660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.476500</td>\n",
       "      <td>1.684867</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824478</td>\n",
       "      <td>0.824503</td>\n",
       "      <td>0.824489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.461800</td>\n",
       "      <td>1.692480</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824556</td>\n",
       "      <td>0.824377</td>\n",
       "      <td>0.824439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.458200</td>\n",
       "      <td>1.690971</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824516</td>\n",
       "      <td>0.824419</td>\n",
       "      <td>0.824458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 01:40:15,952] Trial 12 finished with value: 0.8244579440359041 and parameters: {'learning_rate': 6.373988700422221e-05, 'weight_decay': 0.008, 'warmup_steps': 16, 'lambda_param': 0.9, 'temperature': 3.0}. Best is trial 12 with value: 0.8244579440359041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13 with params: {'learning_rate': 0.00039689817307863315, 'weight_decay': 0.009000000000000001, 'warmup_steps': 21, 'lambda_param': 1.0, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:05 < 02:02, 17.17 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.565600</td>\n",
       "      <td>1.410758</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809713</td>\n",
       "      <td>0.809401</td>\n",
       "      <td>0.809489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.722800</td>\n",
       "      <td>1.797154</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811880</td>\n",
       "      <td>0.811821</td>\n",
       "      <td>0.811846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.483900</td>\n",
       "      <td>1.900979</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810783</td>\n",
       "      <td>0.810611</td>\n",
       "      <td>0.810670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.363200</td>\n",
       "      <td>1.803357</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807291</td>\n",
       "      <td>0.807232</td>\n",
       "      <td>0.807257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.292400</td>\n",
       "      <td>2.019283</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805156</td>\n",
       "      <td>0.805233</td>\n",
       "      <td>0.805042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.237000</td>\n",
       "      <td>2.039925</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808509</td>\n",
       "      <td>0.808611</td>\n",
       "      <td>0.808474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.201300</td>\n",
       "      <td>2.297753</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.796238</td>\n",
       "      <td>0.796182</td>\n",
       "      <td>0.795870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.178000</td>\n",
       "      <td>2.128620</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.809035</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>0.808480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.153900</td>\n",
       "      <td>2.282848</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805656</td>\n",
       "      <td>0.805443</td>\n",
       "      <td>0.805037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.136800</td>\n",
       "      <td>2.200842</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.804977</td>\n",
       "      <td>0.805022</td>\n",
       "      <td>0.804996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 01:44:22,038] Trial 13 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 with params: {'learning_rate': 4.273142277230917e-05, 'weight_decay': 0.01, 'warmup_steps': 15, 'lambda_param': 0.9, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:06 < 02:03, 17.11 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.631100</td>\n",
       "      <td>1.794211</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.797183</td>\n",
       "      <td>0.796718</td>\n",
       "      <td>0.796824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.686100</td>\n",
       "      <td>1.585323</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.796962</td>\n",
       "      <td>0.795256</td>\n",
       "      <td>0.795397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.312900</td>\n",
       "      <td>1.489485</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809575</td>\n",
       "      <td>0.809653</td>\n",
       "      <td>0.809597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.104800</td>\n",
       "      <td>1.507626</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812163</td>\n",
       "      <td>0.811611</td>\n",
       "      <td>0.811732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.963400</td>\n",
       "      <td>1.473799</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817612</td>\n",
       "      <td>0.817704</td>\n",
       "      <td>0.817632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.872800</td>\n",
       "      <td>1.501563</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815445</td>\n",
       "      <td>0.815536</td>\n",
       "      <td>0.815361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.804200</td>\n",
       "      <td>1.557654</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813301</td>\n",
       "      <td>0.813326</td>\n",
       "      <td>0.813073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.754400</td>\n",
       "      <td>1.545942</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815374</td>\n",
       "      <td>0.815200</td>\n",
       "      <td>0.815260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.710500</td>\n",
       "      <td>1.583273</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819083</td>\n",
       "      <td>0.819083</td>\n",
       "      <td>0.818807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.678400</td>\n",
       "      <td>1.558667</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819901</td>\n",
       "      <td>0.819872</td>\n",
       "      <td>0.819886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 01:48:29,192] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 with params: {'learning_rate': 7.868373273873772e-05, 'weight_decay': 0.008, 'warmup_steps': 17, 'lambda_param': 0.6000000000000001, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:05, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.287800</td>\n",
       "      <td>1.620094</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808509</td>\n",
       "      <td>0.808611</td>\n",
       "      <td>0.808474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.312000</td>\n",
       "      <td>1.478902</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809585</td>\n",
       "      <td>0.809527</td>\n",
       "      <td>0.809552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.973700</td>\n",
       "      <td>1.493011</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.807800</td>\n",
       "      <td>1.581482</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.826815</td>\n",
       "      <td>0.823745</td>\n",
       "      <td>0.823939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.696000</td>\n",
       "      <td>1.602885</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819083</td>\n",
       "      <td>0.819083</td>\n",
       "      <td>0.818807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.627400</td>\n",
       "      <td>1.594582</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822946</td>\n",
       "      <td>0.822672</td>\n",
       "      <td>0.822236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.564900</td>\n",
       "      <td>1.653934</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813025</td>\n",
       "      <td>0.813116</td>\n",
       "      <td>0.813044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>1.663041</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816603</td>\n",
       "      <td>0.816284</td>\n",
       "      <td>0.816375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.485100</td>\n",
       "      <td>1.685076</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.822200</td>\n",
       "      <td>0.821630</td>\n",
       "      <td>0.821067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.461200</td>\n",
       "      <td>1.712574</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817612</td>\n",
       "      <td>0.817704</td>\n",
       "      <td>0.817632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.441100</td>\n",
       "      <td>1.722196</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819901</td>\n",
       "      <td>0.819872</td>\n",
       "      <td>0.819886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.423200</td>\n",
       "      <td>1.738865</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817808</td>\n",
       "      <td>0.817873</td>\n",
       "      <td>0.817658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.411400</td>\n",
       "      <td>1.736607</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822200</td>\n",
       "      <td>0.822293</td>\n",
       "      <td>0.822219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.396400</td>\n",
       "      <td>1.741177</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822185</td>\n",
       "      <td>0.822251</td>\n",
       "      <td>0.822208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.394800</td>\n",
       "      <td>1.740496</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821209</td>\n",
       "      <td>0.821086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 01:54:36,717] Trial 15 finished with value: 0.8210858585858586 and parameters: {'learning_rate': 7.868373273873772e-05, 'weight_decay': 0.008, 'warmup_steps': 17, 'lambda_param': 0.6000000000000001, 'temperature': 6.0}. Best is trial 12 with value: 0.8244579440359041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16 with params: {'learning_rate': 3.8257922999035495e-05, 'weight_decay': 0.01, 'warmup_steps': 4, 'lambda_param': 0.4, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:00 < 02:00, 17.49 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.682100</td>\n",
       "      <td>1.826397</td>\n",
       "      <td>0.790138</td>\n",
       "      <td>0.790289</td>\n",
       "      <td>0.789835</td>\n",
       "      <td>0.789936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.755600</td>\n",
       "      <td>1.618063</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.794831</td>\n",
       "      <td>0.792919</td>\n",
       "      <td>0.793051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.385300</td>\n",
       "      <td>1.503162</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808438</td>\n",
       "      <td>0.808527</td>\n",
       "      <td>0.808456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.170400</td>\n",
       "      <td>1.513338</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813462</td>\n",
       "      <td>0.812695</td>\n",
       "      <td>0.812837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.024100</td>\n",
       "      <td>1.476060</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815319</td>\n",
       "      <td>0.815410</td>\n",
       "      <td>0.815338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.928400</td>\n",
       "      <td>1.490340</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818915</td>\n",
       "      <td>0.818792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.858900</td>\n",
       "      <td>1.537074</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814406</td>\n",
       "      <td>0.814452</td>\n",
       "      <td>0.814219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.804900</td>\n",
       "      <td>1.526349</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816603</td>\n",
       "      <td>0.816284</td>\n",
       "      <td>0.816375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.759300</td>\n",
       "      <td>1.557133</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.817006</td>\n",
       "      <td>0.816873</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.725300</td>\n",
       "      <td>1.541744</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819926</td>\n",
       "      <td>0.819830</td>\n",
       "      <td>0.819869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 01:58:38,336] Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17 with params: {'learning_rate': 3.306391905724834e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 8, 'lambda_param': 1.0, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:09, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.769100</td>\n",
       "      <td>1.883306</td>\n",
       "      <td>0.785550</td>\n",
       "      <td>0.785772</td>\n",
       "      <td>0.785205</td>\n",
       "      <td>0.785313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.857200</td>\n",
       "      <td>1.656872</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.794340</td>\n",
       "      <td>0.793045</td>\n",
       "      <td>0.793185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.485800</td>\n",
       "      <td>1.529088</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807401</td>\n",
       "      <td>0.807314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.263400</td>\n",
       "      <td>1.528627</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811703</td>\n",
       "      <td>0.810232</td>\n",
       "      <td>0.810401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.110600</td>\n",
       "      <td>1.476891</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813041</td>\n",
       "      <td>0.812947</td>\n",
       "      <td>0.812985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.007700</td>\n",
       "      <td>1.472615</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816620</td>\n",
       "      <td>0.816498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.935800</td>\n",
       "      <td>1.506234</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810926</td>\n",
       "      <td>0.810990</td>\n",
       "      <td>0.810778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>1.502936</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813078</td>\n",
       "      <td>0.812905</td>\n",
       "      <td>0.812965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.828800</td>\n",
       "      <td>1.522659</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815596</td>\n",
       "      <td>0.815621</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.792000</td>\n",
       "      <td>1.519530</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820017</td>\n",
       "      <td>0.819746</td>\n",
       "      <td>0.819829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.767800</td>\n",
       "      <td>1.523309</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820162</td>\n",
       "      <td>0.819662</td>\n",
       "      <td>0.819781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.750700</td>\n",
       "      <td>1.535089</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814269</td>\n",
       "      <td>0.814368</td>\n",
       "      <td>0.814211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.733300</td>\n",
       "      <td>1.538055</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.713600</td>\n",
       "      <td>1.549767</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816470</td>\n",
       "      <td>0.816410</td>\n",
       "      <td>0.816436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>1.551789</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816470</td>\n",
       "      <td>0.816410</td>\n",
       "      <td>0.816436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 02:04:50,160] Trial 17 finished with value: 0.8164355445622714 and parameters: {'learning_rate': 3.306391905724834e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 8, 'lambda_param': 1.0, 'temperature': 5.0}. Best is trial 12 with value: 0.8244579440359041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18 with params: {'learning_rate': 1.2783135103593331e-05, 'weight_decay': 0.007, 'warmup_steps': 25, 'lambda_param': 0.9, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:05 < 02:02, 17.16 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.186900</td>\n",
       "      <td>2.576349</td>\n",
       "      <td>0.715596</td>\n",
       "      <td>0.717403</td>\n",
       "      <td>0.714616</td>\n",
       "      <td>0.714333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.619200</td>\n",
       "      <td>2.041369</td>\n",
       "      <td>0.783257</td>\n",
       "      <td>0.784358</td>\n",
       "      <td>0.783794</td>\n",
       "      <td>0.783209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.175700</td>\n",
       "      <td>1.839095</td>\n",
       "      <td>0.783257</td>\n",
       "      <td>0.783277</td>\n",
       "      <td>0.783037</td>\n",
       "      <td>0.783106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.926700</td>\n",
       "      <td>1.750789</td>\n",
       "      <td>0.786697</td>\n",
       "      <td>0.786747</td>\n",
       "      <td>0.786457</td>\n",
       "      <td>0.786536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.766000</td>\n",
       "      <td>1.701892</td>\n",
       "      <td>0.790138</td>\n",
       "      <td>0.790956</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.789717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.638400</td>\n",
       "      <td>1.631299</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.801706</td>\n",
       "      <td>0.801349</td>\n",
       "      <td>0.801442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.550500</td>\n",
       "      <td>1.595429</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806239</td>\n",
       "      <td>0.805980</td>\n",
       "      <td>0.806058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.463900</td>\n",
       "      <td>1.573703</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805066</td>\n",
       "      <td>0.804854</td>\n",
       "      <td>0.804922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.405800</td>\n",
       "      <td>1.546115</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803839</td>\n",
       "      <td>0.803812</td>\n",
       "      <td>0.803825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.357500</td>\n",
       "      <td>1.545266</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806675</td>\n",
       "      <td>0.805770</td>\n",
       "      <td>0.805915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 02:08:56,375] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 19 with params: {'learning_rate': 3.912340804652161e-05, 'weight_decay': 0.008, 'warmup_steps': 32, 'lambda_param': 1.0, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:05 < 02:02, 17.12 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.698300</td>\n",
       "      <td>1.826058</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791477</td>\n",
       "      <td>0.790962</td>\n",
       "      <td>0.791069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.750400</td>\n",
       "      <td>1.615230</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.793768</td>\n",
       "      <td>0.791751</td>\n",
       "      <td>0.791877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.374400</td>\n",
       "      <td>1.499324</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808438</td>\n",
       "      <td>0.808527</td>\n",
       "      <td>0.808456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.159000</td>\n",
       "      <td>1.509355</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811162</td>\n",
       "      <td>0.810400</td>\n",
       "      <td>0.810540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.013000</td>\n",
       "      <td>1.475894</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815390</td>\n",
       "      <td>0.815494</td>\n",
       "      <td>0.815355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.917400</td>\n",
       "      <td>1.493327</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820032</td>\n",
       "      <td>0.820125</td>\n",
       "      <td>0.819948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.847700</td>\n",
       "      <td>1.546207</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.794200</td>\n",
       "      <td>1.530899</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817721</td>\n",
       "      <td>0.817452</td>\n",
       "      <td>0.817534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.749200</td>\n",
       "      <td>1.567896</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815799</td>\n",
       "      <td>0.815705</td>\n",
       "      <td>0.815365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.715400</td>\n",
       "      <td>1.548695</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817631</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 02:13:03,358] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 with params: {'learning_rate': 0.00012648802951407994, 'weight_decay': 0.007, 'warmup_steps': 15, 'lambda_param': 0.7000000000000001, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:03 < 02:01, 17.30 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.030700</td>\n",
       "      <td>1.530320</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.805639</td>\n",
       "      <td>0.804570</td>\n",
       "      <td>0.803806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.058900</td>\n",
       "      <td>1.499202</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.811197</td>\n",
       "      <td>0.808937</td>\n",
       "      <td>0.809102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.778200</td>\n",
       "      <td>1.554448</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819731</td>\n",
       "      <td>0.819294</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.634200</td>\n",
       "      <td>1.590132</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.810603</td>\n",
       "      <td>0.807685</td>\n",
       "      <td>0.807829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.538800</td>\n",
       "      <td>1.695674</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.808588</td>\n",
       "      <td>0.807906</td>\n",
       "      <td>0.807290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.473000</td>\n",
       "      <td>1.735913</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805946</td>\n",
       "      <td>0.805527</td>\n",
       "      <td>0.805020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.413500</td>\n",
       "      <td>1.859123</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807524</td>\n",
       "      <td>0.807569</td>\n",
       "      <td>0.807338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.376900</td>\n",
       "      <td>1.848705</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813269</td>\n",
       "      <td>0.812779</td>\n",
       "      <td>0.812894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.342900</td>\n",
       "      <td>1.887439</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.807942</td>\n",
       "      <td>0.806864</td>\n",
       "      <td>0.806101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.321700</td>\n",
       "      <td>1.885771</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806128</td>\n",
       "      <td>0.806191</td>\n",
       "      <td>0.806150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 02:17:07,831] Trial 20 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 21 with params: {'learning_rate': 9.982843963014127e-05, 'weight_decay': 0.01, 'warmup_steps': 17, 'lambda_param': 0.7000000000000001, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:03 < 02:01, 17.29 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.159700</td>\n",
       "      <td>1.575162</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813760</td>\n",
       "      <td>0.813495</td>\n",
       "      <td>0.813061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.179200</td>\n",
       "      <td>1.503784</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808976</td>\n",
       "      <td>0.808064</td>\n",
       "      <td>0.808212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.868100</td>\n",
       "      <td>1.519828</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826913</td>\n",
       "      <td>0.827008</td>\n",
       "      <td>0.826829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.715700</td>\n",
       "      <td>1.588813</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.820901</td>\n",
       "      <td>0.818031</td>\n",
       "      <td>0.818210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.612400</td>\n",
       "      <td>1.646063</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.818666</td>\n",
       "      <td>0.818167</td>\n",
       "      <td>0.817632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.548300</td>\n",
       "      <td>1.673641</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811464</td>\n",
       "      <td>0.811200</td>\n",
       "      <td>0.810768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.484200</td>\n",
       "      <td>1.744611</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813096</td>\n",
       "      <td>0.813200</td>\n",
       "      <td>0.813061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.450500</td>\n",
       "      <td>1.727914</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815566</td>\n",
       "      <td>0.815073</td>\n",
       "      <td>0.815190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.410800</td>\n",
       "      <td>1.783590</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.815682</td>\n",
       "      <td>0.814831</td>\n",
       "      <td>0.814158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.389300</td>\n",
       "      <td>1.801487</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813220</td>\n",
       "      <td>0.813284</td>\n",
       "      <td>0.813071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 02:21:12,413] Trial 21 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 22 with params: {'learning_rate': 8.008902647410555e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 20, 'lambda_param': 0.8, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:08, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.281800</td>\n",
       "      <td>1.616754</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808509</td>\n",
       "      <td>0.808611</td>\n",
       "      <td>0.808474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.302000</td>\n",
       "      <td>1.479848</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808451</td>\n",
       "      <td>0.808359</td>\n",
       "      <td>0.808395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.965300</td>\n",
       "      <td>1.495386</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.800400</td>\n",
       "      <td>1.582399</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.827847</td>\n",
       "      <td>0.824914</td>\n",
       "      <td>0.825113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.689400</td>\n",
       "      <td>1.610151</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819083</td>\n",
       "      <td>0.819083</td>\n",
       "      <td>0.818807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.621200</td>\n",
       "      <td>1.600829</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822946</td>\n",
       "      <td>0.822672</td>\n",
       "      <td>0.822236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.558800</td>\n",
       "      <td>1.661115</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811869</td>\n",
       "      <td>0.811947</td>\n",
       "      <td>0.811891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.519100</td>\n",
       "      <td>1.668438</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815489</td>\n",
       "      <td>0.815115</td>\n",
       "      <td>0.815215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.479500</td>\n",
       "      <td>1.693013</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.823440</td>\n",
       "      <td>0.822798</td>\n",
       "      <td>0.822208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.455600</td>\n",
       "      <td>1.720135</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.818831</td>\n",
       "      <td>0.818773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.435600</td>\n",
       "      <td>1.726828</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.417700</td>\n",
       "      <td>1.744138</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817890</td>\n",
       "      <td>0.817915</td>\n",
       "      <td>0.817660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.406100</td>\n",
       "      <td>1.741117</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822200</td>\n",
       "      <td>0.822293</td>\n",
       "      <td>0.822219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.391100</td>\n",
       "      <td>1.744963</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821044</td>\n",
       "      <td>0.821125</td>\n",
       "      <td>0.821067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.389500</td>\n",
       "      <td>1.744826</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816620</td>\n",
       "      <td>0.816498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 02:27:23,001] Trial 22 finished with value: 0.8164983164983165 and parameters: {'learning_rate': 8.008902647410555e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 20, 'lambda_param': 0.8, 'temperature': 4.0}. Best is trial 12 with value: 0.8244579440359041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 23 with params: {'learning_rate': 0.000119266773192184, 'weight_decay': 0.007, 'warmup_steps': 9, 'lambda_param': 0.5, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 02:02 < 04:05, 17.16 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.051200</td>\n",
       "      <td>1.541211</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.805232</td>\n",
       "      <td>0.804486</td>\n",
       "      <td>0.803841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.085400</td>\n",
       "      <td>1.498174</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.815423</td>\n",
       "      <td>0.813610</td>\n",
       "      <td>0.813788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.798900</td>\n",
       "      <td>1.533609</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819302</td>\n",
       "      <td>0.819167</td>\n",
       "      <td>0.818804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.653300</td>\n",
       "      <td>1.588236</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.811884</td>\n",
       "      <td>0.808811</td>\n",
       "      <td>0.808954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.556300</td>\n",
       "      <td>1.660801</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814711</td>\n",
       "      <td>0.814579</td>\n",
       "      <td>0.814216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 02:29:26,938] Trial 23 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 24 with params: {'learning_rate': 0.00019145028201717734, 'weight_decay': 0.007, 'warmup_steps': 33, 'lambda_param': 0.6000000000000001, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:03 < 02:02, 17.25 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.853800</td>\n",
       "      <td>1.443416</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.802932</td>\n",
       "      <td>0.802191</td>\n",
       "      <td>0.801547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.905800</td>\n",
       "      <td>1.577543</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812627</td>\n",
       "      <td>0.811442</td>\n",
       "      <td>0.811606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.652000</td>\n",
       "      <td>1.711648</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822946</td>\n",
       "      <td>0.822672</td>\n",
       "      <td>0.822236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.516500</td>\n",
       "      <td>1.609046</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819157</td>\n",
       "      <td>0.818452</td>\n",
       "      <td>0.818593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.428200</td>\n",
       "      <td>1.793581</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815921</td>\n",
       "      <td>0.815747</td>\n",
       "      <td>0.815361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.364400</td>\n",
       "      <td>1.925175</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807449</td>\n",
       "      <td>0.807527</td>\n",
       "      <td>0.807335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.312100</td>\n",
       "      <td>2.130208</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798644</td>\n",
       "      <td>0.798518</td>\n",
       "      <td>0.798161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.279600</td>\n",
       "      <td>2.001292</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805010</td>\n",
       "      <td>0.805107</td>\n",
       "      <td>0.805020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.251000</td>\n",
       "      <td>2.023747</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.810498</td>\n",
       "      <td>0.808243</td>\n",
       "      <td>0.807111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.233200</td>\n",
       "      <td>2.093798</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.795261</td>\n",
       "      <td>0.795098</td>\n",
       "      <td>0.794718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 02:33:32,120] Trial 24 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 with params: {'learning_rate': 9.489632568623659e-05, 'weight_decay': 0.007, 'warmup_steps': 19, 'lambda_param': 0.2, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:06 < 02:03, 17.07 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.187500</td>\n",
       "      <td>1.590824</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814711</td>\n",
       "      <td>0.814579</td>\n",
       "      <td>0.814216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.202500</td>\n",
       "      <td>1.490427</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812080</td>\n",
       "      <td>0.811653</td>\n",
       "      <td>0.811759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.887800</td>\n",
       "      <td>1.511893</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825737</td>\n",
       "      <td>0.825840</td>\n",
       "      <td>0.825680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.733400</td>\n",
       "      <td>1.596763</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.819867</td>\n",
       "      <td>0.816862</td>\n",
       "      <td>0.817035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.628900</td>\n",
       "      <td>1.646701</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820649</td>\n",
       "      <td>0.820378</td>\n",
       "      <td>0.819943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.564000</td>\n",
       "      <td>1.663303</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.816057</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.815355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.500800</td>\n",
       "      <td>1.734756</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810858</td>\n",
       "      <td>0.810948</td>\n",
       "      <td>0.810774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.465500</td>\n",
       "      <td>1.719303</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816603</td>\n",
       "      <td>0.816284</td>\n",
       "      <td>0.816375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.425700</td>\n",
       "      <td>1.765879</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.814849</td>\n",
       "      <td>0.813747</td>\n",
       "      <td>0.812985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>1.785792</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813220</td>\n",
       "      <td>0.813284</td>\n",
       "      <td>0.813071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 02:37:40,220] Trial 25 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 with params: {'learning_rate': 3.176385176660576e-05, 'weight_decay': 0.01, 'warmup_steps': 13, 'lambda_param': 0.30000000000000004, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:09, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.796200</td>\n",
       "      <td>1.903103</td>\n",
       "      <td>0.784404</td>\n",
       "      <td>0.784582</td>\n",
       "      <td>0.784078</td>\n",
       "      <td>0.784181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.887200</td>\n",
       "      <td>1.666679</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791899</td>\n",
       "      <td>0.790793</td>\n",
       "      <td>0.790928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.514800</td>\n",
       "      <td>1.536957</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809597</td>\n",
       "      <td>0.809695</td>\n",
       "      <td>0.809608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.290400</td>\n",
       "      <td>1.533306</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810472</td>\n",
       "      <td>0.809106</td>\n",
       "      <td>0.809271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.136000</td>\n",
       "      <td>1.476029</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813041</td>\n",
       "      <td>0.812947</td>\n",
       "      <td>0.812985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.030900</td>\n",
       "      <td>1.468947</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815319</td>\n",
       "      <td>0.815410</td>\n",
       "      <td>0.815338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.957900</td>\n",
       "      <td>1.497909</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808632</td>\n",
       "      <td>0.808695</td>\n",
       "      <td>0.808484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.896500</td>\n",
       "      <td>1.496811</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814206</td>\n",
       "      <td>0.814073</td>\n",
       "      <td>0.814122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.848900</td>\n",
       "      <td>1.514422</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.811500</td>\n",
       "      <td>1.514418</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.818620</td>\n",
       "      <td>0.818692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.786800</td>\n",
       "      <td>1.517985</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819058</td>\n",
       "      <td>0.818494</td>\n",
       "      <td>0.818620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.769300</td>\n",
       "      <td>1.527512</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814269</td>\n",
       "      <td>0.814368</td>\n",
       "      <td>0.814211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.751800</td>\n",
       "      <td>1.529754</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.731700</td>\n",
       "      <td>1.541353</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.722900</td>\n",
       "      <td>1.543349</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816470</td>\n",
       "      <td>0.816410</td>\n",
       "      <td>0.816436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 02:43:51,551] Trial 26 finished with value: 0.8164355445622714 and parameters: {'learning_rate': 3.176385176660576e-05, 'weight_decay': 0.01, 'warmup_steps': 13, 'lambda_param': 0.30000000000000004, 'temperature': 6.5}. Best is trial 12 with value: 0.8244579440359041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 27 with params: {'learning_rate': 0.00014421241424714628, 'weight_decay': 0.007, 'warmup_steps': 5, 'lambda_param': 1.0, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 02:01 < 04:03, 17.28 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.947200</td>\n",
       "      <td>1.478452</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.800451</td>\n",
       "      <td>0.799855</td>\n",
       "      <td>0.799267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.002400</td>\n",
       "      <td>1.480841</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.815423</td>\n",
       "      <td>0.813610</td>\n",
       "      <td>0.813788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.736000</td>\n",
       "      <td>1.604708</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.826464</td>\n",
       "      <td>0.826135</td>\n",
       "      <td>0.825673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.595200</td>\n",
       "      <td>1.599332</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814793</td>\n",
       "      <td>0.813779</td>\n",
       "      <td>0.813937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.502100</td>\n",
       "      <td>1.736624</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.815136</td>\n",
       "      <td>0.814705</td>\n",
       "      <td>0.814196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 02:45:54,311] Trial 27 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 28 with params: {'learning_rate': 6.745391470707147e-05, 'weight_decay': 0.005, 'warmup_steps': 22, 'lambda_param': 0.9, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:11, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.380300</td>\n",
       "      <td>1.654670</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.796969</td>\n",
       "      <td>0.797055</td>\n",
       "      <td>0.796986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.400800</td>\n",
       "      <td>1.472839</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.802770</td>\n",
       "      <td>0.802560</td>\n",
       "      <td>0.802627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.046000</td>\n",
       "      <td>1.466779</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.873300</td>\n",
       "      <td>1.544458</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.827161</td>\n",
       "      <td>0.825040</td>\n",
       "      <td>0.825243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.753000</td>\n",
       "      <td>1.520913</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823443</td>\n",
       "      <td>0.823546</td>\n",
       "      <td>0.823386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.683100</td>\n",
       "      <td>1.550079</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819302</td>\n",
       "      <td>0.819167</td>\n",
       "      <td>0.818804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.618500</td>\n",
       "      <td>1.612075</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.577200</td>\n",
       "      <td>1.631968</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821270</td>\n",
       "      <td>0.820830</td>\n",
       "      <td>0.820942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.536700</td>\n",
       "      <td>1.649047</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821871</td>\n",
       "      <td>0.821546</td>\n",
       "      <td>0.821086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.510900</td>\n",
       "      <td>1.645016</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.491100</td>\n",
       "      <td>1.687193</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.472300</td>\n",
       "      <td>1.703222</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.458400</td>\n",
       "      <td>1.701562</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823329</td>\n",
       "      <td>0.823377</td>\n",
       "      <td>0.823349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.443400</td>\n",
       "      <td>1.708971</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823387</td>\n",
       "      <td>0.823251</td>\n",
       "      <td>0.823302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.440400</td>\n",
       "      <td>1.707405</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824490</td>\n",
       "      <td>0.824461</td>\n",
       "      <td>0.824475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 02:52:07,757] Trial 28 finished with value: 0.8244745722574152 and parameters: {'learning_rate': 6.745391470707147e-05, 'weight_decay': 0.005, 'warmup_steps': 22, 'lambda_param': 0.9, 'temperature': 3.0}. Best is trial 28 with value: 0.8244745722574152.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 29 with params: {'learning_rate': 0.00012014952338564047, 'weight_decay': 0.01, 'warmup_steps': 18, 'lambda_param': 0.5, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:08 < 02:04, 16.96 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.060700</td>\n",
       "      <td>1.543397</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.806480</td>\n",
       "      <td>0.805654</td>\n",
       "      <td>0.804980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.083100</td>\n",
       "      <td>1.496804</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.814560</td>\n",
       "      <td>0.812400</td>\n",
       "      <td>0.812574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.795800</td>\n",
       "      <td>1.537935</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.821141</td>\n",
       "      <td>0.820504</td>\n",
       "      <td>0.819914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.650600</td>\n",
       "      <td>1.583416</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.811884</td>\n",
       "      <td>0.808811</td>\n",
       "      <td>0.808954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.553800</td>\n",
       "      <td>1.674285</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.809474</td>\n",
       "      <td>0.808990</td>\n",
       "      <td>0.808456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.488700</td>\n",
       "      <td>1.719595</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810541</td>\n",
       "      <td>0.810116</td>\n",
       "      <td>0.809608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.427800</td>\n",
       "      <td>1.829854</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807449</td>\n",
       "      <td>0.807527</td>\n",
       "      <td>0.807335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.392400</td>\n",
       "      <td>1.822708</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813358</td>\n",
       "      <td>0.812737</td>\n",
       "      <td>0.812866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.357000</td>\n",
       "      <td>1.859523</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.809204</td>\n",
       "      <td>0.808032</td>\n",
       "      <td>0.807238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.334600</td>\n",
       "      <td>1.873248</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807281</td>\n",
       "      <td>0.807359</td>\n",
       "      <td>0.807303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 02:56:17,085] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 with params: {'learning_rate': 8.24648153819458e-05, 'weight_decay': 0.004, 'warmup_steps': 31, 'lambda_param': 1.0, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:11, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.281600</td>\n",
       "      <td>1.614570</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805156</td>\n",
       "      <td>0.805233</td>\n",
       "      <td>0.805042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.289700</td>\n",
       "      <td>1.479908</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810832</td>\n",
       "      <td>0.810569</td>\n",
       "      <td>0.810648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.953500</td>\n",
       "      <td>1.492614</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.789500</td>\n",
       "      <td>1.576003</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.826566</td>\n",
       "      <td>0.823788</td>\n",
       "      <td>0.823985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.679600</td>\n",
       "      <td>1.609669</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821480</td>\n",
       "      <td>0.821420</td>\n",
       "      <td>0.821100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.611600</td>\n",
       "      <td>1.603887</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.824168</td>\n",
       "      <td>0.823840</td>\n",
       "      <td>0.823380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.548800</td>\n",
       "      <td>1.668163</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813007</td>\n",
       "      <td>0.813031</td>\n",
       "      <td>0.813018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.509500</td>\n",
       "      <td>1.671510</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817721</td>\n",
       "      <td>0.817452</td>\n",
       "      <td>0.817534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.470600</td>\n",
       "      <td>1.702965</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.821537</td>\n",
       "      <td>0.820588</td>\n",
       "      <td>0.819886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.446300</td>\n",
       "      <td>1.729361</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815319</td>\n",
       "      <td>0.815410</td>\n",
       "      <td>0.815338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.426300</td>\n",
       "      <td>1.734929</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819891</td>\n",
       "      <td>0.819957</td>\n",
       "      <td>0.819914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.408200</td>\n",
       "      <td>1.752700</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815514</td>\n",
       "      <td>0.815578</td>\n",
       "      <td>0.815365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.396900</td>\n",
       "      <td>1.751434</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822200</td>\n",
       "      <td>0.822293</td>\n",
       "      <td>0.822219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.381800</td>\n",
       "      <td>1.754693</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822196</td>\n",
       "      <td>0.822167</td>\n",
       "      <td>0.822180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.380800</td>\n",
       "      <td>1.754845</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818915</td>\n",
       "      <td>0.818792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 03:02:30,788] Trial 30 finished with value: 0.8187920875420875 and parameters: {'learning_rate': 8.24648153819458e-05, 'weight_decay': 0.004, 'warmup_steps': 31, 'lambda_param': 1.0, 'temperature': 3.5}. Best is trial 28 with value: 0.8244745722574152.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 31 with params: {'learning_rate': 7.40121657218587e-05, 'weight_decay': 0.008, 'warmup_steps': 23, 'lambda_param': 1.0, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:39 < 02:19, 15.06 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.328900</td>\n",
       "      <td>1.630184</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807401</td>\n",
       "      <td>0.807314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.345700</td>\n",
       "      <td>1.462211</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810895</td>\n",
       "      <td>0.810527</td>\n",
       "      <td>0.810624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>1.462479</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816478</td>\n",
       "      <td>0.816578</td>\n",
       "      <td>0.816490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.833200</td>\n",
       "      <td>1.553651</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.823801</td>\n",
       "      <td>0.821577</td>\n",
       "      <td>0.821773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.717100</td>\n",
       "      <td>1.544853</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818994</td>\n",
       "      <td>0.819041</td>\n",
       "      <td>0.818806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.649200</td>\n",
       "      <td>1.573982</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821597</td>\n",
       "      <td>0.821462</td>\n",
       "      <td>0.821097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.585300</td>\n",
       "      <td>1.633579</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815374</td>\n",
       "      <td>0.815200</td>\n",
       "      <td>0.815260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.545800</td>\n",
       "      <td>1.651827</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816546</td>\n",
       "      <td>0.816326</td>\n",
       "      <td>0.816397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.505500</td>\n",
       "      <td>1.681497</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.817434</td>\n",
       "      <td>0.816999</td>\n",
       "      <td>0.816490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.480600</td>\n",
       "      <td>1.672595</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816447</td>\n",
       "      <td>0.816494</td>\n",
       "      <td>0.816466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 03:07:11,338] Trial 31 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 32 with params: {'learning_rate': 4.956842169562857e-05, 'weight_decay': 0.006, 'warmup_steps': 16, 'lambda_param': 0.6000000000000001, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.548400</td>\n",
       "      <td>1.755046</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798230</td>\n",
       "      <td>0.797929</td>\n",
       "      <td>0.798012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.592200</td>\n",
       "      <td>1.539707</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.802196</td>\n",
       "      <td>0.801139</td>\n",
       "      <td>0.801285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.219500</td>\n",
       "      <td>1.483426</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811863</td>\n",
       "      <td>0.811863</td>\n",
       "      <td>0.811863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.022900</td>\n",
       "      <td>1.512097</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820362</td>\n",
       "      <td>0.819578</td>\n",
       "      <td>0.819726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.887900</td>\n",
       "      <td>1.476141</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816620</td>\n",
       "      <td>0.816498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.805600</td>\n",
       "      <td>1.515721</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.738300</td>\n",
       "      <td>1.573887</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815348</td>\n",
       "      <td>0.815452</td>\n",
       "      <td>0.815347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.693300</td>\n",
       "      <td>1.575145</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823433</td>\n",
       "      <td>0.823209</td>\n",
       "      <td>0.823282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.650200</td>\n",
       "      <td>1.605544</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817985</td>\n",
       "      <td>0.817957</td>\n",
       "      <td>0.817660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.620300</td>\n",
       "      <td>1.580389</td>\n",
       "      <td>0.829128</td>\n",
       "      <td>0.829079</td>\n",
       "      <td>0.829050</td>\n",
       "      <td>0.829063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.599300</td>\n",
       "      <td>1.609199</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824758</td>\n",
       "      <td>0.824251</td>\n",
       "      <td>0.824373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.581800</td>\n",
       "      <td>1.624889</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.565400</td>\n",
       "      <td>1.633557</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823335</td>\n",
       "      <td>0.823335</td>\n",
       "      <td>0.823335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.550100</td>\n",
       "      <td>1.643814</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825649</td>\n",
       "      <td>0.825587</td>\n",
       "      <td>0.825614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.543800</td>\n",
       "      <td>1.643516</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824490</td>\n",
       "      <td>0.824461</td>\n",
       "      <td>0.824475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 03:13:25,885] Trial 32 finished with value: 0.8244745722574152 and parameters: {'learning_rate': 4.956842169562857e-05, 'weight_decay': 0.006, 'warmup_steps': 16, 'lambda_param': 0.6000000000000001, 'temperature': 6.5}. Best is trial 28 with value: 0.8244745722574152.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 33 with params: {'learning_rate': 2.9884730997511285e-05, 'weight_decay': 0.004, 'warmup_steps': 11, 'lambda_param': 0.5, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 02:02 < 04:04, 17.21 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.828400</td>\n",
       "      <td>1.932654</td>\n",
       "      <td>0.784404</td>\n",
       "      <td>0.784762</td>\n",
       "      <td>0.783994</td>\n",
       "      <td>0.784113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.929800</td>\n",
       "      <td>1.685021</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792587</td>\n",
       "      <td>0.792130</td>\n",
       "      <td>0.792232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.558400</td>\n",
       "      <td>1.551132</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.804987</td>\n",
       "      <td>0.805064</td>\n",
       "      <td>0.805009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.331700</td>\n",
       "      <td>1.542397</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810472</td>\n",
       "      <td>0.809106</td>\n",
       "      <td>0.809271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.175200</td>\n",
       "      <td>1.481170</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809658</td>\n",
       "      <td>0.809443</td>\n",
       "      <td>0.809512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 03:15:29,242] Trial 33 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 34 with params: {'learning_rate': 3.058885041448953e-05, 'weight_decay': 0.006, 'warmup_steps': 22, 'lambda_param': 0.8, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:11, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.824900</td>\n",
       "      <td>1.925214</td>\n",
       "      <td>0.780963</td>\n",
       "      <td>0.781174</td>\n",
       "      <td>0.780616</td>\n",
       "      <td>0.780721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.917100</td>\n",
       "      <td>1.678869</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793775</td>\n",
       "      <td>0.793256</td>\n",
       "      <td>0.793365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.543500</td>\n",
       "      <td>1.545381</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806144</td>\n",
       "      <td>0.806233</td>\n",
       "      <td>0.806162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.316900</td>\n",
       "      <td>1.537699</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810472</td>\n",
       "      <td>0.809106</td>\n",
       "      <td>0.809271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.160800</td>\n",
       "      <td>1.478499</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810783</td>\n",
       "      <td>0.810611</td>\n",
       "      <td>0.810670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.053500</td>\n",
       "      <td>1.467777</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814162</td>\n",
       "      <td>0.814242</td>\n",
       "      <td>0.814185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.979300</td>\n",
       "      <td>1.491757</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806419</td>\n",
       "      <td>0.806443</td>\n",
       "      <td>0.806192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.916200</td>\n",
       "      <td>1.492218</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813041</td>\n",
       "      <td>0.812947</td>\n",
       "      <td>0.812985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.868100</td>\n",
       "      <td>1.508328</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814331</td>\n",
       "      <td>0.814410</td>\n",
       "      <td>0.814216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.830100</td>\n",
       "      <td>1.510549</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815374</td>\n",
       "      <td>0.815200</td>\n",
       "      <td>0.815260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.805200</td>\n",
       "      <td>1.513108</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817864</td>\n",
       "      <td>0.817368</td>\n",
       "      <td>0.817486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.787200</td>\n",
       "      <td>1.521144</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814331</td>\n",
       "      <td>0.814410</td>\n",
       "      <td>0.814216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.769600</td>\n",
       "      <td>1.522635</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815303</td>\n",
       "      <td>0.815368</td>\n",
       "      <td>0.815326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.749200</td>\n",
       "      <td>1.534407</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814153</td>\n",
       "      <td>0.814200</td>\n",
       "      <td>0.814172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.740200</td>\n",
       "      <td>1.536143</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814175</td>\n",
       "      <td>0.814116</td>\n",
       "      <td>0.814141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 03:21:42,683] Trial 34 finished with value: 0.8141409888692999 and parameters: {'learning_rate': 3.058885041448953e-05, 'weight_decay': 0.006, 'warmup_steps': 22, 'lambda_param': 0.8, 'temperature': 7.0}. Best is trial 28 with value: 0.8244745722574152.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 35 with params: {'learning_rate': 3.681082791006686e-05, 'weight_decay': 0.005, 'warmup_steps': 24, 'lambda_param': 0.7000000000000001, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:06 < 02:03, 17.07 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.723600</td>\n",
       "      <td>1.845541</td>\n",
       "      <td>0.790138</td>\n",
       "      <td>0.790289</td>\n",
       "      <td>0.789835</td>\n",
       "      <td>0.789936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.788900</td>\n",
       "      <td>1.631833</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.790397</td>\n",
       "      <td>0.788288</td>\n",
       "      <td>0.788402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.414600</td>\n",
       "      <td>1.508941</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805149</td>\n",
       "      <td>0.805029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.196200</td>\n",
       "      <td>1.514242</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811406</td>\n",
       "      <td>0.810316</td>\n",
       "      <td>0.810474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.047400</td>\n",
       "      <td>1.474268</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.949200</td>\n",
       "      <td>1.483832</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.878900</td>\n",
       "      <td>1.531221</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813301</td>\n",
       "      <td>0.813326</td>\n",
       "      <td>0.813073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.823000</td>\n",
       "      <td>1.519036</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814250</td>\n",
       "      <td>0.814031</td>\n",
       "      <td>0.814102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.777200</td>\n",
       "      <td>1.549747</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814839</td>\n",
       "      <td>0.814621</td>\n",
       "      <td>0.814211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.742300</td>\n",
       "      <td>1.536296</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817669</td>\n",
       "      <td>0.817494</td>\n",
       "      <td>0.817555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 03:25:50,620] Trial 35 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 36 with params: {'learning_rate': 8.871468526497837e-05, 'weight_decay': 0.006, 'warmup_steps': 20, 'lambda_param': 1.0, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:09, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.224600</td>\n",
       "      <td>1.602324</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805094</td>\n",
       "      <td>0.805191</td>\n",
       "      <td>0.805037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.239200</td>\n",
       "      <td>1.482374</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814307</td>\n",
       "      <td>0.813989</td>\n",
       "      <td>0.814079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.916600</td>\n",
       "      <td>1.510656</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821150</td>\n",
       "      <td>0.821251</td>\n",
       "      <td>0.821092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.759000</td>\n",
       "      <td>1.592869</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.825291</td>\n",
       "      <td>0.822661</td>\n",
       "      <td>0.822858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.651800</td>\n",
       "      <td>1.638876</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819431</td>\n",
       "      <td>0.819209</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.585900</td>\n",
       "      <td>1.640948</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.818353</td>\n",
       "      <td>0.818083</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.523200</td>\n",
       "      <td>1.709842</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810858</td>\n",
       "      <td>0.810948</td>\n",
       "      <td>0.810774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.486300</td>\n",
       "      <td>1.702778</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816603</td>\n",
       "      <td>0.816284</td>\n",
       "      <td>0.816375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.446500</td>\n",
       "      <td>1.737768</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.818416</td>\n",
       "      <td>0.817210</td>\n",
       "      <td>0.816417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.424200</td>\n",
       "      <td>1.759692</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815445</td>\n",
       "      <td>0.815536</td>\n",
       "      <td>0.815361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.403800</td>\n",
       "      <td>1.752381</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.387300</td>\n",
       "      <td>1.775147</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815596</td>\n",
       "      <td>0.815621</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.375700</td>\n",
       "      <td>1.772672</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815348</td>\n",
       "      <td>0.815452</td>\n",
       "      <td>0.815347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.360500</td>\n",
       "      <td>1.771022</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819889</td>\n",
       "      <td>0.819915</td>\n",
       "      <td>0.819901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.358900</td>\n",
       "      <td>1.773977</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816620</td>\n",
       "      <td>0.816498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 03:32:01,704] Trial 36 finished with value: 0.8164983164983165 and parameters: {'learning_rate': 8.871468526497837e-05, 'weight_decay': 0.006, 'warmup_steps': 20, 'lambda_param': 1.0, 'temperature': 3.0}. Best is trial 28 with value: 0.8244745722574152.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 37 with params: {'learning_rate': 4.729948829550423e-05, 'weight_decay': 0.002, 'warmup_steps': 9, 'lambda_param': 0.8, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:10, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.567500</td>\n",
       "      <td>1.766300</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795997</td>\n",
       "      <td>0.795592</td>\n",
       "      <td>0.795690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.619300</td>\n",
       "      <td>1.553097</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.802482</td>\n",
       "      <td>0.801055</td>\n",
       "      <td>0.801208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.247600</td>\n",
       "      <td>1.484196</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813017</td>\n",
       "      <td>0.812989</td>\n",
       "      <td>0.813002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.047800</td>\n",
       "      <td>1.511284</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819270</td>\n",
       "      <td>0.818410</td>\n",
       "      <td>0.818563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.910700</td>\n",
       "      <td>1.473663</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817612</td>\n",
       "      <td>0.817704</td>\n",
       "      <td>0.817632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.826000</td>\n",
       "      <td>1.510134</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.758400</td>\n",
       "      <td>1.567850</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815348</td>\n",
       "      <td>0.815452</td>\n",
       "      <td>0.815347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.712100</td>\n",
       "      <td>1.565419</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818972</td>\n",
       "      <td>0.818536</td>\n",
       "      <td>0.818646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.668700</td>\n",
       "      <td>1.597768</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.638400</td>\n",
       "      <td>1.571882</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825682</td>\n",
       "      <td>0.825545</td>\n",
       "      <td>0.825596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.617100</td>\n",
       "      <td>1.597636</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823655</td>\n",
       "      <td>0.823082</td>\n",
       "      <td>0.823212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.599900</td>\n",
       "      <td>1.612650</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.583200</td>\n",
       "      <td>1.622159</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823354</td>\n",
       "      <td>0.823293</td>\n",
       "      <td>0.823319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.567500</td>\n",
       "      <td>1.632792</td>\n",
       "      <td>0.827982</td>\n",
       "      <td>0.827978</td>\n",
       "      <td>0.827840</td>\n",
       "      <td>0.827891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.560900</td>\n",
       "      <td>1.632560</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826811</td>\n",
       "      <td>0.826713</td>\n",
       "      <td>0.826753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 03:38:14,266] Trial 37 finished with value: 0.8267526114341277 and parameters: {'learning_rate': 4.729948829550423e-05, 'weight_decay': 0.002, 'warmup_steps': 9, 'lambda_param': 0.8, 'temperature': 2.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 38 with params: {'learning_rate': 3.6395130105526165e-05, 'weight_decay': 0.002, 'warmup_steps': 11, 'lambda_param': 1.0, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:03, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.717300</td>\n",
       "      <td>1.845659</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791477</td>\n",
       "      <td>0.790962</td>\n",
       "      <td>0.791069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.792000</td>\n",
       "      <td>1.633310</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.790397</td>\n",
       "      <td>0.788288</td>\n",
       "      <td>0.788402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.420300</td>\n",
       "      <td>1.511129</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805149</td>\n",
       "      <td>0.805029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.202100</td>\n",
       "      <td>1.516341</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810324</td>\n",
       "      <td>0.809148</td>\n",
       "      <td>0.809308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.053200</td>\n",
       "      <td>1.474301</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.954900</td>\n",
       "      <td>1.482508</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.884700</td>\n",
       "      <td>1.527069</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814406</td>\n",
       "      <td>0.814452</td>\n",
       "      <td>0.814219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.828600</td>\n",
       "      <td>1.517086</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813128</td>\n",
       "      <td>0.812863</td>\n",
       "      <td>0.812943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.544525</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815921</td>\n",
       "      <td>0.815747</td>\n",
       "      <td>0.815361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.747500</td>\n",
       "      <td>1.533002</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818796</td>\n",
       "      <td>0.818662</td>\n",
       "      <td>0.818712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.724000</td>\n",
       "      <td>1.540696</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822380</td>\n",
       "      <td>0.821998</td>\n",
       "      <td>0.822101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.707900</td>\n",
       "      <td>1.555631</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816478</td>\n",
       "      <td>0.816578</td>\n",
       "      <td>0.816490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.690500</td>\n",
       "      <td>1.561595</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817597</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.671800</td>\n",
       "      <td>1.572983</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.663700</td>\n",
       "      <td>1.574643</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 03:44:19,647] Trial 38 finished with value: 0.8164519659846763 and parameters: {'learning_rate': 3.6395130105526165e-05, 'weight_decay': 0.002, 'warmup_steps': 11, 'lambda_param': 1.0, 'temperature': 2.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 39 with params: {'learning_rate': 6.784398075892817e-05, 'weight_decay': 0.003, 'warmup_steps': 3, 'lambda_param': 0.8, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:09, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.352800</td>\n",
       "      <td>1.650285</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.801586</td>\n",
       "      <td>0.801686</td>\n",
       "      <td>0.801584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.393300</td>\n",
       "      <td>1.473599</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805066</td>\n",
       "      <td>0.804854</td>\n",
       "      <td>0.804922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.042800</td>\n",
       "      <td>1.464201</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.870800</td>\n",
       "      <td>1.552901</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.827161</td>\n",
       "      <td>0.825040</td>\n",
       "      <td>0.825243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.750800</td>\n",
       "      <td>1.521291</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821150</td>\n",
       "      <td>0.821251</td>\n",
       "      <td>0.821092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.680800</td>\n",
       "      <td>1.546347</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820280</td>\n",
       "      <td>0.820251</td>\n",
       "      <td>0.819954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.616900</td>\n",
       "      <td>1.618838</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816470</td>\n",
       "      <td>0.816410</td>\n",
       "      <td>0.816436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.575900</td>\n",
       "      <td>1.633003</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817956</td>\n",
       "      <td>0.817326</td>\n",
       "      <td>0.817459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.535100</td>\n",
       "      <td>1.648961</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.820336</td>\n",
       "      <td>0.819948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.509900</td>\n",
       "      <td>1.642194</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.489500</td>\n",
       "      <td>1.688787</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818765</td>\n",
       "      <td>0.818704</td>\n",
       "      <td>0.818730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.470700</td>\n",
       "      <td>1.702422</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815691</td>\n",
       "      <td>0.815663</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.457200</td>\n",
       "      <td>1.701594</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819891</td>\n",
       "      <td>0.819957</td>\n",
       "      <td>0.819914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.442300</td>\n",
       "      <td>1.709230</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824516</td>\n",
       "      <td>0.824419</td>\n",
       "      <td>0.824458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.439400</td>\n",
       "      <td>1.706788</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822183</td>\n",
       "      <td>0.822209</td>\n",
       "      <td>0.822195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 03:50:31,307] Trial 39 finished with value: 0.8221950933949345 and parameters: {'learning_rate': 6.784398075892817e-05, 'weight_decay': 0.003, 'warmup_steps': 3, 'lambda_param': 0.8, 'temperature': 2.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 40 with params: {'learning_rate': 8.788434110215489e-05, 'weight_decay': 0.001, 'warmup_steps': 40, 'lambda_param': 0.6000000000000001, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:04, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.261400</td>\n",
       "      <td>1.604087</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808713</td>\n",
       "      <td>0.808737</td>\n",
       "      <td>0.808486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.256000</td>\n",
       "      <td>1.488320</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812163</td>\n",
       "      <td>0.811611</td>\n",
       "      <td>0.811732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.924500</td>\n",
       "      <td>1.504689</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818915</td>\n",
       "      <td>0.818792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.764200</td>\n",
       "      <td>1.583161</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.825291</td>\n",
       "      <td>0.822661</td>\n",
       "      <td>0.822858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.656500</td>\n",
       "      <td>1.626550</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.818217</td>\n",
       "      <td>0.818041</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.590100</td>\n",
       "      <td>1.628462</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.822029</td>\n",
       "      <td>0.821588</td>\n",
       "      <td>0.821077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.526900</td>\n",
       "      <td>1.699162</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808438</td>\n",
       "      <td>0.808527</td>\n",
       "      <td>0.808456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.489000</td>\n",
       "      <td>1.694115</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819965</td>\n",
       "      <td>0.819788</td>\n",
       "      <td>0.819850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.450300</td>\n",
       "      <td>1.729847</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.819236</td>\n",
       "      <td>0.818294</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.426600</td>\n",
       "      <td>1.758510</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818772</td>\n",
       "      <td>0.818873</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.406700</td>\n",
       "      <td>1.752769</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819891</td>\n",
       "      <td>0.819957</td>\n",
       "      <td>0.819914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.388900</td>\n",
       "      <td>1.773258</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>1.771799</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.362700</td>\n",
       "      <td>1.773655</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818741</td>\n",
       "      <td>0.818788</td>\n",
       "      <td>0.818761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.361900</td>\n",
       "      <td>1.774519</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 03:56:37,163] Trial 40 finished with value: 0.817648799542307 and parameters: {'learning_rate': 8.788434110215489e-05, 'weight_decay': 0.001, 'warmup_steps': 40, 'lambda_param': 0.6000000000000001, 'temperature': 5.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 41 with params: {'learning_rate': 1.1001377595702983e-05, 'weight_decay': 0.002, 'warmup_steps': 10, 'lambda_param': 0.6000000000000001, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:04 < 02:02, 17.24 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.212200</td>\n",
       "      <td>2.664117</td>\n",
       "      <td>0.697248</td>\n",
       "      <td>0.701780</td>\n",
       "      <td>0.695714</td>\n",
       "      <td>0.694412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.742700</td>\n",
       "      <td>2.146275</td>\n",
       "      <td>0.774083</td>\n",
       "      <td>0.775514</td>\n",
       "      <td>0.774701</td>\n",
       "      <td>0.773997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.298900</td>\n",
       "      <td>1.903440</td>\n",
       "      <td>0.778670</td>\n",
       "      <td>0.778616</td>\n",
       "      <td>0.778532</td>\n",
       "      <td>0.778565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.039500</td>\n",
       "      <td>1.803485</td>\n",
       "      <td>0.783257</td>\n",
       "      <td>0.783395</td>\n",
       "      <td>0.782952</td>\n",
       "      <td>0.783049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>1.751443</td>\n",
       "      <td>0.785550</td>\n",
       "      <td>0.786079</td>\n",
       "      <td>0.785078</td>\n",
       "      <td>0.785204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.746200</td>\n",
       "      <td>1.681650</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793548</td>\n",
       "      <td>0.793424</td>\n",
       "      <td>0.793469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.659700</td>\n",
       "      <td>1.640727</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.799271</td>\n",
       "      <td>0.799181</td>\n",
       "      <td>0.799217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.573900</td>\n",
       "      <td>1.614591</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.804004</td>\n",
       "      <td>0.803644</td>\n",
       "      <td>0.803738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.515400</td>\n",
       "      <td>1.584253</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809585</td>\n",
       "      <td>0.809527</td>\n",
       "      <td>0.809552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.465400</td>\n",
       "      <td>1.576448</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805267</td>\n",
       "      <td>0.804728</td>\n",
       "      <td>0.804845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 04:00:42,143] Trial 41 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 42 with params: {'learning_rate': 0.00010946176175251309, 'weight_decay': 0.003, 'warmup_steps': 15, 'lambda_param': 0.7000000000000001, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:03 < 02:01, 17.29 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.105700</td>\n",
       "      <td>1.557352</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810541</td>\n",
       "      <td>0.810116</td>\n",
       "      <td>0.809608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.129400</td>\n",
       "      <td>1.495547</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.818352</td>\n",
       "      <td>0.815778</td>\n",
       "      <td>0.815956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.829900</td>\n",
       "      <td>1.511364</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823506</td>\n",
       "      <td>0.823588</td>\n",
       "      <td>0.823391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.682100</td>\n",
       "      <td>1.572977</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.815754</td>\n",
       "      <td>0.812190</td>\n",
       "      <td>0.812327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.582100</td>\n",
       "      <td>1.637788</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819574</td>\n",
       "      <td>0.819251</td>\n",
       "      <td>0.818792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.518400</td>\n",
       "      <td>1.669984</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814981</td>\n",
       "      <td>0.814663</td>\n",
       "      <td>0.814205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.455900</td>\n",
       "      <td>1.757690</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809575</td>\n",
       "      <td>0.809653</td>\n",
       "      <td>0.809597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.422200</td>\n",
       "      <td>1.776243</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817864</td>\n",
       "      <td>0.817368</td>\n",
       "      <td>0.817486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.384100</td>\n",
       "      <td>1.813128</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.816732</td>\n",
       "      <td>0.815957</td>\n",
       "      <td>0.815312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.360300</td>\n",
       "      <td>1.840136</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809597</td>\n",
       "      <td>0.809695</td>\n",
       "      <td>0.809608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 04:04:46,686] Trial 42 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 43 with params: {'learning_rate': 0.00019674186242712736, 'weight_decay': 0.003, 'warmup_steps': 3, 'lambda_param': 0.1, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:03 < 02:01, 17.30 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.785300</td>\n",
       "      <td>1.463033</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.809436</td>\n",
       "      <td>0.808074</td>\n",
       "      <td>0.807217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.892300</td>\n",
       "      <td>1.592979</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.807093</td>\n",
       "      <td>0.805643</td>\n",
       "      <td>0.805804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.644500</td>\n",
       "      <td>1.674823</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821044</td>\n",
       "      <td>0.821125</td>\n",
       "      <td>0.821067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.509900</td>\n",
       "      <td>1.654472</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812491</td>\n",
       "      <td>0.811484</td>\n",
       "      <td>0.811640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.423100</td>\n",
       "      <td>1.764680</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811209</td>\n",
       "      <td>0.811116</td>\n",
       "      <td>0.810778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.358800</td>\n",
       "      <td>1.944070</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.805639</td>\n",
       "      <td>0.804570</td>\n",
       "      <td>0.803806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.308400</td>\n",
       "      <td>2.128054</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798768</td>\n",
       "      <td>0.798560</td>\n",
       "      <td>0.798156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.275600</td>\n",
       "      <td>1.963653</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.802717</td>\n",
       "      <td>0.802812</td>\n",
       "      <td>0.802726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.246300</td>\n",
       "      <td>1.953340</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.805049</td>\n",
       "      <td>0.804443</td>\n",
       "      <td>0.803855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.228100</td>\n",
       "      <td>1.982694</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.802683</td>\n",
       "      <td>0.802728</td>\n",
       "      <td>0.802701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 04:08:50,940] Trial 43 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 44 with params: {'learning_rate': 3.75792536289279e-05, 'weight_decay': 0.003, 'warmup_steps': 18, 'lambda_param': 1.0, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 02:00 < 04:00, 17.47 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.706100</td>\n",
       "      <td>1.836159</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791477</td>\n",
       "      <td>0.790962</td>\n",
       "      <td>0.791069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.772800</td>\n",
       "      <td>1.625482</td>\n",
       "      <td>0.790138</td>\n",
       "      <td>0.791458</td>\n",
       "      <td>0.789457</td>\n",
       "      <td>0.789577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.399600</td>\n",
       "      <td>1.505708</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805149</td>\n",
       "      <td>0.805029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.182800</td>\n",
       "      <td>1.512655</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812368</td>\n",
       "      <td>0.811526</td>\n",
       "      <td>0.811673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.035200</td>\n",
       "      <td>1.474698</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817597</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 04:10:52,410] Trial 44 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 45 with params: {'learning_rate': 0.00043371026242218253, 'weight_decay': 0.009000000000000001, 'warmup_steps': 32, 'lambda_param': 0.5, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:03 < 02:01, 17.31 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.567400</td>\n",
       "      <td>1.474552</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813041</td>\n",
       "      <td>0.812947</td>\n",
       "      <td>0.812985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.715200</td>\n",
       "      <td>1.816958</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813041</td>\n",
       "      <td>0.812947</td>\n",
       "      <td>0.812985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.478400</td>\n",
       "      <td>1.873214</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812543</td>\n",
       "      <td>0.812326</td>\n",
       "      <td>0.811918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.354200</td>\n",
       "      <td>1.852375</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.800512</td>\n",
       "      <td>0.798676</td>\n",
       "      <td>0.798823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.280700</td>\n",
       "      <td>1.977269</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.233800</td>\n",
       "      <td>2.044938</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816858</td>\n",
       "      <td>0.816157</td>\n",
       "      <td>0.816296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.199000</td>\n",
       "      <td>2.013567</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816447</td>\n",
       "      <td>0.816494</td>\n",
       "      <td>0.816466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.171800</td>\n",
       "      <td>2.042676</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.817603</td>\n",
       "      <td>0.817041</td>\n",
       "      <td>0.816479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.145800</td>\n",
       "      <td>2.163199</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803834</td>\n",
       "      <td>0.803896</td>\n",
       "      <td>0.803855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.134400</td>\n",
       "      <td>2.241283</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794869</td>\n",
       "      <td>0.794929</td>\n",
       "      <td>0.794722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 04:14:56,594] Trial 45 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 46 with params: {'learning_rate': 9.705653773363448e-05, 'weight_decay': 0.0, 'warmup_steps': 15, 'lambda_param': 0.8, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:02 < 02:01, 17.38 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.172000</td>\n",
       "      <td>1.584306</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814711</td>\n",
       "      <td>0.814579</td>\n",
       "      <td>0.814216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.191500</td>\n",
       "      <td>1.498430</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807660</td>\n",
       "      <td>0.806980</td>\n",
       "      <td>0.807111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.879000</td>\n",
       "      <td>1.513908</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826858</td>\n",
       "      <td>0.826966</td>\n",
       "      <td>0.826824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.725500</td>\n",
       "      <td>1.594527</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.819624</td>\n",
       "      <td>0.816905</td>\n",
       "      <td>0.817083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.621500</td>\n",
       "      <td>1.644288</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819431</td>\n",
       "      <td>0.819209</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.556900</td>\n",
       "      <td>1.666190</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.813537</td>\n",
       "      <td>0.813053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.493400</td>\n",
       "      <td>1.737785</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813151</td>\n",
       "      <td>0.813242</td>\n",
       "      <td>0.813067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.458600</td>\n",
       "      <td>1.722656</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815566</td>\n",
       "      <td>0.815073</td>\n",
       "      <td>0.815190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.418800</td>\n",
       "      <td>1.773734</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.816935</td>\n",
       "      <td>0.815999</td>\n",
       "      <td>0.815297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.397300</td>\n",
       "      <td>1.793807</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810858</td>\n",
       "      <td>0.810948</td>\n",
       "      <td>0.810774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 04:19:00,165] Trial 46 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 47 with params: {'learning_rate': 3.32509088330528e-05, 'weight_decay': 0.007, 'warmup_steps': 8, 'lambda_param': 0.7000000000000001, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:08, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.765900</td>\n",
       "      <td>1.880866</td>\n",
       "      <td>0.785550</td>\n",
       "      <td>0.785772</td>\n",
       "      <td>0.785205</td>\n",
       "      <td>0.785313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.853300</td>\n",
       "      <td>1.655462</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.794340</td>\n",
       "      <td>0.793045</td>\n",
       "      <td>0.793185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.481900</td>\n",
       "      <td>1.528062</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807401</td>\n",
       "      <td>0.807314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.259600</td>\n",
       "      <td>1.528009</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811703</td>\n",
       "      <td>0.810232</td>\n",
       "      <td>0.810401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.107100</td>\n",
       "      <td>1.476690</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813041</td>\n",
       "      <td>0.812947</td>\n",
       "      <td>0.812985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.004500</td>\n",
       "      <td>1.473152</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815390</td>\n",
       "      <td>0.815494</td>\n",
       "      <td>0.815355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.932700</td>\n",
       "      <td>1.507212</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809818</td>\n",
       "      <td>0.809864</td>\n",
       "      <td>0.809632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.873100</td>\n",
       "      <td>1.503598</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813078</td>\n",
       "      <td>0.812905</td>\n",
       "      <td>0.812965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.826000</td>\n",
       "      <td>1.523681</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.789400</td>\n",
       "      <td>1.520154</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820017</td>\n",
       "      <td>0.819746</td>\n",
       "      <td>0.819829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.765100</td>\n",
       "      <td>1.524289</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821356</td>\n",
       "      <td>0.820788</td>\n",
       "      <td>0.820916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.748100</td>\n",
       "      <td>1.536128</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814269</td>\n",
       "      <td>0.814368</td>\n",
       "      <td>0.814211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.730700</td>\n",
       "      <td>1.539302</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.711100</td>\n",
       "      <td>1.551150</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816470</td>\n",
       "      <td>0.816410</td>\n",
       "      <td>0.816436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>1.553019</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816470</td>\n",
       "      <td>0.816410</td>\n",
       "      <td>0.816436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 04:25:10,951] Trial 47 finished with value: 0.8164355445622714 and parameters: {'learning_rate': 3.32509088330528e-05, 'weight_decay': 0.007, 'warmup_steps': 8, 'lambda_param': 0.7000000000000001, 'temperature': 2.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 48 with params: {'learning_rate': 3.371313519569357e-05, 'weight_decay': 0.01, 'warmup_steps': 23, 'lambda_param': 0.7000000000000001, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:10, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.771900</td>\n",
       "      <td>1.880530</td>\n",
       "      <td>0.786697</td>\n",
       "      <td>0.786965</td>\n",
       "      <td>0.786331</td>\n",
       "      <td>0.786444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.848900</td>\n",
       "      <td>1.653151</td>\n",
       "      <td>0.790138</td>\n",
       "      <td>0.791111</td>\n",
       "      <td>0.789541</td>\n",
       "      <td>0.789673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.474600</td>\n",
       "      <td>1.524805</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805149</td>\n",
       "      <td>0.805029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>1.524058</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810472</td>\n",
       "      <td>0.809106</td>\n",
       "      <td>0.809271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.099500</td>\n",
       "      <td>1.475045</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814175</td>\n",
       "      <td>0.814116</td>\n",
       "      <td>0.814141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.997000</td>\n",
       "      <td>1.473297</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818856</td>\n",
       "      <td>0.818957</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.925300</td>\n",
       "      <td>1.510709</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811007</td>\n",
       "      <td>0.811032</td>\n",
       "      <td>0.810780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.866000</td>\n",
       "      <td>1.504578</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814206</td>\n",
       "      <td>0.814073</td>\n",
       "      <td>0.814122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.819100</td>\n",
       "      <td>1.527663</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819186</td>\n",
       "      <td>0.819125</td>\n",
       "      <td>0.818806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.782700</td>\n",
       "      <td>1.522356</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821197</td>\n",
       "      <td>0.820872</td>\n",
       "      <td>0.820965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.758500</td>\n",
       "      <td>1.527184</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821356</td>\n",
       "      <td>0.820788</td>\n",
       "      <td>0.820916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.741700</td>\n",
       "      <td>1.540097</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815445</td>\n",
       "      <td>0.815536</td>\n",
       "      <td>0.815361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.724200</td>\n",
       "      <td>1.543783</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.704800</td>\n",
       "      <td>1.555271</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.696400</td>\n",
       "      <td>1.557088</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815312</td>\n",
       "      <td>0.815284</td>\n",
       "      <td>0.815297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 04:31:23,075] Trial 48 finished with value: 0.8152967721140121 and parameters: {'learning_rate': 3.371313519569357e-05, 'weight_decay': 0.01, 'warmup_steps': 23, 'lambda_param': 0.7000000000000001, 'temperature': 2.5}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 49 with params: {'learning_rate': 6.854309974927711e-05, 'weight_decay': 0.001, 'warmup_steps': 5, 'lambda_param': 0.6000000000000001, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:07, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.349900</td>\n",
       "      <td>1.647439</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.800423</td>\n",
       "      <td>0.800518</td>\n",
       "      <td>0.800432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.387300</td>\n",
       "      <td>1.471918</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803943</td>\n",
       "      <td>0.803686</td>\n",
       "      <td>0.803763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.037400</td>\n",
       "      <td>1.464575</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.866200</td>\n",
       "      <td>1.553644</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.827161</td>\n",
       "      <td>0.825040</td>\n",
       "      <td>0.825243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.746700</td>\n",
       "      <td>1.522830</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822326</td>\n",
       "      <td>0.822419</td>\n",
       "      <td>0.822242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.677000</td>\n",
       "      <td>1.549337</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820280</td>\n",
       "      <td>0.820251</td>\n",
       "      <td>0.819954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.613000</td>\n",
       "      <td>1.619827</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816470</td>\n",
       "      <td>0.816410</td>\n",
       "      <td>0.816436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.572300</td>\n",
       "      <td>1.634573</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816759</td>\n",
       "      <td>0.816199</td>\n",
       "      <td>0.816324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.531500</td>\n",
       "      <td>1.652645</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822946</td>\n",
       "      <td>0.822672</td>\n",
       "      <td>0.822236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.506400</td>\n",
       "      <td>1.644757</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.486100</td>\n",
       "      <td>1.691022</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.467200</td>\n",
       "      <td>1.705235</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.453700</td>\n",
       "      <td>1.704290</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819891</td>\n",
       "      <td>0.819957</td>\n",
       "      <td>0.819914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.438800</td>\n",
       "      <td>1.711626</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824516</td>\n",
       "      <td>0.824419</td>\n",
       "      <td>0.824458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.436000</td>\n",
       "      <td>1.709184</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823335</td>\n",
       "      <td>0.823335</td>\n",
       "      <td>0.823335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 04:37:33,339] Trial 49 finished with value: 0.8233350172602509 and parameters: {'learning_rate': 6.854309974927711e-05, 'weight_decay': 0.001, 'warmup_steps': 5, 'lambda_param': 0.6000000000000001, 'temperature': 2.5}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 with params: {'learning_rate': 3.9622765700351934e-05, 'weight_decay': 0.007, 'warmup_steps': 24, 'lambda_param': 0.5, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 02:02 < 04:04, 17.23 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.682600</td>\n",
       "      <td>1.819836</td>\n",
       "      <td>0.790138</td>\n",
       "      <td>0.790289</td>\n",
       "      <td>0.789835</td>\n",
       "      <td>0.789936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.739200</td>\n",
       "      <td>1.610420</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.794654</td>\n",
       "      <td>0.792961</td>\n",
       "      <td>0.793098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.364600</td>\n",
       "      <td>1.497949</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807281</td>\n",
       "      <td>0.807359</td>\n",
       "      <td>0.807303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.150600</td>\n",
       "      <td>1.509340</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812259</td>\n",
       "      <td>0.811569</td>\n",
       "      <td>0.811704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.005400</td>\n",
       "      <td>1.475828</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815390</td>\n",
       "      <td>0.815494</td>\n",
       "      <td>0.815355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 04:39:36,364] Trial 50 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 51 with params: {'learning_rate': 4.805371039568404e-05, 'weight_decay': 0.0, 'warmup_steps': 14, 'lambda_param': 0.4, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:08, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.563800</td>\n",
       "      <td>1.762676</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.797112</td>\n",
       "      <td>0.796761</td>\n",
       "      <td>0.796851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.611000</td>\n",
       "      <td>1.548985</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.802482</td>\n",
       "      <td>0.801055</td>\n",
       "      <td>0.801208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.238400</td>\n",
       "      <td>1.483992</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813017</td>\n",
       "      <td>0.812989</td>\n",
       "      <td>0.813002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.039500</td>\n",
       "      <td>1.510977</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816858</td>\n",
       "      <td>0.816157</td>\n",
       "      <td>0.816296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.903100</td>\n",
       "      <td>1.474455</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816478</td>\n",
       "      <td>0.816578</td>\n",
       "      <td>0.816490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.819100</td>\n",
       "      <td>1.512364</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.751500</td>\n",
       "      <td>1.570451</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816620</td>\n",
       "      <td>0.816498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.705600</td>\n",
       "      <td>1.568679</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817786</td>\n",
       "      <td>0.817410</td>\n",
       "      <td>0.817511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>1.601428</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.632200</td>\n",
       "      <td>1.575152</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826811</td>\n",
       "      <td>0.826713</td>\n",
       "      <td>0.826753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>1.601626</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824758</td>\n",
       "      <td>0.824251</td>\n",
       "      <td>0.824373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.593700</td>\n",
       "      <td>1.616909</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818856</td>\n",
       "      <td>0.818957</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.577100</td>\n",
       "      <td>1.626477</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823354</td>\n",
       "      <td>0.823293</td>\n",
       "      <td>0.823319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.561600</td>\n",
       "      <td>1.636820</td>\n",
       "      <td>0.827982</td>\n",
       "      <td>0.827978</td>\n",
       "      <td>0.827840</td>\n",
       "      <td>0.827891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.555100</td>\n",
       "      <td>1.636971</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825649</td>\n",
       "      <td>0.825587</td>\n",
       "      <td>0.825614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 04:45:46,683] Trial 51 finished with value: 0.8256137673341579 and parameters: {'learning_rate': 4.805371039568404e-05, 'weight_decay': 0.0, 'warmup_steps': 14, 'lambda_param': 0.4, 'temperature': 2.5}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 52 with params: {'learning_rate': 1.7644803369444844e-05, 'weight_decay': 0.0, 'warmup_steps': 20, 'lambda_param': 0.2, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 02:01 < 04:03, 17.32 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.086700</td>\n",
       "      <td>2.311123</td>\n",
       "      <td>0.752294</td>\n",
       "      <td>0.752747</td>\n",
       "      <td>0.751789</td>\n",
       "      <td>0.751871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.338300</td>\n",
       "      <td>1.858709</td>\n",
       "      <td>0.790138</td>\n",
       "      <td>0.790360</td>\n",
       "      <td>0.790383</td>\n",
       "      <td>0.790137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.928800</td>\n",
       "      <td>1.724935</td>\n",
       "      <td>0.784404</td>\n",
       "      <td>0.784510</td>\n",
       "      <td>0.784121</td>\n",
       "      <td>0.784212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.694000</td>\n",
       "      <td>1.649889</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.795289</td>\n",
       "      <td>0.794256</td>\n",
       "      <td>0.794394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.533100</td>\n",
       "      <td>1.592234</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.801254</td>\n",
       "      <td>0.799928</td>\n",
       "      <td>0.800079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 04:47:49,116] Trial 52 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 53 with params: {'learning_rate': 0.00011842484457522068, 'weight_decay': 0.002, 'warmup_steps': 27, 'lambda_param': 0.2, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:10 < 02:05, 16.79 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.079400</td>\n",
       "      <td>1.548264</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.806684</td>\n",
       "      <td>0.805696</td>\n",
       "      <td>0.804963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.090900</td>\n",
       "      <td>1.501012</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.812682</td>\n",
       "      <td>0.810021</td>\n",
       "      <td>0.810180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.800700</td>\n",
       "      <td>1.529983</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820800</td>\n",
       "      <td>0.820420</td>\n",
       "      <td>0.819935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.654600</td>\n",
       "      <td>1.580673</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.812919</td>\n",
       "      <td>0.809979</td>\n",
       "      <td>0.810130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.557400</td>\n",
       "      <td>1.675333</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.813006</td>\n",
       "      <td>0.812453</td>\n",
       "      <td>0.811891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.493300</td>\n",
       "      <td>1.708860</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.814070</td>\n",
       "      <td>0.813579</td>\n",
       "      <td>0.813044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.431600</td>\n",
       "      <td>1.824292</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808713</td>\n",
       "      <td>0.808737</td>\n",
       "      <td>0.808486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.396900</td>\n",
       "      <td>1.814222</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814558</td>\n",
       "      <td>0.813863</td>\n",
       "      <td>0.814000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.360900</td>\n",
       "      <td>1.850310</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.811081</td>\n",
       "      <td>0.810242</td>\n",
       "      <td>0.809569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.338600</td>\n",
       "      <td>1.870355</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808467</td>\n",
       "      <td>0.808569</td>\n",
       "      <td>0.808466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jovyan/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--recall/11f90e583db35601050aed380d48e83202a896976b9608432fba9244fb447f24 (last modified on Fri Jan 10 23:14:00 2025) since it couldn't be found locally at evaluate-metric--recall, or remotely on the Hugging Face Hub.\n",
      "[I 2025-03-29 04:52:01,197] Trial 53 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 54 with params: {'learning_rate': 3.0513436108398737e-05, 'weight_decay': 0.0, 'warmup_steps': 1, 'lambda_param': 0.30000000000000004, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 02:01 < 04:02, 17.35 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.807700</td>\n",
       "      <td>1.918131</td>\n",
       "      <td>0.783257</td>\n",
       "      <td>0.783473</td>\n",
       "      <td>0.782910</td>\n",
       "      <td>0.783017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.911200</td>\n",
       "      <td>1.676992</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793775</td>\n",
       "      <td>0.793256</td>\n",
       "      <td>0.793365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.541500</td>\n",
       "      <td>1.546477</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806144</td>\n",
       "      <td>0.806233</td>\n",
       "      <td>0.806162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.316300</td>\n",
       "      <td>1.540884</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810472</td>\n",
       "      <td>0.809106</td>\n",
       "      <td>0.809271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.161000</td>\n",
       "      <td>1.480697</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809658</td>\n",
       "      <td>0.809443</td>\n",
       "      <td>0.809512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 04:54:03,607] Trial 54 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 55 with params: {'learning_rate': 4.85417487043681e-05, 'weight_decay': 0.002, 'warmup_steps': 10, 'lambda_param': 0.2, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:08, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.553900</td>\n",
       "      <td>1.759399</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798230</td>\n",
       "      <td>0.797929</td>\n",
       "      <td>0.798012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.603400</td>\n",
       "      <td>1.545109</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.804637</td>\n",
       "      <td>0.803391</td>\n",
       "      <td>0.803545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.231600</td>\n",
       "      <td>1.483492</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811863</td>\n",
       "      <td>0.811863</td>\n",
       "      <td>0.811863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.033800</td>\n",
       "      <td>1.512232</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.818062</td>\n",
       "      <td>0.817283</td>\n",
       "      <td>0.817430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.897900</td>\n",
       "      <td>1.474786</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816478</td>\n",
       "      <td>0.816578</td>\n",
       "      <td>0.816490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.814600</td>\n",
       "      <td>1.512845</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.747200</td>\n",
       "      <td>1.570731</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816620</td>\n",
       "      <td>0.816498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.701700</td>\n",
       "      <td>1.570838</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817786</td>\n",
       "      <td>0.817410</td>\n",
       "      <td>0.817511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.658400</td>\n",
       "      <td>1.601293</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.628400</td>\n",
       "      <td>1.575765</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826811</td>\n",
       "      <td>0.826713</td>\n",
       "      <td>0.826753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.607200</td>\n",
       "      <td>1.603428</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824758</td>\n",
       "      <td>0.824251</td>\n",
       "      <td>0.824373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.589800</td>\n",
       "      <td>1.618251</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.573300</td>\n",
       "      <td>1.627770</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823354</td>\n",
       "      <td>0.823293</td>\n",
       "      <td>0.823319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.557800</td>\n",
       "      <td>1.638034</td>\n",
       "      <td>0.827982</td>\n",
       "      <td>0.827978</td>\n",
       "      <td>0.827840</td>\n",
       "      <td>0.827891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.551400</td>\n",
       "      <td>1.637862</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826811</td>\n",
       "      <td>0.826713</td>\n",
       "      <td>0.826753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 05:00:13,986] Trial 55 finished with value: 0.8267526114341277 and parameters: {'learning_rate': 4.85417487043681e-05, 'weight_decay': 0.002, 'warmup_steps': 10, 'lambda_param': 0.2, 'temperature': 2.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 56 with params: {'learning_rate': 5.232117977967534e-05, 'weight_decay': 0.001, 'warmup_steps': 22, 'lambda_param': 0.4, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:05, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.524600</td>\n",
       "      <td>1.742091</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795997</td>\n",
       "      <td>0.795592</td>\n",
       "      <td>0.795690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.560300</td>\n",
       "      <td>1.525511</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.801962</td>\n",
       "      <td>0.801223</td>\n",
       "      <td>0.801354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.187800</td>\n",
       "      <td>1.483068</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810746</td>\n",
       "      <td>0.810653</td>\n",
       "      <td>0.810690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>1.514725</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822783</td>\n",
       "      <td>0.821830</td>\n",
       "      <td>0.821993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>1.481912</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.782900</td>\n",
       "      <td>1.522455</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819977</td>\n",
       "      <td>0.820083</td>\n",
       "      <td>0.819943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.716100</td>\n",
       "      <td>1.579535</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817597</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.672000</td>\n",
       "      <td>1.586238</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821092</td>\n",
       "      <td>0.820956</td>\n",
       "      <td>0.821007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.629300</td>\n",
       "      <td>1.612220</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817985</td>\n",
       "      <td>0.817957</td>\n",
       "      <td>0.817660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.590965</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825631</td>\n",
       "      <td>0.825714</td>\n",
       "      <td>0.825655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.579400</td>\n",
       "      <td>1.623125</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824758</td>\n",
       "      <td>0.824251</td>\n",
       "      <td>0.824373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.561400</td>\n",
       "      <td>1.639155</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819935</td>\n",
       "      <td>0.820041</td>\n",
       "      <td>0.819935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.545400</td>\n",
       "      <td>1.647056</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824478</td>\n",
       "      <td>0.824503</td>\n",
       "      <td>0.824489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.530400</td>\n",
       "      <td>1.656914</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823335</td>\n",
       "      <td>0.823335</td>\n",
       "      <td>0.823335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.524700</td>\n",
       "      <td>1.656025</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823335</td>\n",
       "      <td>0.823335</td>\n",
       "      <td>0.823335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 05:06:21,259] Trial 56 finished with value: 0.8233350172602509 and parameters: {'learning_rate': 5.232117977967534e-05, 'weight_decay': 0.001, 'warmup_steps': 22, 'lambda_param': 0.4, 'temperature': 3.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 57 with params: {'learning_rate': 2.581226824745506e-05, 'weight_decay': 0.004, 'warmup_steps': 10, 'lambda_param': 0.0, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:10, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.906400</td>\n",
       "      <td>2.019541</td>\n",
       "      <td>0.776376</td>\n",
       "      <td>0.776662</td>\n",
       "      <td>0.775985</td>\n",
       "      <td>0.776093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.034700</td>\n",
       "      <td>1.728666</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792366</td>\n",
       "      <td>0.792340</td>\n",
       "      <td>0.792352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.661700</td>\n",
       "      <td>1.591483</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.801566</td>\n",
       "      <td>0.801476</td>\n",
       "      <td>0.801511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.431700</td>\n",
       "      <td>1.566219</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.806192</td>\n",
       "      <td>0.804433</td>\n",
       "      <td>0.804593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.272100</td>\n",
       "      <td>1.502903</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813358</td>\n",
       "      <td>0.812737</td>\n",
       "      <td>0.812866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.157500</td>\n",
       "      <td>1.476812</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814206</td>\n",
       "      <td>0.814073</td>\n",
       "      <td>0.814122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.078900</td>\n",
       "      <td>1.481011</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806270</td>\n",
       "      <td>0.806359</td>\n",
       "      <td>0.806186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.009700</td>\n",
       "      <td>1.485973</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809585</td>\n",
       "      <td>0.809527</td>\n",
       "      <td>0.809552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.487237</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813220</td>\n",
       "      <td>0.813284</td>\n",
       "      <td>0.813071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.919200</td>\n",
       "      <td>1.496400</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816546</td>\n",
       "      <td>0.816326</td>\n",
       "      <td>0.816397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>1.492822</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813017</td>\n",
       "      <td>0.812989</td>\n",
       "      <td>0.813002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>1.497227</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813025</td>\n",
       "      <td>0.813116</td>\n",
       "      <td>0.813044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.855200</td>\n",
       "      <td>1.496491</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811869</td>\n",
       "      <td>0.811947</td>\n",
       "      <td>0.811891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.834000</td>\n",
       "      <td>1.504880</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811859</td>\n",
       "      <td>0.811905</td>\n",
       "      <td>0.811878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.822400</td>\n",
       "      <td>1.508703</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810713</td>\n",
       "      <td>0.810737</td>\n",
       "      <td>0.810724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 05:12:33,217] Trial 57 finished with value: 0.8107238090978335 and parameters: {'learning_rate': 2.581226824745506e-05, 'weight_decay': 0.004, 'warmup_steps': 10, 'lambda_param': 0.0, 'temperature': 2.5}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 58 with params: {'learning_rate': 8.838493696481511e-05, 'weight_decay': 0.001, 'warmup_steps': 14, 'lambda_param': 0.0, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.219400</td>\n",
       "      <td>1.602901</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808564</td>\n",
       "      <td>0.808653</td>\n",
       "      <td>0.808480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.239800</td>\n",
       "      <td>1.484848</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816603</td>\n",
       "      <td>0.816284</td>\n",
       "      <td>0.816375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.918000</td>\n",
       "      <td>1.509622</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820032</td>\n",
       "      <td>0.820125</td>\n",
       "      <td>0.819948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.760400</td>\n",
       "      <td>1.596513</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.826815</td>\n",
       "      <td>0.823745</td>\n",
       "      <td>0.823939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.653100</td>\n",
       "      <td>1.637751</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.818217</td>\n",
       "      <td>0.818041</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.587100</td>\n",
       "      <td>1.640759</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.818353</td>\n",
       "      <td>0.818083</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.524500</td>\n",
       "      <td>1.707264</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812037</td>\n",
       "      <td>0.812116</td>\n",
       "      <td>0.811923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.487400</td>\n",
       "      <td>1.701404</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816603</td>\n",
       "      <td>0.816284</td>\n",
       "      <td>0.816375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.447500</td>\n",
       "      <td>1.733759</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.816935</td>\n",
       "      <td>0.815999</td>\n",
       "      <td>0.815297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.425200</td>\n",
       "      <td>1.759158</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815445</td>\n",
       "      <td>0.815536</td>\n",
       "      <td>0.815361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.404900</td>\n",
       "      <td>1.755129</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.388300</td>\n",
       "      <td>1.776047</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814596</td>\n",
       "      <td>0.814536</td>\n",
       "      <td>0.814219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.376800</td>\n",
       "      <td>1.773507</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814326</td>\n",
       "      <td>0.814205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.361600</td>\n",
       "      <td>1.772341</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818741</td>\n",
       "      <td>0.818788</td>\n",
       "      <td>0.818761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>1.774672</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814269</td>\n",
       "      <td>0.814368</td>\n",
       "      <td>0.814211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 05:18:46,951] Trial 58 finished with value: 0.8142113874173404 and parameters: {'learning_rate': 8.838493696481511e-05, 'weight_decay': 0.001, 'warmup_steps': 14, 'lambda_param': 0.0, 'temperature': 2.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 59 with params: {'learning_rate': 4.1580499478084515e-05, 'weight_decay': 0.002, 'warmup_steps': 9, 'lambda_param': 0.4, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:07, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.640500</td>\n",
       "      <td>1.801016</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.796074</td>\n",
       "      <td>0.795550</td>\n",
       "      <td>0.795661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.701900</td>\n",
       "      <td>1.592467</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.795724</td>\n",
       "      <td>0.794129</td>\n",
       "      <td>0.794270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.330100</td>\n",
       "      <td>1.492009</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808438</td>\n",
       "      <td>0.808527</td>\n",
       "      <td>0.808456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.120200</td>\n",
       "      <td>1.509098</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811060</td>\n",
       "      <td>0.810442</td>\n",
       "      <td>0.810570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.977800</td>\n",
       "      <td>1.474583</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817641</td>\n",
       "      <td>0.817746</td>\n",
       "      <td>0.817641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.885900</td>\n",
       "      <td>1.499106</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.817200</td>\n",
       "      <td>1.552991</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813301</td>\n",
       "      <td>0.813326</td>\n",
       "      <td>0.813073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.766500</td>\n",
       "      <td>1.540810</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816546</td>\n",
       "      <td>0.816326</td>\n",
       "      <td>0.816397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.722100</td>\n",
       "      <td>1.577288</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819083</td>\n",
       "      <td>0.819083</td>\n",
       "      <td>0.818807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.689600</td>\n",
       "      <td>1.554563</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818765</td>\n",
       "      <td>0.818704</td>\n",
       "      <td>0.818730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.667500</td>\n",
       "      <td>1.570422</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821270</td>\n",
       "      <td>0.820830</td>\n",
       "      <td>0.820942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.651300</td>\n",
       "      <td>1.586193</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818856</td>\n",
       "      <td>0.818957</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.634100</td>\n",
       "      <td>1.595225</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.617000</td>\n",
       "      <td>1.606232</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819965</td>\n",
       "      <td>0.819788</td>\n",
       "      <td>0.819850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.609600</td>\n",
       "      <td>1.607645</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818765</td>\n",
       "      <td>0.818704</td>\n",
       "      <td>0.818730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 05:24:56,739] Trial 59 finished with value: 0.818730100255243 and parameters: {'learning_rate': 4.1580499478084515e-05, 'weight_decay': 0.002, 'warmup_steps': 9, 'lambda_param': 0.4, 'temperature': 2.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 60 with params: {'learning_rate': 6.905127566839599e-05, 'weight_decay': 0.001, 'warmup_steps': 16, 'lambda_param': 0.7000000000000001, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:04, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.359500</td>\n",
       "      <td>1.647137</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.800560</td>\n",
       "      <td>0.800442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.385500</td>\n",
       "      <td>1.470166</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806239</td>\n",
       "      <td>0.805980</td>\n",
       "      <td>0.806058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.033800</td>\n",
       "      <td>1.465321</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817597</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.863000</td>\n",
       "      <td>1.551011</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.826111</td>\n",
       "      <td>0.823872</td>\n",
       "      <td>0.824073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.743800</td>\n",
       "      <td>1.524870</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822270</td>\n",
       "      <td>0.822377</td>\n",
       "      <td>0.822236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.674400</td>\n",
       "      <td>1.554514</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819302</td>\n",
       "      <td>0.819167</td>\n",
       "      <td>0.818804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.610100</td>\n",
       "      <td>1.619296</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819901</td>\n",
       "      <td>0.819872</td>\n",
       "      <td>0.819886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.569500</td>\n",
       "      <td>1.636655</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817956</td>\n",
       "      <td>0.817326</td>\n",
       "      <td>0.817459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.528700</td>\n",
       "      <td>1.655372</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.823097</td>\n",
       "      <td>0.822714</td>\n",
       "      <td>0.822229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.503600</td>\n",
       "      <td>1.647444</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.483400</td>\n",
       "      <td>1.692168</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.464600</td>\n",
       "      <td>1.706667</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817985</td>\n",
       "      <td>0.817957</td>\n",
       "      <td>0.817660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.451000</td>\n",
       "      <td>1.705210</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823335</td>\n",
       "      <td>0.823335</td>\n",
       "      <td>0.823335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.436000</td>\n",
       "      <td>1.712216</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823354</td>\n",
       "      <td>0.823293</td>\n",
       "      <td>0.823319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.433300</td>\n",
       "      <td>1.710239</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823335</td>\n",
       "      <td>0.823335</td>\n",
       "      <td>0.823335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 05:31:03,382] Trial 60 finished with value: 0.8233350172602509 and parameters: {'learning_rate': 6.905127566839599e-05, 'weight_decay': 0.001, 'warmup_steps': 16, 'lambda_param': 0.7000000000000001, 'temperature': 2.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 61 with params: {'learning_rate': 3.293272179510502e-05, 'weight_decay': 0.006, 'warmup_steps': 16, 'lambda_param': 0.5, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 02:02 < 04:04, 17.21 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.778600</td>\n",
       "      <td>1.888045</td>\n",
       "      <td>0.785550</td>\n",
       "      <td>0.785772</td>\n",
       "      <td>0.785205</td>\n",
       "      <td>0.785313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.862900</td>\n",
       "      <td>1.658194</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.794340</td>\n",
       "      <td>0.793045</td>\n",
       "      <td>0.793185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.489900</td>\n",
       "      <td>1.529512</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807401</td>\n",
       "      <td>0.807314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.266700</td>\n",
       "      <td>1.528075</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812776</td>\n",
       "      <td>0.811400</td>\n",
       "      <td>0.811569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.113500</td>\n",
       "      <td>1.474186</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813041</td>\n",
       "      <td>0.812947</td>\n",
       "      <td>0.812985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 05:33:06,577] Trial 61 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 62 with params: {'learning_rate': 7.283898624298514e-05, 'weight_decay': 0.008, 'warmup_steps': 29, 'lambda_param': 0.5, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:01, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.346200</td>\n",
       "      <td>1.635009</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.803938</td>\n",
       "      <td>0.803868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.356300</td>\n",
       "      <td>1.463603</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808673</td>\n",
       "      <td>0.808190</td>\n",
       "      <td>0.808302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.007600</td>\n",
       "      <td>1.463327</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816478</td>\n",
       "      <td>0.816578</td>\n",
       "      <td>0.816490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.839900</td>\n",
       "      <td>1.551403</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.824852</td>\n",
       "      <td>0.822746</td>\n",
       "      <td>0.822944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.723200</td>\n",
       "      <td>1.541484</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820101</td>\n",
       "      <td>0.820167</td>\n",
       "      <td>0.819952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.655100</td>\n",
       "      <td>1.569376</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819431</td>\n",
       "      <td>0.819209</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.590900</td>\n",
       "      <td>1.630850</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817669</td>\n",
       "      <td>0.817494</td>\n",
       "      <td>0.817555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.550900</td>\n",
       "      <td>1.651564</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815425</td>\n",
       "      <td>0.815157</td>\n",
       "      <td>0.815238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.510700</td>\n",
       "      <td>1.676816</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.818502</td>\n",
       "      <td>0.818125</td>\n",
       "      <td>0.817641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.485500</td>\n",
       "      <td>1.669231</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817597</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.465700</td>\n",
       "      <td>1.711302</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817597</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.447100</td>\n",
       "      <td>1.727444</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819186</td>\n",
       "      <td>0.819125</td>\n",
       "      <td>0.818806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.434000</td>\n",
       "      <td>1.724437</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821066</td>\n",
       "      <td>0.821167</td>\n",
       "      <td>0.821077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.419000</td>\n",
       "      <td>1.729696</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824490</td>\n",
       "      <td>0.824461</td>\n",
       "      <td>0.824475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.416500</td>\n",
       "      <td>1.728267</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821044</td>\n",
       "      <td>0.821125</td>\n",
       "      <td>0.821067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 05:39:10,403] Trial 62 finished with value: 0.8210670314637483 and parameters: {'learning_rate': 7.283898624298514e-05, 'weight_decay': 0.008, 'warmup_steps': 29, 'lambda_param': 0.5, 'temperature': 4.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 63 with params: {'learning_rate': 5.799674988791627e-05, 'weight_decay': 0.0, 'warmup_steps': 15, 'lambda_param': 0.4, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:06, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.458500</td>\n",
       "      <td>1.707602</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795997</td>\n",
       "      <td>0.795592</td>\n",
       "      <td>0.795690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.493400</td>\n",
       "      <td>1.501392</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805120</td>\n",
       "      <td>0.804812</td>\n",
       "      <td>0.804898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.127200</td>\n",
       "      <td>1.474702</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811910</td>\n",
       "      <td>0.811779</td>\n",
       "      <td>0.811828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.943100</td>\n",
       "      <td>1.525525</td>\n",
       "      <td>0.827982</td>\n",
       "      <td>0.828748</td>\n",
       "      <td>0.827503</td>\n",
       "      <td>0.827688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.815400</td>\n",
       "      <td>1.490251</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.740600</td>\n",
       "      <td>1.529663</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817890</td>\n",
       "      <td>0.817915</td>\n",
       "      <td>0.817660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.675300</td>\n",
       "      <td>1.582151</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.632300</td>\n",
       "      <td>1.598231</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823433</td>\n",
       "      <td>0.823209</td>\n",
       "      <td>0.823282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.590100</td>\n",
       "      <td>1.612853</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.562300</td>\n",
       "      <td>1.603143</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826773</td>\n",
       "      <td>0.826840</td>\n",
       "      <td>0.826796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.542400</td>\n",
       "      <td>1.641102</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823493</td>\n",
       "      <td>0.823167</td>\n",
       "      <td>0.823261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.523900</td>\n",
       "      <td>1.656619</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.508500</td>\n",
       "      <td>1.661909</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825649</td>\n",
       "      <td>0.825587</td>\n",
       "      <td>0.825614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.493800</td>\n",
       "      <td>1.670432</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825682</td>\n",
       "      <td>0.825545</td>\n",
       "      <td>0.825596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.489200</td>\n",
       "      <td>1.669574</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824516</td>\n",
       "      <td>0.824419</td>\n",
       "      <td>0.824458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 05:45:18,795] Trial 63 finished with value: 0.8244579440359041 and parameters: {'learning_rate': 5.799674988791627e-05, 'weight_decay': 0.0, 'warmup_steps': 15, 'lambda_param': 0.4, 'temperature': 3.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 64 with params: {'learning_rate': 5.986275918990953e-05, 'weight_decay': 0.008, 'warmup_steps': 38, 'lambda_param': 0.0, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:07, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.470300</td>\n",
       "      <td>1.704977</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798295</td>\n",
       "      <td>0.797887</td>\n",
       "      <td>0.797986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.481500</td>\n",
       "      <td>1.497755</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.802770</td>\n",
       "      <td>0.802560</td>\n",
       "      <td>0.802627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.112100</td>\n",
       "      <td>1.475677</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811910</td>\n",
       "      <td>0.811779</td>\n",
       "      <td>0.811828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.928900</td>\n",
       "      <td>1.526775</td>\n",
       "      <td>0.831422</td>\n",
       "      <td>0.832450</td>\n",
       "      <td>0.830881</td>\n",
       "      <td>0.831084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.802700</td>\n",
       "      <td>1.505807</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820101</td>\n",
       "      <td>0.820167</td>\n",
       "      <td>0.819952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.728700</td>\n",
       "      <td>1.542955</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.663400</td>\n",
       "      <td>1.591856</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.620200</td>\n",
       "      <td>1.608597</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822314</td>\n",
       "      <td>0.822040</td>\n",
       "      <td>0.822124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.578500</td>\n",
       "      <td>1.627863</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819186</td>\n",
       "      <td>0.819125</td>\n",
       "      <td>0.818806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.551000</td>\n",
       "      <td>1.620109</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822185</td>\n",
       "      <td>0.822251</td>\n",
       "      <td>0.822208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.531300</td>\n",
       "      <td>1.659595</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821092</td>\n",
       "      <td>0.820956</td>\n",
       "      <td>0.821007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.512600</td>\n",
       "      <td>1.677723</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815514</td>\n",
       "      <td>0.815578</td>\n",
       "      <td>0.815365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.497500</td>\n",
       "      <td>1.680306</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824490</td>\n",
       "      <td>0.824461</td>\n",
       "      <td>0.824475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.483100</td>\n",
       "      <td>1.688929</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824516</td>\n",
       "      <td>0.824419</td>\n",
       "      <td>0.824458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.478600</td>\n",
       "      <td>1.688331</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823354</td>\n",
       "      <td>0.823293</td>\n",
       "      <td>0.823319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 05:51:27,615] Trial 64 finished with value: 0.8233192116411863 and parameters: {'learning_rate': 5.986275918990953e-05, 'weight_decay': 0.008, 'warmup_steps': 38, 'lambda_param': 0.0, 'temperature': 3.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 65 with params: {'learning_rate': 7.873581912408055e-05, 'weight_decay': 0.0, 'warmup_steps': 6, 'lambda_param': 0.30000000000000004, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:04, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.272700</td>\n",
       "      <td>1.618046</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811869</td>\n",
       "      <td>0.811947</td>\n",
       "      <td>0.811891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.307000</td>\n",
       "      <td>1.482477</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810723</td>\n",
       "      <td>0.810695</td>\n",
       "      <td>0.810708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.972300</td>\n",
       "      <td>1.497007</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.807300</td>\n",
       "      <td>1.594864</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.825787</td>\n",
       "      <td>0.822577</td>\n",
       "      <td>0.822764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.695200</td>\n",
       "      <td>1.608028</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818994</td>\n",
       "      <td>0.819041</td>\n",
       "      <td>0.818806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.626900</td>\n",
       "      <td>1.601951</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.817135</td>\n",
       "      <td>0.816915</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.564600</td>\n",
       "      <td>1.660205</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811891</td>\n",
       "      <td>0.811990</td>\n",
       "      <td>0.811902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>1.669175</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812163</td>\n",
       "      <td>0.811611</td>\n",
       "      <td>0.811732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>1.686080</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.818842</td>\n",
       "      <td>0.818210</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.461100</td>\n",
       "      <td>1.716239</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817597</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.441100</td>\n",
       "      <td>1.726819</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815312</td>\n",
       "      <td>0.815284</td>\n",
       "      <td>0.815297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.423300</td>\n",
       "      <td>1.745507</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815514</td>\n",
       "      <td>0.815578</td>\n",
       "      <td>0.815365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.411800</td>\n",
       "      <td>1.742886</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821066</td>\n",
       "      <td>0.821167</td>\n",
       "      <td>0.821077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.396900</td>\n",
       "      <td>1.747556</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823329</td>\n",
       "      <td>0.823377</td>\n",
       "      <td>0.823349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.394900</td>\n",
       "      <td>1.746947</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823338</td>\n",
       "      <td>0.823419</td>\n",
       "      <td>0.823361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 05:57:33,729] Trial 65 finished with value: 0.8233610438808797 and parameters: {'learning_rate': 7.873581912408055e-05, 'weight_decay': 0.0, 'warmup_steps': 6, 'lambda_param': 0.30000000000000004, 'temperature': 2.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 66 with params: {'learning_rate': 0.00044749265830226623, 'weight_decay': 0.003, 'warmup_steps': 42, 'lambda_param': 0.0, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:05 < 02:02, 17.13 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.580700</td>\n",
       "      <td>1.457958</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811880</td>\n",
       "      <td>0.811821</td>\n",
       "      <td>0.811846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>1.940680</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806375</td>\n",
       "      <td>0.805896</td>\n",
       "      <td>0.806007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.472800</td>\n",
       "      <td>1.952868</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.802936</td>\n",
       "      <td>0.802981</td>\n",
       "      <td>0.802751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.349100</td>\n",
       "      <td>2.011808</td>\n",
       "      <td>0.790138</td>\n",
       "      <td>0.790071</td>\n",
       "      <td>0.790130</td>\n",
       "      <td>0.790091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.282700</td>\n",
       "      <td>2.090972</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.798225</td>\n",
       "      <td>0.795687</td>\n",
       "      <td>0.794430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.230100</td>\n",
       "      <td>2.043356</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815445</td>\n",
       "      <td>0.815536</td>\n",
       "      <td>0.815361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>2.133976</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807271</td>\n",
       "      <td>0.807317</td>\n",
       "      <td>0.807290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.165800</td>\n",
       "      <td>1.991647</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811869</td>\n",
       "      <td>0.811947</td>\n",
       "      <td>0.811891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.147500</td>\n",
       "      <td>2.050966</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806156</td>\n",
       "      <td>0.806064</td>\n",
       "      <td>0.806101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.129100</td>\n",
       "      <td>2.333233</td>\n",
       "      <td>0.790138</td>\n",
       "      <td>0.792508</td>\n",
       "      <td>0.790930</td>\n",
       "      <td>0.789965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 06:01:40,281] Trial 66 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 67 with params: {'learning_rate': 2.754583220865359e-05, 'weight_decay': 0.001, 'warmup_steps': 14, 'lambda_param': 0.5, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 02:06 < 04:13, 16.62 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.874900</td>\n",
       "      <td>1.980004</td>\n",
       "      <td>0.787844</td>\n",
       "      <td>0.788070</td>\n",
       "      <td>0.787499</td>\n",
       "      <td>0.787609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.988900</td>\n",
       "      <td>1.711377</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791253</td>\n",
       "      <td>0.791130</td>\n",
       "      <td>0.791175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.617200</td>\n",
       "      <td>1.572584</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803839</td>\n",
       "      <td>0.803812</td>\n",
       "      <td>0.803825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.388100</td>\n",
       "      <td>1.555055</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.807258</td>\n",
       "      <td>0.805601</td>\n",
       "      <td>0.805763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.229400</td>\n",
       "      <td>1.491795</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813269</td>\n",
       "      <td>0.812779</td>\n",
       "      <td>0.812894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 06:03:47,855] Trial 67 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 68 with params: {'learning_rate': 5.288130004639587e-05, 'weight_decay': 0.007, 'warmup_steps': 8, 'lambda_param': 0.6000000000000001, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:06, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.503500</td>\n",
       "      <td>1.735837</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793775</td>\n",
       "      <td>0.793256</td>\n",
       "      <td>0.793365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.549500</td>\n",
       "      <td>1.521128</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.801962</td>\n",
       "      <td>0.801223</td>\n",
       "      <td>0.801354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.180000</td>\n",
       "      <td>1.481138</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810746</td>\n",
       "      <td>0.810653</td>\n",
       "      <td>0.810690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.989000</td>\n",
       "      <td>1.519278</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822783</td>\n",
       "      <td>0.821830</td>\n",
       "      <td>0.821993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.856900</td>\n",
       "      <td>1.480088</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818915</td>\n",
       "      <td>0.818792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.778200</td>\n",
       "      <td>1.520098</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819977</td>\n",
       "      <td>0.820083</td>\n",
       "      <td>0.819943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.711800</td>\n",
       "      <td>1.576715</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818741</td>\n",
       "      <td>0.818788</td>\n",
       "      <td>0.818761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>1.586503</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821092</td>\n",
       "      <td>0.820956</td>\n",
       "      <td>0.821007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.608133</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817985</td>\n",
       "      <td>0.817957</td>\n",
       "      <td>0.817660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.596100</td>\n",
       "      <td>1.587421</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825623</td>\n",
       "      <td>0.825671</td>\n",
       "      <td>0.825643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.575600</td>\n",
       "      <td>1.622034</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824758</td>\n",
       "      <td>0.824251</td>\n",
       "      <td>0.824373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.557500</td>\n",
       "      <td>1.636619</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821209</td>\n",
       "      <td>0.821086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.541300</td>\n",
       "      <td>1.644548</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823335</td>\n",
       "      <td>0.823335</td>\n",
       "      <td>0.823335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.526300</td>\n",
       "      <td>1.654187</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823354</td>\n",
       "      <td>0.823293</td>\n",
       "      <td>0.823319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.520900</td>\n",
       "      <td>1.653268</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825649</td>\n",
       "      <td>0.825587</td>\n",
       "      <td>0.825614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jovyan/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--accuracy/f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14 (last modified on Sat Oct 12 13:56:14 2024) since it couldn't be found locally at evaluate-metric--accuracy, or remotely on the Hugging Face Hub.\n",
      "[I 2025-03-29 06:09:56,464] Trial 68 finished with value: 0.8256137673341579 and parameters: {'learning_rate': 5.288130004639587e-05, 'weight_decay': 0.007, 'warmup_steps': 8, 'lambda_param': 0.6000000000000001, 'temperature': 7.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 69 with params: {'learning_rate': 5.776197337240459e-05, 'weight_decay': 0.007, 'warmup_steps': 14, 'lambda_param': 0.7000000000000001, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:08, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.459700</td>\n",
       "      <td>1.708988</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795997</td>\n",
       "      <td>0.795592</td>\n",
       "      <td>0.795690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.495700</td>\n",
       "      <td>1.502012</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805120</td>\n",
       "      <td>0.804812</td>\n",
       "      <td>0.804898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.129400</td>\n",
       "      <td>1.475093</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811910</td>\n",
       "      <td>0.811779</td>\n",
       "      <td>0.811828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.945100</td>\n",
       "      <td>1.525367</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.827523</td>\n",
       "      <td>0.826377</td>\n",
       "      <td>0.826555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.817100</td>\n",
       "      <td>1.489601</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.742200</td>\n",
       "      <td>1.528669</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816700</td>\n",
       "      <td>0.816747</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.676800</td>\n",
       "      <td>1.581920</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819901</td>\n",
       "      <td>0.819872</td>\n",
       "      <td>0.819886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.633900</td>\n",
       "      <td>1.597627</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823433</td>\n",
       "      <td>0.823209</td>\n",
       "      <td>0.823282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.591500</td>\n",
       "      <td>1.612518</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.563800</td>\n",
       "      <td>1.602166</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826773</td>\n",
       "      <td>0.826840</td>\n",
       "      <td>0.826796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.543800</td>\n",
       "      <td>1.640152</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823493</td>\n",
       "      <td>0.823167</td>\n",
       "      <td>0.823261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.525400</td>\n",
       "      <td>1.655311</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.509900</td>\n",
       "      <td>1.660743</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825649</td>\n",
       "      <td>0.825587</td>\n",
       "      <td>0.825614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.495200</td>\n",
       "      <td>1.669427</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825682</td>\n",
       "      <td>0.825545</td>\n",
       "      <td>0.825596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.490500</td>\n",
       "      <td>1.668564</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824516</td>\n",
       "      <td>0.824419</td>\n",
       "      <td>0.824458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 06:16:07,416] Trial 69 finished with value: 0.8244579440359041 and parameters: {'learning_rate': 5.776197337240459e-05, 'weight_decay': 0.007, 'warmup_steps': 14, 'lambda_param': 0.7000000000000001, 'temperature': 7.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 70 with params: {'learning_rate': 1.9019739852416414e-05, 'weight_decay': 0.001, 'warmup_steps': 5, 'lambda_param': 0.7000000000000001, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:01 < 02:01, 17.39 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.048800</td>\n",
       "      <td>2.244318</td>\n",
       "      <td>0.760321</td>\n",
       "      <td>0.760988</td>\n",
       "      <td>0.759756</td>\n",
       "      <td>0.759841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.270700</td>\n",
       "      <td>1.824009</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792454</td>\n",
       "      <td>0.792551</td>\n",
       "      <td>0.792418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.873000</td>\n",
       "      <td>1.695159</td>\n",
       "      <td>0.786697</td>\n",
       "      <td>0.786807</td>\n",
       "      <td>0.786415</td>\n",
       "      <td>0.786507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.640600</td>\n",
       "      <td>1.628679</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798680</td>\n",
       "      <td>0.797718</td>\n",
       "      <td>0.797858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.479800</td>\n",
       "      <td>1.570823</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805718</td>\n",
       "      <td>0.804559</td>\n",
       "      <td>0.804713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.357900</td>\n",
       "      <td>1.517002</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808487</td>\n",
       "      <td>0.808316</td>\n",
       "      <td>0.808375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.271600</td>\n",
       "      <td>1.503743</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811869</td>\n",
       "      <td>0.811947</td>\n",
       "      <td>0.811891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.192800</td>\n",
       "      <td>1.498816</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809585</td>\n",
       "      <td>0.809527</td>\n",
       "      <td>0.809552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.139100</td>\n",
       "      <td>1.484733</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807275</td>\n",
       "      <td>0.807275</td>\n",
       "      <td>0.807275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.095500</td>\n",
       "      <td>1.489991</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811060</td>\n",
       "      <td>0.810442</td>\n",
       "      <td>0.810570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 06:20:10,470] Trial 70 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 71 with params: {'learning_rate': 0.00011150517132664043, 'weight_decay': 0.0, 'warmup_steps': 6, 'lambda_param': 0.30000000000000004, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:03 < 02:01, 17.29 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.082400</td>\n",
       "      <td>1.551894</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812684</td>\n",
       "      <td>0.812368</td>\n",
       "      <td>0.811911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.118800</td>\n",
       "      <td>1.499836</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.819395</td>\n",
       "      <td>0.816947</td>\n",
       "      <td>0.817129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.823900</td>\n",
       "      <td>1.515887</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825737</td>\n",
       "      <td>0.825840</td>\n",
       "      <td>0.825680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.676600</td>\n",
       "      <td>1.582136</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.813711</td>\n",
       "      <td>0.809853</td>\n",
       "      <td>0.809968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.577300</td>\n",
       "      <td>1.633244</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820184</td>\n",
       "      <td>0.820209</td>\n",
       "      <td>0.819954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.514000</td>\n",
       "      <td>1.689271</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.809168</td>\n",
       "      <td>0.808906</td>\n",
       "      <td>0.808474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.452000</td>\n",
       "      <td>1.774781</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810731</td>\n",
       "      <td>0.810821</td>\n",
       "      <td>0.810750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.416900</td>\n",
       "      <td>1.786566</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816675</td>\n",
       "      <td>0.816241</td>\n",
       "      <td>0.816350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.380100</td>\n",
       "      <td>1.825347</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.814432</td>\n",
       "      <td>0.813663</td>\n",
       "      <td>0.813018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.356400</td>\n",
       "      <td>1.849505</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806144</td>\n",
       "      <td>0.806233</td>\n",
       "      <td>0.806162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 06:24:14,987] Trial 71 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 72 with params: {'learning_rate': 5.1133032728766223e-05, 'weight_decay': 0.007, 'warmup_steps': 6, 'lambda_param': 0.30000000000000004, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:08, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.520400</td>\n",
       "      <td>1.745180</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794885</td>\n",
       "      <td>0.794424</td>\n",
       "      <td>0.794528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.569800</td>\n",
       "      <td>1.529601</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.800865</td>\n",
       "      <td>0.800055</td>\n",
       "      <td>0.800190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.199700</td>\n",
       "      <td>1.482279</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811880</td>\n",
       "      <td>0.811821</td>\n",
       "      <td>0.811846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.006200</td>\n",
       "      <td>1.517542</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822783</td>\n",
       "      <td>0.821830</td>\n",
       "      <td>0.821993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.872700</td>\n",
       "      <td>1.477635</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817641</td>\n",
       "      <td>0.817746</td>\n",
       "      <td>0.817641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.792300</td>\n",
       "      <td>1.516745</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818915</td>\n",
       "      <td>0.818792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.725600</td>\n",
       "      <td>1.574198</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818741</td>\n",
       "      <td>0.818788</td>\n",
       "      <td>0.818761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.681100</td>\n",
       "      <td>1.581033</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822261</td>\n",
       "      <td>0.822083</td>\n",
       "      <td>0.822145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.638000</td>\n",
       "      <td>1.605787</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.608600</td>\n",
       "      <td>1.582627</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826772</td>\n",
       "      <td>0.826798</td>\n",
       "      <td>0.826784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.587900</td>\n",
       "      <td>1.615100</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822554</td>\n",
       "      <td>0.821914</td>\n",
       "      <td>0.822051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.570100</td>\n",
       "      <td>1.629369</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821209</td>\n",
       "      <td>0.821086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.553800</td>\n",
       "      <td>1.637703</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822196</td>\n",
       "      <td>0.822167</td>\n",
       "      <td>0.822180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.538600</td>\n",
       "      <td>1.647728</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825649</td>\n",
       "      <td>0.825587</td>\n",
       "      <td>0.825614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.532800</td>\n",
       "      <td>1.647092</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825649</td>\n",
       "      <td>0.825587</td>\n",
       "      <td>0.825614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 06:30:24,978] Trial 72 finished with value: 0.8256137673341579 and parameters: {'learning_rate': 5.1133032728766223e-05, 'weight_decay': 0.007, 'warmup_steps': 6, 'lambda_param': 0.30000000000000004, 'temperature': 7.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 73 with params: {'learning_rate': 4.3374804421380576e-05, 'weight_decay': 0.008, 'warmup_steps': 0, 'lambda_param': 0.30000000000000004, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 02:01 < 04:03, 17.29 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.605300</td>\n",
       "      <td>1.788512</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.797266</td>\n",
       "      <td>0.796676</td>\n",
       "      <td>0.796794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.670800</td>\n",
       "      <td>1.578169</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.797140</td>\n",
       "      <td>0.795213</td>\n",
       "      <td>0.795351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.300900</td>\n",
       "      <td>1.488418</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811859</td>\n",
       "      <td>0.811905</td>\n",
       "      <td>0.811878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.095200</td>\n",
       "      <td>1.511152</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813358</td>\n",
       "      <td>0.812737</td>\n",
       "      <td>0.812866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.955200</td>\n",
       "      <td>1.474094</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817597</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 06:32:27,639] Trial 73 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 74 with params: {'learning_rate': 9.354579012866187e-05, 'weight_decay': 0.008, 'warmup_steps': 4, 'lambda_param': 0.7000000000000001, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:04 < 02:02, 17.19 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.175400</td>\n",
       "      <td>1.585012</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815596</td>\n",
       "      <td>0.815621</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.212000</td>\n",
       "      <td>1.496431</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809782</td>\n",
       "      <td>0.809358</td>\n",
       "      <td>0.809464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.895800</td>\n",
       "      <td>1.510957</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822270</td>\n",
       "      <td>0.822377</td>\n",
       "      <td>0.822236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.740300</td>\n",
       "      <td>1.595570</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.819867</td>\n",
       "      <td>0.816862</td>\n",
       "      <td>0.817035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.634600</td>\n",
       "      <td>1.644177</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.818353</td>\n",
       "      <td>0.818083</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.569200</td>\n",
       "      <td>1.653128</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.817434</td>\n",
       "      <td>0.816999</td>\n",
       "      <td>0.816490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.506400</td>\n",
       "      <td>1.719910</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812032</td>\n",
       "      <td>0.811911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.469900</td>\n",
       "      <td>1.719381</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820017</td>\n",
       "      <td>0.819746</td>\n",
       "      <td>0.819829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.430600</td>\n",
       "      <td>1.771032</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.815891</td>\n",
       "      <td>0.814873</td>\n",
       "      <td>0.814141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.408500</td>\n",
       "      <td>1.786339</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810802</td>\n",
       "      <td>0.810906</td>\n",
       "      <td>0.810768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 06:36:33,445] Trial 74 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 75 with params: {'learning_rate': 5.9829333956504966e-05, 'weight_decay': 0.005, 'warmup_steps': 13, 'lambda_param': 0.2, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:09, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.438500</td>\n",
       "      <td>1.696884</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795997</td>\n",
       "      <td>0.795592</td>\n",
       "      <td>0.795690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.473500</td>\n",
       "      <td>1.495383</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.804004</td>\n",
       "      <td>0.803644</td>\n",
       "      <td>0.803738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.109700</td>\n",
       "      <td>1.472662</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811910</td>\n",
       "      <td>0.811779</td>\n",
       "      <td>0.811828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.928100</td>\n",
       "      <td>1.530250</td>\n",
       "      <td>0.827982</td>\n",
       "      <td>0.829269</td>\n",
       "      <td>0.827376</td>\n",
       "      <td>0.827582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.801900</td>\n",
       "      <td>1.496193</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818856</td>\n",
       "      <td>0.818957</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.728400</td>\n",
       "      <td>1.532853</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820184</td>\n",
       "      <td>0.820209</td>\n",
       "      <td>0.819954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.663400</td>\n",
       "      <td>1.585216</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.620500</td>\n",
       "      <td>1.602189</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822380</td>\n",
       "      <td>0.821998</td>\n",
       "      <td>0.822101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.578600</td>\n",
       "      <td>1.616435</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819186</td>\n",
       "      <td>0.819125</td>\n",
       "      <td>0.818806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.551500</td>\n",
       "      <td>1.608897</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.531500</td>\n",
       "      <td>1.648651</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822314</td>\n",
       "      <td>0.822040</td>\n",
       "      <td>0.822124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>1.663970</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816700</td>\n",
       "      <td>0.816747</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.497700</td>\n",
       "      <td>1.668515</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825623</td>\n",
       "      <td>0.825671</td>\n",
       "      <td>0.825643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.483000</td>\n",
       "      <td>1.676794</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825682</td>\n",
       "      <td>0.825545</td>\n",
       "      <td>0.825596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.478700</td>\n",
       "      <td>1.675606</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824516</td>\n",
       "      <td>0.824419</td>\n",
       "      <td>0.824458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 06:42:44,995] Trial 75 finished with value: 0.8244579440359041 and parameters: {'learning_rate': 5.9829333956504966e-05, 'weight_decay': 0.005, 'warmup_steps': 13, 'lambda_param': 0.2, 'temperature': 6.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 76 with params: {'learning_rate': 2.4333546860341735e-05, 'weight_decay': 0.005, 'warmup_steps': 4, 'lambda_param': 0.30000000000000004, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:07 < 02:03, 17.00 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.932600</td>\n",
       "      <td>2.057061</td>\n",
       "      <td>0.774083</td>\n",
       "      <td>0.774567</td>\n",
       "      <td>0.773607</td>\n",
       "      <td>0.773718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.076300</td>\n",
       "      <td>1.744299</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792359</td>\n",
       "      <td>0.792382</td>\n",
       "      <td>0.792370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.701500</td>\n",
       "      <td>1.610021</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.799351</td>\n",
       "      <td>0.799097</td>\n",
       "      <td>0.799172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.471300</td>\n",
       "      <td>1.577093</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.804952</td>\n",
       "      <td>0.803307</td>\n",
       "      <td>0.803465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.311100</td>\n",
       "      <td>1.515049</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814669</td>\n",
       "      <td>0.813821</td>\n",
       "      <td>0.813970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.194600</td>\n",
       "      <td>1.482825</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811910</td>\n",
       "      <td>0.811779</td>\n",
       "      <td>0.811828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.114600</td>\n",
       "      <td>1.483147</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806270</td>\n",
       "      <td>0.806359</td>\n",
       "      <td>0.806186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.043500</td>\n",
       "      <td>1.487179</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803830</td>\n",
       "      <td>0.803854</td>\n",
       "      <td>0.803841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.993100</td>\n",
       "      <td>1.484397</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809737</td>\n",
       "      <td>0.809617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.951800</td>\n",
       "      <td>1.493232</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815425</td>\n",
       "      <td>0.815157</td>\n",
       "      <td>0.815238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 06:46:53,671] Trial 76 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 77 with params: {'learning_rate': 4.753316387686598e-05, 'weight_decay': 0.007, 'warmup_steps': 4, 'lambda_param': 0.5, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:08, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.559300</td>\n",
       "      <td>1.764487</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794885</td>\n",
       "      <td>0.794424</td>\n",
       "      <td>0.794528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.614700</td>\n",
       "      <td>1.551103</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.803558</td>\n",
       "      <td>0.802223</td>\n",
       "      <td>0.802377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.243900</td>\n",
       "      <td>1.483976</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813017</td>\n",
       "      <td>0.812989</td>\n",
       "      <td>0.813002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.045000</td>\n",
       "      <td>1.513168</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819270</td>\n",
       "      <td>0.818410</td>\n",
       "      <td>0.818563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.908300</td>\n",
       "      <td>1.474082</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817612</td>\n",
       "      <td>0.817704</td>\n",
       "      <td>0.817632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>1.510372</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.756500</td>\n",
       "      <td>1.567732</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815348</td>\n",
       "      <td>0.815452</td>\n",
       "      <td>0.815347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.710300</td>\n",
       "      <td>1.566961</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818972</td>\n",
       "      <td>0.818536</td>\n",
       "      <td>0.818646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.666900</td>\n",
       "      <td>1.597602</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815691</td>\n",
       "      <td>0.815663</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.636600</td>\n",
       "      <td>1.572272</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825682</td>\n",
       "      <td>0.825545</td>\n",
       "      <td>0.825596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.615400</td>\n",
       "      <td>1.598428</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823655</td>\n",
       "      <td>0.823082</td>\n",
       "      <td>0.823212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.598100</td>\n",
       "      <td>1.613156</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818915</td>\n",
       "      <td>0.818792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.581500</td>\n",
       "      <td>1.622287</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823354</td>\n",
       "      <td>0.823293</td>\n",
       "      <td>0.823319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.565800</td>\n",
       "      <td>1.632933</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826852</td>\n",
       "      <td>0.826671</td>\n",
       "      <td>0.826734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.559200</td>\n",
       "      <td>1.632544</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826811</td>\n",
       "      <td>0.826713</td>\n",
       "      <td>0.826753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 06:53:04,712] Trial 77 finished with value: 0.8267526114341277 and parameters: {'learning_rate': 4.753316387686598e-05, 'weight_decay': 0.007, 'warmup_steps': 4, 'lambda_param': 0.5, 'temperature': 7.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 78 with params: {'learning_rate': 2.0050664717347798e-05, 'weight_decay': 0.007, 'warmup_steps': 0, 'lambda_param': 0.7000000000000001, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 02:02 < 04:04, 17.22 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.022200</td>\n",
       "      <td>2.199641</td>\n",
       "      <td>0.762615</td>\n",
       "      <td>0.763293</td>\n",
       "      <td>0.762051</td>\n",
       "      <td>0.762139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.225300</td>\n",
       "      <td>1.803446</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794705</td>\n",
       "      <td>0.794803</td>\n",
       "      <td>0.794703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.834900</td>\n",
       "      <td>1.676316</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791402</td>\n",
       "      <td>0.791004</td>\n",
       "      <td>0.791099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.603900</td>\n",
       "      <td>1.616002</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.802333</td>\n",
       "      <td>0.801097</td>\n",
       "      <td>0.801248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.443000</td>\n",
       "      <td>1.558649</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805718</td>\n",
       "      <td>0.804559</td>\n",
       "      <td>0.804713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 06:55:07,966] Trial 78 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 79 with params: {'learning_rate': 0.00010177804621038942, 'weight_decay': 0.007, 'warmup_steps': 6, 'lambda_param': 0.30000000000000004, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:07 < 02:03, 16.98 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.131400</td>\n",
       "      <td>1.566302</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815691</td>\n",
       "      <td>0.815663</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.166400</td>\n",
       "      <td>1.499518</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.813956</td>\n",
       "      <td>0.811148</td>\n",
       "      <td>0.811306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.859000</td>\n",
       "      <td>1.493815</td>\n",
       "      <td>0.827982</td>\n",
       "      <td>0.827946</td>\n",
       "      <td>0.828050</td>\n",
       "      <td>0.827959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.708500</td>\n",
       "      <td>1.564139</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.819666</td>\n",
       "      <td>0.815568</td>\n",
       "      <td>0.815698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.605700</td>\n",
       "      <td>1.612581</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.825104</td>\n",
       "      <td>0.824924</td>\n",
       "      <td>0.824536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.542100</td>\n",
       "      <td>1.638556</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.813006</td>\n",
       "      <td>0.812453</td>\n",
       "      <td>0.811891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.479200</td>\n",
       "      <td>1.725177</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811859</td>\n",
       "      <td>0.811905</td>\n",
       "      <td>0.811878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.445000</td>\n",
       "      <td>1.737262</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817786</td>\n",
       "      <td>0.817410</td>\n",
       "      <td>0.817511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.405800</td>\n",
       "      <td>1.792651</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.815304</td>\n",
       "      <td>0.814747</td>\n",
       "      <td>0.814185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.382700</td>\n",
       "      <td>1.796987</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806144</td>\n",
       "      <td>0.806233</td>\n",
       "      <td>0.806162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 06:59:16,925] Trial 79 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 80 with params: {'learning_rate': 4.55376183641086e-05, 'weight_decay': 0.007, 'warmup_steps': 2, 'lambda_param': 0.5, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.581400</td>\n",
       "      <td>1.775707</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.797266</td>\n",
       "      <td>0.796676</td>\n",
       "      <td>0.796794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.641100</td>\n",
       "      <td>1.564165</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.800512</td>\n",
       "      <td>0.798676</td>\n",
       "      <td>0.798823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.270500</td>\n",
       "      <td>1.485334</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814153</td>\n",
       "      <td>0.814200</td>\n",
       "      <td>0.814172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.068300</td>\n",
       "      <td>1.511792</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816858</td>\n",
       "      <td>0.816157</td>\n",
       "      <td>0.816296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>1.473731</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821044</td>\n",
       "      <td>0.821125</td>\n",
       "      <td>0.821067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.843300</td>\n",
       "      <td>1.506541</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813151</td>\n",
       "      <td>0.813242</td>\n",
       "      <td>0.813067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.775400</td>\n",
       "      <td>1.562114</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814326</td>\n",
       "      <td>0.814205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.727800</td>\n",
       "      <td>1.557970</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821197</td>\n",
       "      <td>0.820872</td>\n",
       "      <td>0.820965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.684200</td>\n",
       "      <td>1.590648</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817985</td>\n",
       "      <td>0.817957</td>\n",
       "      <td>0.817660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.653300</td>\n",
       "      <td>1.565774</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826852</td>\n",
       "      <td>0.826671</td>\n",
       "      <td>0.826734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.631800</td>\n",
       "      <td>1.589338</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823756</td>\n",
       "      <td>0.823040</td>\n",
       "      <td>0.823185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>1.603799</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819935</td>\n",
       "      <td>0.820041</td>\n",
       "      <td>0.819935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.598200</td>\n",
       "      <td>1.612917</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824516</td>\n",
       "      <td>0.824419</td>\n",
       "      <td>0.824458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.582100</td>\n",
       "      <td>1.624015</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826852</td>\n",
       "      <td>0.826671</td>\n",
       "      <td>0.826734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.575200</td>\n",
       "      <td>1.624080</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825682</td>\n",
       "      <td>0.825545</td>\n",
       "      <td>0.825596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 07:05:31,142] Trial 80 finished with value: 0.8255963283437546 and parameters: {'learning_rate': 4.55376183641086e-05, 'weight_decay': 0.007, 'warmup_steps': 2, 'lambda_param': 0.5, 'temperature': 6.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 81 with params: {'learning_rate': 4.0978781233050886e-05, 'weight_decay': 0.005, 'warmup_steps': 1, 'lambda_param': 0.6000000000000001, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:07, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.640200</td>\n",
       "      <td>1.804502</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794885</td>\n",
       "      <td>0.794424</td>\n",
       "      <td>0.794528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.708600</td>\n",
       "      <td>1.596230</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.794654</td>\n",
       "      <td>0.792961</td>\n",
       "      <td>0.793098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.338500</td>\n",
       "      <td>1.493788</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807401</td>\n",
       "      <td>0.807314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.128300</td>\n",
       "      <td>1.511215</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812259</td>\n",
       "      <td>0.811569</td>\n",
       "      <td>0.811704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.985600</td>\n",
       "      <td>1.475657</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817612</td>\n",
       "      <td>0.817704</td>\n",
       "      <td>0.817632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.893200</td>\n",
       "      <td>1.498717</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818856</td>\n",
       "      <td>0.818957</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.824500</td>\n",
       "      <td>1.548983</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814494</td>\n",
       "      <td>0.814494</td>\n",
       "      <td>0.814220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.773200</td>\n",
       "      <td>1.538921</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816546</td>\n",
       "      <td>0.816326</td>\n",
       "      <td>0.816397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.728500</td>\n",
       "      <td>1.572933</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.695800</td>\n",
       "      <td>1.552133</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818765</td>\n",
       "      <td>0.818704</td>\n",
       "      <td>0.818730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.673600</td>\n",
       "      <td>1.567810</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822554</td>\n",
       "      <td>0.821914</td>\n",
       "      <td>0.822051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.657600</td>\n",
       "      <td>1.582355</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818915</td>\n",
       "      <td>0.818792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.640300</td>\n",
       "      <td>1.591504</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818765</td>\n",
       "      <td>0.818704</td>\n",
       "      <td>0.818730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.623000</td>\n",
       "      <td>1.602646</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816603</td>\n",
       "      <td>0.816284</td>\n",
       "      <td>0.816375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.615600</td>\n",
       "      <td>1.603928</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817669</td>\n",
       "      <td>0.817494</td>\n",
       "      <td>0.817555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 07:11:40,752] Trial 81 finished with value: 0.8175547376579559 and parameters: {'learning_rate': 4.0978781233050886e-05, 'weight_decay': 0.005, 'warmup_steps': 1, 'lambda_param': 0.6000000000000001, 'temperature': 7.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 82 with params: {'learning_rate': 5.711389093170868e-05, 'weight_decay': 0.008, 'warmup_steps': 2, 'lambda_param': 0.5, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:07, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.451800</td>\n",
       "      <td>1.712198</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793775</td>\n",
       "      <td>0.793256</td>\n",
       "      <td>0.793365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.500300</td>\n",
       "      <td>1.504575</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805267</td>\n",
       "      <td>0.804728</td>\n",
       "      <td>0.804845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.135600</td>\n",
       "      <td>1.476628</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813041</td>\n",
       "      <td>0.812947</td>\n",
       "      <td>0.812985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.950900</td>\n",
       "      <td>1.529591</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.826603</td>\n",
       "      <td>0.825166</td>\n",
       "      <td>0.825356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.822300</td>\n",
       "      <td>1.489312</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818856</td>\n",
       "      <td>0.818957</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.746900</td>\n",
       "      <td>1.524795</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819977</td>\n",
       "      <td>0.820083</td>\n",
       "      <td>0.819943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.681800</td>\n",
       "      <td>1.581362</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.638500</td>\n",
       "      <td>1.597538</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820083</td>\n",
       "      <td>0.819704</td>\n",
       "      <td>0.819806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.596000</td>\n",
       "      <td>1.611858</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815799</td>\n",
       "      <td>0.815705</td>\n",
       "      <td>0.815365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.568300</td>\n",
       "      <td>1.599393</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825631</td>\n",
       "      <td>0.825714</td>\n",
       "      <td>0.825655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.548000</td>\n",
       "      <td>1.637507</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825865</td>\n",
       "      <td>0.825419</td>\n",
       "      <td>0.825533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.529600</td>\n",
       "      <td>1.652111</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.514300</td>\n",
       "      <td>1.657294</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823354</td>\n",
       "      <td>0.823293</td>\n",
       "      <td>0.823319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.499300</td>\n",
       "      <td>1.666262</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826811</td>\n",
       "      <td>0.826713</td>\n",
       "      <td>0.826753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.494800</td>\n",
       "      <td>1.664931</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825682</td>\n",
       "      <td>0.825545</td>\n",
       "      <td>0.825596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 07:17:49,944] Trial 82 finished with value: 0.8255963283437546 and parameters: {'learning_rate': 5.711389093170868e-05, 'weight_decay': 0.008, 'warmup_steps': 2, 'lambda_param': 0.5, 'temperature': 5.5}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 83 with params: {'learning_rate': 2.3043021487289137e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 11, 'lambda_param': 0.6000000000000001, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:04 < 02:02, 17.19 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.965100</td>\n",
       "      <td>2.100938</td>\n",
       "      <td>0.774083</td>\n",
       "      <td>0.774688</td>\n",
       "      <td>0.773564</td>\n",
       "      <td>0.773675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.120200</td>\n",
       "      <td>1.760385</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.795887</td>\n",
       "      <td>0.795833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.740300</td>\n",
       "      <td>1.628387</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.799409</td>\n",
       "      <td>0.799055</td>\n",
       "      <td>0.799147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.509300</td>\n",
       "      <td>1.586274</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.803715</td>\n",
       "      <td>0.802181</td>\n",
       "      <td>0.802336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.348300</td>\n",
       "      <td>1.525536</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813462</td>\n",
       "      <td>0.812695</td>\n",
       "      <td>0.812837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>1.487974</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808451</td>\n",
       "      <td>0.808359</td>\n",
       "      <td>0.808395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.148100</td>\n",
       "      <td>1.485290</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806270</td>\n",
       "      <td>0.806359</td>\n",
       "      <td>0.806186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.075200</td>\n",
       "      <td>1.487578</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.804977</td>\n",
       "      <td>0.805022</td>\n",
       "      <td>0.804996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.024100</td>\n",
       "      <td>1.482174</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812032</td>\n",
       "      <td>0.811911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.982300</td>\n",
       "      <td>1.489975</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814377</td>\n",
       "      <td>0.813947</td>\n",
       "      <td>0.814055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 07:21:56,115] Trial 83 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 84 with params: {'learning_rate': 6.225359863207699e-05, 'weight_decay': 0.01, 'warmup_steps': 3, 'lambda_param': 0.5, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:17, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.403000</td>\n",
       "      <td>1.680715</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.799409</td>\n",
       "      <td>0.799055</td>\n",
       "      <td>0.799147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.446300</td>\n",
       "      <td>1.487781</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.804004</td>\n",
       "      <td>0.803644</td>\n",
       "      <td>0.803738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.087800</td>\n",
       "      <td>1.470281</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814206</td>\n",
       "      <td>0.814073</td>\n",
       "      <td>0.814122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.909700</td>\n",
       "      <td>1.539558</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.827161</td>\n",
       "      <td>0.825040</td>\n",
       "      <td>0.825243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.785300</td>\n",
       "      <td>1.505474</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819977</td>\n",
       "      <td>0.820083</td>\n",
       "      <td>0.819943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.713200</td>\n",
       "      <td>1.532899</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820101</td>\n",
       "      <td>0.820167</td>\n",
       "      <td>0.819952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.648800</td>\n",
       "      <td>1.597291</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.606100</td>\n",
       "      <td>1.614076</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820162</td>\n",
       "      <td>0.819662</td>\n",
       "      <td>0.819781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.564800</td>\n",
       "      <td>1.625202</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820390</td>\n",
       "      <td>0.820293</td>\n",
       "      <td>0.819952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.538500</td>\n",
       "      <td>1.618982</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.518200</td>\n",
       "      <td>1.662655</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822261</td>\n",
       "      <td>0.822083</td>\n",
       "      <td>0.822145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.499500</td>\n",
       "      <td>1.677568</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815691</td>\n",
       "      <td>0.815663</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.484900</td>\n",
       "      <td>1.679344</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824478</td>\n",
       "      <td>0.824503</td>\n",
       "      <td>0.824489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.470100</td>\n",
       "      <td>1.687739</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823387</td>\n",
       "      <td>0.823251</td>\n",
       "      <td>0.823302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.466300</td>\n",
       "      <td>1.685854</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823387</td>\n",
       "      <td>0.823251</td>\n",
       "      <td>0.823302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 07:28:15,547] Trial 84 finished with value: 0.823301543190383 and parameters: {'learning_rate': 6.225359863207699e-05, 'weight_decay': 0.01, 'warmup_steps': 3, 'lambda_param': 0.5, 'temperature': 5.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 85 with params: {'learning_rate': 6.39995377037567e-05, 'weight_decay': 0.007, 'warmup_steps': 7, 'lambda_param': 0.4, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:18, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.392400</td>\n",
       "      <td>1.669903</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798138</td>\n",
       "      <td>0.798013</td>\n",
       "      <td>0.798059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.429600</td>\n",
       "      <td>1.482578</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805066</td>\n",
       "      <td>0.804854</td>\n",
       "      <td>0.804922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.072900</td>\n",
       "      <td>1.469148</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816501</td>\n",
       "      <td>0.816368</td>\n",
       "      <td>0.816417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.896800</td>\n",
       "      <td>1.542256</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.828421</td>\n",
       "      <td>0.826166</td>\n",
       "      <td>0.826372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.773800</td>\n",
       "      <td>1.509087</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821209</td>\n",
       "      <td>0.821086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.702600</td>\n",
       "      <td>1.537112</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821377</td>\n",
       "      <td>0.821377</td>\n",
       "      <td>0.821101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.638100</td>\n",
       "      <td>1.601884</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818765</td>\n",
       "      <td>0.818704</td>\n",
       "      <td>0.818730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.596000</td>\n",
       "      <td>1.619634</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820162</td>\n",
       "      <td>0.819662</td>\n",
       "      <td>0.819781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>1.631596</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.820336</td>\n",
       "      <td>0.819948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.529000</td>\n",
       "      <td>1.625702</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.508800</td>\n",
       "      <td>1.670602</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819926</td>\n",
       "      <td>0.819830</td>\n",
       "      <td>0.819869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>1.685433</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815691</td>\n",
       "      <td>0.815663</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.475500</td>\n",
       "      <td>1.686976</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824478</td>\n",
       "      <td>0.824503</td>\n",
       "      <td>0.824489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.460700</td>\n",
       "      <td>1.694628</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823387</td>\n",
       "      <td>0.823251</td>\n",
       "      <td>0.823302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.457200</td>\n",
       "      <td>1.692494</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825649</td>\n",
       "      <td>0.825587</td>\n",
       "      <td>0.825614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 07:34:35,733] Trial 85 finished with value: 0.8256137673341579 and parameters: {'learning_rate': 6.39995377037567e-05, 'weight_decay': 0.007, 'warmup_steps': 7, 'lambda_param': 0.4, 'temperature': 5.5}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 86 with params: {'learning_rate': 7.37531771471803e-05, 'weight_decay': 0.006, 'warmup_steps': 0, 'lambda_param': 0.4, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:11 < 02:05, 16.75 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.297200</td>\n",
       "      <td>1.629826</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809565</td>\n",
       "      <td>0.809611</td>\n",
       "      <td>0.809584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.344700</td>\n",
       "      <td>1.470178</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807362</td>\n",
       "      <td>0.807148</td>\n",
       "      <td>0.807217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.001600</td>\n",
       "      <td>1.463001</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817612</td>\n",
       "      <td>0.817704</td>\n",
       "      <td>0.817632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.835100</td>\n",
       "      <td>1.564903</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.825291</td>\n",
       "      <td>0.822661</td>\n",
       "      <td>0.822858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.719000</td>\n",
       "      <td>1.543746</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820101</td>\n",
       "      <td>0.820167</td>\n",
       "      <td>0.819952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.650300</td>\n",
       "      <td>1.571406</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814711</td>\n",
       "      <td>0.814579</td>\n",
       "      <td>0.814216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.587100</td>\n",
       "      <td>1.641222</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814250</td>\n",
       "      <td>0.814031</td>\n",
       "      <td>0.814102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.547700</td>\n",
       "      <td>1.652279</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815657</td>\n",
       "      <td>0.815031</td>\n",
       "      <td>0.815163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.507100</td>\n",
       "      <td>1.684139</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.816057</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.815355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.482200</td>\n",
       "      <td>1.675113</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816456</td>\n",
       "      <td>0.816536</td>\n",
       "      <td>0.816479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 07:38:48,472] Trial 86 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 87 with params: {'learning_rate': 4.6539544844268765e-05, 'weight_decay': 0.007, 'warmup_steps': 2, 'lambda_param': 0.5, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:10, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.569100</td>\n",
       "      <td>1.769944</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.796074</td>\n",
       "      <td>0.795550</td>\n",
       "      <td>0.795661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.627300</td>\n",
       "      <td>1.557476</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.800338</td>\n",
       "      <td>0.798718</td>\n",
       "      <td>0.798867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.256900</td>\n",
       "      <td>1.484533</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813007</td>\n",
       "      <td>0.813031</td>\n",
       "      <td>0.813018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.056400</td>\n",
       "      <td>1.512564</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.818062</td>\n",
       "      <td>0.817283</td>\n",
       "      <td>0.817430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.918900</td>\n",
       "      <td>1.473955</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.818831</td>\n",
       "      <td>0.818773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.833500</td>\n",
       "      <td>1.508472</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.765800</td>\n",
       "      <td>1.564695</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814326</td>\n",
       "      <td>0.814205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.718900</td>\n",
       "      <td>1.562494</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820083</td>\n",
       "      <td>0.819704</td>\n",
       "      <td>0.819806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.675400</td>\n",
       "      <td>1.594252</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815691</td>\n",
       "      <td>0.815663</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.644800</td>\n",
       "      <td>1.569012</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826852</td>\n",
       "      <td>0.826671</td>\n",
       "      <td>0.826734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.623500</td>\n",
       "      <td>1.593934</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821456</td>\n",
       "      <td>0.820746</td>\n",
       "      <td>0.820889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.606400</td>\n",
       "      <td>1.608620</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821209</td>\n",
       "      <td>0.821086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.589800</td>\n",
       "      <td>1.617630</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823354</td>\n",
       "      <td>0.823293</td>\n",
       "      <td>0.823319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.573800</td>\n",
       "      <td>1.628525</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826852</td>\n",
       "      <td>0.826671</td>\n",
       "      <td>0.826734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.567100</td>\n",
       "      <td>1.628300</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825682</td>\n",
       "      <td>0.825545</td>\n",
       "      <td>0.825596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 07:45:01,550] Trial 87 finished with value: 0.8255963283437546 and parameters: {'learning_rate': 4.6539544844268765e-05, 'weight_decay': 0.007, 'warmup_steps': 2, 'lambda_param': 0.5, 'temperature': 5.5}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 88 with params: {'learning_rate': 8.939389629581151e-05, 'weight_decay': 0.007, 'warmup_steps': 3, 'lambda_param': 0.6000000000000001, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:06 < 02:03, 17.10 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.197400</td>\n",
       "      <td>1.596941</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814269</td>\n",
       "      <td>0.814368</td>\n",
       "      <td>0.814211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.233900</td>\n",
       "      <td>1.490361</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812080</td>\n",
       "      <td>0.811653</td>\n",
       "      <td>0.811759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.914200</td>\n",
       "      <td>1.506668</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821212</td>\n",
       "      <td>0.821293</td>\n",
       "      <td>0.821097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.756900</td>\n",
       "      <td>1.602089</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.820124</td>\n",
       "      <td>0.816820</td>\n",
       "      <td>0.816984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.649700</td>\n",
       "      <td>1.636750</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820390</td>\n",
       "      <td>0.820293</td>\n",
       "      <td>0.819952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.583800</td>\n",
       "      <td>1.641056</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.818502</td>\n",
       "      <td>0.818125</td>\n",
       "      <td>0.817641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.521600</td>\n",
       "      <td>1.705021</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809682</td>\n",
       "      <td>0.809779</td>\n",
       "      <td>0.809624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.483800</td>\n",
       "      <td>1.706805</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818900</td>\n",
       "      <td>0.818578</td>\n",
       "      <td>0.818670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.444400</td>\n",
       "      <td>1.746377</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.817151</td>\n",
       "      <td>0.816042</td>\n",
       "      <td>0.815279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.421800</td>\n",
       "      <td>1.766512</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813096</td>\n",
       "      <td>0.813200</td>\n",
       "      <td>0.813061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 07:49:08,763] Trial 88 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 89 with params: {'learning_rate': 4.155106814683351e-05, 'weight_decay': 0.007, 'warmup_steps': 7, 'lambda_param': 0.30000000000000004, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:09, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.638800</td>\n",
       "      <td>1.800937</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.796074</td>\n",
       "      <td>0.795550</td>\n",
       "      <td>0.795661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.701700</td>\n",
       "      <td>1.592440</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.795724</td>\n",
       "      <td>0.794129</td>\n",
       "      <td>0.794270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.330300</td>\n",
       "      <td>1.492045</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808438</td>\n",
       "      <td>0.808527</td>\n",
       "      <td>0.808456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.120500</td>\n",
       "      <td>1.509287</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811060</td>\n",
       "      <td>0.810442</td>\n",
       "      <td>0.810570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.978100</td>\n",
       "      <td>1.474445</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817612</td>\n",
       "      <td>0.817704</td>\n",
       "      <td>0.817632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.886300</td>\n",
       "      <td>1.499032</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.817600</td>\n",
       "      <td>1.552233</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813301</td>\n",
       "      <td>0.813326</td>\n",
       "      <td>0.813073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.766900</td>\n",
       "      <td>1.540570</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816546</td>\n",
       "      <td>0.816326</td>\n",
       "      <td>0.816397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.722400</td>\n",
       "      <td>1.576254</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817985</td>\n",
       "      <td>0.817957</td>\n",
       "      <td>0.817660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.689900</td>\n",
       "      <td>1.554185</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818765</td>\n",
       "      <td>0.818704</td>\n",
       "      <td>0.818730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.667800</td>\n",
       "      <td>1.570039</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820162</td>\n",
       "      <td>0.819662</td>\n",
       "      <td>0.819781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.651600</td>\n",
       "      <td>1.585498</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818856</td>\n",
       "      <td>0.818957</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.634500</td>\n",
       "      <td>1.594705</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.617300</td>\n",
       "      <td>1.605505</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819965</td>\n",
       "      <td>0.819788</td>\n",
       "      <td>0.819850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.609900</td>\n",
       "      <td>1.607175</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817631</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 07:55:21,032] Trial 89 finished with value: 0.8175739418412338 and parameters: {'learning_rate': 4.155106814683351e-05, 'weight_decay': 0.007, 'warmup_steps': 7, 'lambda_param': 0.30000000000000004, 'temperature': 7.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 90 with params: {'learning_rate': 6.142202590452693e-05, 'weight_decay': 0.008, 'warmup_steps': 8, 'lambda_param': 0.0, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:06, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.417600</td>\n",
       "      <td>1.686678</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.797183</td>\n",
       "      <td>0.796718</td>\n",
       "      <td>0.796824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.455800</td>\n",
       "      <td>1.490049</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805187</td>\n",
       "      <td>0.804770</td>\n",
       "      <td>0.804872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.095000</td>\n",
       "      <td>1.471593</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811910</td>\n",
       "      <td>0.811779</td>\n",
       "      <td>0.811828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.915700</td>\n",
       "      <td>1.535391</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.828213</td>\n",
       "      <td>0.826208</td>\n",
       "      <td>0.826413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.790700</td>\n",
       "      <td>1.501442</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821150</td>\n",
       "      <td>0.821251</td>\n",
       "      <td>0.821092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.718300</td>\n",
       "      <td>1.533630</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821377</td>\n",
       "      <td>0.821377</td>\n",
       "      <td>0.821101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.653500</td>\n",
       "      <td>1.589901</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.610800</td>\n",
       "      <td>1.607838</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821270</td>\n",
       "      <td>0.820830</td>\n",
       "      <td>0.820942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.569300</td>\n",
       "      <td>1.620875</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820390</td>\n",
       "      <td>0.820293</td>\n",
       "      <td>0.819952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.542600</td>\n",
       "      <td>1.614677</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822196</td>\n",
       "      <td>0.822167</td>\n",
       "      <td>0.822180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.522500</td>\n",
       "      <td>1.656786</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822261</td>\n",
       "      <td>0.822083</td>\n",
       "      <td>0.822145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.503900</td>\n",
       "      <td>1.672299</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817890</td>\n",
       "      <td>0.817915</td>\n",
       "      <td>0.817660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.489000</td>\n",
       "      <td>1.675454</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825623</td>\n",
       "      <td>0.825671</td>\n",
       "      <td>0.825643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.474200</td>\n",
       "      <td>1.683421</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825682</td>\n",
       "      <td>0.825545</td>\n",
       "      <td>0.825596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.470300</td>\n",
       "      <td>1.681942</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824516</td>\n",
       "      <td>0.824419</td>\n",
       "      <td>0.824458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 08:01:29,237] Trial 90 finished with value: 0.8244579440359041 and parameters: {'learning_rate': 6.142202590452693e-05, 'weight_decay': 0.008, 'warmup_steps': 8, 'lambda_param': 0.0, 'temperature': 4.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 91 with params: {'learning_rate': 3.992873798941882e-05, 'weight_decay': 0.007, 'warmup_steps': 2, 'lambda_param': 0.5, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.656000</td>\n",
       "      <td>1.812441</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792587</td>\n",
       "      <td>0.792130</td>\n",
       "      <td>0.792232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.726200</td>\n",
       "      <td>1.604275</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.794654</td>\n",
       "      <td>0.792961</td>\n",
       "      <td>0.793098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.356100</td>\n",
       "      <td>1.497048</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807281</td>\n",
       "      <td>0.807359</td>\n",
       "      <td>0.807303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.144000</td>\n",
       "      <td>1.511758</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812259</td>\n",
       "      <td>0.811569</td>\n",
       "      <td>0.811704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.476001</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816478</td>\n",
       "      <td>0.816578</td>\n",
       "      <td>0.816490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.906300</td>\n",
       "      <td>1.495912</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819977</td>\n",
       "      <td>0.820083</td>\n",
       "      <td>0.819943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.837400</td>\n",
       "      <td>1.544939</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814406</td>\n",
       "      <td>0.814452</td>\n",
       "      <td>0.814219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.785000</td>\n",
       "      <td>1.534059</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.818620</td>\n",
       "      <td>0.818692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.567282</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.706800</td>\n",
       "      <td>1.548522</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818765</td>\n",
       "      <td>0.818704</td>\n",
       "      <td>0.818730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.684400</td>\n",
       "      <td>1.562202</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822460</td>\n",
       "      <td>0.821956</td>\n",
       "      <td>0.822077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.668400</td>\n",
       "      <td>1.577103</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817641</td>\n",
       "      <td>0.817746</td>\n",
       "      <td>0.817641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.651100</td>\n",
       "      <td>1.585638</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818741</td>\n",
       "      <td>0.818788</td>\n",
       "      <td>0.818761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.633500</td>\n",
       "      <td>1.596569</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816546</td>\n",
       "      <td>0.816326</td>\n",
       "      <td>0.816397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.625800</td>\n",
       "      <td>1.598279</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818796</td>\n",
       "      <td>0.818662</td>\n",
       "      <td>0.818712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 08:07:43,946] Trial 91 finished with value: 0.8187119728836396 and parameters: {'learning_rate': 3.992873798941882e-05, 'weight_decay': 0.007, 'warmup_steps': 2, 'lambda_param': 0.5, 'temperature': 5.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 92 with params: {'learning_rate': 0.00038371788124985846, 'weight_decay': 0.003, 'warmup_steps': 43, 'lambda_param': 0.9, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 02:01 < 04:04, 17.25 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.619100</td>\n",
       "      <td>1.468707</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.801683</td>\n",
       "      <td>0.801770</td>\n",
       "      <td>0.801599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.739000</td>\n",
       "      <td>1.815433</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807275</td>\n",
       "      <td>0.807275</td>\n",
       "      <td>0.807275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.507300</td>\n",
       "      <td>1.872901</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809818</td>\n",
       "      <td>0.809864</td>\n",
       "      <td>0.809632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.375300</td>\n",
       "      <td>1.925328</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805530</td>\n",
       "      <td>0.805401</td>\n",
       "      <td>0.805042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.299400</td>\n",
       "      <td>2.010037</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809585</td>\n",
       "      <td>0.809527</td>\n",
       "      <td>0.809552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 08:09:47,162] Trial 92 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 93 with params: {'learning_rate': 3.0725128262141896e-05, 'weight_decay': 0.007, 'warmup_steps': 3, 'lambda_param': 0.5, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:04 < 02:02, 17.22 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.805800</td>\n",
       "      <td>1.915222</td>\n",
       "      <td>0.783257</td>\n",
       "      <td>0.783473</td>\n",
       "      <td>0.782910</td>\n",
       "      <td>0.783017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.907100</td>\n",
       "      <td>1.675085</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794967</td>\n",
       "      <td>0.794382</td>\n",
       "      <td>0.794497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.536900</td>\n",
       "      <td>1.544749</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806144</td>\n",
       "      <td>0.806233</td>\n",
       "      <td>0.806162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.311900</td>\n",
       "      <td>1.539647</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810472</td>\n",
       "      <td>0.809106</td>\n",
       "      <td>0.809271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.156700</td>\n",
       "      <td>1.479654</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810783</td>\n",
       "      <td>0.810611</td>\n",
       "      <td>0.810670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.050300</td>\n",
       "      <td>1.469167</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814153</td>\n",
       "      <td>0.814200</td>\n",
       "      <td>0.814172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.976600</td>\n",
       "      <td>1.492795</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808632</td>\n",
       "      <td>0.808695</td>\n",
       "      <td>0.808484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.914000</td>\n",
       "      <td>1.494526</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813041</td>\n",
       "      <td>0.812947</td>\n",
       "      <td>0.812985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.866100</td>\n",
       "      <td>1.508781</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815514</td>\n",
       "      <td>0.815578</td>\n",
       "      <td>0.815365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.828000</td>\n",
       "      <td>1.511360</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815425</td>\n",
       "      <td>0.815157</td>\n",
       "      <td>0.815238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 08:13:52,750] Trial 93 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 94 with params: {'learning_rate': 6.128220142314674e-05, 'weight_decay': 0.007, 'warmup_steps': 10, 'lambda_param': 0.5, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:08, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.421300</td>\n",
       "      <td>1.687904</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.797183</td>\n",
       "      <td>0.796718</td>\n",
       "      <td>0.796824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.457700</td>\n",
       "      <td>1.490467</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805187</td>\n",
       "      <td>0.804770</td>\n",
       "      <td>0.804872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.096400</td>\n",
       "      <td>1.471673</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811910</td>\n",
       "      <td>0.811779</td>\n",
       "      <td>0.811828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.916700</td>\n",
       "      <td>1.534281</td>\n",
       "      <td>0.827982</td>\n",
       "      <td>0.829269</td>\n",
       "      <td>0.827376</td>\n",
       "      <td>0.827582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.791700</td>\n",
       "      <td>1.501329</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818856</td>\n",
       "      <td>0.818957</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.719200</td>\n",
       "      <td>1.534172</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822575</td>\n",
       "      <td>0.822546</td>\n",
       "      <td>0.822247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.654300</td>\n",
       "      <td>1.588726</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.611600</td>\n",
       "      <td>1.606837</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821270</td>\n",
       "      <td>0.820830</td>\n",
       "      <td>0.820942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.570100</td>\n",
       "      <td>1.620381</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820390</td>\n",
       "      <td>0.820293</td>\n",
       "      <td>0.819952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.543300</td>\n",
       "      <td>1.614210</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822196</td>\n",
       "      <td>0.822167</td>\n",
       "      <td>0.822180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.523300</td>\n",
       "      <td>1.655775</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822261</td>\n",
       "      <td>0.822083</td>\n",
       "      <td>0.822145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.504700</td>\n",
       "      <td>1.671118</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817890</td>\n",
       "      <td>0.817915</td>\n",
       "      <td>0.817660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.489700</td>\n",
       "      <td>1.674594</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825623</td>\n",
       "      <td>0.825671</td>\n",
       "      <td>0.825643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.474900</td>\n",
       "      <td>1.682811</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824556</td>\n",
       "      <td>0.824377</td>\n",
       "      <td>0.824439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.471000</td>\n",
       "      <td>1.681198</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824516</td>\n",
       "      <td>0.824419</td>\n",
       "      <td>0.824458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 08:20:03,123] Trial 94 finished with value: 0.8244579440359041 and parameters: {'learning_rate': 6.128220142314674e-05, 'weight_decay': 0.007, 'warmup_steps': 10, 'lambda_param': 0.5, 'temperature': 5.5}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 95 with params: {'learning_rate': 2.0235786228099924e-05, 'weight_decay': 0.003, 'warmup_steps': 35, 'lambda_param': 0.30000000000000004, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:06 < 02:03, 17.04 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.040200</td>\n",
       "      <td>2.213183</td>\n",
       "      <td>0.762615</td>\n",
       "      <td>0.763293</td>\n",
       "      <td>0.762051</td>\n",
       "      <td>0.762139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.231200</td>\n",
       "      <td>1.804215</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794747</td>\n",
       "      <td>0.794845</td>\n",
       "      <td>0.794712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.833400</td>\n",
       "      <td>1.675681</td>\n",
       "      <td>0.790138</td>\n",
       "      <td>0.790221</td>\n",
       "      <td>0.789877</td>\n",
       "      <td>0.789965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.600500</td>\n",
       "      <td>1.612577</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.800029</td>\n",
       "      <td>0.798802</td>\n",
       "      <td>0.798950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.438600</td>\n",
       "      <td>1.555229</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806801</td>\n",
       "      <td>0.805727</td>\n",
       "      <td>0.805880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.316700</td>\n",
       "      <td>1.505264</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811910</td>\n",
       "      <td>0.811779</td>\n",
       "      <td>0.811828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.230900</td>\n",
       "      <td>1.494940</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.804022</td>\n",
       "      <td>0.803886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.153500</td>\n",
       "      <td>1.492118</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808451</td>\n",
       "      <td>0.808359</td>\n",
       "      <td>0.808395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.100500</td>\n",
       "      <td>1.480692</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806144</td>\n",
       "      <td>0.806233</td>\n",
       "      <td>0.806162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.057700</td>\n",
       "      <td>1.485487</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812163</td>\n",
       "      <td>0.811611</td>\n",
       "      <td>0.811732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 08:24:11,190] Trial 95 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 96 with params: {'learning_rate': 4.2762128019163814e-05, 'weight_decay': 0.008, 'warmup_steps': 4, 'lambda_param': 0.5, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 02:02 < 04:06, 17.11 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.619400</td>\n",
       "      <td>1.792682</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.797183</td>\n",
       "      <td>0.796718</td>\n",
       "      <td>0.796824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.682000</td>\n",
       "      <td>1.583147</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.795895</td>\n",
       "      <td>0.794087</td>\n",
       "      <td>0.794224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.311000</td>\n",
       "      <td>1.489393</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810715</td>\n",
       "      <td>0.810779</td>\n",
       "      <td>0.810738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.103600</td>\n",
       "      <td>1.509974</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813358</td>\n",
       "      <td>0.812737</td>\n",
       "      <td>0.812866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.962700</td>\n",
       "      <td>1.474243</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817597</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 08:26:15,379] Trial 96 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 97 with params: {'learning_rate': 3.5631162174406863e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 0, 'lambda_param': 0.6000000000000001, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:08, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.717000</td>\n",
       "      <td>1.850968</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791477</td>\n",
       "      <td>0.790962</td>\n",
       "      <td>0.791069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.801900</td>\n",
       "      <td>1.637876</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.792521</td>\n",
       "      <td>0.790625</td>\n",
       "      <td>0.790752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.432700</td>\n",
       "      <td>1.515974</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805149</td>\n",
       "      <td>0.805029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.214400</td>\n",
       "      <td>1.521315</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.809103</td>\n",
       "      <td>0.808022</td>\n",
       "      <td>0.808177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.065200</td>\n",
       "      <td>1.476221</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816470</td>\n",
       "      <td>0.816410</td>\n",
       "      <td>0.816436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.966200</td>\n",
       "      <td>1.481581</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.895900</td>\n",
       "      <td>1.520633</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814406</td>\n",
       "      <td>0.814452</td>\n",
       "      <td>0.814219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.839000</td>\n",
       "      <td>1.514855</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811954</td>\n",
       "      <td>0.811737</td>\n",
       "      <td>0.811807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.792600</td>\n",
       "      <td>1.538190</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.757200</td>\n",
       "      <td>1.529584</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817631</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.733700</td>\n",
       "      <td>1.536651</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821270</td>\n",
       "      <td>0.820830</td>\n",
       "      <td>0.820942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.717400</td>\n",
       "      <td>1.549555</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814185</td>\n",
       "      <td>0.814284</td>\n",
       "      <td>0.814196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.555300</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816447</td>\n",
       "      <td>0.816494</td>\n",
       "      <td>0.816466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.681300</td>\n",
       "      <td>1.566929</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816470</td>\n",
       "      <td>0.816410</td>\n",
       "      <td>0.816436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.672900</td>\n",
       "      <td>1.568776</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815312</td>\n",
       "      <td>0.815284</td>\n",
       "      <td>0.815297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 08:32:25,508] Trial 97 finished with value: 0.8152967721140121 and parameters: {'learning_rate': 3.5631162174406863e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 0, 'lambda_param': 0.6000000000000001, 'temperature': 6.5}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 98 with params: {'learning_rate': 0.0001425495875889341, 'weight_decay': 0.01, 'warmup_steps': 10, 'lambda_param': 0.2, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:06 < 02:03, 17.05 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.962100</td>\n",
       "      <td>1.488798</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.803337</td>\n",
       "      <td>0.802275</td>\n",
       "      <td>0.801511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.008300</td>\n",
       "      <td>1.487937</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.816486</td>\n",
       "      <td>0.814779</td>\n",
       "      <td>0.814958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.739500</td>\n",
       "      <td>1.588777</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819302</td>\n",
       "      <td>0.819167</td>\n",
       "      <td>0.818804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.598200</td>\n",
       "      <td>1.588491</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813708</td>\n",
       "      <td>0.812611</td>\n",
       "      <td>0.812772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.505300</td>\n",
       "      <td>1.718367</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.813006</td>\n",
       "      <td>0.812453</td>\n",
       "      <td>0.811891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.439900</td>\n",
       "      <td>1.793903</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.808780</td>\n",
       "      <td>0.807948</td>\n",
       "      <td>0.807275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.381800</td>\n",
       "      <td>1.944325</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.799629</td>\n",
       "      <td>0.799602</td>\n",
       "      <td>0.799312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.345200</td>\n",
       "      <td>1.911878</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807566</td>\n",
       "      <td>0.807022</td>\n",
       "      <td>0.807141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.312800</td>\n",
       "      <td>1.928295</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.811740</td>\n",
       "      <td>0.810369</td>\n",
       "      <td>0.809512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.292900</td>\n",
       "      <td>1.953779</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.800423</td>\n",
       "      <td>0.800518</td>\n",
       "      <td>0.800432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 08:36:33,427] Trial 98 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 99 with params: {'learning_rate': 3.796915148861297e-05, 'weight_decay': 0.002, 'warmup_steps': 13, 'lambda_param': 0.2, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 02:03 < 04:06, 17.05 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.695400</td>\n",
       "      <td>1.830900</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791477</td>\n",
       "      <td>0.790962</td>\n",
       "      <td>0.791069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.764000</td>\n",
       "      <td>1.621585</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.792521</td>\n",
       "      <td>0.790625</td>\n",
       "      <td>0.790752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.391800</td>\n",
       "      <td>1.504078</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807401</td>\n",
       "      <td>0.807314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.175900</td>\n",
       "      <td>1.512359</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813462</td>\n",
       "      <td>0.812695</td>\n",
       "      <td>0.812837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.028900</td>\n",
       "      <td>1.474977</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816456</td>\n",
       "      <td>0.816536</td>\n",
       "      <td>0.816479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 08:38:38,164] Trial 99 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 with params: {'learning_rate': 0.0004540061556428691, 'weight_decay': 0.003, 'warmup_steps': 24, 'lambda_param': 1.0, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:07 < 02:03, 17.03 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.542200</td>\n",
       "      <td>1.430372</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814406</td>\n",
       "      <td>0.814452</td>\n",
       "      <td>0.814219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.704000</td>\n",
       "      <td>1.885834</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806562</td>\n",
       "      <td>0.805812</td>\n",
       "      <td>0.805947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.473100</td>\n",
       "      <td>1.874916</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806739</td>\n",
       "      <td>0.806569</td>\n",
       "      <td>0.806186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.351600</td>\n",
       "      <td>1.981315</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.800400</td>\n",
       "      <td>0.800476</td>\n",
       "      <td>0.800421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.282900</td>\n",
       "      <td>1.991686</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808564</td>\n",
       "      <td>0.808653</td>\n",
       "      <td>0.808480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.228700</td>\n",
       "      <td>2.111898</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.801577</td>\n",
       "      <td>0.799844</td>\n",
       "      <td>0.799995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.195300</td>\n",
       "      <td>2.092685</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.788955</td>\n",
       "      <td>0.789046</td>\n",
       "      <td>0.788963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.165800</td>\n",
       "      <td>2.045467</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.801750</td>\n",
       "      <td>0.801812</td>\n",
       "      <td>0.801603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.147700</td>\n",
       "      <td>2.076681</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.802932</td>\n",
       "      <td>0.802191</td>\n",
       "      <td>0.801547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.131400</td>\n",
       "      <td>2.042845</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.802683</td>\n",
       "      <td>0.802728</td>\n",
       "      <td>0.802701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 08:42:46,673] Trial 100 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 101 with params: {'learning_rate': 9.122504721242308e-05, 'weight_decay': 0.003, 'warmup_steps': 25, 'lambda_param': 0.9, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:07 < 02:03, 17.02 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.216100</td>\n",
       "      <td>1.597898</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812200</td>\n",
       "      <td>0.812200</td>\n",
       "      <td>0.811927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.225100</td>\n",
       "      <td>1.484043</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815425</td>\n",
       "      <td>0.815157</td>\n",
       "      <td>0.815238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.904800</td>\n",
       "      <td>1.515131</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823506</td>\n",
       "      <td>0.823588</td>\n",
       "      <td>0.823391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.748200</td>\n",
       "      <td>1.592366</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.822978</td>\n",
       "      <td>0.820367</td>\n",
       "      <td>0.820557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.642300</td>\n",
       "      <td>1.647316</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820649</td>\n",
       "      <td>0.820378</td>\n",
       "      <td>0.819943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.576800</td>\n",
       "      <td>1.651143</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.817278</td>\n",
       "      <td>0.816957</td>\n",
       "      <td>0.816498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.513800</td>\n",
       "      <td>1.724512</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814269</td>\n",
       "      <td>0.814368</td>\n",
       "      <td>0.814211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.477600</td>\n",
       "      <td>1.712223</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815489</td>\n",
       "      <td>0.815115</td>\n",
       "      <td>0.815215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.438100</td>\n",
       "      <td>1.755260</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.817151</td>\n",
       "      <td>0.816042</td>\n",
       "      <td>0.815279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.415800</td>\n",
       "      <td>1.772547</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815514</td>\n",
       "      <td>0.815578</td>\n",
       "      <td>0.815365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 08:46:55,145] Trial 101 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 102 with params: {'learning_rate': 5.658976697281868e-05, 'weight_decay': 0.004, 'warmup_steps': 17, 'lambda_param': 0.9, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:10, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.474700</td>\n",
       "      <td>1.716415</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793775</td>\n",
       "      <td>0.793256</td>\n",
       "      <td>0.793365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.509300</td>\n",
       "      <td>1.506161</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805187</td>\n",
       "      <td>0.804770</td>\n",
       "      <td>0.804872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.141400</td>\n",
       "      <td>1.477235</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811910</td>\n",
       "      <td>0.811779</td>\n",
       "      <td>0.811828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.955300</td>\n",
       "      <td>1.521725</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.827385</td>\n",
       "      <td>0.826419</td>\n",
       "      <td>0.826587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.826400</td>\n",
       "      <td>1.486412</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.750400</td>\n",
       "      <td>1.527364</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818918</td>\n",
       "      <td>0.818999</td>\n",
       "      <td>0.818804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.684800</td>\n",
       "      <td>1.580441</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.641700</td>\n",
       "      <td>1.595293</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822221</td>\n",
       "      <td>0.822125</td>\n",
       "      <td>0.822163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.599300</td>\n",
       "      <td>1.611765</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.571100</td>\n",
       "      <td>1.599348</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826787</td>\n",
       "      <td>0.826882</td>\n",
       "      <td>0.826807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.551100</td>\n",
       "      <td>1.636226</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823493</td>\n",
       "      <td>0.823167</td>\n",
       "      <td>0.823261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.532700</td>\n",
       "      <td>1.651981</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.517100</td>\n",
       "      <td>1.657719</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823335</td>\n",
       "      <td>0.823335</td>\n",
       "      <td>0.823335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.502400</td>\n",
       "      <td>1.666622</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825682</td>\n",
       "      <td>0.825545</td>\n",
       "      <td>0.825596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.497500</td>\n",
       "      <td>1.665774</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822196</td>\n",
       "      <td>0.822167</td>\n",
       "      <td>0.822180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 08:53:08,138] Trial 102 finished with value: 0.8221801222215643 and parameters: {'learning_rate': 5.658976697281868e-05, 'weight_decay': 0.004, 'warmup_steps': 17, 'lambda_param': 0.9, 'temperature': 2.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 103 with params: {'learning_rate': 8.487287964854836e-05, 'weight_decay': 0.005, 'warmup_steps': 7, 'lambda_param': 0.5, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 02:05 < 04:10, 16.77 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.232200</td>\n",
       "      <td>1.606430</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811891</td>\n",
       "      <td>0.811990</td>\n",
       "      <td>0.811902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.262400</td>\n",
       "      <td>1.483992</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813078</td>\n",
       "      <td>0.812905</td>\n",
       "      <td>0.812965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.936700</td>\n",
       "      <td>1.504104</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.776700</td>\n",
       "      <td>1.599970</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.826815</td>\n",
       "      <td>0.823745</td>\n",
       "      <td>0.823939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.667500</td>\n",
       "      <td>1.628715</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 08:55:14,688] Trial 103 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 104 with params: {'learning_rate': 4.471564007079742e-05, 'weight_decay': 0.007, 'warmup_steps': 8, 'lambda_param': 0.30000000000000004, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:11, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.598300</td>\n",
       "      <td>1.780846</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.799481</td>\n",
       "      <td>0.799013</td>\n",
       "      <td>0.799119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.654600</td>\n",
       "      <td>1.570291</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.800512</td>\n",
       "      <td>0.798676</td>\n",
       "      <td>0.798823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.282800</td>\n",
       "      <td>1.486344</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814162</td>\n",
       "      <td>0.814242</td>\n",
       "      <td>0.814185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.078600</td>\n",
       "      <td>1.509243</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814461</td>\n",
       "      <td>0.813905</td>\n",
       "      <td>0.814028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.939300</td>\n",
       "      <td>1.473041</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.818831</td>\n",
       "      <td>0.818773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.851400</td>\n",
       "      <td>1.504877</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814331</td>\n",
       "      <td>0.814410</td>\n",
       "      <td>0.814216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.783300</td>\n",
       "      <td>1.560949</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815390</td>\n",
       "      <td>0.815494</td>\n",
       "      <td>0.815355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.735200</td>\n",
       "      <td>1.553850</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821137</td>\n",
       "      <td>0.820914</td>\n",
       "      <td>0.820987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.691500</td>\n",
       "      <td>1.589000</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819186</td>\n",
       "      <td>0.819125</td>\n",
       "      <td>0.818806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.660300</td>\n",
       "      <td>1.563592</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826852</td>\n",
       "      <td>0.826671</td>\n",
       "      <td>0.826734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.638700</td>\n",
       "      <td>1.585089</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820255</td>\n",
       "      <td>0.819620</td>\n",
       "      <td>0.819755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.621900</td>\n",
       "      <td>1.600008</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821209</td>\n",
       "      <td>0.821086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.605100</td>\n",
       "      <td>1.609671</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823387</td>\n",
       "      <td>0.823251</td>\n",
       "      <td>0.823302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.588800</td>\n",
       "      <td>1.620737</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825729</td>\n",
       "      <td>0.825503</td>\n",
       "      <td>0.825577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.581800</td>\n",
       "      <td>1.621123</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825649</td>\n",
       "      <td>0.825587</td>\n",
       "      <td>0.825614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 09:01:28,305] Trial 104 finished with value: 0.8256137673341579 and parameters: {'learning_rate': 4.471564007079742e-05, 'weight_decay': 0.007, 'warmup_steps': 8, 'lambda_param': 0.30000000000000004, 'temperature': 5.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 105 with params: {'learning_rate': 3.5168576861786074e-05, 'weight_decay': 0.01, 'warmup_steps': 14, 'lambda_param': 0.30000000000000004, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 02:02 < 04:04, 17.21 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.739600</td>\n",
       "      <td>1.859886</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.789178</td>\n",
       "      <td>0.788667</td>\n",
       "      <td>0.788773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.816600</td>\n",
       "      <td>1.642497</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.790397</td>\n",
       "      <td>0.788288</td>\n",
       "      <td>0.788402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.444200</td>\n",
       "      <td>1.517478</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805149</td>\n",
       "      <td>0.805029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.224100</td>\n",
       "      <td>1.519579</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.809103</td>\n",
       "      <td>0.808022</td>\n",
       "      <td>0.808177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.073600</td>\n",
       "      <td>1.474528</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 09:03:31,726] Trial 105 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 106 with params: {'learning_rate': 7.122930804692333e-05, 'weight_decay': 0.007, 'warmup_steps': 1, 'lambda_param': 0.5, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:10, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.321100</td>\n",
       "      <td>1.637565</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807401</td>\n",
       "      <td>0.807314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.364100</td>\n",
       "      <td>1.468762</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806191</td>\n",
       "      <td>0.806022</td>\n",
       "      <td>0.806080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.018400</td>\n",
       "      <td>1.462655</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.818831</td>\n",
       "      <td>0.818773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.849700</td>\n",
       "      <td>1.560095</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.827161</td>\n",
       "      <td>0.825040</td>\n",
       "      <td>0.825243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.732000</td>\n",
       "      <td>1.534887</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821150</td>\n",
       "      <td>0.821251</td>\n",
       "      <td>0.821092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.662900</td>\n",
       "      <td>1.561040</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817890</td>\n",
       "      <td>0.817915</td>\n",
       "      <td>0.817660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.599500</td>\n",
       "      <td>1.632099</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.818620</td>\n",
       "      <td>0.818692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.559500</td>\n",
       "      <td>1.643690</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817956</td>\n",
       "      <td>0.817326</td>\n",
       "      <td>0.817459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.518600</td>\n",
       "      <td>1.667520</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815921</td>\n",
       "      <td>0.815747</td>\n",
       "      <td>0.815361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.493800</td>\n",
       "      <td>1.660430</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816447</td>\n",
       "      <td>0.816494</td>\n",
       "      <td>0.816466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.473500</td>\n",
       "      <td>1.705758</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819926</td>\n",
       "      <td>0.819830</td>\n",
       "      <td>0.819869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>1.722904</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815799</td>\n",
       "      <td>0.815705</td>\n",
       "      <td>0.815365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.442000</td>\n",
       "      <td>1.719850</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819906</td>\n",
       "      <td>0.819999</td>\n",
       "      <td>0.819925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.427200</td>\n",
       "      <td>1.726487</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.821041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.424600</td>\n",
       "      <td>1.724045</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821044</td>\n",
       "      <td>0.821125</td>\n",
       "      <td>0.821067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 09:09:44,474] Trial 106 finished with value: 0.8210670314637483 and parameters: {'learning_rate': 7.122930804692333e-05, 'weight_decay': 0.007, 'warmup_steps': 1, 'lambda_param': 0.5, 'temperature': 5.5}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 107 with params: {'learning_rate': 0.00031471170796524536, 'weight_decay': 0.008, 'warmup_steps': 8, 'lambda_param': 0.5, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 02:01 < 04:03, 17.26 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.602400</td>\n",
       "      <td>1.449678</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810723</td>\n",
       "      <td>0.810695</td>\n",
       "      <td>0.810708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.769100</td>\n",
       "      <td>1.786569</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809959</td>\n",
       "      <td>0.809274</td>\n",
       "      <td>0.809407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.531100</td>\n",
       "      <td>1.823716</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819889</td>\n",
       "      <td>0.819915</td>\n",
       "      <td>0.819901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.399700</td>\n",
       "      <td>1.822692</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808862</td>\n",
       "      <td>0.808106</td>\n",
       "      <td>0.808244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.328100</td>\n",
       "      <td>1.952712</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809597</td>\n",
       "      <td>0.809695</td>\n",
       "      <td>0.809608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 09:11:47,744] Trial 107 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 108 with params: {'learning_rate': 1.7064665691774607e-05, 'weight_decay': 0.007, 'warmup_steps': 7, 'lambda_param': 0.2, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 02:02 < 04:05, 17.15 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.093100</td>\n",
       "      <td>2.331280</td>\n",
       "      <td>0.746560</td>\n",
       "      <td>0.746938</td>\n",
       "      <td>0.746074</td>\n",
       "      <td>0.746151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.362000</td>\n",
       "      <td>1.872413</td>\n",
       "      <td>0.787844</td>\n",
       "      <td>0.788066</td>\n",
       "      <td>0.788088</td>\n",
       "      <td>0.787844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.951400</td>\n",
       "      <td>1.736415</td>\n",
       "      <td>0.783257</td>\n",
       "      <td>0.783395</td>\n",
       "      <td>0.782952</td>\n",
       "      <td>0.783049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.716600</td>\n",
       "      <td>1.659683</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.797470</td>\n",
       "      <td>0.796592</td>\n",
       "      <td>0.796727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.556200</td>\n",
       "      <td>1.601991</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798949</td>\n",
       "      <td>0.797634</td>\n",
       "      <td>0.797781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 09:13:51,737] Trial 108 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 109 with params: {'learning_rate': 2.2890061022371275e-05, 'weight_decay': 0.006, 'warmup_steps': 2, 'lambda_param': 0.2, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:09 < 02:04, 16.84 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.962100</td>\n",
       "      <td>2.100765</td>\n",
       "      <td>0.774083</td>\n",
       "      <td>0.774688</td>\n",
       "      <td>0.773564</td>\n",
       "      <td>0.773675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.122100</td>\n",
       "      <td>1.761682</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.795887</td>\n",
       "      <td>0.795833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.743600</td>\n",
       "      <td>1.630664</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.799409</td>\n",
       "      <td>0.799055</td>\n",
       "      <td>0.799147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.513100</td>\n",
       "      <td>1.588140</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.803715</td>\n",
       "      <td>0.802181</td>\n",
       "      <td>0.802336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.352300</td>\n",
       "      <td>1.527647</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812368</td>\n",
       "      <td>0.811526</td>\n",
       "      <td>0.811673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.234100</td>\n",
       "      <td>1.489479</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808451</td>\n",
       "      <td>0.808359</td>\n",
       "      <td>0.808395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.152300</td>\n",
       "      <td>1.486290</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806270</td>\n",
       "      <td>0.806359</td>\n",
       "      <td>0.806186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.079300</td>\n",
       "      <td>1.488551</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806134</td>\n",
       "      <td>0.806106</td>\n",
       "      <td>0.806119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.028100</td>\n",
       "      <td>1.482728</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812032</td>\n",
       "      <td>0.811911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.986200</td>\n",
       "      <td>1.490476</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813192</td>\n",
       "      <td>0.812821</td>\n",
       "      <td>0.812920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 09:18:03,025] Trial 109 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 110 with params: {'learning_rate': 4.393785846446947e-05, 'weight_decay': 0.007, 'warmup_steps': 9, 'lambda_param': 0.5, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:10, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.609300</td>\n",
       "      <td>1.785666</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798372</td>\n",
       "      <td>0.797845</td>\n",
       "      <td>0.797957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.666200</td>\n",
       "      <td>1.575632</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.798389</td>\n",
       "      <td>0.796340</td>\n",
       "      <td>0.796476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.294200</td>\n",
       "      <td>1.487220</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811859</td>\n",
       "      <td>0.811905</td>\n",
       "      <td>0.811878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.088500</td>\n",
       "      <td>1.508682</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814461</td>\n",
       "      <td>0.813905</td>\n",
       "      <td>0.814028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.948400</td>\n",
       "      <td>1.473304</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817597</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.859500</td>\n",
       "      <td>1.503563</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.791200</td>\n",
       "      <td>1.559323</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814269</td>\n",
       "      <td>0.814368</td>\n",
       "      <td>0.814211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.742500</td>\n",
       "      <td>1.550496</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817721</td>\n",
       "      <td>0.817452</td>\n",
       "      <td>0.817534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.698700</td>\n",
       "      <td>1.586120</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819186</td>\n",
       "      <td>0.819125</td>\n",
       "      <td>0.818806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.667200</td>\n",
       "      <td>1.561460</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825649</td>\n",
       "      <td>0.825587</td>\n",
       "      <td>0.825614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.645500</td>\n",
       "      <td>1.581237</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820255</td>\n",
       "      <td>0.819620</td>\n",
       "      <td>0.819755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.628900</td>\n",
       "      <td>1.596668</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822270</td>\n",
       "      <td>0.822377</td>\n",
       "      <td>0.822236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.612000</td>\n",
       "      <td>1.606268</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822261</td>\n",
       "      <td>0.822083</td>\n",
       "      <td>0.822145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.595500</td>\n",
       "      <td>1.617246</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824610</td>\n",
       "      <td>0.824335</td>\n",
       "      <td>0.824419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.588400</td>\n",
       "      <td>1.617980</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823387</td>\n",
       "      <td>0.823251</td>\n",
       "      <td>0.823302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 09:24:15,490] Trial 110 finished with value: 0.823301543190383 and parameters: {'learning_rate': 4.393785846446947e-05, 'weight_decay': 0.007, 'warmup_steps': 9, 'lambda_param': 0.5, 'temperature': 7.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 111 with params: {'learning_rate': 8.440743911611171e-05, 'weight_decay': 0.005, 'warmup_steps': 17, 'lambda_param': 0.30000000000000004, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:07 < 02:03, 16.99 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.248600</td>\n",
       "      <td>1.608647</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807271</td>\n",
       "      <td>0.807317</td>\n",
       "      <td>0.807290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.267300</td>\n",
       "      <td>1.481631</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813041</td>\n",
       "      <td>0.812947</td>\n",
       "      <td>0.812985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.939100</td>\n",
       "      <td>1.505806</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.778500</td>\n",
       "      <td>1.592082</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.827847</td>\n",
       "      <td>0.824914</td>\n",
       "      <td>0.825113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.669300</td>\n",
       "      <td>1.629343</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819302</td>\n",
       "      <td>0.819167</td>\n",
       "      <td>0.818804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.602500</td>\n",
       "      <td>1.623487</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821871</td>\n",
       "      <td>0.821546</td>\n",
       "      <td>0.821086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.540100</td>\n",
       "      <td>1.685704</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811975</td>\n",
       "      <td>0.812074</td>\n",
       "      <td>0.811918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.502100</td>\n",
       "      <td>1.686329</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817786</td>\n",
       "      <td>0.817410</td>\n",
       "      <td>0.817511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.462200</td>\n",
       "      <td>1.711864</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.816935</td>\n",
       "      <td>0.815999</td>\n",
       "      <td>0.815297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.439400</td>\n",
       "      <td>1.740270</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817641</td>\n",
       "      <td>0.817746</td>\n",
       "      <td>0.817641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 09:28:24,217] Trial 111 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 112 with params: {'learning_rate': 7.958553193484505e-05, 'weight_decay': 0.006, 'warmup_steps': 23, 'lambda_param': 0.9, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.289500</td>\n",
       "      <td>1.619868</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.804044</td>\n",
       "      <td>0.804107</td>\n",
       "      <td>0.803897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.308600</td>\n",
       "      <td>1.476976</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809569</td>\n",
       "      <td>0.809569</td>\n",
       "      <td>0.809569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>1.486483</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.804200</td>\n",
       "      <td>1.573087</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.827847</td>\n",
       "      <td>0.824914</td>\n",
       "      <td>0.825113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.692500</td>\n",
       "      <td>1.595807</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821480</td>\n",
       "      <td>0.821420</td>\n",
       "      <td>0.821100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.623900</td>\n",
       "      <td>1.590353</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.820336</td>\n",
       "      <td>0.819948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.561100</td>\n",
       "      <td>1.651421</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816456</td>\n",
       "      <td>0.816536</td>\n",
       "      <td>0.816479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.521200</td>\n",
       "      <td>1.657454</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816675</td>\n",
       "      <td>0.816241</td>\n",
       "      <td>0.816350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.481900</td>\n",
       "      <td>1.685459</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.820085</td>\n",
       "      <td>0.819378</td>\n",
       "      <td>0.818761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.457500</td>\n",
       "      <td>1.711079</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817612</td>\n",
       "      <td>0.817704</td>\n",
       "      <td>0.817632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.437700</td>\n",
       "      <td>1.722776</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821059</td>\n",
       "      <td>0.820999</td>\n",
       "      <td>0.821025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.419500</td>\n",
       "      <td>1.738347</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815596</td>\n",
       "      <td>0.815621</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.407600</td>\n",
       "      <td>1.738517</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822200</td>\n",
       "      <td>0.822293</td>\n",
       "      <td>0.822219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.392600</td>\n",
       "      <td>1.742830</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822185</td>\n",
       "      <td>0.822251</td>\n",
       "      <td>0.822208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.391500</td>\n",
       "      <td>1.742726</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 09:34:41,109] Trial 112 finished with value: 0.817648799542307 and parameters: {'learning_rate': 7.958553193484505e-05, 'weight_decay': 0.006, 'warmup_steps': 23, 'lambda_param': 0.9, 'temperature': 4.5}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 113 with params: {'learning_rate': 4.546434510128894e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 8, 'lambda_param': 0.2, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:15, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.588900</td>\n",
       "      <td>1.776396</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.797183</td>\n",
       "      <td>0.796718</td>\n",
       "      <td>0.796824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.644100</td>\n",
       "      <td>1.565139</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.800512</td>\n",
       "      <td>0.798676</td>\n",
       "      <td>0.798823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.272300</td>\n",
       "      <td>1.485608</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814153</td>\n",
       "      <td>0.814200</td>\n",
       "      <td>0.814172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.069400</td>\n",
       "      <td>1.509963</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816858</td>\n",
       "      <td>0.816157</td>\n",
       "      <td>0.816296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.930700</td>\n",
       "      <td>1.472995</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821044</td>\n",
       "      <td>0.821125</td>\n",
       "      <td>0.821067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.843800</td>\n",
       "      <td>1.506364</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814331</td>\n",
       "      <td>0.814410</td>\n",
       "      <td>0.814216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.775800</td>\n",
       "      <td>1.563093</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814326</td>\n",
       "      <td>0.814205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.728300</td>\n",
       "      <td>1.557251</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821197</td>\n",
       "      <td>0.820872</td>\n",
       "      <td>0.820965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.684700</td>\n",
       "      <td>1.591369</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.653800</td>\n",
       "      <td>1.565964</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826852</td>\n",
       "      <td>0.826671</td>\n",
       "      <td>0.826734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.632200</td>\n",
       "      <td>1.588814</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822554</td>\n",
       "      <td>0.821914</td>\n",
       "      <td>0.822051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.615400</td>\n",
       "      <td>1.603578</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818772</td>\n",
       "      <td>0.818873</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.598600</td>\n",
       "      <td>1.613237</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823354</td>\n",
       "      <td>0.823293</td>\n",
       "      <td>0.823319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.582500</td>\n",
       "      <td>1.624371</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825729</td>\n",
       "      <td>0.825503</td>\n",
       "      <td>0.825577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.575600</td>\n",
       "      <td>1.624541</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825649</td>\n",
       "      <td>0.825587</td>\n",
       "      <td>0.825614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 09:40:57,993] Trial 113 finished with value: 0.8256137673341579 and parameters: {'learning_rate': 4.546434510128894e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 8, 'lambda_param': 0.2, 'temperature': 5.5}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 114 with params: {'learning_rate': 7.806615700810692e-05, 'weight_decay': 0.007, 'warmup_steps': 1, 'lambda_param': 0.30000000000000004, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:07 < 02:03, 17.02 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.269100</td>\n",
       "      <td>1.618651</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813009</td>\n",
       "      <td>0.813074</td>\n",
       "      <td>0.813032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.311500</td>\n",
       "      <td>1.483055</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809569</td>\n",
       "      <td>0.809569</td>\n",
       "      <td>0.809569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.976500</td>\n",
       "      <td>1.495875</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815390</td>\n",
       "      <td>0.815494</td>\n",
       "      <td>0.815355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.811000</td>\n",
       "      <td>1.597236</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.822442</td>\n",
       "      <td>0.819115</td>\n",
       "      <td>0.819287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.698400</td>\n",
       "      <td>1.606961</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817890</td>\n",
       "      <td>0.817915</td>\n",
       "      <td>0.817660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.630100</td>\n",
       "      <td>1.600079</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.818094</td>\n",
       "      <td>0.817999</td>\n",
       "      <td>0.817658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.567700</td>\n",
       "      <td>1.661951</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813025</td>\n",
       "      <td>0.813116</td>\n",
       "      <td>0.813044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.528000</td>\n",
       "      <td>1.669875</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814461</td>\n",
       "      <td>0.813905</td>\n",
       "      <td>0.814028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.488000</td>\n",
       "      <td>1.686978</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819901</td>\n",
       "      <td>0.819336</td>\n",
       "      <td>0.818773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.463800</td>\n",
       "      <td>1.716067</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814162</td>\n",
       "      <td>0.814242</td>\n",
       "      <td>0.814185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 09:45:06,299] Trial 114 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 115 with params: {'learning_rate': 4.563581482424318e-05, 'weight_decay': 0.008, 'warmup_steps': 8, 'lambda_param': 0.30000000000000004, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.586800</td>\n",
       "      <td>1.775466</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.797183</td>\n",
       "      <td>0.796718</td>\n",
       "      <td>0.796824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.641700</td>\n",
       "      <td>1.563935</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.800512</td>\n",
       "      <td>0.798676</td>\n",
       "      <td>0.798823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.269900</td>\n",
       "      <td>1.485458</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814153</td>\n",
       "      <td>0.814200</td>\n",
       "      <td>0.814172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.067400</td>\n",
       "      <td>1.510179</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816858</td>\n",
       "      <td>0.816157</td>\n",
       "      <td>0.816296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.928800</td>\n",
       "      <td>1.473091</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821044</td>\n",
       "      <td>0.821125</td>\n",
       "      <td>0.821067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.842100</td>\n",
       "      <td>1.506642</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814331</td>\n",
       "      <td>0.814410</td>\n",
       "      <td>0.814216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.774100</td>\n",
       "      <td>1.563589</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814326</td>\n",
       "      <td>0.814205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.726800</td>\n",
       "      <td>1.558023</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821197</td>\n",
       "      <td>0.820872</td>\n",
       "      <td>0.820965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.683200</td>\n",
       "      <td>1.592042</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.652300</td>\n",
       "      <td>1.566443</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826852</td>\n",
       "      <td>0.826671</td>\n",
       "      <td>0.826734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.630800</td>\n",
       "      <td>1.589683</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822554</td>\n",
       "      <td>0.821914</td>\n",
       "      <td>0.822051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.613900</td>\n",
       "      <td>1.604410</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818772</td>\n",
       "      <td>0.818873</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.597100</td>\n",
       "      <td>1.613997</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823354</td>\n",
       "      <td>0.823293</td>\n",
       "      <td>0.823319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.581000</td>\n",
       "      <td>1.625123</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826852</td>\n",
       "      <td>0.826671</td>\n",
       "      <td>0.826734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.574200</td>\n",
       "      <td>1.625221</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825649</td>\n",
       "      <td>0.825587</td>\n",
       "      <td>0.825614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 09:51:20,822] Trial 115 finished with value: 0.8256137673341579 and parameters: {'learning_rate': 4.563581482424318e-05, 'weight_decay': 0.008, 'warmup_steps': 8, 'lambda_param': 0.30000000000000004, 'temperature': 5.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 116 with params: {'learning_rate': 6.643822835431652e-05, 'weight_decay': 0.008, 'warmup_steps': 7, 'lambda_param': 0.2, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.370700</td>\n",
       "      <td>1.657216</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798097</td>\n",
       "      <td>0.798097</td>\n",
       "      <td>0.798097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.406700</td>\n",
       "      <td>1.476728</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.801600</td>\n",
       "      <td>0.801433</td>\n",
       "      <td>0.801490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.053300</td>\n",
       "      <td>1.467038</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.879900</td>\n",
       "      <td>1.549585</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.826111</td>\n",
       "      <td>0.823872</td>\n",
       "      <td>0.824073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.758900</td>\n",
       "      <td>1.515848</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823503</td>\n",
       "      <td>0.823380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.688600</td>\n",
       "      <td>1.543014</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821377</td>\n",
       "      <td>0.821377</td>\n",
       "      <td>0.821101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.624400</td>\n",
       "      <td>1.611920</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818765</td>\n",
       "      <td>0.818704</td>\n",
       "      <td>0.818730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.583000</td>\n",
       "      <td>1.628732</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817956</td>\n",
       "      <td>0.817326</td>\n",
       "      <td>0.817459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.542100</td>\n",
       "      <td>1.642737</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820649</td>\n",
       "      <td>0.820378</td>\n",
       "      <td>0.819943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.516700</td>\n",
       "      <td>1.636951</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819889</td>\n",
       "      <td>0.819915</td>\n",
       "      <td>0.819901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.496400</td>\n",
       "      <td>1.682811</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.477500</td>\n",
       "      <td>1.696255</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.463600</td>\n",
       "      <td>1.696175</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823329</td>\n",
       "      <td>0.823377</td>\n",
       "      <td>0.823349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.448700</td>\n",
       "      <td>1.704008</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824516</td>\n",
       "      <td>0.824419</td>\n",
       "      <td>0.824458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.445600</td>\n",
       "      <td>1.701754</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825649</td>\n",
       "      <td>0.825587</td>\n",
       "      <td>0.825614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 09:57:35,499] Trial 116 finished with value: 0.8256137673341579 and parameters: {'learning_rate': 6.643822835431652e-05, 'weight_decay': 0.008, 'warmup_steps': 7, 'lambda_param': 0.2, 'temperature': 6.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 117 with params: {'learning_rate': 7.15073888525604e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 11, 'lambda_param': 0.1, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:07 < 02:03, 17.03 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.334000</td>\n",
       "      <td>1.638669</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.802854</td>\n",
       "      <td>0.802736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.364200</td>\n",
       "      <td>1.466261</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808536</td>\n",
       "      <td>0.808274</td>\n",
       "      <td>0.808353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.016600</td>\n",
       "      <td>1.463185</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.818831</td>\n",
       "      <td>0.818773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>1.556110</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.827161</td>\n",
       "      <td>0.825040</td>\n",
       "      <td>0.825243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.730500</td>\n",
       "      <td>1.534140</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822326</td>\n",
       "      <td>0.822419</td>\n",
       "      <td>0.822242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.661500</td>\n",
       "      <td>1.564158</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820280</td>\n",
       "      <td>0.820251</td>\n",
       "      <td>0.819954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.597600</td>\n",
       "      <td>1.628035</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817669</td>\n",
       "      <td>0.817494</td>\n",
       "      <td>0.817555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.557900</td>\n",
       "      <td>1.642917</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820162</td>\n",
       "      <td>0.819662</td>\n",
       "      <td>0.819781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.517100</td>\n",
       "      <td>1.667777</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819574</td>\n",
       "      <td>0.819251</td>\n",
       "      <td>0.818792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.492300</td>\n",
       "      <td>1.660472</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817597</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 10:01:43,938] Trial 117 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 118 with params: {'learning_rate': 0.0004838234070984164, 'weight_decay': 0.006, 'warmup_steps': 9, 'lambda_param': 0.0, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 02:01 < 04:04, 17.24 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.477600</td>\n",
       "      <td>1.525790</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.811987</td>\n",
       "      <td>0.810411</td>\n",
       "      <td>0.809489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.693200</td>\n",
       "      <td>1.851123</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808976</td>\n",
       "      <td>0.808064</td>\n",
       "      <td>0.808212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.464900</td>\n",
       "      <td>1.953027</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819891</td>\n",
       "      <td>0.819957</td>\n",
       "      <td>0.819914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.347000</td>\n",
       "      <td>1.892196</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.805523</td>\n",
       "      <td>0.803181</td>\n",
       "      <td>0.803328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.276200</td>\n",
       "      <td>2.184135</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.801831</td>\n",
       "      <td>0.801854</td>\n",
       "      <td>0.801605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 10:03:47,272] Trial 118 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 119 with params: {'learning_rate': 1.0704036787379217e-05, 'weight_decay': 0.003, 'warmup_steps': 35, 'lambda_param': 0.4, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:09 < 02:04, 16.89 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.224100</td>\n",
       "      <td>2.685822</td>\n",
       "      <td>0.698394</td>\n",
       "      <td>0.703721</td>\n",
       "      <td>0.696756</td>\n",
       "      <td>0.695220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.772500</td>\n",
       "      <td>2.172384</td>\n",
       "      <td>0.771789</td>\n",
       "      <td>0.773406</td>\n",
       "      <td>0.772449</td>\n",
       "      <td>0.771681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.326600</td>\n",
       "      <td>1.920143</td>\n",
       "      <td>0.779817</td>\n",
       "      <td>0.779753</td>\n",
       "      <td>0.779700</td>\n",
       "      <td>0.779723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.063300</td>\n",
       "      <td>1.814999</td>\n",
       "      <td>0.783257</td>\n",
       "      <td>0.783330</td>\n",
       "      <td>0.782994</td>\n",
       "      <td>0.783079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.896700</td>\n",
       "      <td>1.761667</td>\n",
       "      <td>0.784404</td>\n",
       "      <td>0.784990</td>\n",
       "      <td>0.783910</td>\n",
       "      <td>0.784036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.766700</td>\n",
       "      <td>1.691937</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792386</td>\n",
       "      <td>0.792298</td>\n",
       "      <td>0.792333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.680000</td>\n",
       "      <td>1.649980</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798112</td>\n",
       "      <td>0.798055</td>\n",
       "      <td>0.798079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.594000</td>\n",
       "      <td>1.622757</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803943</td>\n",
       "      <td>0.803686</td>\n",
       "      <td>0.803763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.535300</td>\n",
       "      <td>1.591915</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808451</td>\n",
       "      <td>0.808359</td>\n",
       "      <td>0.808395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.485000</td>\n",
       "      <td>1.582510</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.802969</td>\n",
       "      <td>0.802433</td>\n",
       "      <td>0.802549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 10:07:57,733] Trial 119 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 120 with params: {'learning_rate': 3.931465750764011e-05, 'weight_decay': 0.008, 'warmup_steps': 3, 'lambda_param': 0.0, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.665800</td>\n",
       "      <td>1.817330</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791402</td>\n",
       "      <td>0.791004</td>\n",
       "      <td>0.791099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.736900</td>\n",
       "      <td>1.609550</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.794654</td>\n",
       "      <td>0.792961</td>\n",
       "      <td>0.793098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.366700</td>\n",
       "      <td>1.499202</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808438</td>\n",
       "      <td>0.808527</td>\n",
       "      <td>0.808456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.153500</td>\n",
       "      <td>1.512133</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814669</td>\n",
       "      <td>0.813821</td>\n",
       "      <td>0.813970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.008700</td>\n",
       "      <td>1.476215</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817612</td>\n",
       "      <td>0.817704</td>\n",
       "      <td>0.817632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.914200</td>\n",
       "      <td>1.494146</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819977</td>\n",
       "      <td>0.820083</td>\n",
       "      <td>0.819943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.845100</td>\n",
       "      <td>1.542271</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814406</td>\n",
       "      <td>0.814452</td>\n",
       "      <td>0.814219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.792100</td>\n",
       "      <td>1.531135</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820017</td>\n",
       "      <td>0.819746</td>\n",
       "      <td>0.819829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.746900</td>\n",
       "      <td>1.563786</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815799</td>\n",
       "      <td>0.815705</td>\n",
       "      <td>0.815365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.713400</td>\n",
       "      <td>1.546119</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819926</td>\n",
       "      <td>0.819830</td>\n",
       "      <td>0.819869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.690800</td>\n",
       "      <td>1.558859</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821270</td>\n",
       "      <td>0.820830</td>\n",
       "      <td>0.820942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.674900</td>\n",
       "      <td>1.573648</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817641</td>\n",
       "      <td>0.817746</td>\n",
       "      <td>0.817641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>1.582092</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816447</td>\n",
       "      <td>0.816494</td>\n",
       "      <td>0.816466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.639700</td>\n",
       "      <td>1.592905</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816546</td>\n",
       "      <td>0.816326</td>\n",
       "      <td>0.816397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.632000</td>\n",
       "      <td>1.594715</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816501</td>\n",
       "      <td>0.816368</td>\n",
       "      <td>0.816417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 10:14:12,399] Trial 120 finished with value: 0.816417187730268 and parameters: {'learning_rate': 3.931465750764011e-05, 'weight_decay': 0.008, 'warmup_steps': 3, 'lambda_param': 0.0, 'temperature': 5.5}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 121 with params: {'learning_rate': 5.4996185653935916e-05, 'weight_decay': 0.008, 'warmup_steps': 22, 'lambda_param': 0.2, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:09, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.496500</td>\n",
       "      <td>1.726882</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793775</td>\n",
       "      <td>0.793256</td>\n",
       "      <td>0.793365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.528700</td>\n",
       "      <td>1.513049</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.804163</td>\n",
       "      <td>0.803559</td>\n",
       "      <td>0.803682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.158400</td>\n",
       "      <td>1.480211</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811910</td>\n",
       "      <td>0.811779</td>\n",
       "      <td>0.811828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.969700</td>\n",
       "      <td>1.518595</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823871</td>\n",
       "      <td>0.822998</td>\n",
       "      <td>0.823156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.839500</td>\n",
       "      <td>1.485498</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.762300</td>\n",
       "      <td>1.527864</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820032</td>\n",
       "      <td>0.820125</td>\n",
       "      <td>0.819948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.696100</td>\n",
       "      <td>1.581702</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818741</td>\n",
       "      <td>0.818788</td>\n",
       "      <td>0.818761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.652700</td>\n",
       "      <td>1.593463</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822221</td>\n",
       "      <td>0.822125</td>\n",
       "      <td>0.822163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.610100</td>\n",
       "      <td>1.613490</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.581500</td>\n",
       "      <td>1.598017</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825653</td>\n",
       "      <td>0.825756</td>\n",
       "      <td>0.825665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.561300</td>\n",
       "      <td>1.633297</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823567</td>\n",
       "      <td>0.823125</td>\n",
       "      <td>0.823237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.543000</td>\n",
       "      <td>1.649307</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819977</td>\n",
       "      <td>0.820083</td>\n",
       "      <td>0.819943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.527200</td>\n",
       "      <td>1.656468</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823329</td>\n",
       "      <td>0.823377</td>\n",
       "      <td>0.823349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>1.665644</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826811</td>\n",
       "      <td>0.826713</td>\n",
       "      <td>0.826753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.507300</td>\n",
       "      <td>1.664570</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824490</td>\n",
       "      <td>0.824461</td>\n",
       "      <td>0.824475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 10:20:24,371] Trial 121 finished with value: 0.8244745722574152 and parameters: {'learning_rate': 5.4996185653935916e-05, 'weight_decay': 0.008, 'warmup_steps': 22, 'lambda_param': 0.2, 'temperature': 5.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 122 with params: {'learning_rate': 5.013479350078533e-05, 'weight_decay': 0.008, 'warmup_steps': 3, 'lambda_param': 0.2, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:08, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.528100</td>\n",
       "      <td>1.750355</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794815</td>\n",
       "      <td>0.794466</td>\n",
       "      <td>0.794556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.581300</td>\n",
       "      <td>1.534846</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.800982</td>\n",
       "      <td>0.800013</td>\n",
       "      <td>0.800155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.211400</td>\n",
       "      <td>1.482620</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811880</td>\n",
       "      <td>0.811821</td>\n",
       "      <td>0.811846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.016500</td>\n",
       "      <td>1.516977</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819396</td>\n",
       "      <td>0.818367</td>\n",
       "      <td>0.818531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.882300</td>\n",
       "      <td>1.476889</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817641</td>\n",
       "      <td>0.817746</td>\n",
       "      <td>0.817641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.800800</td>\n",
       "      <td>1.514669</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.733900</td>\n",
       "      <td>1.572461</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.818831</td>\n",
       "      <td>0.818773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.689000</td>\n",
       "      <td>1.577845</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821197</td>\n",
       "      <td>0.820872</td>\n",
       "      <td>0.820965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.645800</td>\n",
       "      <td>1.603978</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.616200</td>\n",
       "      <td>1.579607</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826785</td>\n",
       "      <td>0.826755</td>\n",
       "      <td>0.826769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.595300</td>\n",
       "      <td>1.610496</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822554</td>\n",
       "      <td>0.821914</td>\n",
       "      <td>0.822051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.577700</td>\n",
       "      <td>1.624926</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819977</td>\n",
       "      <td>0.820083</td>\n",
       "      <td>0.819943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.561300</td>\n",
       "      <td>1.633243</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822196</td>\n",
       "      <td>0.822167</td>\n",
       "      <td>0.822180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.545900</td>\n",
       "      <td>1.643381</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825649</td>\n",
       "      <td>0.825587</td>\n",
       "      <td>0.825614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>1.642572</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825649</td>\n",
       "      <td>0.825587</td>\n",
       "      <td>0.825614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 10:26:34,467] Trial 122 finished with value: 0.8256137673341579 and parameters: {'learning_rate': 5.013479350078533e-05, 'weight_decay': 0.008, 'warmup_steps': 3, 'lambda_param': 0.2, 'temperature': 5.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 123 with params: {'learning_rate': 7.183646508196148e-05, 'weight_decay': 0.004, 'warmup_steps': 2, 'lambda_param': 0.2, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:10, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.318200</td>\n",
       "      <td>1.637196</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809597</td>\n",
       "      <td>0.809695</td>\n",
       "      <td>0.809608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.361200</td>\n",
       "      <td>1.467794</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807362</td>\n",
       "      <td>0.807148</td>\n",
       "      <td>0.807217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.015200</td>\n",
       "      <td>1.461297</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.818831</td>\n",
       "      <td>0.818773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.846400</td>\n",
       "      <td>1.561988</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.825064</td>\n",
       "      <td>0.822704</td>\n",
       "      <td>0.822902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.729200</td>\n",
       "      <td>1.537138</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822326</td>\n",
       "      <td>0.822419</td>\n",
       "      <td>0.822242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.659800</td>\n",
       "      <td>1.564632</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817890</td>\n",
       "      <td>0.817915</td>\n",
       "      <td>0.817660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.596500</td>\n",
       "      <td>1.633972</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.818620</td>\n",
       "      <td>0.818692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.556700</td>\n",
       "      <td>1.644416</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816858</td>\n",
       "      <td>0.816157</td>\n",
       "      <td>0.816296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.515900</td>\n",
       "      <td>1.673790</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.817278</td>\n",
       "      <td>0.816957</td>\n",
       "      <td>0.816498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.491000</td>\n",
       "      <td>1.665089</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817597</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.470800</td>\n",
       "      <td>1.708676</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819926</td>\n",
       "      <td>0.819830</td>\n",
       "      <td>0.819869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.452300</td>\n",
       "      <td>1.726328</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815691</td>\n",
       "      <td>0.815663</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.439400</td>\n",
       "      <td>1.723930</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819906</td>\n",
       "      <td>0.819999</td>\n",
       "      <td>0.819925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.424500</td>\n",
       "      <td>1.730421</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823335</td>\n",
       "      <td>0.823335</td>\n",
       "      <td>0.823335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.422100</td>\n",
       "      <td>1.727661</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821044</td>\n",
       "      <td>0.821125</td>\n",
       "      <td>0.821067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 10:32:47,733] Trial 123 finished with value: 0.8210670314637483 and parameters: {'learning_rate': 7.183646508196148e-05, 'weight_decay': 0.004, 'warmup_steps': 2, 'lambda_param': 0.2, 'temperature': 2.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 124 with params: {'learning_rate': 4.126689200396419e-05, 'weight_decay': 0.008, 'warmup_steps': 11, 'lambda_param': 0.30000000000000004, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:04 < 02:02, 17.20 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.646700</td>\n",
       "      <td>1.803706</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794885</td>\n",
       "      <td>0.794424</td>\n",
       "      <td>0.794528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.707600</td>\n",
       "      <td>1.595350</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.795724</td>\n",
       "      <td>0.794129</td>\n",
       "      <td>0.794270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.335400</td>\n",
       "      <td>1.492834</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807401</td>\n",
       "      <td>0.807314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.124900</td>\n",
       "      <td>1.509075</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811060</td>\n",
       "      <td>0.810442</td>\n",
       "      <td>0.810570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.982000</td>\n",
       "      <td>1.474674</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818915</td>\n",
       "      <td>0.818792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.889700</td>\n",
       "      <td>1.498329</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.820900</td>\n",
       "      <td>1.552159</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814494</td>\n",
       "      <td>0.814494</td>\n",
       "      <td>0.814220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.769900</td>\n",
       "      <td>1.539411</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816546</td>\n",
       "      <td>0.816326</td>\n",
       "      <td>0.816397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.725400</td>\n",
       "      <td>1.576073</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819083</td>\n",
       "      <td>0.819083</td>\n",
       "      <td>0.818807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.692700</td>\n",
       "      <td>1.553741</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818765</td>\n",
       "      <td>0.818704</td>\n",
       "      <td>0.818730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 10:36:53,558] Trial 124 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 125 with params: {'learning_rate': 7.41519116745938e-05, 'weight_decay': 0.008, 'warmup_steps': 12, 'lambda_param': 0.30000000000000004, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:10, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.315000</td>\n",
       "      <td>1.632233</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805156</td>\n",
       "      <td>0.805233</td>\n",
       "      <td>0.805042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.347200</td>\n",
       "      <td>1.466106</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809615</td>\n",
       "      <td>0.809485</td>\n",
       "      <td>0.809533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.001100</td>\n",
       "      <td>1.460024</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818772</td>\n",
       "      <td>0.818873</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.833300</td>\n",
       "      <td>1.558449</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.826332</td>\n",
       "      <td>0.823830</td>\n",
       "      <td>0.824030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.717800</td>\n",
       "      <td>1.545991</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817808</td>\n",
       "      <td>0.817873</td>\n",
       "      <td>0.817658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.648400</td>\n",
       "      <td>1.572841</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819302</td>\n",
       "      <td>0.819167</td>\n",
       "      <td>0.818804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.585300</td>\n",
       "      <td>1.632493</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817721</td>\n",
       "      <td>0.817452</td>\n",
       "      <td>0.817534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.545800</td>\n",
       "      <td>1.649063</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817956</td>\n",
       "      <td>0.817326</td>\n",
       "      <td>0.817459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.505200</td>\n",
       "      <td>1.689548</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819731</td>\n",
       "      <td>0.819294</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.480300</td>\n",
       "      <td>1.678890</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817612</td>\n",
       "      <td>0.817704</td>\n",
       "      <td>0.817632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.460300</td>\n",
       "      <td>1.713395</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822196</td>\n",
       "      <td>0.822167</td>\n",
       "      <td>0.822180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.442100</td>\n",
       "      <td>1.732822</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817985</td>\n",
       "      <td>0.817957</td>\n",
       "      <td>0.817660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.429000</td>\n",
       "      <td>1.732053</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818772</td>\n",
       "      <td>0.818873</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.413800</td>\n",
       "      <td>1.737721</td>\n",
       "      <td>0.829128</td>\n",
       "      <td>0.829079</td>\n",
       "      <td>0.829050</td>\n",
       "      <td>0.829063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.412100</td>\n",
       "      <td>1.734154</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824479</td>\n",
       "      <td>0.824545</td>\n",
       "      <td>0.824502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 10:43:06,260] Trial 125 finished with value: 0.8245022789605572 and parameters: {'learning_rate': 7.41519116745938e-05, 'weight_decay': 0.008, 'warmup_steps': 12, 'lambda_param': 0.30000000000000004, 'temperature': 5.5}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 126 with params: {'learning_rate': 3.994436916390084e-05, 'weight_decay': 0.003, 'warmup_steps': 3, 'lambda_param': 0.8, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:10, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.656900</td>\n",
       "      <td>1.812512</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792587</td>\n",
       "      <td>0.792130</td>\n",
       "      <td>0.792232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.726400</td>\n",
       "      <td>1.604366</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.794654</td>\n",
       "      <td>0.792961</td>\n",
       "      <td>0.793098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.356000</td>\n",
       "      <td>1.496960</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807281</td>\n",
       "      <td>0.807359</td>\n",
       "      <td>0.807303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.143800</td>\n",
       "      <td>1.511541</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812259</td>\n",
       "      <td>0.811569</td>\n",
       "      <td>0.811704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.999800</td>\n",
       "      <td>1.475889</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817612</td>\n",
       "      <td>0.817704</td>\n",
       "      <td>0.817632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.906100</td>\n",
       "      <td>1.495647</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819977</td>\n",
       "      <td>0.820083</td>\n",
       "      <td>0.819943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.837100</td>\n",
       "      <td>1.544983</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814406</td>\n",
       "      <td>0.814452</td>\n",
       "      <td>0.814219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.784800</td>\n",
       "      <td>1.533880</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.818620</td>\n",
       "      <td>0.818692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.739800</td>\n",
       "      <td>1.567330</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.706600</td>\n",
       "      <td>1.548480</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819926</td>\n",
       "      <td>0.819830</td>\n",
       "      <td>0.819869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.684200</td>\n",
       "      <td>1.562099</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822460</td>\n",
       "      <td>0.821956</td>\n",
       "      <td>0.822077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.668200</td>\n",
       "      <td>1.577043</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818915</td>\n",
       "      <td>0.818792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.650900</td>\n",
       "      <td>1.585570</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818741</td>\n",
       "      <td>0.818788</td>\n",
       "      <td>0.818761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.633300</td>\n",
       "      <td>1.596668</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816546</td>\n",
       "      <td>0.816326</td>\n",
       "      <td>0.816397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.625600</td>\n",
       "      <td>1.598214</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817631</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 10:49:18,596] Trial 126 finished with value: 0.8175739418412338 and parameters: {'learning_rate': 3.994436916390084e-05, 'weight_decay': 0.003, 'warmup_steps': 3, 'lambda_param': 0.8, 'temperature': 3.5}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 127 with params: {'learning_rate': 6.024366240428301e-05, 'weight_decay': 0.008, 'warmup_steps': 11, 'lambda_param': 0.2, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:05, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.432300</td>\n",
       "      <td>1.694331</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795997</td>\n",
       "      <td>0.795592</td>\n",
       "      <td>0.795690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.468700</td>\n",
       "      <td>1.494145</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.804004</td>\n",
       "      <td>0.803644</td>\n",
       "      <td>0.803738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.105800</td>\n",
       "      <td>1.472286</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811910</td>\n",
       "      <td>0.811779</td>\n",
       "      <td>0.811828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>1.532044</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.828213</td>\n",
       "      <td>0.826208</td>\n",
       "      <td>0.826413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.798900</td>\n",
       "      <td>1.497658</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818856</td>\n",
       "      <td>0.818957</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.725800</td>\n",
       "      <td>1.533010</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822478</td>\n",
       "      <td>0.822504</td>\n",
       "      <td>0.822247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.660700</td>\n",
       "      <td>1.586144</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.618000</td>\n",
       "      <td>1.603615</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821270</td>\n",
       "      <td>0.820830</td>\n",
       "      <td>0.820942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.576200</td>\n",
       "      <td>1.617520</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819186</td>\n",
       "      <td>0.819125</td>\n",
       "      <td>0.818806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.549200</td>\n",
       "      <td>1.610259</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822196</td>\n",
       "      <td>0.822167</td>\n",
       "      <td>0.822180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.529100</td>\n",
       "      <td>1.650741</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823433</td>\n",
       "      <td>0.823209</td>\n",
       "      <td>0.823282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.510600</td>\n",
       "      <td>1.665846</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816700</td>\n",
       "      <td>0.816747</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.495400</td>\n",
       "      <td>1.670070</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825623</td>\n",
       "      <td>0.825671</td>\n",
       "      <td>0.825643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.480700</td>\n",
       "      <td>1.678313</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825682</td>\n",
       "      <td>0.825545</td>\n",
       "      <td>0.825596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.476500</td>\n",
       "      <td>1.677066</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824516</td>\n",
       "      <td>0.824419</td>\n",
       "      <td>0.824458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 10:55:25,913] Trial 127 finished with value: 0.8244579440359041 and parameters: {'learning_rate': 6.024366240428301e-05, 'weight_decay': 0.008, 'warmup_steps': 11, 'lambda_param': 0.2, 'temperature': 4.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 128 with params: {'learning_rate': 5.085042171729124e-05, 'weight_decay': 0.008, 'warmup_steps': 6, 'lambda_param': 0.1, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:10, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.523500</td>\n",
       "      <td>1.746641</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794815</td>\n",
       "      <td>0.794466</td>\n",
       "      <td>0.794556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.573300</td>\n",
       "      <td>1.531282</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.802073</td>\n",
       "      <td>0.801181</td>\n",
       "      <td>0.801321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.203000</td>\n",
       "      <td>1.482370</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811880</td>\n",
       "      <td>0.811821</td>\n",
       "      <td>0.811846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.009100</td>\n",
       "      <td>1.516971</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821570</td>\n",
       "      <td>0.820704</td>\n",
       "      <td>0.820860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.875400</td>\n",
       "      <td>1.477245</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818915</td>\n",
       "      <td>0.818792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.794700</td>\n",
       "      <td>1.516310</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819977</td>\n",
       "      <td>0.820083</td>\n",
       "      <td>0.819943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.727800</td>\n",
       "      <td>1.573711</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818741</td>\n",
       "      <td>0.818788</td>\n",
       "      <td>0.818761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.683300</td>\n",
       "      <td>1.580082</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823433</td>\n",
       "      <td>0.823209</td>\n",
       "      <td>0.823282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.640200</td>\n",
       "      <td>1.605372</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.610800</td>\n",
       "      <td>1.581688</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826772</td>\n",
       "      <td>0.826798</td>\n",
       "      <td>0.826784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>1.613769</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822554</td>\n",
       "      <td>0.821914</td>\n",
       "      <td>0.822051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.572200</td>\n",
       "      <td>1.628181</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821209</td>\n",
       "      <td>0.821086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.555900</td>\n",
       "      <td>1.636640</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822196</td>\n",
       "      <td>0.822167</td>\n",
       "      <td>0.822180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.540600</td>\n",
       "      <td>1.646598</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825649</td>\n",
       "      <td>0.825587</td>\n",
       "      <td>0.825614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.534800</td>\n",
       "      <td>1.646145</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825649</td>\n",
       "      <td>0.825587</td>\n",
       "      <td>0.825614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 11:01:38,657] Trial 128 finished with value: 0.8256137673341579 and parameters: {'learning_rate': 5.085042171729124e-05, 'weight_decay': 0.008, 'warmup_steps': 6, 'lambda_param': 0.1, 'temperature': 6.5}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 129 with params: {'learning_rate': 4.391795313898165e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 10, 'lambda_param': 0.2, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 02:01 < 04:03, 17.26 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.610500</td>\n",
       "      <td>1.785799</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798372</td>\n",
       "      <td>0.797845</td>\n",
       "      <td>0.797957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.666800</td>\n",
       "      <td>1.575921</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.798389</td>\n",
       "      <td>0.796340</td>\n",
       "      <td>0.796476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.294600</td>\n",
       "      <td>1.487191</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811859</td>\n",
       "      <td>0.811905</td>\n",
       "      <td>0.811878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.088800</td>\n",
       "      <td>1.508412</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814461</td>\n",
       "      <td>0.813905</td>\n",
       "      <td>0.814028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.948700</td>\n",
       "      <td>1.473263</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816456</td>\n",
       "      <td>0.816536</td>\n",
       "      <td>0.816479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 11:03:41,600] Trial 129 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 130 with params: {'learning_rate': 4.693907671796952e-05, 'weight_decay': 0.008, 'warmup_steps': 14, 'lambda_param': 0.1, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 02:01 < 04:02, 17.34 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.577000</td>\n",
       "      <td>1.768784</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798295</td>\n",
       "      <td>0.797887</td>\n",
       "      <td>0.797986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.625700</td>\n",
       "      <td>1.556261</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.800338</td>\n",
       "      <td>0.798718</td>\n",
       "      <td>0.798867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.252900</td>\n",
       "      <td>1.484590</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815301</td>\n",
       "      <td>0.815326</td>\n",
       "      <td>0.815312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.052200</td>\n",
       "      <td>1.509662</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816858</td>\n",
       "      <td>0.816157</td>\n",
       "      <td>0.816296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.914800</td>\n",
       "      <td>1.473871</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816478</td>\n",
       "      <td>0.816578</td>\n",
       "      <td>0.816490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 11:05:44,009] Trial 130 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 131 with params: {'learning_rate': 0.00010451766015747133, 'weight_decay': 0.007, 'warmup_steps': 8, 'lambda_param': 0.1, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:12 < 02:06, 16.69 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.120100</td>\n",
       "      <td>1.562648</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814711</td>\n",
       "      <td>0.814579</td>\n",
       "      <td>0.814216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.152400</td>\n",
       "      <td>1.498303</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.811412</td>\n",
       "      <td>0.808895</td>\n",
       "      <td>0.809054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.848600</td>\n",
       "      <td>1.499826</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825798</td>\n",
       "      <td>0.825673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.698800</td>\n",
       "      <td>1.569447</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.816034</td>\n",
       "      <td>0.812147</td>\n",
       "      <td>0.812271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.597100</td>\n",
       "      <td>1.619542</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.825104</td>\n",
       "      <td>0.824924</td>\n",
       "      <td>0.824536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.533700</td>\n",
       "      <td>1.649574</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.814070</td>\n",
       "      <td>0.813579</td>\n",
       "      <td>0.813044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.470700</td>\n",
       "      <td>1.737827</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810731</td>\n",
       "      <td>0.810821</td>\n",
       "      <td>0.810750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.436800</td>\n",
       "      <td>1.755246</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821270</td>\n",
       "      <td>0.820830</td>\n",
       "      <td>0.820942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.398200</td>\n",
       "      <td>1.803018</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.815304</td>\n",
       "      <td>0.814747</td>\n",
       "      <td>0.814185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.374500</td>\n",
       "      <td>1.816890</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808438</td>\n",
       "      <td>0.808527</td>\n",
       "      <td>0.808456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 11:09:57,380] Trial 131 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 132 with params: {'learning_rate': 7.298743902935234e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 2, 'lambda_param': 0.1, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:03 < 02:01, 17.30 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.309200</td>\n",
       "      <td>1.634173</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808467</td>\n",
       "      <td>0.808569</td>\n",
       "      <td>0.808466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.353900</td>\n",
       "      <td>1.468398</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806191</td>\n",
       "      <td>0.806022</td>\n",
       "      <td>0.806080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.008500</td>\n",
       "      <td>1.462088</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818772</td>\n",
       "      <td>0.818873</td>\n",
       "      <td>0.818784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.840100</td>\n",
       "      <td>1.563490</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.826111</td>\n",
       "      <td>0.823872</td>\n",
       "      <td>0.824073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.723700</td>\n",
       "      <td>1.544244</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818994</td>\n",
       "      <td>0.819041</td>\n",
       "      <td>0.818806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.654100</td>\n",
       "      <td>1.568282</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.591300</td>\n",
       "      <td>1.636411</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814250</td>\n",
       "      <td>0.814031</td>\n",
       "      <td>0.814102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.551300</td>\n",
       "      <td>1.647457</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816969</td>\n",
       "      <td>0.816115</td>\n",
       "      <td>0.816266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.510800</td>\n",
       "      <td>1.683766</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.818502</td>\n",
       "      <td>0.818125</td>\n",
       "      <td>0.817641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.485800</td>\n",
       "      <td>1.675906</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816456</td>\n",
       "      <td>0.816536</td>\n",
       "      <td>0.816479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 11:14:01,735] Trial 132 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 133 with params: {'learning_rate': 6.557558100496577e-05, 'weight_decay': 0.01, 'warmup_steps': 4, 'lambda_param': 0.2, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:09, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.374100</td>\n",
       "      <td>1.660896</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798095</td>\n",
       "      <td>0.798139</td>\n",
       "      <td>0.798113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.414200</td>\n",
       "      <td>1.479069</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803896</td>\n",
       "      <td>0.803728</td>\n",
       "      <td>0.803785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.060200</td>\n",
       "      <td>1.467108</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818765</td>\n",
       "      <td>0.818704</td>\n",
       "      <td>0.818730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.885900</td>\n",
       "      <td>1.548577</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.827375</td>\n",
       "      <td>0.824998</td>\n",
       "      <td>0.825202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.764200</td>\n",
       "      <td>1.513839</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822228</td>\n",
       "      <td>0.822335</td>\n",
       "      <td>0.822229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.693500</td>\n",
       "      <td>1.539357</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821377</td>\n",
       "      <td>0.821377</td>\n",
       "      <td>0.821101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.629300</td>\n",
       "      <td>1.610421</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818765</td>\n",
       "      <td>0.818704</td>\n",
       "      <td>0.818730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.587600</td>\n",
       "      <td>1.626202</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817956</td>\n",
       "      <td>0.817326</td>\n",
       "      <td>0.817459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.546800</td>\n",
       "      <td>1.638969</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819431</td>\n",
       "      <td>0.819209</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.521100</td>\n",
       "      <td>1.633709</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821035</td>\n",
       "      <td>0.821083</td>\n",
       "      <td>0.821055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.500900</td>\n",
       "      <td>1.679218</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.482000</td>\n",
       "      <td>1.692676</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814596</td>\n",
       "      <td>0.814536</td>\n",
       "      <td>0.814219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.468000</td>\n",
       "      <td>1.692927</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823329</td>\n",
       "      <td>0.823377</td>\n",
       "      <td>0.823349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.453200</td>\n",
       "      <td>1.701198</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824516</td>\n",
       "      <td>0.824419</td>\n",
       "      <td>0.824458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.449900</td>\n",
       "      <td>1.698500</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825649</td>\n",
       "      <td>0.825587</td>\n",
       "      <td>0.825614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 11:20:13,213] Trial 133 finished with value: 0.8256137673341579 and parameters: {'learning_rate': 6.557558100496577e-05, 'weight_decay': 0.01, 'warmup_steps': 4, 'lambda_param': 0.2, 'temperature': 4.5}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 134 with params: {'learning_rate': 2.935107689661603e-05, 'weight_decay': 0.008, 'warmup_steps': 1, 'lambda_param': 0.2, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 02:01 < 04:02, 17.34 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.829400</td>\n",
       "      <td>1.937957</td>\n",
       "      <td>0.785550</td>\n",
       "      <td>0.785862</td>\n",
       "      <td>0.785162</td>\n",
       "      <td>0.785279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.938800</td>\n",
       "      <td>1.690300</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791402</td>\n",
       "      <td>0.791004</td>\n",
       "      <td>0.791099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.569600</td>\n",
       "      <td>1.556133</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807271</td>\n",
       "      <td>0.807317</td>\n",
       "      <td>0.807290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.343000</td>\n",
       "      <td>1.546860</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.807258</td>\n",
       "      <td>0.805601</td>\n",
       "      <td>0.805763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.186400</td>\n",
       "      <td>1.484376</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810832</td>\n",
       "      <td>0.810569</td>\n",
       "      <td>0.810648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 11:22:15,553] Trial 134 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 135 with params: {'learning_rate': 9.741144451379889e-05, 'weight_decay': 0.01, 'warmup_steps': 6, 'lambda_param': 0.4, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:02 < 02:01, 17.32 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.157400</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810541</td>\n",
       "      <td>0.810116</td>\n",
       "      <td>0.809608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.194700</td>\n",
       "      <td>1.504921</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.809746</td>\n",
       "      <td>0.807853</td>\n",
       "      <td>0.808019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.878700</td>\n",
       "      <td>1.484740</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823503</td>\n",
       "      <td>0.823380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.725700</td>\n",
       "      <td>1.567223</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.821696</td>\n",
       "      <td>0.817904</td>\n",
       "      <td>0.818057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.620900</td>\n",
       "      <td>1.606672</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823892</td>\n",
       "      <td>0.823756</td>\n",
       "      <td>0.823391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.555900</td>\n",
       "      <td>1.638929</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.814244</td>\n",
       "      <td>0.813621</td>\n",
       "      <td>0.813032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.492700</td>\n",
       "      <td>1.714998</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809569</td>\n",
       "      <td>0.809569</td>\n",
       "      <td>0.809569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.458100</td>\n",
       "      <td>1.707872</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820083</td>\n",
       "      <td>0.819704</td>\n",
       "      <td>0.819806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.418500</td>\n",
       "      <td>1.777946</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.816732</td>\n",
       "      <td>0.815957</td>\n",
       "      <td>0.815312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.395600</td>\n",
       "      <td>1.773220</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809575</td>\n",
       "      <td>0.809653</td>\n",
       "      <td>0.809597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 11:26:19,617] Trial 135 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 136 with params: {'learning_rate': 7.071981278419155e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 1, 'lambda_param': 0.1, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:03 < 02:02, 17.25 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.325200</td>\n",
       "      <td>1.638848</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807401</td>\n",
       "      <td>0.807314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.367900</td>\n",
       "      <td>1.469129</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807362</td>\n",
       "      <td>0.807148</td>\n",
       "      <td>0.807217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.021700</td>\n",
       "      <td>1.462874</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817612</td>\n",
       "      <td>0.817704</td>\n",
       "      <td>0.817632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.852700</td>\n",
       "      <td>1.558796</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.827161</td>\n",
       "      <td>0.825040</td>\n",
       "      <td>0.825243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.734600</td>\n",
       "      <td>1.532585</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821150</td>\n",
       "      <td>0.821251</td>\n",
       "      <td>0.821092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.665400</td>\n",
       "      <td>1.558429</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817890</td>\n",
       "      <td>0.817915</td>\n",
       "      <td>0.817660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.602000</td>\n",
       "      <td>1.629652</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817669</td>\n",
       "      <td>0.817494</td>\n",
       "      <td>0.817555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.561900</td>\n",
       "      <td>1.641935</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817956</td>\n",
       "      <td>0.817326</td>\n",
       "      <td>0.817459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.521000</td>\n",
       "      <td>1.664109</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.817135</td>\n",
       "      <td>0.816915</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.496100</td>\n",
       "      <td>1.656974</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816447</td>\n",
       "      <td>0.816494</td>\n",
       "      <td>0.816466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 11:30:24,660] Trial 136 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 137 with params: {'learning_rate': 3.388429037629391e-05, 'weight_decay': 0.0, 'warmup_steps': 8, 'lambda_param': 0.1, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:07, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.755100</td>\n",
       "      <td>1.873133</td>\n",
       "      <td>0.786697</td>\n",
       "      <td>0.786965</td>\n",
       "      <td>0.786331</td>\n",
       "      <td>0.786444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.840200</td>\n",
       "      <td>1.651142</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.790039</td>\n",
       "      <td>0.788372</td>\n",
       "      <td>0.788500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.468800</td>\n",
       "      <td>1.524654</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805149</td>\n",
       "      <td>0.805029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.247300</td>\n",
       "      <td>1.525387</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810472</td>\n",
       "      <td>0.809106</td>\n",
       "      <td>0.809271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.095600</td>\n",
       "      <td>1.476122</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814175</td>\n",
       "      <td>0.814116</td>\n",
       "      <td>0.814141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.993800</td>\n",
       "      <td>1.474852</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>1.511404</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811007</td>\n",
       "      <td>0.811032</td>\n",
       "      <td>0.810780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.863700</td>\n",
       "      <td>1.506363</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813078</td>\n",
       "      <td>0.812905</td>\n",
       "      <td>0.812965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.816700</td>\n",
       "      <td>1.527655</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819186</td>\n",
       "      <td>0.819125</td>\n",
       "      <td>0.818806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.780400</td>\n",
       "      <td>1.522672</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820017</td>\n",
       "      <td>0.819746</td>\n",
       "      <td>0.819829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.756300</td>\n",
       "      <td>1.527274</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821356</td>\n",
       "      <td>0.820788</td>\n",
       "      <td>0.820916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.739600</td>\n",
       "      <td>1.539979</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815390</td>\n",
       "      <td>0.815494</td>\n",
       "      <td>0.815355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.722100</td>\n",
       "      <td>1.543694</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.702800</td>\n",
       "      <td>1.555316</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816470</td>\n",
       "      <td>0.816410</td>\n",
       "      <td>0.816436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.694300</td>\n",
       "      <td>1.557323</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815312</td>\n",
       "      <td>0.815284</td>\n",
       "      <td>0.815297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 11:36:33,624] Trial 137 finished with value: 0.8152967721140121 and parameters: {'learning_rate': 3.388429037629391e-05, 'weight_decay': 0.0, 'warmup_steps': 8, 'lambda_param': 0.1, 'temperature': 3.5}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 138 with params: {'learning_rate': 4.074831272656962e-05, 'weight_decay': 0.002, 'warmup_steps': 10, 'lambda_param': 0.7000000000000001, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:06, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.652900</td>\n",
       "      <td>1.807410</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792518</td>\n",
       "      <td>0.792172</td>\n",
       "      <td>0.792260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.715600</td>\n",
       "      <td>1.599133</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.794654</td>\n",
       "      <td>0.792961</td>\n",
       "      <td>0.793098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.343700</td>\n",
       "      <td>1.494366</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808438</td>\n",
       "      <td>0.808527</td>\n",
       "      <td>0.808456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.132300</td>\n",
       "      <td>1.509382</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811060</td>\n",
       "      <td>0.810442</td>\n",
       "      <td>0.810570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.988900</td>\n",
       "      <td>1.474949</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>1.497330</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818856</td>\n",
       "      <td>0.818957</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.827100</td>\n",
       "      <td>1.550206</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814494</td>\n",
       "      <td>0.814494</td>\n",
       "      <td>0.814220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.775600</td>\n",
       "      <td>1.537233</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816501</td>\n",
       "      <td>0.816368</td>\n",
       "      <td>0.816417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.730900</td>\n",
       "      <td>1.573226</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817985</td>\n",
       "      <td>0.817957</td>\n",
       "      <td>0.817660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.698000</td>\n",
       "      <td>1.552003</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818765</td>\n",
       "      <td>0.818704</td>\n",
       "      <td>0.818730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.675700</td>\n",
       "      <td>1.566382</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821270</td>\n",
       "      <td>0.820830</td>\n",
       "      <td>0.820942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.659600</td>\n",
       "      <td>1.582335</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818856</td>\n",
       "      <td>0.818957</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.642400</td>\n",
       "      <td>1.590989</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818741</td>\n",
       "      <td>0.818788</td>\n",
       "      <td>0.818761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.601957</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817669</td>\n",
       "      <td>0.817494</td>\n",
       "      <td>0.817555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.617500</td>\n",
       "      <td>1.603569</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818796</td>\n",
       "      <td>0.818662</td>\n",
       "      <td>0.818712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 11:42:41,998] Trial 138 finished with value: 0.8187119728836396 and parameters: {'learning_rate': 4.074831272656962e-05, 'weight_decay': 0.002, 'warmup_steps': 10, 'lambda_param': 0.7000000000000001, 'temperature': 2.5}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 139 with params: {'learning_rate': 6.070275777903919e-05, 'weight_decay': 0.01, 'warmup_steps': 1, 'lambda_param': 0.30000000000000004, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:09, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.414600</td>\n",
       "      <td>1.690219</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.797183</td>\n",
       "      <td>0.796718</td>\n",
       "      <td>0.796824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.461700</td>\n",
       "      <td>1.492798</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806375</td>\n",
       "      <td>0.805896</td>\n",
       "      <td>0.806007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.101700</td>\n",
       "      <td>1.471839</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811910</td>\n",
       "      <td>0.811779</td>\n",
       "      <td>0.811828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.921600</td>\n",
       "      <td>1.536773</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.828213</td>\n",
       "      <td>0.826208</td>\n",
       "      <td>0.826413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.795900</td>\n",
       "      <td>1.501627</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818856</td>\n",
       "      <td>0.818957</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.723100</td>\n",
       "      <td>1.530571</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820101</td>\n",
       "      <td>0.820167</td>\n",
       "      <td>0.819952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.658500</td>\n",
       "      <td>1.589589</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.615400</td>\n",
       "      <td>1.607340</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821270</td>\n",
       "      <td>0.820830</td>\n",
       "      <td>0.820942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.573800</td>\n",
       "      <td>1.619494</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819186</td>\n",
       "      <td>0.819125</td>\n",
       "      <td>0.818806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.547000</td>\n",
       "      <td>1.612498</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823335</td>\n",
       "      <td>0.823335</td>\n",
       "      <td>0.823335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.526800</td>\n",
       "      <td>1.654277</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822314</td>\n",
       "      <td>0.822040</td>\n",
       "      <td>0.822124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.508300</td>\n",
       "      <td>1.668810</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.493400</td>\n",
       "      <td>1.671471</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825629</td>\n",
       "      <td>0.825629</td>\n",
       "      <td>0.825629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.478500</td>\n",
       "      <td>1.680394</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824556</td>\n",
       "      <td>0.824377</td>\n",
       "      <td>0.824439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.474600</td>\n",
       "      <td>1.678477</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824516</td>\n",
       "      <td>0.824419</td>\n",
       "      <td>0.824458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 11:48:52,998] Trial 139 finished with value: 0.8244579440359041 and parameters: {'learning_rate': 6.070275777903919e-05, 'weight_decay': 0.01, 'warmup_steps': 1, 'lambda_param': 0.30000000000000004, 'temperature': 4.5}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 140 with params: {'learning_rate': 3.533508539495587e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 7, 'lambda_param': 0.2, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:09 < 02:04, 16.89 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.730200</td>\n",
       "      <td>1.855801</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791477</td>\n",
       "      <td>0.790962</td>\n",
       "      <td>0.791069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.810900</td>\n",
       "      <td>1.640632</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.790397</td>\n",
       "      <td>0.788288</td>\n",
       "      <td>0.788402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.439900</td>\n",
       "      <td>1.516704</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805149</td>\n",
       "      <td>0.805029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.220400</td>\n",
       "      <td>1.520044</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.809103</td>\n",
       "      <td>0.808022</td>\n",
       "      <td>0.808177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.070400</td>\n",
       "      <td>1.475107</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816470</td>\n",
       "      <td>0.816410</td>\n",
       "      <td>0.816436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.970700</td>\n",
       "      <td>1.479162</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.900200</td>\n",
       "      <td>1.520290</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811007</td>\n",
       "      <td>0.811032</td>\n",
       "      <td>0.810780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>1.512543</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811954</td>\n",
       "      <td>0.811737</td>\n",
       "      <td>0.811807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.796500</td>\n",
       "      <td>1.537084</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.818094</td>\n",
       "      <td>0.817999</td>\n",
       "      <td>0.817658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.761000</td>\n",
       "      <td>1.528209</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816470</td>\n",
       "      <td>0.816410</td>\n",
       "      <td>0.816436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 11:53:03,317] Trial 140 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 141 with params: {'learning_rate': 4.77700305636362e-05, 'weight_decay': 0.002, 'warmup_steps': 22, 'lambda_param': 0.4, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2105' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2105/6315 02:03 < 04:07, 16.99 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.575700</td>\n",
       "      <td>1.765908</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798295</td>\n",
       "      <td>0.797887</td>\n",
       "      <td>0.797986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.617300</td>\n",
       "      <td>1.552809</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.801409</td>\n",
       "      <td>0.799886</td>\n",
       "      <td>0.800038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.243000</td>\n",
       "      <td>1.484880</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813017</td>\n",
       "      <td>0.812989</td>\n",
       "      <td>0.813002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.043100</td>\n",
       "      <td>1.509580</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816759</td>\n",
       "      <td>0.816199</td>\n",
       "      <td>0.816324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.906400</td>\n",
       "      <td>1.476256</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815348</td>\n",
       "      <td>0.815452</td>\n",
       "      <td>0.815347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 11:55:08,567] Trial 141 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 142 with params: {'learning_rate': 9.890058814850274e-05, 'weight_decay': 0.001, 'warmup_steps': 10, 'lambda_param': 1.0, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:07 < 02:03, 17.01 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.156200</td>\n",
       "      <td>1.577698</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810388</td>\n",
       "      <td>0.810074</td>\n",
       "      <td>0.809617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.186700</td>\n",
       "      <td>1.502415</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.815614</td>\n",
       "      <td>0.813568</td>\n",
       "      <td>0.813746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.872500</td>\n",
       "      <td>1.489269</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.826924</td>\n",
       "      <td>0.826816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>1.575508</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.820680</td>\n",
       "      <td>0.816736</td>\n",
       "      <td>0.816878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.615900</td>\n",
       "      <td>1.611318</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822808</td>\n",
       "      <td>0.822630</td>\n",
       "      <td>0.822242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.551000</td>\n",
       "      <td>1.658161</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.815304</td>\n",
       "      <td>0.814747</td>\n",
       "      <td>0.814185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>1.724104</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813007</td>\n",
       "      <td>0.813031</td>\n",
       "      <td>0.813018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.453600</td>\n",
       "      <td>1.715070</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820083</td>\n",
       "      <td>0.819704</td>\n",
       "      <td>0.819806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.414300</td>\n",
       "      <td>1.797293</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.814634</td>\n",
       "      <td>0.813705</td>\n",
       "      <td>0.813002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.391700</td>\n",
       "      <td>1.796623</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807443</td>\n",
       "      <td>0.807323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 11:59:17,315] Trial 142 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 143 with params: {'learning_rate': 4.0177761144064346e-05, 'weight_decay': 0.006, 'warmup_steps': 9, 'lambda_param': 0.1, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:11, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.659700</td>\n",
       "      <td>1.811335</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791402</td>\n",
       "      <td>0.791004</td>\n",
       "      <td>0.791099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.724600</td>\n",
       "      <td>1.603394</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.794654</td>\n",
       "      <td>0.792961</td>\n",
       "      <td>0.793098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.353000</td>\n",
       "      <td>1.495936</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807281</td>\n",
       "      <td>0.807359</td>\n",
       "      <td>0.807303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.140700</td>\n",
       "      <td>1.509882</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811060</td>\n",
       "      <td>0.810442</td>\n",
       "      <td>0.810570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.996700</td>\n",
       "      <td>1.475123</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.903100</td>\n",
       "      <td>1.495888</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818856</td>\n",
       "      <td>0.818957</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.834100</td>\n",
       "      <td>1.547650</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815596</td>\n",
       "      <td>0.815621</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.782000</td>\n",
       "      <td>1.534855</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817669</td>\n",
       "      <td>0.817494</td>\n",
       "      <td>0.817555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.737100</td>\n",
       "      <td>1.570182</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817985</td>\n",
       "      <td>0.817957</td>\n",
       "      <td>0.817660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.704000</td>\n",
       "      <td>1.550089</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818765</td>\n",
       "      <td>0.818704</td>\n",
       "      <td>0.818730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.681600</td>\n",
       "      <td>1.563608</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821270</td>\n",
       "      <td>0.820830</td>\n",
       "      <td>0.820942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.665500</td>\n",
       "      <td>1.579248</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818915</td>\n",
       "      <td>0.818792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.648300</td>\n",
       "      <td>1.587802</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818741</td>\n",
       "      <td>0.818788</td>\n",
       "      <td>0.818761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.630700</td>\n",
       "      <td>1.598622</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815374</td>\n",
       "      <td>0.815200</td>\n",
       "      <td>0.815260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.623100</td>\n",
       "      <td>1.600402</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817631</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 12:05:31,154] Trial 143 finished with value: 0.8175739418412338 and parameters: {'learning_rate': 4.0177761144064346e-05, 'weight_decay': 0.006, 'warmup_steps': 9, 'lambda_param': 0.1, 'temperature': 6.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 144 with params: {'learning_rate': 2.149685017125216e-05, 'weight_decay': 0.006, 'warmup_steps': 9, 'lambda_param': 0.6000000000000001, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:04 < 02:02, 17.23 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.997100</td>\n",
       "      <td>2.152298</td>\n",
       "      <td>0.764908</td>\n",
       "      <td>0.765599</td>\n",
       "      <td>0.764345</td>\n",
       "      <td>0.764437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.173500</td>\n",
       "      <td>1.780923</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798129</td>\n",
       "      <td>0.798223</td>\n",
       "      <td>0.798139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.788000</td>\n",
       "      <td>1.652209</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794815</td>\n",
       "      <td>0.794466</td>\n",
       "      <td>0.794556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.557100</td>\n",
       "      <td>1.599891</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.801409</td>\n",
       "      <td>0.799886</td>\n",
       "      <td>0.800038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.395800</td>\n",
       "      <td>1.540354</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810324</td>\n",
       "      <td>0.809148</td>\n",
       "      <td>0.809308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.275700</td>\n",
       "      <td>1.496279</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809585</td>\n",
       "      <td>0.809527</td>\n",
       "      <td>0.809552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.192000</td>\n",
       "      <td>1.489586</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805156</td>\n",
       "      <td>0.805233</td>\n",
       "      <td>0.805042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.116900</td>\n",
       "      <td>1.489613</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810723</td>\n",
       "      <td>0.810695</td>\n",
       "      <td>0.810708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.064800</td>\n",
       "      <td>1.480757</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808509</td>\n",
       "      <td>0.808611</td>\n",
       "      <td>0.808474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.022300</td>\n",
       "      <td>1.487338</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812163</td>\n",
       "      <td>0.811611</td>\n",
       "      <td>0.811732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 12:09:36,431] Trial 144 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 145 with params: {'learning_rate': 8.40722463913065e-05, 'weight_decay': 0.006, 'warmup_steps': 16, 'lambda_param': 0.4, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/6315 04:04 < 02:02, 17.24 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.249500</td>\n",
       "      <td>1.609151</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807271</td>\n",
       "      <td>0.807317</td>\n",
       "      <td>0.807290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.269200</td>\n",
       "      <td>1.481645</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814175</td>\n",
       "      <td>0.814116</td>\n",
       "      <td>0.814141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.940900</td>\n",
       "      <td>1.505433</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816620</td>\n",
       "      <td>0.816498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.780100</td>\n",
       "      <td>1.592283</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.827847</td>\n",
       "      <td>0.824914</td>\n",
       "      <td>0.825113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.670700</td>\n",
       "      <td>1.628766</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819302</td>\n",
       "      <td>0.819167</td>\n",
       "      <td>0.818804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.603900</td>\n",
       "      <td>1.622541</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821871</td>\n",
       "      <td>0.821546</td>\n",
       "      <td>0.821086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.541400</td>\n",
       "      <td>1.684366</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811975</td>\n",
       "      <td>0.812074</td>\n",
       "      <td>0.811918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.503400</td>\n",
       "      <td>1.685328</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817786</td>\n",
       "      <td>0.817410</td>\n",
       "      <td>0.817511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.463500</td>\n",
       "      <td>1.709659</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.817982</td>\n",
       "      <td>0.817126</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.440600</td>\n",
       "      <td>1.738532</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817641</td>\n",
       "      <td>0.817746</td>\n",
       "      <td>0.817641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 12:13:41,732] Trial 145 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 146 with params: {'learning_rate': 3.16246935104891e-05, 'weight_decay': 0.0, 'warmup_steps': 9, 'lambda_param': 0.1, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:10, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.795100</td>\n",
       "      <td>1.903639</td>\n",
       "      <td>0.784404</td>\n",
       "      <td>0.784582</td>\n",
       "      <td>0.784078</td>\n",
       "      <td>0.784181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.888800</td>\n",
       "      <td>1.667398</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791899</td>\n",
       "      <td>0.790793</td>\n",
       "      <td>0.790928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.517200</td>\n",
       "      <td>1.538030</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809597</td>\n",
       "      <td>0.809695</td>\n",
       "      <td>0.809608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.293000</td>\n",
       "      <td>1.534271</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811703</td>\n",
       "      <td>0.810232</td>\n",
       "      <td>0.810401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.138500</td>\n",
       "      <td>1.476598</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813041</td>\n",
       "      <td>0.812947</td>\n",
       "      <td>0.812985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.033300</td>\n",
       "      <td>1.469131</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814162</td>\n",
       "      <td>0.814242</td>\n",
       "      <td>0.814185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.960300</td>\n",
       "      <td>1.497149</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808632</td>\n",
       "      <td>0.808695</td>\n",
       "      <td>0.808484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.898800</td>\n",
       "      <td>1.496816</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814206</td>\n",
       "      <td>0.814073</td>\n",
       "      <td>0.814122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.851100</td>\n",
       "      <td>1.513761</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815596</td>\n",
       "      <td>0.815621</td>\n",
       "      <td>0.815367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.813600</td>\n",
       "      <td>1.513964</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.818620</td>\n",
       "      <td>0.818692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.789000</td>\n",
       "      <td>1.517377</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817956</td>\n",
       "      <td>0.817326</td>\n",
       "      <td>0.817459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.771400</td>\n",
       "      <td>1.526568</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814269</td>\n",
       "      <td>0.814368</td>\n",
       "      <td>0.814211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.753900</td>\n",
       "      <td>1.528606</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.733800</td>\n",
       "      <td>1.540190</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816470</td>\n",
       "      <td>0.816410</td>\n",
       "      <td>0.816436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>1.542171</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817631</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 12:19:53,881] Trial 146 finished with value: 0.8175739418412338 and parameters: {'learning_rate': 3.16246935104891e-05, 'weight_decay': 0.0, 'warmup_steps': 9, 'lambda_param': 0.1, 'temperature': 2.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 147 with params: {'learning_rate': 5.6115221015602515e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 5, 'lambda_param': 0.4, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:09, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.466000</td>\n",
       "      <td>1.717396</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.793775</td>\n",
       "      <td>0.793256</td>\n",
       "      <td>0.793365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.511800</td>\n",
       "      <td>1.507835</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805267</td>\n",
       "      <td>0.804728</td>\n",
       "      <td>0.804845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.145500</td>\n",
       "      <td>1.477247</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811910</td>\n",
       "      <td>0.811779</td>\n",
       "      <td>0.811828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.959300</td>\n",
       "      <td>1.525886</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.824142</td>\n",
       "      <td>0.822914</td>\n",
       "      <td>0.823093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>1.485160</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818856</td>\n",
       "      <td>0.818957</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.753900</td>\n",
       "      <td>1.523412</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819977</td>\n",
       "      <td>0.820083</td>\n",
       "      <td>0.819943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.688400</td>\n",
       "      <td>1.579697</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819889</td>\n",
       "      <td>0.819915</td>\n",
       "      <td>0.819901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.645100</td>\n",
       "      <td>1.594650</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822314</td>\n",
       "      <td>0.822040</td>\n",
       "      <td>0.822124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.602500</td>\n",
       "      <td>1.610401</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815799</td>\n",
       "      <td>0.815705</td>\n",
       "      <td>0.815365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.574500</td>\n",
       "      <td>1.595725</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825631</td>\n",
       "      <td>0.825714</td>\n",
       "      <td>0.825655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.554200</td>\n",
       "      <td>1.633526</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825865</td>\n",
       "      <td>0.825419</td>\n",
       "      <td>0.825533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.535800</td>\n",
       "      <td>1.647995</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818915</td>\n",
       "      <td>0.818792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.520300</td>\n",
       "      <td>1.654351</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824516</td>\n",
       "      <td>0.824419</td>\n",
       "      <td>0.824458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.505400</td>\n",
       "      <td>1.663528</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826811</td>\n",
       "      <td>0.826713</td>\n",
       "      <td>0.826753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.500600</td>\n",
       "      <td>1.662286</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825682</td>\n",
       "      <td>0.825545</td>\n",
       "      <td>0.825596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 12:26:05,392] Trial 147 finished with value: 0.8255963283437546 and parameters: {'learning_rate': 5.6115221015602515e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 5, 'lambda_param': 0.4, 'temperature': 6.5}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 148 with params: {'learning_rate': 6.974273840162806e-05, 'weight_decay': 0.004, 'warmup_steps': 16, 'lambda_param': 0.1, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:09, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.353900</td>\n",
       "      <td>1.644390</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.800560</td>\n",
       "      <td>0.800442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.379500</td>\n",
       "      <td>1.468665</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807417</td>\n",
       "      <td>0.807106</td>\n",
       "      <td>0.807193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.028800</td>\n",
       "      <td>1.464613</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817597</td>\n",
       "      <td>0.817662</td>\n",
       "      <td>0.817620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.858600</td>\n",
       "      <td>1.552002</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.826111</td>\n",
       "      <td>0.823872</td>\n",
       "      <td>0.824073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.739900</td>\n",
       "      <td>1.527478</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822270</td>\n",
       "      <td>0.822377</td>\n",
       "      <td>0.822236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.670800</td>\n",
       "      <td>1.557127</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.818094</td>\n",
       "      <td>0.817999</td>\n",
       "      <td>0.817658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.606600</td>\n",
       "      <td>1.621569</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821059</td>\n",
       "      <td>0.820999</td>\n",
       "      <td>0.821025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.566100</td>\n",
       "      <td>1.638599</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815657</td>\n",
       "      <td>0.815031</td>\n",
       "      <td>0.815163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.525400</td>\n",
       "      <td>1.658874</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821871</td>\n",
       "      <td>0.821546</td>\n",
       "      <td>0.821086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.500300</td>\n",
       "      <td>1.649827</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818741</td>\n",
       "      <td>0.818788</td>\n",
       "      <td>0.818761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.480100</td>\n",
       "      <td>1.694941</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.816452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.461300</td>\n",
       "      <td>1.709463</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.447900</td>\n",
       "      <td>1.707696</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821044</td>\n",
       "      <td>0.821125</td>\n",
       "      <td>0.821067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.432800</td>\n",
       "      <td>1.714266</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823354</td>\n",
       "      <td>0.823293</td>\n",
       "      <td>0.823319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.430200</td>\n",
       "      <td>1.712465</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822196</td>\n",
       "      <td>0.822167</td>\n",
       "      <td>0.822180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 12:32:16,844] Trial 148 finished with value: 0.8221801222215643 and parameters: {'learning_rate': 6.974273840162806e-05, 'weight_decay': 0.004, 'warmup_steps': 16, 'lambda_param': 0.1, 'temperature': 2.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 149 with params: {'learning_rate': 8.221432133065498e-05, 'weight_decay': 0.006, 'warmup_steps': 1, 'lambda_param': 0.2, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6315/6315 06:10, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.240000</td>\n",
       "      <td>1.609083</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813025</td>\n",
       "      <td>0.813116</td>\n",
       "      <td>0.813044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.280200</td>\n",
       "      <td>1.484442</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810723</td>\n",
       "      <td>0.810695</td>\n",
       "      <td>0.810708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.951600</td>\n",
       "      <td>1.500191</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818856</td>\n",
       "      <td>0.818957</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.789700</td>\n",
       "      <td>1.602838</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.828375</td>\n",
       "      <td>0.824830</td>\n",
       "      <td>0.825017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.679100</td>\n",
       "      <td>1.622210</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816789</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.611900</td>\n",
       "      <td>1.617079</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.818217</td>\n",
       "      <td>0.818041</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.549600</td>\n",
       "      <td>1.679772</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810802</td>\n",
       "      <td>0.810906</td>\n",
       "      <td>0.810768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.511000</td>\n",
       "      <td>1.683468</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817721</td>\n",
       "      <td>0.817452</td>\n",
       "      <td>0.817534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.471100</td>\n",
       "      <td>1.706438</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.816732</td>\n",
       "      <td>0.815957</td>\n",
       "      <td>0.815312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.447500</td>\n",
       "      <td>1.734621</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816456</td>\n",
       "      <td>0.816536</td>\n",
       "      <td>0.816479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.427500</td>\n",
       "      <td>1.741164</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813007</td>\n",
       "      <td>0.813031</td>\n",
       "      <td>0.813018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.410500</td>\n",
       "      <td>1.762597</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813396</td>\n",
       "      <td>0.813368</td>\n",
       "      <td>0.813073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.399100</td>\n",
       "      <td>1.758157</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815319</td>\n",
       "      <td>0.815410</td>\n",
       "      <td>0.815338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.384300</td>\n",
       "      <td>1.761708</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821035</td>\n",
       "      <td>0.821083</td>\n",
       "      <td>0.821055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.382400</td>\n",
       "      <td>1.761809</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821066</td>\n",
       "      <td>0.821167</td>\n",
       "      <td>0.821077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 12:38:29,633] Trial 149 finished with value: 0.8210773868712218 and parameters: {'learning_rate': 8.221432133065498e-05, 'weight_decay': 0.006, 'warmup_steps': 1, 'lambda_param': 0.2, 'temperature': 7.0}. Best is trial 37 with value: 0.8267526114341277.\n"
     ]
    }
   ],
   "source": [
    "best_trial2 = trainer.hyperparameter_search(\n",
    "    direction=\"maximize\",\n",
    "    backend=\"optuna\",\n",
    "    hp_space=hp_space,\n",
    "    compute_objective=lambda metrics: metrics[\"eval_f1\"],\n",
    "    pruner=pruner,\n",
    "    sampler=sampler,\n",
    "    study_name=\"Distilation\",\n",
    "    n_trials=150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "25c277ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BestRun(run_id='37', objective=0.8267526114341277, hyperparameters={'learning_rate': 4.729948829550423e-05, 'weight_decay': 0.002, 'warmup_steps': 9, 'lambda_param': 0.8, 'temperature': 2.0}, run_summary=None)\n"
     ]
    }
   ],
   "source": [
    "print(best_trial2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc14977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nápočet epoch na steps\n",
    "data_length = len(train_aug)\n",
    "min_r = math.ceil(data_length/batch_size)*5\n",
    "max_r = math.ceil(data_length/batch_size)*num_epochs\n",
    "warm_up = math.ceil(data_length/batch_size/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b28705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f24245a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bert-base_aug_hp-search\", logging_dir=f\"~/logs/{DATASET}/bert-base_aug_hp-search\", epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ebd4d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_space(trial):\n",
    "    params =  {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 5e-4, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0, 1e-2, step=1e-3),\n",
    "        \"warmup_steps\" : trial.suggest_int(\"warmup_steps\", 0, warm_up),\n",
    "    }\n",
    "    print(f\"Trial {trial.number} with params: {params}\")\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dc12e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pruner = optuna.pruners.HyperbandPruner(min_resource=min_r, max_resource=max_r, reduction_factor=2, bootstrap_count=2)\n",
    "sampler = optuna.samplers.TPESampler(seed=42, multivariate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4414ae99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    args=training_args,\n",
    "    train_dataset=train_aug,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    model_init = lambda: get_Bert()\n",
    ")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbdaec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 17:37:29,505] A new study created in memory with name: Test-base-aug\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 with params: {'learning_rate': 4.3284502212938785e-05, 'weight_decay': 0.01, 'warmup_steps': 169}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11475' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11475/34425 18:32 < 37:04, 10.32 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.343500</td>\n",
       "      <td>0.427888</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.812774</td>\n",
       "      <td>0.811495</td>\n",
       "      <td>0.810670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.202500</td>\n",
       "      <td>0.470815</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818765</td>\n",
       "      <td>0.818704</td>\n",
       "      <td>0.818730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.164500</td>\n",
       "      <td>0.521956</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.802823</td>\n",
       "      <td>0.802517</td>\n",
       "      <td>0.802603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.141800</td>\n",
       "      <td>0.555934</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806338</td>\n",
       "      <td>0.806401</td>\n",
       "      <td>0.806190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.125800</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.799351</td>\n",
       "      <td>0.799097</td>\n",
       "      <td>0.799172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 17:56:03,729] Trial 0 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 with params: {'learning_rate': 0.00010401663679887307, 'weight_decay': 0.001, 'warmup_steps': 36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22950' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22950/34425 36:57 < 18:28, 10.35 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.269000</td>\n",
       "      <td>0.482056</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.800389</td>\n",
       "      <td>0.800434</td>\n",
       "      <td>0.800407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.148800</td>\n",
       "      <td>0.549983</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.796797</td>\n",
       "      <td>0.795298</td>\n",
       "      <td>0.795441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.112300</td>\n",
       "      <td>0.673818</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.806021</td>\n",
       "      <td>0.804475</td>\n",
       "      <td>0.804635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.090400</td>\n",
       "      <td>0.763311</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810802</td>\n",
       "      <td>0.810906</td>\n",
       "      <td>0.810768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>0.892840</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.802770</td>\n",
       "      <td>0.802560</td>\n",
       "      <td>0.802627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.065300</td>\n",
       "      <td>0.980753</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.805523</td>\n",
       "      <td>0.803181</td>\n",
       "      <td>0.803328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>1.043335</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.797112</td>\n",
       "      <td>0.796761</td>\n",
       "      <td>0.796851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.050200</td>\n",
       "      <td>1.141318</td>\n",
       "      <td>0.785550</td>\n",
       "      <td>0.787026</td>\n",
       "      <td>0.784826</td>\n",
       "      <td>0.784926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.046200</td>\n",
       "      <td>1.168056</td>\n",
       "      <td>0.786697</td>\n",
       "      <td>0.786698</td>\n",
       "      <td>0.786499</td>\n",
       "      <td>0.786561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.042600</td>\n",
       "      <td>1.215207</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791213</td>\n",
       "      <td>0.791256</td>\n",
       "      <td>0.791231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 18:33:02,144] Trial 1 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 with params: {'learning_rate': 1.2551115172973821e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 138}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11475' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11475/34425 18:31 < 37:03, 10.32 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.454900</td>\n",
       "      <td>0.433953</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.804401</td>\n",
       "      <td>0.803868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.312700</td>\n",
       "      <td>0.419962</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811945</td>\n",
       "      <td>0.811327</td>\n",
       "      <td>0.810738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.263800</td>\n",
       "      <td>0.419399</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819302</td>\n",
       "      <td>0.819167</td>\n",
       "      <td>0.818804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.234100</td>\n",
       "      <td>0.432901</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824564</td>\n",
       "      <td>0.824672</td>\n",
       "      <td>0.824530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.214000</td>\n",
       "      <td>0.440550</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821066</td>\n",
       "      <td>0.821167</td>\n",
       "      <td>0.821077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 18:51:34,537] Trial 2 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 with params: {'learning_rate': 0.00015958573588141273, 'weight_decay': 0.0, 'warmup_steps': 224}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22950' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22950/34425 37:05 < 18:32, 10.31 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.258600</td>\n",
       "      <td>0.520411</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.796163</td>\n",
       "      <td>0.795508</td>\n",
       "      <td>0.795630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.129500</td>\n",
       "      <td>0.612431</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.792708</td>\n",
       "      <td>0.790583</td>\n",
       "      <td>0.790702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.092800</td>\n",
       "      <td>0.761443</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803896</td>\n",
       "      <td>0.803728</td>\n",
       "      <td>0.803785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.895893</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.809035</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>0.808480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.058700</td>\n",
       "      <td>0.989196</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.801600</td>\n",
       "      <td>0.801433</td>\n",
       "      <td>0.801490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.050200</td>\n",
       "      <td>1.014527</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.803211</td>\n",
       "      <td>0.800886</td>\n",
       "      <td>0.801027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.043400</td>\n",
       "      <td>1.132012</td>\n",
       "      <td>0.786697</td>\n",
       "      <td>0.786662</td>\n",
       "      <td>0.786541</td>\n",
       "      <td>0.786585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>1.174615</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.798808</td>\n",
       "      <td>0.797676</td>\n",
       "      <td>0.797821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>1.250374</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794653</td>\n",
       "      <td>0.794677</td>\n",
       "      <td>0.794664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>1.315318</td>\n",
       "      <td>0.783257</td>\n",
       "      <td>0.783237</td>\n",
       "      <td>0.783331</td>\n",
       "      <td>0.783234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 19:28:41,123] Trial 3 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 with params: {'learning_rate': 0.00025959425503112657, 'weight_decay': 0.002, 'warmup_steps': 42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11475' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11475/34425 18:34 < 37:08, 10.30 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.222400</td>\n",
       "      <td>0.603142</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.789264</td>\n",
       "      <td>0.788625</td>\n",
       "      <td>0.788741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.108700</td>\n",
       "      <td>0.718453</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791775</td>\n",
       "      <td>0.790835</td>\n",
       "      <td>0.790967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>0.862499</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791466</td>\n",
       "      <td>0.791509</td>\n",
       "      <td>0.791283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>1.000960</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795817</td>\n",
       "      <td>0.795761</td>\n",
       "      <td>0.795785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>1.135036</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792575</td>\n",
       "      <td>0.792635</td>\n",
       "      <td>0.792429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 19:47:16,756] Trial 4 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 with params: {'learning_rate': 2.049268011541735e-05, 'weight_decay': 0.003, 'warmup_steps': 121}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34425' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34425/34425 56:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.407200</td>\n",
       "      <td>0.426480</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.814634</td>\n",
       "      <td>0.813705</td>\n",
       "      <td>0.813002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.265200</td>\n",
       "      <td>0.425141</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.824498</td>\n",
       "      <td>0.823924</td>\n",
       "      <td>0.823361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.218900</td>\n",
       "      <td>0.436451</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824620</td>\n",
       "      <td>0.824714</td>\n",
       "      <td>0.824536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.465637</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>0.818746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.175500</td>\n",
       "      <td>0.490894</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813054</td>\n",
       "      <td>0.813158</td>\n",
       "      <td>0.813053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.163500</td>\n",
       "      <td>0.513377</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815348</td>\n",
       "      <td>0.815452</td>\n",
       "      <td>0.815347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.153000</td>\n",
       "      <td>0.526320</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814494</td>\n",
       "      <td>0.814494</td>\n",
       "      <td>0.814220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.145400</td>\n",
       "      <td>0.554926</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806239</td>\n",
       "      <td>0.805980</td>\n",
       "      <td>0.806058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.139700</td>\n",
       "      <td>0.566202</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808487</td>\n",
       "      <td>0.808316</td>\n",
       "      <td>0.808375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.135600</td>\n",
       "      <td>0.578477</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810858</td>\n",
       "      <td>0.810948</td>\n",
       "      <td>0.810774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.131000</td>\n",
       "      <td>0.584429</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.803977</td>\n",
       "      <td>0.804065</td>\n",
       "      <td>0.803893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.127700</td>\n",
       "      <td>0.612062</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810783</td>\n",
       "      <td>0.810611</td>\n",
       "      <td>0.810670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.125800</td>\n",
       "      <td>0.612920</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.804996</td>\n",
       "      <td>0.804938</td>\n",
       "      <td>0.804963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.624148</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.800400</td>\n",
       "      <td>0.800476</td>\n",
       "      <td>0.800421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.624791</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.801536</td>\n",
       "      <td>0.801560</td>\n",
       "      <td>0.801547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 20:43:32,010] Trial 5 finished with value: 0.8015467816601527 and parameters: {'learning_rate': 2.049268011541735e-05, 'weight_decay': 0.003, 'warmup_steps': 121}. Best is trial 5 with value: 0.8015467816601527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 with params: {'learning_rate': 5.4182823195332406e-05, 'weight_decay': 0.003, 'warmup_steps': 141}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11475' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11475/34425 18:57 < 37:55, 10.09 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.322700</td>\n",
       "      <td>0.434832</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.815304</td>\n",
       "      <td>0.814747</td>\n",
       "      <td>0.814185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.186800</td>\n",
       "      <td>0.491836</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811060</td>\n",
       "      <td>0.810442</td>\n",
       "      <td>0.810570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.150500</td>\n",
       "      <td>0.557616</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806462</td>\n",
       "      <td>0.805854</td>\n",
       "      <td>0.805978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>0.603561</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807449</td>\n",
       "      <td>0.807527</td>\n",
       "      <td>0.807335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.111900</td>\n",
       "      <td>0.680761</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794885</td>\n",
       "      <td>0.794424</td>\n",
       "      <td>0.794528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 21:02:30,713] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 with params: {'learning_rate': 1.7258215396625005e-05, 'weight_decay': 0.003, 'warmup_steps': 84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34425' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34425/34425 57:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.421600</td>\n",
       "      <td>0.427752</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.813187</td>\n",
       "      <td>0.812495</td>\n",
       "      <td>0.811878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.281500</td>\n",
       "      <td>0.421546</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.821332</td>\n",
       "      <td>0.820546</td>\n",
       "      <td>0.819901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.427592</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.827164</td>\n",
       "      <td>0.827134</td>\n",
       "      <td>0.826835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.206200</td>\n",
       "      <td>0.451062</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822185</td>\n",
       "      <td>0.822251</td>\n",
       "      <td>0.822208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.188200</td>\n",
       "      <td>0.470256</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815303</td>\n",
       "      <td>0.815368</td>\n",
       "      <td>0.815326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.175700</td>\n",
       "      <td>0.491746</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814185</td>\n",
       "      <td>0.814284</td>\n",
       "      <td>0.814196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.501495</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808713</td>\n",
       "      <td>0.808737</td>\n",
       "      <td>0.808486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.524967</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809658</td>\n",
       "      <td>0.809443</td>\n",
       "      <td>0.809512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.151600</td>\n",
       "      <td>0.535827</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808451</td>\n",
       "      <td>0.808359</td>\n",
       "      <td>0.808395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.147500</td>\n",
       "      <td>0.544024</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810802</td>\n",
       "      <td>0.810906</td>\n",
       "      <td>0.810768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.143100</td>\n",
       "      <td>0.549029</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810731</td>\n",
       "      <td>0.810821</td>\n",
       "      <td>0.810750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.139900</td>\n",
       "      <td>0.571801</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808428</td>\n",
       "      <td>0.808401</td>\n",
       "      <td>0.808413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.137700</td>\n",
       "      <td>0.572250</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808428</td>\n",
       "      <td>0.808401</td>\n",
       "      <td>0.808413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.135700</td>\n",
       "      <td>0.579858</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809575</td>\n",
       "      <td>0.809653</td>\n",
       "      <td>0.809597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.135700</td>\n",
       "      <td>0.580438</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807271</td>\n",
       "      <td>0.807317</td>\n",
       "      <td>0.807290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 21:59:45,562] Trial 7 finished with value: 0.807289775687067 and parameters: {'learning_rate': 1.7258215396625005e-05, 'weight_decay': 0.003, 'warmup_steps': 84}. Best is trial 7 with value: 0.807289775687067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 with params: {'learning_rate': 5.954553793888986e-05, 'weight_decay': 0.008, 'warmup_steps': 46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22950' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22950/34425 38:08 < 19:04, 10.03 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.309300</td>\n",
       "      <td>0.441640</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.814244</td>\n",
       "      <td>0.813621</td>\n",
       "      <td>0.813032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.180600</td>\n",
       "      <td>0.496529</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807767</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.807080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.144700</td>\n",
       "      <td>0.576101</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806562</td>\n",
       "      <td>0.805812</td>\n",
       "      <td>0.805947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.122100</td>\n",
       "      <td>0.631857</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805230</td>\n",
       "      <td>0.805275</td>\n",
       "      <td>0.805045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.106200</td>\n",
       "      <td>0.727037</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.796645</td>\n",
       "      <td>0.795340</td>\n",
       "      <td>0.795483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.094900</td>\n",
       "      <td>0.766699</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791899</td>\n",
       "      <td>0.790793</td>\n",
       "      <td>0.790928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.832209</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795803</td>\n",
       "      <td>0.795803</td>\n",
       "      <td>0.795803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.076700</td>\n",
       "      <td>0.939559</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.800066</td>\n",
       "      <td>0.797381</td>\n",
       "      <td>0.797499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.954106</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791227</td>\n",
       "      <td>0.791172</td>\n",
       "      <td>0.791195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.991315</td>\n",
       "      <td>0.790138</td>\n",
       "      <td>0.790072</td>\n",
       "      <td>0.790046</td>\n",
       "      <td>0.790058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 22:37:54,877] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 with params: {'learning_rate': 7.475992999956501e-05, 'weight_decay': 0.006, 'warmup_steps': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11475' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11475/34425 18:33 < 37:07, 10.30 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.455015</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811007</td>\n",
       "      <td>0.811032</td>\n",
       "      <td>0.810780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.167200</td>\n",
       "      <td>0.518119</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.809244</td>\n",
       "      <td>0.807980</td>\n",
       "      <td>0.808141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.131400</td>\n",
       "      <td>0.618824</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.801111</td>\n",
       "      <td>0.799971</td>\n",
       "      <td>0.800118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.108800</td>\n",
       "      <td>0.683271</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808467</td>\n",
       "      <td>0.808569</td>\n",
       "      <td>0.808466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.092800</td>\n",
       "      <td>0.817841</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.793118</td>\n",
       "      <td>0.791919</td>\n",
       "      <td>0.792057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 22:56:29,707] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 with params: {'learning_rate': 1.0829253790120454e-05, 'weight_decay': 0.001, 'warmup_steps': 33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22950' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22950/34425 37:09 < 18:34, 10.29 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.464900</td>\n",
       "      <td>0.437980</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.801351</td>\n",
       "      <td>0.800939</td>\n",
       "      <td>0.800432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.326900</td>\n",
       "      <td>0.420554</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.815682</td>\n",
       "      <td>0.814831</td>\n",
       "      <td>0.814158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.278300</td>\n",
       "      <td>0.418483</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.248000</td>\n",
       "      <td>0.427841</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823506</td>\n",
       "      <td>0.823588</td>\n",
       "      <td>0.823391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.227100</td>\n",
       "      <td>0.431849</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823503</td>\n",
       "      <td>0.823380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.212900</td>\n",
       "      <td>0.440911</td>\n",
       "      <td>0.827982</td>\n",
       "      <td>0.827982</td>\n",
       "      <td>0.828092</td>\n",
       "      <td>0.827967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.200700</td>\n",
       "      <td>0.449416</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823506</td>\n",
       "      <td>0.823588</td>\n",
       "      <td>0.823391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.462048</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825629</td>\n",
       "      <td>0.825629</td>\n",
       "      <td>0.825629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.185900</td>\n",
       "      <td>0.471645</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820017</td>\n",
       "      <td>0.819746</td>\n",
       "      <td>0.819829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.181400</td>\n",
       "      <td>0.473546</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 23:33:40,624] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 with params: {'learning_rate': 1.3099353602199278e-05, 'weight_decay': 0.002, 'warmup_steps': 145}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34425' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34425/34425 55:46, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.451100</td>\n",
       "      <td>0.432882</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.804401</td>\n",
       "      <td>0.803868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.308600</td>\n",
       "      <td>0.419943</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811945</td>\n",
       "      <td>0.811327</td>\n",
       "      <td>0.810738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.259700</td>\n",
       "      <td>0.419925</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.820336</td>\n",
       "      <td>0.819948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.230100</td>\n",
       "      <td>0.434665</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825737</td>\n",
       "      <td>0.825840</td>\n",
       "      <td>0.825680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.210300</td>\n",
       "      <td>0.443637</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821066</td>\n",
       "      <td>0.821167</td>\n",
       "      <td>0.821077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.196800</td>\n",
       "      <td>0.459222</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822200</td>\n",
       "      <td>0.822293</td>\n",
       "      <td>0.822219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.185300</td>\n",
       "      <td>0.468314</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.177500</td>\n",
       "      <td>0.485418</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816501</td>\n",
       "      <td>0.816368</td>\n",
       "      <td>0.816417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.171300</td>\n",
       "      <td>0.495313</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816470</td>\n",
       "      <td>0.816410</td>\n",
       "      <td>0.816436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.167100</td>\n",
       "      <td>0.499449</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.162700</td>\n",
       "      <td>0.502836</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811891</td>\n",
       "      <td>0.811990</td>\n",
       "      <td>0.811902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.159600</td>\n",
       "      <td>0.519806</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809565</td>\n",
       "      <td>0.809611</td>\n",
       "      <td>0.809584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.157200</td>\n",
       "      <td>0.520015</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811869</td>\n",
       "      <td>0.811947</td>\n",
       "      <td>0.811891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.155400</td>\n",
       "      <td>0.525142</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810731</td>\n",
       "      <td>0.810821</td>\n",
       "      <td>0.810750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.155500</td>\n",
       "      <td>0.525211</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810731</td>\n",
       "      <td>0.810821</td>\n",
       "      <td>0.810750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 00:29:28,958] Trial 11 finished with value: 0.8107497010902807 and parameters: {'learning_rate': 1.3099353602199278e-05, 'weight_decay': 0.002, 'warmup_steps': 145}. Best is trial 11 with value: 0.8107497010902807.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 with params: {'learning_rate': 1.0500886098732501e-05, 'weight_decay': 0.0, 'warmup_steps': 210}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22950' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22950/34425 36:15 < 18:07, 10.55 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.476000</td>\n",
       "      <td>0.439287</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.799216</td>\n",
       "      <td>0.798687</td>\n",
       "      <td>0.798127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.330300</td>\n",
       "      <td>0.420917</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.815304</td>\n",
       "      <td>0.814747</td>\n",
       "      <td>0.814185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.281400</td>\n",
       "      <td>0.418668</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.427170</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823506</td>\n",
       "      <td>0.823588</td>\n",
       "      <td>0.823391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.229800</td>\n",
       "      <td>0.430807</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824522</td>\n",
       "      <td>0.824630</td>\n",
       "      <td>0.824523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.215400</td>\n",
       "      <td>0.439175</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826858</td>\n",
       "      <td>0.826966</td>\n",
       "      <td>0.826824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.203100</td>\n",
       "      <td>0.447630</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824620</td>\n",
       "      <td>0.824714</td>\n",
       "      <td>0.824536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.194900</td>\n",
       "      <td>0.459492</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825629</td>\n",
       "      <td>0.825629</td>\n",
       "      <td>0.825629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.188200</td>\n",
       "      <td>0.468992</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820017</td>\n",
       "      <td>0.819746</td>\n",
       "      <td>0.819829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.183600</td>\n",
       "      <td>0.470685</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 01:05:45,126] Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13 with params: {'learning_rate': 1.712316550761407e-05, 'weight_decay': 0.005, 'warmup_steps': 60}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34425' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34425/34425 55:32, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.421300</td>\n",
       "      <td>0.427899</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.812132</td>\n",
       "      <td>0.811369</td>\n",
       "      <td>0.810724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.421412</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.822385</td>\n",
       "      <td>0.821672</td>\n",
       "      <td>0.821055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.234600</td>\n",
       "      <td>0.427296</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.827164</td>\n",
       "      <td>0.827134</td>\n",
       "      <td>0.826835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.206800</td>\n",
       "      <td>0.450440</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822185</td>\n",
       "      <td>0.822251</td>\n",
       "      <td>0.822208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.188800</td>\n",
       "      <td>0.469307</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815319</td>\n",
       "      <td>0.815410</td>\n",
       "      <td>0.815338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.176300</td>\n",
       "      <td>0.490723</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814185</td>\n",
       "      <td>0.814284</td>\n",
       "      <td>0.814196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.165600</td>\n",
       "      <td>0.500328</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810926</td>\n",
       "      <td>0.810990</td>\n",
       "      <td>0.810778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.158000</td>\n",
       "      <td>0.523466</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809658</td>\n",
       "      <td>0.809443</td>\n",
       "      <td>0.809512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.152200</td>\n",
       "      <td>0.534463</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808451</td>\n",
       "      <td>0.808359</td>\n",
       "      <td>0.808395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.148100</td>\n",
       "      <td>0.542435</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811975</td>\n",
       "      <td>0.812074</td>\n",
       "      <td>0.811918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.143700</td>\n",
       "      <td>0.547300</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809597</td>\n",
       "      <td>0.809695</td>\n",
       "      <td>0.809608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.140500</td>\n",
       "      <td>0.569906</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807275</td>\n",
       "      <td>0.807275</td>\n",
       "      <td>0.807275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.138300</td>\n",
       "      <td>0.570275</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808428</td>\n",
       "      <td>0.808401</td>\n",
       "      <td>0.808413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.136300</td>\n",
       "      <td>0.577730</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809575</td>\n",
       "      <td>0.809653</td>\n",
       "      <td>0.809597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.136300</td>\n",
       "      <td>0.578400</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.807271</td>\n",
       "      <td>0.807317</td>\n",
       "      <td>0.807290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 03:01:19,781] Trial 13 finished with value: 0.807289775687067 and parameters: {'learning_rate': 1.712316550761407e-05, 'weight_decay': 0.005, 'warmup_steps': 60}. Best is trial 11 with value: 0.8107497010902807.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 with params: {'learning_rate': 1.622732935569823e-05, 'weight_decay': 0.006, 'warmup_steps': 208}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22950' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22950/34425 37:19 < 18:39, 10.25 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.433800</td>\n",
       "      <td>0.428627</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810708</td>\n",
       "      <td>0.810158</td>\n",
       "      <td>0.809597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.287800</td>\n",
       "      <td>0.420898</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.815486</td>\n",
       "      <td>0.814789</td>\n",
       "      <td>0.814172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.239600</td>\n",
       "      <td>0.425328</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823892</td>\n",
       "      <td>0.823756</td>\n",
       "      <td>0.823391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.211300</td>\n",
       "      <td>0.446719</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822200</td>\n",
       "      <td>0.822293</td>\n",
       "      <td>0.822219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.192900</td>\n",
       "      <td>0.463520</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.817620</td>\n",
       "      <td>0.817607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.180200</td>\n",
       "      <td>0.484477</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815319</td>\n",
       "      <td>0.815410</td>\n",
       "      <td>0.815338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.169300</td>\n",
       "      <td>0.494203</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809906</td>\n",
       "      <td>0.809906</td>\n",
       "      <td>0.809633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.161700</td>\n",
       "      <td>0.516274</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810895</td>\n",
       "      <td>0.810527</td>\n",
       "      <td>0.810624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.155800</td>\n",
       "      <td>0.526253</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811880</td>\n",
       "      <td>0.811821</td>\n",
       "      <td>0.811846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.151700</td>\n",
       "      <td>0.533862</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809737</td>\n",
       "      <td>0.809617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 03:38:39,857] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 with params: {'learning_rate': 1.071934208458698e-05, 'weight_decay': 0.001, 'warmup_steps': 134}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34425' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34425/34425 55:37, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.470300</td>\n",
       "      <td>0.438454</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.800282</td>\n",
       "      <td>0.799813</td>\n",
       "      <td>0.799280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.328100</td>\n",
       "      <td>0.420689</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.813187</td>\n",
       "      <td>0.812495</td>\n",
       "      <td>0.811878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.279300</td>\n",
       "      <td>0.418641</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.249000</td>\n",
       "      <td>0.427605</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823506</td>\n",
       "      <td>0.823588</td>\n",
       "      <td>0.823391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.431665</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823503</td>\n",
       "      <td>0.823380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.213700</td>\n",
       "      <td>0.440587</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.826924</td>\n",
       "      <td>0.826816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.201500</td>\n",
       "      <td>0.449027</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823506</td>\n",
       "      <td>0.823588</td>\n",
       "      <td>0.823391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.193300</td>\n",
       "      <td>0.461409</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825629</td>\n",
       "      <td>0.825629</td>\n",
       "      <td>0.825629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.186600</td>\n",
       "      <td>0.471045</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820017</td>\n",
       "      <td>0.819746</td>\n",
       "      <td>0.819829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.182100</td>\n",
       "      <td>0.472896</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.177700</td>\n",
       "      <td>0.476383</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816620</td>\n",
       "      <td>0.816498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.174500</td>\n",
       "      <td>0.489349</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815336</td>\n",
       "      <td>0.815242</td>\n",
       "      <td>0.815279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.171900</td>\n",
       "      <td>0.489658</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815301</td>\n",
       "      <td>0.815326</td>\n",
       "      <td>0.815312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0.493492</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816478</td>\n",
       "      <td>0.816578</td>\n",
       "      <td>0.816490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.170400</td>\n",
       "      <td>0.493490</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815303</td>\n",
       "      <td>0.815368</td>\n",
       "      <td>0.815326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 04:34:22,040] Trial 15 finished with value: 0.8153259275336583 and parameters: {'learning_rate': 1.071934208458698e-05, 'weight_decay': 0.001, 'warmup_steps': 134}. Best is trial 15 with value: 0.8153259275336583.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16 with params: {'learning_rate': 1.2586176447406365e-05, 'weight_decay': 0.0, 'warmup_steps': 126}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34425' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34425/34425 57:10, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.454100</td>\n",
       "      <td>0.433833</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.804401</td>\n",
       "      <td>0.803868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.312400</td>\n",
       "      <td>0.419957</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811945</td>\n",
       "      <td>0.811327</td>\n",
       "      <td>0.810738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.263500</td>\n",
       "      <td>0.419411</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819302</td>\n",
       "      <td>0.819167</td>\n",
       "      <td>0.818804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.233800</td>\n",
       "      <td>0.433004</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824564</td>\n",
       "      <td>0.824672</td>\n",
       "      <td>0.824530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.213800</td>\n",
       "      <td>0.440757</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821066</td>\n",
       "      <td>0.821167</td>\n",
       "      <td>0.821077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.200100</td>\n",
       "      <td>0.454994</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823338</td>\n",
       "      <td>0.823419</td>\n",
       "      <td>0.823361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.188500</td>\n",
       "      <td>0.463972</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820032</td>\n",
       "      <td>0.820125</td>\n",
       "      <td>0.819948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.180600</td>\n",
       "      <td>0.480178</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816501</td>\n",
       "      <td>0.816368</td>\n",
       "      <td>0.816417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.174300</td>\n",
       "      <td>0.490060</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817631</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.493691</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.165700</td>\n",
       "      <td>0.497019</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813096</td>\n",
       "      <td>0.813200</td>\n",
       "      <td>0.813061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.513120</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813017</td>\n",
       "      <td>0.812989</td>\n",
       "      <td>0.813002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.160100</td>\n",
       "      <td>0.513277</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810715</td>\n",
       "      <td>0.810779</td>\n",
       "      <td>0.810738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.158400</td>\n",
       "      <td>0.518156</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810731</td>\n",
       "      <td>0.810821</td>\n",
       "      <td>0.810750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.158500</td>\n",
       "      <td>0.518173</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810731</td>\n",
       "      <td>0.810821</td>\n",
       "      <td>0.810750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 05:31:34,519] Trial 16 finished with value: 0.8107497010902807 and parameters: {'learning_rate': 1.2586176447406365e-05, 'weight_decay': 0.0, 'warmup_steps': 126}. Best is trial 15 with value: 0.8153259275336583.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17 with params: {'learning_rate': 0.00023041229790746586, 'weight_decay': 0.008, 'warmup_steps': 186}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22950' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22950/34425 37:01 < 18:30, 10.33 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.238500</td>\n",
       "      <td>0.565906</td>\n",
       "      <td>0.787844</td>\n",
       "      <td>0.787924</td>\n",
       "      <td>0.787583</td>\n",
       "      <td>0.787670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.114400</td>\n",
       "      <td>0.633720</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.792339</td>\n",
       "      <td>0.787952</td>\n",
       "      <td>0.787919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.814400</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.795887</td>\n",
       "      <td>0.795833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>1.008509</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.799292</td>\n",
       "      <td>0.799392</td>\n",
       "      <td>0.799291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.049200</td>\n",
       "      <td>1.083615</td>\n",
       "      <td>0.783257</td>\n",
       "      <td>0.783207</td>\n",
       "      <td>0.783289</td>\n",
       "      <td>0.783222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>1.104995</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791775</td>\n",
       "      <td>0.790835</td>\n",
       "      <td>0.790967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>1.168335</td>\n",
       "      <td>0.785550</td>\n",
       "      <td>0.785531</td>\n",
       "      <td>0.785373</td>\n",
       "      <td>0.785426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>1.187894</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.797470</td>\n",
       "      <td>0.796592</td>\n",
       "      <td>0.796727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.027200</td>\n",
       "      <td>1.316508</td>\n",
       "      <td>0.778670</td>\n",
       "      <td>0.778799</td>\n",
       "      <td>0.778364</td>\n",
       "      <td>0.778457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>1.396634</td>\n",
       "      <td>0.780963</td>\n",
       "      <td>0.781040</td>\n",
       "      <td>0.781121</td>\n",
       "      <td>0.780956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 06:08:37,035] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18 with params: {'learning_rate': 0.0002950137270531351, 'weight_decay': 0.01, 'warmup_steps': 78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22950' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22950/34425 36:57 < 18:29, 10.35 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.220600</td>\n",
       "      <td>0.625377</td>\n",
       "      <td>0.776376</td>\n",
       "      <td>0.776991</td>\n",
       "      <td>0.775859</td>\n",
       "      <td>0.775973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.104600</td>\n",
       "      <td>0.715590</td>\n",
       "      <td>0.778670</td>\n",
       "      <td>0.779172</td>\n",
       "      <td>0.778195</td>\n",
       "      <td>0.778313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.875053</td>\n",
       "      <td>0.784404</td>\n",
       "      <td>0.784764</td>\n",
       "      <td>0.784710</td>\n",
       "      <td>0.784403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.998958</td>\n",
       "      <td>0.797018</td>\n",
       "      <td>0.798951</td>\n",
       "      <td>0.797729</td>\n",
       "      <td>0.796901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.044500</td>\n",
       "      <td>1.102123</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794967</td>\n",
       "      <td>0.794382</td>\n",
       "      <td>0.794497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>1.354660</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.789363</td>\n",
       "      <td>0.788583</td>\n",
       "      <td>0.788706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.032300</td>\n",
       "      <td>1.278281</td>\n",
       "      <td>0.775229</td>\n",
       "      <td>0.776396</td>\n",
       "      <td>0.775785</td>\n",
       "      <td>0.775171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>1.145869</td>\n",
       "      <td>0.786697</td>\n",
       "      <td>0.787293</td>\n",
       "      <td>0.786204</td>\n",
       "      <td>0.786333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>1.436580</td>\n",
       "      <td>0.778670</td>\n",
       "      <td>0.779079</td>\n",
       "      <td>0.778995</td>\n",
       "      <td>0.778667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>1.427998</td>\n",
       "      <td>0.771789</td>\n",
       "      <td>0.772006</td>\n",
       "      <td>0.772028</td>\n",
       "      <td>0.771789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 06:45:36,028] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 19 with params: {'learning_rate': 5.125465771181014e-05, 'weight_decay': 0.0, 'warmup_steps': 130}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11475' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11475/34425 18:36 < 37:13, 10.27 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.326600</td>\n",
       "      <td>0.433107</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.814634</td>\n",
       "      <td>0.813705</td>\n",
       "      <td>0.813002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.190400</td>\n",
       "      <td>0.487070</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814377</td>\n",
       "      <td>0.813947</td>\n",
       "      <td>0.814055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.153800</td>\n",
       "      <td>0.548656</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805267</td>\n",
       "      <td>0.804728</td>\n",
       "      <td>0.804845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.131200</td>\n",
       "      <td>0.590688</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.804044</td>\n",
       "      <td>0.804107</td>\n",
       "      <td>0.803897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.115200</td>\n",
       "      <td>0.664429</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.794885</td>\n",
       "      <td>0.794424</td>\n",
       "      <td>0.794528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 07:04:13,870] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 with params: {'learning_rate': 3.137316955693352e-05, 'weight_decay': 0.002, 'warmup_steps': 208}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22950' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22950/34425 37:26 < 18:43, 10.21 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.373600</td>\n",
       "      <td>0.427496</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.813589</td>\n",
       "      <td>0.812579</td>\n",
       "      <td>0.811846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.227600</td>\n",
       "      <td>0.445428</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820184</td>\n",
       "      <td>0.820209</td>\n",
       "      <td>0.819954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.476633</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810723</td>\n",
       "      <td>0.810695</td>\n",
       "      <td>0.810708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.162300</td>\n",
       "      <td>0.511112</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814269</td>\n",
       "      <td>0.814368</td>\n",
       "      <td>0.814211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.146300</td>\n",
       "      <td>0.553680</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806128</td>\n",
       "      <td>0.806191</td>\n",
       "      <td>0.806150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.575558</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810713</td>\n",
       "      <td>0.810737</td>\n",
       "      <td>0.810724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.124500</td>\n",
       "      <td>0.608109</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.800827</td>\n",
       "      <td>0.800770</td>\n",
       "      <td>0.800458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.116200</td>\n",
       "      <td>0.651710</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.800177</td>\n",
       "      <td>0.798760</td>\n",
       "      <td>0.798910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.110800</td>\n",
       "      <td>0.670960</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.800400</td>\n",
       "      <td>0.800476</td>\n",
       "      <td>0.800421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.106600</td>\n",
       "      <td>0.694375</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795836</td>\n",
       "      <td>0.795929</td>\n",
       "      <td>0.795845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 07:41:42,122] Trial 20 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 21 with params: {'learning_rate': 1.1921977502684865e-05, 'weight_decay': 0.0, 'warmup_steps': 99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22950' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22950/34425 37:04 < 18:32, 10.32 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.458200</td>\n",
       "      <td>0.435255</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.802580</td>\n",
       "      <td>0.802107</td>\n",
       "      <td>0.801574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.317700</td>\n",
       "      <td>0.420081</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.813381</td>\n",
       "      <td>0.812537</td>\n",
       "      <td>0.811863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.268800</td>\n",
       "      <td>0.418914</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821480</td>\n",
       "      <td>0.821420</td>\n",
       "      <td>0.821100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.238900</td>\n",
       "      <td>0.430994</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822326</td>\n",
       "      <td>0.822419</td>\n",
       "      <td>0.822242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.218500</td>\n",
       "      <td>0.437234</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821066</td>\n",
       "      <td>0.821167</td>\n",
       "      <td>0.821077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.204600</td>\n",
       "      <td>0.449574</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823359</td>\n",
       "      <td>0.823461</td>\n",
       "      <td>0.823371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.192800</td>\n",
       "      <td>0.458465</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821150</td>\n",
       "      <td>0.821251</td>\n",
       "      <td>0.821092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.184800</td>\n",
       "      <td>0.473412</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816470</td>\n",
       "      <td>0.816410</td>\n",
       "      <td>0.816436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.178400</td>\n",
       "      <td>0.483296</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819965</td>\n",
       "      <td>0.819788</td>\n",
       "      <td>0.819850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.174100</td>\n",
       "      <td>0.486183</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815390</td>\n",
       "      <td>0.815494</td>\n",
       "      <td>0.815355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jovyan/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--recall/11f90e583db35601050aed380d48e83202a896976b9608432fba9244fb447f24 (last modified on Fri Jan 10 23:14:00 2025) since it couldn't be found locally at evaluate-metric--recall, or remotely on the Hugging Face Hub.\n",
      "[I 2025-03-30 08:18:47,891] Trial 21 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 22 with params: {'learning_rate': 1.0587611658805354e-05, 'weight_decay': 0.002, 'warmup_steps': 144}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34425' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34425/34425 55:37, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.472000</td>\n",
       "      <td>0.438878</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.799216</td>\n",
       "      <td>0.798687</td>\n",
       "      <td>0.798127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.329300</td>\n",
       "      <td>0.420792</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.815304</td>\n",
       "      <td>0.814747</td>\n",
       "      <td>0.814185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.280500</td>\n",
       "      <td>0.418652</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.250100</td>\n",
       "      <td>0.427330</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823506</td>\n",
       "      <td>0.823588</td>\n",
       "      <td>0.823391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.229100</td>\n",
       "      <td>0.431074</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824522</td>\n",
       "      <td>0.824630</td>\n",
       "      <td>0.824523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.214700</td>\n",
       "      <td>0.439606</td>\n",
       "      <td>0.827982</td>\n",
       "      <td>0.827982</td>\n",
       "      <td>0.828092</td>\n",
       "      <td>0.827967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.202500</td>\n",
       "      <td>0.448025</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823506</td>\n",
       "      <td>0.823588</td>\n",
       "      <td>0.823391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.194300</td>\n",
       "      <td>0.460122</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825629</td>\n",
       "      <td>0.825629</td>\n",
       "      <td>0.825629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.187600</td>\n",
       "      <td>0.469706</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820017</td>\n",
       "      <td>0.819746</td>\n",
       "      <td>0.819829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.183100</td>\n",
       "      <td>0.471465</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.178700</td>\n",
       "      <td>0.474984</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815390</td>\n",
       "      <td>0.815494</td>\n",
       "      <td>0.815355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.175400</td>\n",
       "      <td>0.487672</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815336</td>\n",
       "      <td>0.815242</td>\n",
       "      <td>0.815279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.172800</td>\n",
       "      <td>0.487995</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815301</td>\n",
       "      <td>0.815326</td>\n",
       "      <td>0.815312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.171200</td>\n",
       "      <td>0.491759</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817612</td>\n",
       "      <td>0.817704</td>\n",
       "      <td>0.817632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.171300</td>\n",
       "      <td>0.491713</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815303</td>\n",
       "      <td>0.815368</td>\n",
       "      <td>0.815326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 09:14:27,463] Trial 22 finished with value: 0.8153259275336583 and parameters: {'learning_rate': 1.0587611658805354e-05, 'weight_decay': 0.002, 'warmup_steps': 144}. Best is trial 15 with value: 0.8153259275336583.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 23 with params: {'learning_rate': 1.0102129930667866e-05, 'weight_decay': 0.004, 'warmup_steps': 179}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34425' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34425/34425 57:00, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.478300</td>\n",
       "      <td>0.440440</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.796756</td>\n",
       "      <td>0.796350</td>\n",
       "      <td>0.795845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.334000</td>\n",
       "      <td>0.421304</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.816368</td>\n",
       "      <td>0.815873</td>\n",
       "      <td>0.815338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.285200</td>\n",
       "      <td>0.418737</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819186</td>\n",
       "      <td>0.819125</td>\n",
       "      <td>0.818806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.254700</td>\n",
       "      <td>0.426334</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821288</td>\n",
       "      <td>0.821335</td>\n",
       "      <td>0.821100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.233400</td>\n",
       "      <td>0.429192</td>\n",
       "      <td>0.827982</td>\n",
       "      <td>0.827982</td>\n",
       "      <td>0.828092</td>\n",
       "      <td>0.827967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.218800</td>\n",
       "      <td>0.436289</td>\n",
       "      <td>0.827982</td>\n",
       "      <td>0.828031</td>\n",
       "      <td>0.828134</td>\n",
       "      <td>0.827974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.206400</td>\n",
       "      <td>0.444459</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823506</td>\n",
       "      <td>0.823588</td>\n",
       "      <td>0.823391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.198100</td>\n",
       "      <td>0.455328</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824490</td>\n",
       "      <td>0.824461</td>\n",
       "      <td>0.824475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.191400</td>\n",
       "      <td>0.464733</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822314</td>\n",
       "      <td>0.822040</td>\n",
       "      <td>0.822124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.186700</td>\n",
       "      <td>0.465950</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.182300</td>\n",
       "      <td>0.469665</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.179000</td>\n",
       "      <td>0.481453</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815312</td>\n",
       "      <td>0.815284</td>\n",
       "      <td>0.815297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.481826</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813009</td>\n",
       "      <td>0.813074</td>\n",
       "      <td>0.813032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.174800</td>\n",
       "      <td>0.485331</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.174800</td>\n",
       "      <td>0.485274</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816447</td>\n",
       "      <td>0.816494</td>\n",
       "      <td>0.816466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 10:11:30,124] Trial 23 finished with value: 0.8164664530353019 and parameters: {'learning_rate': 1.0102129930667866e-05, 'weight_decay': 0.004, 'warmup_steps': 179}. Best is trial 23 with value: 0.8164664530353019.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 24 with params: {'learning_rate': 1.2968345869509177e-05, 'weight_decay': 0.004, 'warmup_steps': 203}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34425' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34425/34425 56:20, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>0.433194</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.803812</td>\n",
       "      <td>0.803275</td>\n",
       "      <td>0.802715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.309700</td>\n",
       "      <td>0.419932</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811945</td>\n",
       "      <td>0.811327</td>\n",
       "      <td>0.810738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.260700</td>\n",
       "      <td>0.419820</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.820336</td>\n",
       "      <td>0.819948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.231000</td>\n",
       "      <td>0.434221</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823443</td>\n",
       "      <td>0.823546</td>\n",
       "      <td>0.823386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.211100</td>\n",
       "      <td>0.443024</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822200</td>\n",
       "      <td>0.822293</td>\n",
       "      <td>0.822219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.197500</td>\n",
       "      <td>0.458447</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823338</td>\n",
       "      <td>0.823419</td>\n",
       "      <td>0.823361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.467524</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.816505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.178200</td>\n",
       "      <td>0.484406</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816501</td>\n",
       "      <td>0.816368</td>\n",
       "      <td>0.816417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.171900</td>\n",
       "      <td>0.494277</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816501</td>\n",
       "      <td>0.816368</td>\n",
       "      <td>0.816417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.167700</td>\n",
       "      <td>0.498462</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818856</td>\n",
       "      <td>0.818957</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.501679</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813025</td>\n",
       "      <td>0.813116</td>\n",
       "      <td>0.813044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.160200</td>\n",
       "      <td>0.518548</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810715</td>\n",
       "      <td>0.810779</td>\n",
       "      <td>0.810738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.157800</td>\n",
       "      <td>0.518846</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811869</td>\n",
       "      <td>0.811947</td>\n",
       "      <td>0.811891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.156100</td>\n",
       "      <td>0.523915</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810731</td>\n",
       "      <td>0.810821</td>\n",
       "      <td>0.810750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.156200</td>\n",
       "      <td>0.523911</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810731</td>\n",
       "      <td>0.810821</td>\n",
       "      <td>0.810750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 11:07:52,669] Trial 24 finished with value: 0.8107497010902807 and parameters: {'learning_rate': 1.2968345869509177e-05, 'weight_decay': 0.004, 'warmup_steps': 203}. Best is trial 23 with value: 0.8164664530353019.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 with params: {'learning_rate': 1.126880146707781e-05, 'weight_decay': 0.004, 'warmup_steps': 161}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22950' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22950/34425 36:38 < 18:19, 10.44 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.466600</td>\n",
       "      <td>0.437030</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.803812</td>\n",
       "      <td>0.803275</td>\n",
       "      <td>0.802715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.323300</td>\n",
       "      <td>0.420391</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.813381</td>\n",
       "      <td>0.812537</td>\n",
       "      <td>0.811863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.274400</td>\n",
       "      <td>0.418744</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820390</td>\n",
       "      <td>0.820293</td>\n",
       "      <td>0.819952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.244100</td>\n",
       "      <td>0.429077</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825800</td>\n",
       "      <td>0.825882</td>\n",
       "      <td>0.825684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.223400</td>\n",
       "      <td>0.434113</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822270</td>\n",
       "      <td>0.822377</td>\n",
       "      <td>0.822236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.209300</td>\n",
       "      <td>0.444739</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825798</td>\n",
       "      <td>0.825673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.197300</td>\n",
       "      <td>0.453473</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821150</td>\n",
       "      <td>0.821251</td>\n",
       "      <td>0.821092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.189200</td>\n",
       "      <td>0.467040</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821059</td>\n",
       "      <td>0.820999</td>\n",
       "      <td>0.821025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.182700</td>\n",
       "      <td>0.476886</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819965</td>\n",
       "      <td>0.819788</td>\n",
       "      <td>0.819850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.178200</td>\n",
       "      <td>0.479219</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815445</td>\n",
       "      <td>0.815536</td>\n",
       "      <td>0.815361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 11:44:32,281] Trial 25 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 with params: {'learning_rate': 1.2685258643513274e-05, 'weight_decay': 0.004, 'warmup_steps': 124}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34425' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34425/34425 56:16, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.453200</td>\n",
       "      <td>0.433626</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.804401</td>\n",
       "      <td>0.803868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.311600</td>\n",
       "      <td>0.419951</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811945</td>\n",
       "      <td>0.811327</td>\n",
       "      <td>0.810738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.262800</td>\n",
       "      <td>0.419501</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819302</td>\n",
       "      <td>0.819167</td>\n",
       "      <td>0.818804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.233100</td>\n",
       "      <td>0.433292</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825737</td>\n",
       "      <td>0.825840</td>\n",
       "      <td>0.825680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.213100</td>\n",
       "      <td>0.441267</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821066</td>\n",
       "      <td>0.821167</td>\n",
       "      <td>0.821077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.199400</td>\n",
       "      <td>0.455776</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824479</td>\n",
       "      <td>0.824545</td>\n",
       "      <td>0.824502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.187800</td>\n",
       "      <td>0.464807</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818856</td>\n",
       "      <td>0.818957</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.481184</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816501</td>\n",
       "      <td>0.816368</td>\n",
       "      <td>0.816417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.173700</td>\n",
       "      <td>0.491068</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817631</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.169400</td>\n",
       "      <td>0.494792</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.165100</td>\n",
       "      <td>0.498124</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813096</td>\n",
       "      <td>0.813200</td>\n",
       "      <td>0.813061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.514379</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813017</td>\n",
       "      <td>0.812989</td>\n",
       "      <td>0.813002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.159500</td>\n",
       "      <td>0.514599</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810715</td>\n",
       "      <td>0.810779</td>\n",
       "      <td>0.810738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.157800</td>\n",
       "      <td>0.519474</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810731</td>\n",
       "      <td>0.810821</td>\n",
       "      <td>0.810750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.157900</td>\n",
       "      <td>0.519492</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810731</td>\n",
       "      <td>0.810821</td>\n",
       "      <td>0.810750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 12:40:50,657] Trial 26 finished with value: 0.8107497010902807 and parameters: {'learning_rate': 1.2685258643513274e-05, 'weight_decay': 0.004, 'warmup_steps': 124}. Best is trial 23 with value: 0.8164664530353019.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 27 with params: {'learning_rate': 4.7996786970552803e-05, 'weight_decay': 0.006, 'warmup_steps': 146}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11475' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11475/34425 18:00 < 36:01, 10.62 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.333200</td>\n",
       "      <td>0.431517</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.811740</td>\n",
       "      <td>0.810369</td>\n",
       "      <td>0.809512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.195000</td>\n",
       "      <td>0.481111</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815489</td>\n",
       "      <td>0.815115</td>\n",
       "      <td>0.815215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.157900</td>\n",
       "      <td>0.538526</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.802890</td>\n",
       "      <td>0.802475</td>\n",
       "      <td>0.802577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.135300</td>\n",
       "      <td>0.575645</td>\n",
       "      <td>0.806193</td>\n",
       "      <td>0.806338</td>\n",
       "      <td>0.806401</td>\n",
       "      <td>0.806190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.119300</td>\n",
       "      <td>0.645639</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.795997</td>\n",
       "      <td>0.795592</td>\n",
       "      <td>0.795690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 12:58:52,372] Trial 27 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 28 with params: {'learning_rate': 0.000319720536453825, 'weight_decay': 0.002, 'warmup_steps': 163}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11475' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11475/34425 19:06 < 38:14, 10.00 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.224600</td>\n",
       "      <td>0.662365</td>\n",
       "      <td>0.778670</td>\n",
       "      <td>0.779907</td>\n",
       "      <td>0.777985</td>\n",
       "      <td>0.778079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.103700</td>\n",
       "      <td>0.736552</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.795128</td>\n",
       "      <td>0.791498</td>\n",
       "      <td>0.791540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.820939</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.795532</td>\n",
       "      <td>0.795182</td>\n",
       "      <td>0.794703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.054100</td>\n",
       "      <td>1.078004</td>\n",
       "      <td>0.786697</td>\n",
       "      <td>0.789428</td>\n",
       "      <td>0.787552</td>\n",
       "      <td>0.786477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.043400</td>\n",
       "      <td>1.100700</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792518</td>\n",
       "      <td>0.792172</td>\n",
       "      <td>0.792260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 13:18:00,527] Trial 28 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 29 with params: {'learning_rate': 1.2526936444247373e-05, 'weight_decay': 0.001, 'warmup_steps': 161}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34425' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34425/34425 55:52, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.456200</td>\n",
       "      <td>0.434087</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.804401</td>\n",
       "      <td>0.803868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.313000</td>\n",
       "      <td>0.420021</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811945</td>\n",
       "      <td>0.811327</td>\n",
       "      <td>0.810738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.264000</td>\n",
       "      <td>0.419410</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819302</td>\n",
       "      <td>0.819167</td>\n",
       "      <td>0.818804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.234200</td>\n",
       "      <td>0.432796</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824564</td>\n",
       "      <td>0.824672</td>\n",
       "      <td>0.824530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.214100</td>\n",
       "      <td>0.440474</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821066</td>\n",
       "      <td>0.821167</td>\n",
       "      <td>0.821077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.200400</td>\n",
       "      <td>0.454612</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824479</td>\n",
       "      <td>0.824545</td>\n",
       "      <td>0.824502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.188800</td>\n",
       "      <td>0.463589</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820032</td>\n",
       "      <td>0.820125</td>\n",
       "      <td>0.819948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.180900</td>\n",
       "      <td>0.479720</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816501</td>\n",
       "      <td>0.816368</td>\n",
       "      <td>0.816417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.174600</td>\n",
       "      <td>0.489675</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817631</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0.493238</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.166000</td>\n",
       "      <td>0.496514</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814269</td>\n",
       "      <td>0.814368</td>\n",
       "      <td>0.814211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.162800</td>\n",
       "      <td>0.512614</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814158</td>\n",
       "      <td>0.814158</td>\n",
       "      <td>0.814158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.160400</td>\n",
       "      <td>0.512827</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811869</td>\n",
       "      <td>0.811947</td>\n",
       "      <td>0.811891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.158700</td>\n",
       "      <td>0.517666</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810731</td>\n",
       "      <td>0.810821</td>\n",
       "      <td>0.810750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.158800</td>\n",
       "      <td>0.517635</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810731</td>\n",
       "      <td>0.810821</td>\n",
       "      <td>0.810750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 14:13:55,073] Trial 29 finished with value: 0.8107497010902807 and parameters: {'learning_rate': 1.2526936444247373e-05, 'weight_decay': 0.001, 'warmup_steps': 161}. Best is trial 23 with value: 0.8164664530353019.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 with params: {'learning_rate': 1.1656700835830033e-05, 'weight_decay': 0.003, 'warmup_steps': 184}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34425' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34425/34425 55:46, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.464400</td>\n",
       "      <td>0.436052</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.802580</td>\n",
       "      <td>0.802107</td>\n",
       "      <td>0.801574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.420167</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.813381</td>\n",
       "      <td>0.812537</td>\n",
       "      <td>0.811863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.271000</td>\n",
       "      <td>0.418839</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820280</td>\n",
       "      <td>0.820251</td>\n",
       "      <td>0.819954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.240900</td>\n",
       "      <td>0.430135</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824620</td>\n",
       "      <td>0.824714</td>\n",
       "      <td>0.824536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.220400</td>\n",
       "      <td>0.436010</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819935</td>\n",
       "      <td>0.820041</td>\n",
       "      <td>0.819935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.206400</td>\n",
       "      <td>0.447824</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824522</td>\n",
       "      <td>0.824630</td>\n",
       "      <td>0.824523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.194500</td>\n",
       "      <td>0.456636</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821150</td>\n",
       "      <td>0.821251</td>\n",
       "      <td>0.821092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.186500</td>\n",
       "      <td>0.471045</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821059</td>\n",
       "      <td>0.820999</td>\n",
       "      <td>0.821025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.480902</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821137</td>\n",
       "      <td>0.820914</td>\n",
       "      <td>0.820987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.175600</td>\n",
       "      <td>0.483657</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816620</td>\n",
       "      <td>0.816498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.171300</td>\n",
       "      <td>0.486856</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813054</td>\n",
       "      <td>0.813158</td>\n",
       "      <td>0.813053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.168100</td>\n",
       "      <td>0.501575</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815303</td>\n",
       "      <td>0.815368</td>\n",
       "      <td>0.815326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.165600</td>\n",
       "      <td>0.501889</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815303</td>\n",
       "      <td>0.815368</td>\n",
       "      <td>0.815326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.164000</td>\n",
       "      <td>0.506252</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815348</td>\n",
       "      <td>0.815452</td>\n",
       "      <td>0.815347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.164000</td>\n",
       "      <td>0.506139</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815319</td>\n",
       "      <td>0.815410</td>\n",
       "      <td>0.815338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 15:09:43,515] Trial 30 finished with value: 0.8153375871244556 and parameters: {'learning_rate': 1.1656700835830033e-05, 'weight_decay': 0.003, 'warmup_steps': 184}. Best is trial 23 with value: 0.8164664530353019.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 31 with params: {'learning_rate': 1.074137206210587e-05, 'weight_decay': 0.003, 'warmup_steps': 187}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34425' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34425/34425 56:26, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.472600</td>\n",
       "      <td>0.438513</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.800282</td>\n",
       "      <td>0.799813</td>\n",
       "      <td>0.799280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.328000</td>\n",
       "      <td>0.420655</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.813187</td>\n",
       "      <td>0.812495</td>\n",
       "      <td>0.811878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.279100</td>\n",
       "      <td>0.418635</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.248700</td>\n",
       "      <td>0.427704</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823506</td>\n",
       "      <td>0.823588</td>\n",
       "      <td>0.823391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.227700</td>\n",
       "      <td>0.431771</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823503</td>\n",
       "      <td>0.823380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.213400</td>\n",
       "      <td>0.440889</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.826924</td>\n",
       "      <td>0.826816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.449339</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823506</td>\n",
       "      <td>0.823588</td>\n",
       "      <td>0.823391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.193000</td>\n",
       "      <td>0.461794</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825629</td>\n",
       "      <td>0.825629</td>\n",
       "      <td>0.825629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.186400</td>\n",
       "      <td>0.471395</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820017</td>\n",
       "      <td>0.819746</td>\n",
       "      <td>0.819829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.181900</td>\n",
       "      <td>0.473331</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.817655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.177500</td>\n",
       "      <td>0.476754</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816620</td>\n",
       "      <td>0.816498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.174200</td>\n",
       "      <td>0.489777</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817607</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.817591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.171700</td>\n",
       "      <td>0.490149</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815301</td>\n",
       "      <td>0.815326</td>\n",
       "      <td>0.815312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.170100</td>\n",
       "      <td>0.494009</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816478</td>\n",
       "      <td>0.816578</td>\n",
       "      <td>0.816490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.170100</td>\n",
       "      <td>0.493903</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816447</td>\n",
       "      <td>0.816494</td>\n",
       "      <td>0.816466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 16:06:11,237] Trial 31 finished with value: 0.8164664530353019 and parameters: {'learning_rate': 1.074137206210587e-05, 'weight_decay': 0.003, 'warmup_steps': 187}. Best is trial 23 with value: 0.8164664530353019.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 32 with params: {'learning_rate': 1.1817619001250758e-05, 'weight_decay': 0.005, 'warmup_steps': 168}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34425' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34425/34425 56:35, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.462300</td>\n",
       "      <td>0.435672</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.802580</td>\n",
       "      <td>0.802107</td>\n",
       "      <td>0.801574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.318700</td>\n",
       "      <td>0.420131</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.813381</td>\n",
       "      <td>0.812537</td>\n",
       "      <td>0.811863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.269700</td>\n",
       "      <td>0.418921</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820280</td>\n",
       "      <td>0.820251</td>\n",
       "      <td>0.819954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.239600</td>\n",
       "      <td>0.430612</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823443</td>\n",
       "      <td>0.823546</td>\n",
       "      <td>0.823386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.219200</td>\n",
       "      <td>0.436822</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821066</td>\n",
       "      <td>0.821167</td>\n",
       "      <td>0.821077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.205200</td>\n",
       "      <td>0.449067</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824522</td>\n",
       "      <td>0.824630</td>\n",
       "      <td>0.824523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.193400</td>\n",
       "      <td>0.457904</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821150</td>\n",
       "      <td>0.821251</td>\n",
       "      <td>0.821092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>0.472642</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821059</td>\n",
       "      <td>0.820999</td>\n",
       "      <td>0.821025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.179000</td>\n",
       "      <td>0.482521</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819965</td>\n",
       "      <td>0.819788</td>\n",
       "      <td>0.819850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.174600</td>\n",
       "      <td>0.485386</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816620</td>\n",
       "      <td>0.816498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0.488605</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813054</td>\n",
       "      <td>0.813158</td>\n",
       "      <td>0.813053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.167100</td>\n",
       "      <td>0.503589</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815303</td>\n",
       "      <td>0.815368</td>\n",
       "      <td>0.815326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.164600</td>\n",
       "      <td>0.503882</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815303</td>\n",
       "      <td>0.815368</td>\n",
       "      <td>0.815326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>0.508293</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814185</td>\n",
       "      <td>0.814284</td>\n",
       "      <td>0.814196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>0.508206</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814153</td>\n",
       "      <td>0.814200</td>\n",
       "      <td>0.814172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 17:02:49,192] Trial 32 finished with value: 0.814172283698243 and parameters: {'learning_rate': 1.1817619001250758e-05, 'weight_decay': 0.005, 'warmup_steps': 168}. Best is trial 23 with value: 0.8164664530353019.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 33 with params: {'learning_rate': 1.0808761869111402e-05, 'weight_decay': 0.002, 'warmup_steps': 221}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22950' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22950/34425 37:55 < 18:57, 10.08 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.473700</td>\n",
       "      <td>0.438397</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.801351</td>\n",
       "      <td>0.800939</td>\n",
       "      <td>0.800432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.327600</td>\n",
       "      <td>0.420656</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.813187</td>\n",
       "      <td>0.812495</td>\n",
       "      <td>0.811878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.278500</td>\n",
       "      <td>0.418667</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.248100</td>\n",
       "      <td>0.427887</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823506</td>\n",
       "      <td>0.823588</td>\n",
       "      <td>0.823391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.227100</td>\n",
       "      <td>0.432187</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822228</td>\n",
       "      <td>0.822335</td>\n",
       "      <td>0.822229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.212800</td>\n",
       "      <td>0.441517</td>\n",
       "      <td>0.827982</td>\n",
       "      <td>0.827982</td>\n",
       "      <td>0.828092</td>\n",
       "      <td>0.827967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.200700</td>\n",
       "      <td>0.450074</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822326</td>\n",
       "      <td>0.822419</td>\n",
       "      <td>0.822242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.462633</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824490</td>\n",
       "      <td>0.824461</td>\n",
       "      <td>0.824475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.185900</td>\n",
       "      <td>0.472294</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821137</td>\n",
       "      <td>0.820914</td>\n",
       "      <td>0.820987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.181400</td>\n",
       "      <td>0.474231</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815445</td>\n",
       "      <td>0.815536</td>\n",
       "      <td>0.815361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 17:40:45,670] Trial 33 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 34 with params: {'learning_rate': 1.7935920764592027e-05, 'weight_decay': 0.003, 'warmup_steps': 183}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22950' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22950/34425 37:49 < 18:54, 10.11 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.423000</td>\n",
       "      <td>0.427230</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.813381</td>\n",
       "      <td>0.812537</td>\n",
       "      <td>0.811863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.278100</td>\n",
       "      <td>0.422170</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.820085</td>\n",
       "      <td>0.819378</td>\n",
       "      <td>0.818761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.230600</td>\n",
       "      <td>0.429243</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825966</td>\n",
       "      <td>0.825966</td>\n",
       "      <td>0.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.203000</td>\n",
       "      <td>0.454092</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821035</td>\n",
       "      <td>0.821083</td>\n",
       "      <td>0.821055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.185300</td>\n",
       "      <td>0.474544</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815303</td>\n",
       "      <td>0.815368</td>\n",
       "      <td>0.815326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.172900</td>\n",
       "      <td>0.496566</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.814185</td>\n",
       "      <td>0.814284</td>\n",
       "      <td>0.814196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.162200</td>\n",
       "      <td>0.507239</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808713</td>\n",
       "      <td>0.808737</td>\n",
       "      <td>0.808486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.154700</td>\n",
       "      <td>0.531869</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808536</td>\n",
       "      <td>0.808274</td>\n",
       "      <td>0.808353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.148800</td>\n",
       "      <td>0.542176</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.809615</td>\n",
       "      <td>0.809485</td>\n",
       "      <td>0.809533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.144700</td>\n",
       "      <td>0.551700</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808509</td>\n",
       "      <td>0.808611</td>\n",
       "      <td>0.808474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 18:18:36,053] Trial 34 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 35 with params: {'learning_rate': 1.7316542519300505e-05, 'weight_decay': 0.003, 'warmup_steps': 189}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11475' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11475/34425 18:31 < 37:02, 10.32 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.426600</td>\n",
       "      <td>0.427696</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.814244</td>\n",
       "      <td>0.813621</td>\n",
       "      <td>0.813032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.281500</td>\n",
       "      <td>0.421616</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.821332</td>\n",
       "      <td>0.820546</td>\n",
       "      <td>0.819901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.233700</td>\n",
       "      <td>0.427755</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.827164</td>\n",
       "      <td>0.827134</td>\n",
       "      <td>0.826835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.205900</td>\n",
       "      <td>0.451368</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822185</td>\n",
       "      <td>0.822251</td>\n",
       "      <td>0.822208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.187900</td>\n",
       "      <td>0.470524</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816447</td>\n",
       "      <td>0.816494</td>\n",
       "      <td>0.816466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 18:37:08,349] Trial 35 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 36 with params: {'learning_rate': 0.0004180301872969493, 'weight_decay': 0.006, 'warmup_steps': 27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22950' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22950/34425 37:01 < 18:31, 10.33 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.206000</td>\n",
       "      <td>0.657687</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791663</td>\n",
       "      <td>0.790877</td>\n",
       "      <td>0.791003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.098600</td>\n",
       "      <td>0.718008</td>\n",
       "      <td>0.772936</td>\n",
       "      <td>0.773259</td>\n",
       "      <td>0.772523</td>\n",
       "      <td>0.772630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.068200</td>\n",
       "      <td>0.965540</td>\n",
       "      <td>0.775229</td>\n",
       "      <td>0.779963</td>\n",
       "      <td>0.776375</td>\n",
       "      <td>0.774707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.052100</td>\n",
       "      <td>1.068864</td>\n",
       "      <td>0.769495</td>\n",
       "      <td>0.770131</td>\n",
       "      <td>0.769902</td>\n",
       "      <td>0.769481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>1.015832</td>\n",
       "      <td>0.786697</td>\n",
       "      <td>0.786745</td>\n",
       "      <td>0.786836</td>\n",
       "      <td>0.786687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>1.184265</td>\n",
       "      <td>0.783257</td>\n",
       "      <td>0.783562</td>\n",
       "      <td>0.782868</td>\n",
       "      <td>0.782983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>1.164445</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.800282</td>\n",
       "      <td>0.799813</td>\n",
       "      <td>0.799280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>1.361584</td>\n",
       "      <td>0.770642</td>\n",
       "      <td>0.771059</td>\n",
       "      <td>0.770186</td>\n",
       "      <td>0.770293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>1.400639</td>\n",
       "      <td>0.782110</td>\n",
       "      <td>0.783666</td>\n",
       "      <td>0.782752</td>\n",
       "      <td>0.782017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>1.339002</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.788994</td>\n",
       "      <td>0.788793</td>\n",
       "      <td>0.788856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 19:14:11,651] Trial 36 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 37 with params: {'learning_rate': 1.1598919146420157e-05, 'weight_decay': 0.003, 'warmup_steps': 173}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22950' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22950/34425 36:20 < 18:10, 10.53 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.464300</td>\n",
       "      <td>0.436209</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.802580</td>\n",
       "      <td>0.802107</td>\n",
       "      <td>0.801574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.320500</td>\n",
       "      <td>0.420187</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.813381</td>\n",
       "      <td>0.812537</td>\n",
       "      <td>0.811863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.271500</td>\n",
       "      <td>0.418849</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.820280</td>\n",
       "      <td>0.820251</td>\n",
       "      <td>0.819954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.241400</td>\n",
       "      <td>0.429948</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824620</td>\n",
       "      <td>0.824714</td>\n",
       "      <td>0.824536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.220800</td>\n",
       "      <td>0.435755</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821066</td>\n",
       "      <td>0.821167</td>\n",
       "      <td>0.821077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.206800</td>\n",
       "      <td>0.447332</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823359</td>\n",
       "      <td>0.823461</td>\n",
       "      <td>0.823371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.194900</td>\n",
       "      <td>0.456154</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821150</td>\n",
       "      <td>0.821251</td>\n",
       "      <td>0.821092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>0.470434</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821059</td>\n",
       "      <td>0.820999</td>\n",
       "      <td>0.821025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.180400</td>\n",
       "      <td>0.480262</td>\n",
       "      <td>0.819954</td>\n",
       "      <td>0.819965</td>\n",
       "      <td>0.819788</td>\n",
       "      <td>0.819850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>0.482919</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816620</td>\n",
       "      <td>0.816498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 19:50:33,095] Trial 37 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 38 with params: {'learning_rate': 1.001349090137674e-05, 'weight_decay': 0.004, 'warmup_steps': 224}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22950' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22950/34425 37:02 < 18:31, 10.33 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.481400</td>\n",
       "      <td>0.440904</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.796756</td>\n",
       "      <td>0.796350</td>\n",
       "      <td>0.795845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.335000</td>\n",
       "      <td>0.421464</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.816368</td>\n",
       "      <td>0.815873</td>\n",
       "      <td>0.815338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.286100</td>\n",
       "      <td>0.418802</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819186</td>\n",
       "      <td>0.819125</td>\n",
       "      <td>0.818806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.255500</td>\n",
       "      <td>0.426170</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821288</td>\n",
       "      <td>0.821335</td>\n",
       "      <td>0.821100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.234200</td>\n",
       "      <td>0.428971</td>\n",
       "      <td>0.827982</td>\n",
       "      <td>0.827982</td>\n",
       "      <td>0.828092</td>\n",
       "      <td>0.827967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.219600</td>\n",
       "      <td>0.435812</td>\n",
       "      <td>0.827982</td>\n",
       "      <td>0.828093</td>\n",
       "      <td>0.828176</td>\n",
       "      <td>0.827978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.207100</td>\n",
       "      <td>0.443929</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824620</td>\n",
       "      <td>0.824714</td>\n",
       "      <td>0.824536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.198800</td>\n",
       "      <td>0.454669</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823335</td>\n",
       "      <td>0.823335</td>\n",
       "      <td>0.823335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.463936</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823493</td>\n",
       "      <td>0.823167</td>\n",
       "      <td>0.823261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.187300</td>\n",
       "      <td>0.465181</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815514</td>\n",
       "      <td>0.815578</td>\n",
       "      <td>0.815365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 20:27:36,420] Trial 38 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 39 with params: {'learning_rate': 0.00019841930077213002, 'weight_decay': 0.006, 'warmup_steps': 86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22950' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22950/34425 36:33 < 18:16, 10.46 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.236800</td>\n",
       "      <td>0.560124</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.793261</td>\n",
       "      <td>0.791877</td>\n",
       "      <td>0.792015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.118200</td>\n",
       "      <td>0.650924</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.796706</td>\n",
       "      <td>0.793919</td>\n",
       "      <td>0.794020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.083000</td>\n",
       "      <td>0.844828</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805024</td>\n",
       "      <td>0.804896</td>\n",
       "      <td>0.804943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.950590</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>0.810388</td>\n",
       "      <td>0.810074</td>\n",
       "      <td>0.809617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.052100</td>\n",
       "      <td>1.043822</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.789172</td>\n",
       "      <td>0.789214</td>\n",
       "      <td>0.788990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>1.122687</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.792036</td>\n",
       "      <td>0.790751</td>\n",
       "      <td>0.790887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.038100</td>\n",
       "      <td>1.206624</td>\n",
       "      <td>0.792431</td>\n",
       "      <td>0.792364</td>\n",
       "      <td>0.792424</td>\n",
       "      <td>0.792385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>1.274352</td>\n",
       "      <td>0.791284</td>\n",
       "      <td>0.791214</td>\n",
       "      <td>0.791214</td>\n",
       "      <td>0.791214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.029400</td>\n",
       "      <td>1.296659</td>\n",
       "      <td>0.778670</td>\n",
       "      <td>0.778875</td>\n",
       "      <td>0.778322</td>\n",
       "      <td>0.778425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>1.340388</td>\n",
       "      <td>0.779817</td>\n",
       "      <td>0.779817</td>\n",
       "      <td>0.779911</td>\n",
       "      <td>0.779798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 21:04:11,232] Trial 39 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 40 with params: {'learning_rate': 1.0014689401833803e-05, 'weight_decay': 0.005, 'warmup_steps': 144}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34425' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34425/34425 57:24, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.477500</td>\n",
       "      <td>0.440663</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.796756</td>\n",
       "      <td>0.796350</td>\n",
       "      <td>0.795845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.334700</td>\n",
       "      <td>0.421394</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.816543</td>\n",
       "      <td>0.815915</td>\n",
       "      <td>0.815326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.286100</td>\n",
       "      <td>0.418771</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819186</td>\n",
       "      <td>0.819125</td>\n",
       "      <td>0.818806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.255600</td>\n",
       "      <td>0.426129</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821288</td>\n",
       "      <td>0.821335</td>\n",
       "      <td>0.821100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.234200</td>\n",
       "      <td>0.428861</td>\n",
       "      <td>0.827982</td>\n",
       "      <td>0.827982</td>\n",
       "      <td>0.828092</td>\n",
       "      <td>0.827967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.219700</td>\n",
       "      <td>0.435613</td>\n",
       "      <td>0.827982</td>\n",
       "      <td>0.828093</td>\n",
       "      <td>0.828176</td>\n",
       "      <td>0.827978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.207200</td>\n",
       "      <td>0.443758</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823443</td>\n",
       "      <td>0.823546</td>\n",
       "      <td>0.823386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.198900</td>\n",
       "      <td>0.454425</td>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.824490</td>\n",
       "      <td>0.824461</td>\n",
       "      <td>0.824475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.192100</td>\n",
       "      <td>0.463755</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823493</td>\n",
       "      <td>0.823167</td>\n",
       "      <td>0.823261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.187400</td>\n",
       "      <td>0.464977</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816625</td>\n",
       "      <td>0.816705</td>\n",
       "      <td>0.816510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.183000</td>\n",
       "      <td>0.468637</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.179700</td>\n",
       "      <td>0.480250</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815312</td>\n",
       "      <td>0.815284</td>\n",
       "      <td>0.815297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.177100</td>\n",
       "      <td>0.480653</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813007</td>\n",
       "      <td>0.813031</td>\n",
       "      <td>0.813018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.175500</td>\n",
       "      <td>0.484060</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816620</td>\n",
       "      <td>0.816498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.175500</td>\n",
       "      <td>0.484059</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.815303</td>\n",
       "      <td>0.815368</td>\n",
       "      <td>0.815326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 22:01:37,609] Trial 40 finished with value: 0.8153259275336583 and parameters: {'learning_rate': 1.0014689401833803e-05, 'weight_decay': 0.005, 'warmup_steps': 144}. Best is trial 23 with value: 0.8164664530353019.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 41 with params: {'learning_rate': 1.2775087742305899e-05, 'weight_decay': 0.001, 'warmup_steps': 157}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34425' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34425/34425 56:36, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.454100</td>\n",
       "      <td>0.433555</td>\n",
       "      <td>0.803899</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.804401</td>\n",
       "      <td>0.803868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.311000</td>\n",
       "      <td>0.419960</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.811945</td>\n",
       "      <td>0.811327</td>\n",
       "      <td>0.810738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.262100</td>\n",
       "      <td>0.419574</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.819302</td>\n",
       "      <td>0.819167</td>\n",
       "      <td>0.818804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.433600</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825737</td>\n",
       "      <td>0.825840</td>\n",
       "      <td>0.825680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>0.441854</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821066</td>\n",
       "      <td>0.821167</td>\n",
       "      <td>0.821077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.198800</td>\n",
       "      <td>0.456657</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823338</td>\n",
       "      <td>0.823419</td>\n",
       "      <td>0.823361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.187300</td>\n",
       "      <td>0.465700</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.818856</td>\n",
       "      <td>0.818957</td>\n",
       "      <td>0.818799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.179400</td>\n",
       "      <td>0.482230</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816501</td>\n",
       "      <td>0.816368</td>\n",
       "      <td>0.816417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.173100</td>\n",
       "      <td>0.492106</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817631</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.168900</td>\n",
       "      <td>0.496024</td>\n",
       "      <td>0.817661</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.817789</td>\n",
       "      <td>0.817649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.164600</td>\n",
       "      <td>0.499252</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813096</td>\n",
       "      <td>0.813200</td>\n",
       "      <td>0.813061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.515750</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811863</td>\n",
       "      <td>0.811863</td>\n",
       "      <td>0.811863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.158900</td>\n",
       "      <td>0.516050</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.811869</td>\n",
       "      <td>0.811947</td>\n",
       "      <td>0.811891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.157300</td>\n",
       "      <td>0.520919</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810731</td>\n",
       "      <td>0.810821</td>\n",
       "      <td>0.810750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.157300</td>\n",
       "      <td>0.520940</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810731</td>\n",
       "      <td>0.810821</td>\n",
       "      <td>0.810750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 22:58:15,340] Trial 41 finished with value: 0.8107497010902807 and parameters: {'learning_rate': 1.2775087742305899e-05, 'weight_decay': 0.001, 'warmup_steps': 157}. Best is trial 23 with value: 0.8164664530353019.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 42 with params: {'learning_rate': 1.0890360023105325e-05, 'weight_decay': 0.002, 'warmup_steps': 119}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20656' max='34425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20656/34425 33:07 < 22:04, 10.39 it/s, Epoch 9/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.468000</td>\n",
       "      <td>0.437943</td>\n",
       "      <td>0.800459</td>\n",
       "      <td>0.801351</td>\n",
       "      <td>0.800939</td>\n",
       "      <td>0.800432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.326500</td>\n",
       "      <td>0.420551</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.814432</td>\n",
       "      <td>0.813663</td>\n",
       "      <td>0.813018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.277700</td>\n",
       "      <td>0.418631</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.816891</td>\n",
       "      <td>0.816831</td>\n",
       "      <td>0.816513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.247400</td>\n",
       "      <td>0.428055</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.823506</td>\n",
       "      <td>0.823588</td>\n",
       "      <td>0.823391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.226500</td>\n",
       "      <td>0.432392</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.821209</td>\n",
       "      <td>0.821086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.212300</td>\n",
       "      <td>0.441739</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.826924</td>\n",
       "      <td>0.826816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.200100</td>\n",
       "      <td>0.450301</td>\n",
       "      <td>0.822248</td>\n",
       "      <td>0.822326</td>\n",
       "      <td>0.822419</td>\n",
       "      <td>0.822242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.463090</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.825629</td>\n",
       "      <td>0.825629</td>\n",
       "      <td>0.825629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_trial3 = trainer.hyperparameter_search(\n",
    "    direction=\"maximize\",\n",
    "    backend=\"optuna\",\n",
    "    hp_space=hp_space,\n",
    "    compute_objective=lambda metrics: metrics[\"eval_f1\"],\n",
    "    pruner=pruner,\n",
    "    sampler=sampler,\n",
    "    study_name=\"Test-base-aug\",\n",
    "    n_trials=150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a68e47b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_trial3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbest_trial3\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_trial3' is not defined"
     ]
    }
   ],
   "source": [
    "print(best_trial3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60102d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799ac624",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bert-distill_aug_hp-search\", logging_dir=f\"~/logs/{DATASET}/bert-distill_aug_hp-search\", remove_unused_columns=False, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca79d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_space(trial):\n",
    "    params =  {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 5e-4, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0, 1e-2, step=1e-3),\n",
    "        \"warmup_steps\" : trial.suggest_int(\"warmup_steps\", 0, warm_up),\n",
    "        \"lambda_param\": trial.suggest_float(\"lambda_param\",0,1,step=.1),\n",
    "        \"temperature\": trial.suggest_float(\"temperature\", 2,7, step=.5)\n",
    "    }\n",
    "    print(f\"Trial {trial.number} with params: {params}\")\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c11b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pruner = optuna.pruners.HyperbandPruner(min_resource=min_r, max_resource=max_r, reduction_factor=2, bootstrap_count=2)\n",
    "sampler = optuna.samplers.TPESampler(seed=42, multivariate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b353692",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BertForSequenceClassification' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDistilTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_aug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43meval\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_init\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_Bert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/base.py:414\u001b[0m, in \u001b[0;36mDistilTrainer.__init__\u001b[0;34m(self, student_model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, student_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstudent_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstudent \u001b[38;5;241m=\u001b[39m student_model\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_function \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mKLDivLoss(reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatchmean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:477\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_init \u001b[38;5;241m=\u001b[39m model_init\n\u001b[0;32m--> 477\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_model_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Trainer` requires either a `model` or `model_init` argument\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:1879\u001b[0m, in \u001b[0;36mTrainer.call_model_init\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m   1877\u001b[0m model_init_argcount \u001b[38;5;241m=\u001b[39m number_of_arguments(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_init)\n\u001b[1;32m   1878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_init_argcount \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1879\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1880\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_init_argcount \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1881\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_init(trial)\n",
      "Cell \u001b[0;32mIn[39], line 6\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mDistilTrainer(\n\u001b[1;32m      2\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m      3\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_aug,\n\u001b[1;32m      4\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28meval\u001b[39m,\n\u001b[1;32m      5\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mbase\u001b[38;5;241m.\u001b[39mcompute_metrics,\n\u001b[0;32m----> 6\u001b[0m     model_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mget_Bert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m )\n",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m, in \u001b[0;36mget_Bert\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_Bert\u001b[39m():\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBertForSequenceClassification\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle/bert_uncased_L-2_H-128_A-2\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BertForSequenceClassification' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = base.DistilTrainer(\n",
    "    args=training_args,\n",
    "    train_dataset=train_aug,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    model_init = lambda: get_Bert()\n",
    ")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6e26f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial4 = trainer.hyperparameter_search(\n",
    "    direction=\"maximize\",\n",
    "    backend=\"optuna\",\n",
    "    hp_space=hp_space,\n",
    "    compute_objective=lambda metrics: metrics[\"eval_f1\"],\n",
    "    pruner=pruner,\n",
    "    sampler=sampler,\n",
    "    study_name=\"Test-Distill-aug\",\n",
    "    n_trials=150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896e187f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_trial4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbest_trial4\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_trial4' is not defined"
     ]
    }
   ],
   "source": [
    "print(best_trial4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349df401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best normal training score:  BestRun(run_id='132', objective=0.49578714001038604, hyperparameters={'learning_rate': 0.0004675471848767979, 'weight_decay': 0.01, 'warmup_steps': 4}, run_summary=None)\n",
      "Best distilation trianing score:  BestRun(run_id='86', objective=0.4778879458794155, hyperparameters={'learning_rate': 0.00048481023093695626, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.4, 'temperature': 2.5}, run_summary=None)\n",
      "Best distilation trianing score with augmentations:  BestRun(run_id='92', objective=0.7644517643387146, hyperparameters={'learning_rate': 0.0004922578519032032, 'weight_decay': 0.008, 'warmup_steps': 6, 'lambda_param': 1.0, 'temperature': 4.0}, run_summary=None)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best normal training score: \", best_trial)\n",
    "print(\"Best distilation trianing score: \", best_trial2)\n",
    "#print(\"Best normal training score with augmentations: \", best_trial3)\n",
    "print(\"Best distilation trianing score with augmentations: \",best_trial4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7955fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
