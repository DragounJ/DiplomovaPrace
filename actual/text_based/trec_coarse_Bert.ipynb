{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trénink s destilací nad datasetem TREC (coarse) s modelem BERT TINY\n",
    "V tomto notebooku je trénován BERT TINY nad původním i augmentovaným datasetem TREC (coarse), jako učitelský model je využíván finetunued BERT nad stejným datasetem.\n",
    "\n",
    "Pro původní i augmentovaný dataset je na základě nalezených hyperparametrů ze sešitu hp_search proveden normální trénink a trénink s destilací znalostí. V rámci tréninků je oproti prohledávání hyperparametrů využito EarlyStoppingu pro zamezení přeučení. Navíc jsou získány také výsledky nad testovací částí datasetu a další metriky využívané v práci (velikost modelu a rychlost inference).\n",
    "\n",
    "Při destilaci je využíváno předpočítaných logitů ze sešitu precompute_logits. Konfigurace jednotlivých tréninků odpovídá výstup pěti nejlepších běhů z prohledávání hyperparametrů u dané konfigurace. Maximální délka tréninku je nastavena na 20 epoch. EarlyStopping pracuje s trpělivostí čtyř epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import knihoven a základní nastavení"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, BertForSequenceClassification, BertTokenizer, EarlyStoppingCallback\n",
    "from datasets import load_from_disk\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import base\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resetování náhodného seedu pro replikovatelnost výsledků."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ověření dostupnosti GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and will be used: NVIDIA A100 80GB PCIe MIG 2g.20gb\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and will be used:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Načtení datasetu a jeho základní předzpracování."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"trec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_from_disk(f\"~/data/{DATASET}/train-logits_coarse\")\n",
    "eval = load_from_disk(f\"~/data/{DATASET}/eval-logits_coarse\")\n",
    "test = load_from_disk(f\"~/data/{DATASET}/test-logits_coarse\")\n",
    "\n",
    "train_aug = load_from_disk(f\"~/data/{DATASET}/train-logits-augmented_coarse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"carrassi-ni/bert-base-trec-question-classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizace, padding a převod na IDčka skrze tokenizer učitele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the train dataset\")\n",
    "eval = eval.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the eval dataset\")\n",
    "test = test.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the test dataset\")\n",
    "\n",
    "train_aug = train_aug.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the augmented dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Příprava dataloaderů pro finální ověření rychlosti inference. Testování probíhá pouze nad jedním záznamem z trénovací části."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gpu = copy.deepcopy(train)\n",
    "train_data_gpu.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"], device=\"cuda\")\n",
    "gpu_data_loader = DataLoader(train_data_gpu, batch_size=1, shuffle=False)\n",
    "\n",
    "train_data_cpu = copy.deepcopy(train)\n",
    "train_data_cpu.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"], device=\"cpu\")\n",
    "cpu_data_loader = DataLoader(train_data_cpu, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normální trénink s původním datasetem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Získání předtrénovaného modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\", num_labels=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konfigurace tréninku, zvolené parametry odpovídají pěti nejlepším výstupům z prohledávání hyperparametrů."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bert-base_coarse\", logging_dir=f\"~/logs/{DATASET}/bert-base_coarse\", epochs=20, lr=0.00045, weight_decay=.003, warmup_steps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konfigurace trenéra s trpělivostí 4 epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 4)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Spuštění tréninku, výstupy nad validační částí datasetu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='420' max='700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [420/700 00:59 < 00:40, 6.98 it/s, Epoch 12/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.539200</td>\n",
       "      <td>1.230905</td>\n",
       "      <td>0.571952</td>\n",
       "      <td>0.549015</td>\n",
       "      <td>0.474968</td>\n",
       "      <td>0.481256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.017900</td>\n",
       "      <td>0.846594</td>\n",
       "      <td>0.690192</td>\n",
       "      <td>0.597085</td>\n",
       "      <td>0.589547</td>\n",
       "      <td>0.589943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.629500</td>\n",
       "      <td>0.711778</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.808883</td>\n",
       "      <td>0.660910</td>\n",
       "      <td>0.663113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.403300</td>\n",
       "      <td>0.654502</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.833215</td>\n",
       "      <td>0.720405</td>\n",
       "      <td>0.744266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.262300</td>\n",
       "      <td>0.648941</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.817606</td>\n",
       "      <td>0.748744</td>\n",
       "      <td>0.769059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.172400</td>\n",
       "      <td>0.715405</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.818460</td>\n",
       "      <td>0.741942</td>\n",
       "      <td>0.765189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.111300</td>\n",
       "      <td>0.737910</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.818045</td>\n",
       "      <td>0.751066</td>\n",
       "      <td>0.772577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.080800</td>\n",
       "      <td>0.744790</td>\n",
       "      <td>0.805683</td>\n",
       "      <td>0.828014</td>\n",
       "      <td>0.771898</td>\n",
       "      <td>0.791861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.066300</td>\n",
       "      <td>0.822157</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.826576</td>\n",
       "      <td>0.755023</td>\n",
       "      <td>0.778773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.888195</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.788297</td>\n",
       "      <td>0.758031</td>\n",
       "      <td>0.767168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.041100</td>\n",
       "      <td>0.839626</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.777078</td>\n",
       "      <td>0.764976</td>\n",
       "      <td>0.770012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>0.922305</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.759619</td>\n",
       "      <td>0.771637</td>\n",
       "      <td>0.762839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=420, training_loss=0.36715816543215796, metrics={'train_runtime': 61.639, 'train_samples_per_second': 1415.013, 'train_steps_per_second': 11.356, 'total_flos': 39005907393600.0, 'train_loss': 0.36715816543215796, 'epoch': 12.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Přepnutí modelu do evaluačního režimu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-1): 2 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=128, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Otestování modelu nad testovací částí datasetu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5971861481666565,\n",
       " 'eval_accuracy': 0.844,\n",
       " 'eval_precision': 0.8336845142766452,\n",
       " 'eval_recall': 0.8331648587390704,\n",
       " 'eval_f1': 0.8316674032757624,\n",
       " 'eval_runtime': 3.2722,\n",
       " 'eval_samples_per_second': 152.803,\n",
       " 'eval_steps_per_second': 1.222,\n",
       " 'epoch': 12.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uložení modelu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bert-base_coarse.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trénink s destilací s původním datasetem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Získání předtrénovaného studentského modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "student_model = BertForSequenceClassification.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\", num_labels=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konfigurace tréninku s destilací, zvolené parametry odpovídají pěti nejlepším výstupům z prohledávání hyperparametrů."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bert-distill_coarse\", logging_dir=f\"~/logs/{DATASET}/bert-distill_coarse\", remove_unused_columns=False, epochs=20, lr=.0004, weight_decay=.006, warmup_steps=3, temp=2.5, lambda_param=.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konfigurace destilačního trenéra s trpělivostí 4 epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainer(\n",
    "    student_model=student_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 4)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spuštění tréninku s destilací, výstupy nad validační částí datasetu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='630' max='700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [630/700 01:36 < 00:10, 6.54 it/s, Epoch 18/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.874400</td>\n",
       "      <td>3.274858</td>\n",
       "      <td>0.545371</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.452891</td>\n",
       "      <td>0.455550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.858800</td>\n",
       "      <td>2.414468</td>\n",
       "      <td>0.669111</td>\n",
       "      <td>0.592933</td>\n",
       "      <td>0.569114</td>\n",
       "      <td>0.572565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.946400</td>\n",
       "      <td>1.865984</td>\n",
       "      <td>0.742438</td>\n",
       "      <td>0.627257</td>\n",
       "      <td>0.638587</td>\n",
       "      <td>0.632136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.278200</td>\n",
       "      <td>1.559126</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.823563</td>\n",
       "      <td>0.673642</td>\n",
       "      <td>0.678479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.822400</td>\n",
       "      <td>1.452547</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.661701</td>\n",
       "      <td>0.671452</td>\n",
       "      <td>0.665183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.530500</td>\n",
       "      <td>1.428145</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.834769</td>\n",
       "      <td>0.714999</td>\n",
       "      <td>0.734863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>1.453631</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.813232</td>\n",
       "      <td>0.735755</td>\n",
       "      <td>0.755643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.261400</td>\n",
       "      <td>1.432611</td>\n",
       "      <td>0.805683</td>\n",
       "      <td>0.825315</td>\n",
       "      <td>0.753287</td>\n",
       "      <td>0.774574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.198700</td>\n",
       "      <td>1.520586</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.820757</td>\n",
       "      <td>0.760647</td>\n",
       "      <td>0.779352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.158300</td>\n",
       "      <td>1.616826</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.810850</td>\n",
       "      <td>0.747417</td>\n",
       "      <td>0.766915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.136100</td>\n",
       "      <td>1.483503</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.828620</td>\n",
       "      <td>0.760126</td>\n",
       "      <td>0.783170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.122800</td>\n",
       "      <td>1.534680</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.805095</td>\n",
       "      <td>0.758072</td>\n",
       "      <td>0.774100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.102700</td>\n",
       "      <td>1.504687</td>\n",
       "      <td>0.807516</td>\n",
       "      <td>0.831693</td>\n",
       "      <td>0.763218</td>\n",
       "      <td>0.786221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.104400</td>\n",
       "      <td>1.509801</td>\n",
       "      <td>0.810266</td>\n",
       "      <td>0.838267</td>\n",
       "      <td>0.765199</td>\n",
       "      <td>0.789798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.090100</td>\n",
       "      <td>1.504141</td>\n",
       "      <td>0.804766</td>\n",
       "      <td>0.828538</td>\n",
       "      <td>0.762592</td>\n",
       "      <td>0.784078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.096900</td>\n",
       "      <td>1.516467</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.824733</td>\n",
       "      <td>0.760356</td>\n",
       "      <td>0.781227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.080800</td>\n",
       "      <td>1.527455</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.822120</td>\n",
       "      <td>0.759375</td>\n",
       "      <td>0.779352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.078400</td>\n",
       "      <td>1.518797</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.825687</td>\n",
       "      <td>0.761431</td>\n",
       "      <td>0.782483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=630, training_loss=0.7270351145002577, metrics={'train_runtime': 96.4329, 'train_samples_per_second': 904.464, 'train_steps_per_second': 7.259, 'total_flos': 58508861090400.0, 'train_loss': 0.7270351145002577, 'epoch': 18.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Přepnutí studenta do evaluačního režimu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-1): 2 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=128, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Otestování modelu nad testovací částí datasetu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.4004614353179932,\n",
       " 'eval_accuracy': 0.838,\n",
       " 'eval_precision': 0.821224466394745,\n",
       " 'eval_recall': 0.8388925302933874,\n",
       " 'eval_f1': 0.8259890406235443,\n",
       " 'eval_runtime': 3.2361,\n",
       " 'eval_samples_per_second': 154.508,\n",
       " 'eval_steps_per_second': 1.236,\n",
       " 'epoch': 18.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uložení studentského modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student_model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bert-distil_coarse.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normální trénink s augmentovaným datasetem\n",
    "Získání předtrénovaného modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\", num_labels=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konfigurace tréninku, zvolené parametry odpovídají pěti nejlepším výstupům z prohledávání hyperparametrů.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bert-base-aug_coarse\", logging_dir=f\"~/logs/{DATASET}/bert-base-aug_coarse\", epochs=20, lr=.00003, weight_decay=.005, warmup_steps=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konfigurace trenéra s trpělivostí 4 epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_aug,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 4)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Spuštění tréninku, výstupy nad validační částí datasetu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3355' max='6100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3355/6100 02:11 < 01:47, 25.43 it/s, Epoch 11/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.554400</td>\n",
       "      <td>1.375357</td>\n",
       "      <td>0.506874</td>\n",
       "      <td>0.568107</td>\n",
       "      <td>0.402775</td>\n",
       "      <td>0.393190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.134600</td>\n",
       "      <td>0.988684</td>\n",
       "      <td>0.697525</td>\n",
       "      <td>0.628769</td>\n",
       "      <td>0.591833</td>\n",
       "      <td>0.602613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.834700</td>\n",
       "      <td>0.804513</td>\n",
       "      <td>0.744271</td>\n",
       "      <td>0.646096</td>\n",
       "      <td>0.635124</td>\n",
       "      <td>0.638677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.636000</td>\n",
       "      <td>0.719141</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.829947</td>\n",
       "      <td>0.675570</td>\n",
       "      <td>0.692393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.492700</td>\n",
       "      <td>0.663883</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.818350</td>\n",
       "      <td>0.734783</td>\n",
       "      <td>0.758528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.398000</td>\n",
       "      <td>0.651590</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.826361</td>\n",
       "      <td>0.749804</td>\n",
       "      <td>0.773761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.337300</td>\n",
       "      <td>0.641690</td>\n",
       "      <td>0.806599</td>\n",
       "      <td>0.831157</td>\n",
       "      <td>0.753869</td>\n",
       "      <td>0.778146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.289100</td>\n",
       "      <td>0.648874</td>\n",
       "      <td>0.805683</td>\n",
       "      <td>0.828512</td>\n",
       "      <td>0.752877</td>\n",
       "      <td>0.776549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.255400</td>\n",
       "      <td>0.657757</td>\n",
       "      <td>0.804766</td>\n",
       "      <td>0.828051</td>\n",
       "      <td>0.752326</td>\n",
       "      <td>0.776070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.231200</td>\n",
       "      <td>0.671070</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.823683</td>\n",
       "      <td>0.750083</td>\n",
       "      <td>0.772650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.675293</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.823742</td>\n",
       "      <td>0.751611</td>\n",
       "      <td>0.773587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3355, training_loss=0.5793979991566051, metrics={'train_runtime': 132.1774, 'train_samples_per_second': 5889.356, 'train_steps_per_second': 46.15, 'total_flos': 319117694781600.0, 'train_loss': 0.5793979991566051, 'epoch': 11.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Přepnutí modelu do evaluačního režimu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-1): 2 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=128, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Otestování modelu nad testovací částí datasetu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.47989678382873535,\n",
       " 'eval_accuracy': 0.854,\n",
       " 'eval_precision': 0.8755966694475799,\n",
       " 'eval_recall': 0.8254649373070079,\n",
       " 'eval_f1': 0.8440515515873256,\n",
       " 'eval_runtime': 5.451,\n",
       " 'eval_samples_per_second': 91.726,\n",
       " 'eval_steps_per_second': 0.734,\n",
       " 'epoch': 11.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uložení modelu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bert-base-aug_coarse.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trénink s destilací s augmentovaným datasetem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Získání předtrénovaného studentského modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "student_model = BertForSequenceClassification.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\", num_labels=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konfigurace tréninku s destilací, zvolené parametry odpovídají pěti nejlepším výstupům z prohledávání hyperparametrů."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bert-distill-aug_coarse\", logging_dir=f\"~/logs/{DATASET}/bert-distill-aug_coarse\", remove_unused_columns=False, epochs=20, lr=.00025, weight_decay=.005, temp=4, lambda_param=.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konfigurace destilačního trenéra s trpělivostí 4 epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainer(\n",
    "    student_model=student_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_aug,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 4)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spuštění tréninku s destilací, výstupy nad validační částí datasetu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3965' max='6100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3965/6100 02:36 < 01:24, 25.28 it/s, Epoch 13/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.340900</td>\n",
       "      <td>1.589709</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.755488</td>\n",
       "      <td>0.688767</td>\n",
       "      <td>0.692523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.538800</td>\n",
       "      <td>1.298756</td>\n",
       "      <td>0.827681</td>\n",
       "      <td>0.843854</td>\n",
       "      <td>0.782121</td>\n",
       "      <td>0.801464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.294000</td>\n",
       "      <td>1.343081</td>\n",
       "      <td>0.826764</td>\n",
       "      <td>0.838112</td>\n",
       "      <td>0.782522</td>\n",
       "      <td>0.798631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.227100</td>\n",
       "      <td>1.255016</td>\n",
       "      <td>0.832264</td>\n",
       "      <td>0.837746</td>\n",
       "      <td>0.783864</td>\n",
       "      <td>0.802893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>1.259071</td>\n",
       "      <td>0.840513</td>\n",
       "      <td>0.846026</td>\n",
       "      <td>0.788898</td>\n",
       "      <td>0.809829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.166200</td>\n",
       "      <td>1.240512</td>\n",
       "      <td>0.841430</td>\n",
       "      <td>0.843660</td>\n",
       "      <td>0.790784</td>\n",
       "      <td>0.809900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.147300</td>\n",
       "      <td>1.297121</td>\n",
       "      <td>0.840513</td>\n",
       "      <td>0.830456</td>\n",
       "      <td>0.790599</td>\n",
       "      <td>0.805768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.136300</td>\n",
       "      <td>1.251859</td>\n",
       "      <td>0.842346</td>\n",
       "      <td>0.830643</td>\n",
       "      <td>0.792419</td>\n",
       "      <td>0.806550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.125600</td>\n",
       "      <td>1.289922</td>\n",
       "      <td>0.841430</td>\n",
       "      <td>0.840766</td>\n",
       "      <td>0.802678</td>\n",
       "      <td>0.815739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.116200</td>\n",
       "      <td>1.301587</td>\n",
       "      <td>0.842346</td>\n",
       "      <td>0.831805</td>\n",
       "      <td>0.792937</td>\n",
       "      <td>0.807246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>1.335589</td>\n",
       "      <td>0.831347</td>\n",
       "      <td>0.821210</td>\n",
       "      <td>0.784340</td>\n",
       "      <td>0.797447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.104100</td>\n",
       "      <td>1.309408</td>\n",
       "      <td>0.835014</td>\n",
       "      <td>0.836709</td>\n",
       "      <td>0.787103</td>\n",
       "      <td>0.804061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.099100</td>\n",
       "      <td>1.242411</td>\n",
       "      <td>0.843263</td>\n",
       "      <td>0.831984</td>\n",
       "      <td>0.792560</td>\n",
       "      <td>0.807316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3965, training_loss=0.35348223365119846, metrics={'train_runtime': 157.083, 'train_samples_per_second': 4955.598, 'train_steps_per_second': 38.833, 'total_flos': 377139093832800.0, 'train_loss': 0.35348223365119846, 'epoch': 13.0})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Přepnutí studenta do evaluačního režimu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-1): 2 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=128, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otestování studenta nad testovací částí datasetu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.409029245376587,\n",
       " 'eval_accuracy': 0.854,\n",
       " 'eval_precision': 0.8545244870998044,\n",
       " 'eval_recall': 0.8491272999587253,\n",
       " 'eval_f1': 0.8489970789959579,\n",
       " 'eval_runtime': 3.7279,\n",
       " 'eval_samples_per_second': 134.125,\n",
       " 'eval_steps_per_second': 1.073,\n",
       " 'epoch': 13.0}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uložení studentského modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student_model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bert-distil-aug_coarse.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Získání počtu trénovatelných parametrů v modelu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 16.742MB.\n",
      "Total Trainable Params: 4386694.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Modules</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert.embeddings.word_embeddings.weight</td>\n",
       "      <td>3906816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert.embeddings.position_embeddings.weight</td>\n",
       "      <td>65536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert.embeddings.token_type_embeddings.weight</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert.embeddings.LayerNorm.weight</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bert.embeddings.LayerNorm.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bert.encoder.layer.0.attention.self.query.weight</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bert.encoder.layer.0.attention.self.query.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bert.encoder.layer.0.attention.self.key.weight</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bert.encoder.layer.0.attention.self.key.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bert.encoder.layer.0.attention.self.value.weight</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bert.encoder.layer.0.attention.self.value.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bert.encoder.layer.0.attention.output.dense.we...</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bert.encoder.layer.0.attention.output.dense.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bert.encoder.layer.0.attention.output.LayerNor...</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bert.encoder.layer.0.attention.output.LayerNor...</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bert.encoder.layer.0.intermediate.dense.weight</td>\n",
       "      <td>65536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bert.encoder.layer.0.intermediate.dense.bias</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bert.encoder.layer.0.output.dense.weight</td>\n",
       "      <td>65536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bert.encoder.layer.0.output.dense.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bert.encoder.layer.0.output.LayerNorm.weight</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bert.encoder.layer.0.output.LayerNorm.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bert.encoder.layer.1.attention.self.query.weight</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bert.encoder.layer.1.attention.self.query.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bert.encoder.layer.1.attention.self.key.weight</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bert.encoder.layer.1.attention.self.key.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bert.encoder.layer.1.attention.self.value.weight</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bert.encoder.layer.1.attention.self.value.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bert.encoder.layer.1.attention.output.dense.we...</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bert.encoder.layer.1.attention.output.dense.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bert.encoder.layer.1.attention.output.LayerNor...</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>bert.encoder.layer.1.attention.output.LayerNor...</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>bert.encoder.layer.1.intermediate.dense.weight</td>\n",
       "      <td>65536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>bert.encoder.layer.1.intermediate.dense.bias</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>bert.encoder.layer.1.output.dense.weight</td>\n",
       "      <td>65536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>bert.encoder.layer.1.output.dense.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>bert.encoder.layer.1.output.LayerNorm.weight</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>bert.encoder.layer.1.output.LayerNorm.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>bert.pooler.dense.weight</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>bert.pooler.dense.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>classifier.weight</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>classifier.bias</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Modules Parameters\n",
       "0              bert.embeddings.word_embeddings.weight    3906816\n",
       "1          bert.embeddings.position_embeddings.weight      65536\n",
       "2        bert.embeddings.token_type_embeddings.weight        256\n",
       "3                    bert.embeddings.LayerNorm.weight        128\n",
       "4                      bert.embeddings.LayerNorm.bias        128\n",
       "5    bert.encoder.layer.0.attention.self.query.weight      16384\n",
       "6      bert.encoder.layer.0.attention.self.query.bias        128\n",
       "7      bert.encoder.layer.0.attention.self.key.weight      16384\n",
       "8        bert.encoder.layer.0.attention.self.key.bias        128\n",
       "9    bert.encoder.layer.0.attention.self.value.weight      16384\n",
       "10     bert.encoder.layer.0.attention.self.value.bias        128\n",
       "11  bert.encoder.layer.0.attention.output.dense.we...      16384\n",
       "12   bert.encoder.layer.0.attention.output.dense.bias        128\n",
       "13  bert.encoder.layer.0.attention.output.LayerNor...        128\n",
       "14  bert.encoder.layer.0.attention.output.LayerNor...        128\n",
       "15     bert.encoder.layer.0.intermediate.dense.weight      65536\n",
       "16       bert.encoder.layer.0.intermediate.dense.bias        512\n",
       "17           bert.encoder.layer.0.output.dense.weight      65536\n",
       "18             bert.encoder.layer.0.output.dense.bias        128\n",
       "19       bert.encoder.layer.0.output.LayerNorm.weight        128\n",
       "20         bert.encoder.layer.0.output.LayerNorm.bias        128\n",
       "21   bert.encoder.layer.1.attention.self.query.weight      16384\n",
       "22     bert.encoder.layer.1.attention.self.query.bias        128\n",
       "23     bert.encoder.layer.1.attention.self.key.weight      16384\n",
       "24       bert.encoder.layer.1.attention.self.key.bias        128\n",
       "25   bert.encoder.layer.1.attention.self.value.weight      16384\n",
       "26     bert.encoder.layer.1.attention.self.value.bias        128\n",
       "27  bert.encoder.layer.1.attention.output.dense.we...      16384\n",
       "28   bert.encoder.layer.1.attention.output.dense.bias        128\n",
       "29  bert.encoder.layer.1.attention.output.LayerNor...        128\n",
       "30  bert.encoder.layer.1.attention.output.LayerNor...        128\n",
       "31     bert.encoder.layer.1.intermediate.dense.weight      65536\n",
       "32       bert.encoder.layer.1.intermediate.dense.bias        512\n",
       "33           bert.encoder.layer.1.output.dense.weight      65536\n",
       "34             bert.encoder.layer.1.output.dense.bias        128\n",
       "35       bert.encoder.layer.1.output.LayerNorm.weight        128\n",
       "36         bert.encoder.layer.1.output.LayerNorm.bias        128\n",
       "37                           bert.pooler.dense.weight      16384\n",
       "38                             bert.pooler.dense.bias        128\n",
       "39                                  classifier.weight        768\n",
       "40                                    classifier.bias          6"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.count_parameters(student_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Změření rychlosti inference při použití CPU, 1000 pokusů s jedním záznamem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7089f9f9e7d0>\n",
      "self.infer_speed_comp()\n",
      "  3.95 ms\n",
      "  1 measurement, 1000 runs , 4 threads\n"
     ]
    }
   ],
   "source": [
    "cpu_benchmark = base.BenchMarkRunner(student_model, cpu_data_loader, \"cpu\", 1000)\n",
    "print(cpu_benchmark.run_benchmark())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Změření rychlosti inference při použití GPU, 1000 pokusů s jedním záznamem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7089f9f41630>\n",
      "self.infer_speed_comp()\n",
      "  2.30 ms\n",
      "  1 measurement, 1000 runs , 4 threads\n"
     ]
    }
   ],
   "source": [
    "gpu_benchmark = base.BenchMarkRunner(student_model, gpu_data_loader, \"cuda\", 1000)\n",
    "print(gpu_benchmark.run_benchmark())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
