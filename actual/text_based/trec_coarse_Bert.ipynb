{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Torchtext není k dispozici pro poslední verzi pytorch, budeme tedy využuívat něco jiného ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, BertForSequenceClassification, BertTokenizer, EarlyStoppingCallback\n",
    "from datasets import load_from_disk\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import base\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"trec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and will be used: NVIDIA A100 80GB PCIe MIG 2g.20gb\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and will be used:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_from_disk(f\"~/data/{DATASET}/train-logits_coarse\")\n",
    "eval = load_from_disk(f\"~/data/{DATASET}/eval-logits_coarse\")\n",
    "test = load_from_disk(f\"~/data/{DATASET}/test-logits_coarse\")\n",
    "\n",
    "train_aug = load_from_disk(f\"~/data/{DATASET}/train-logits-augmented_coarse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"carrassi-ni/bert-base-trec-question-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b401d24d6b741459a5cf765293741a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the train dataset:   0%|          | 0/4361 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72b1ac6643d46389ad4a33e8d6044b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the eval dataset:   0%|          | 0/1091 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8374fa7ce3e47d4b98b25e3aa3ca520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the test dataset:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63c94c570b949f0a5776422739e9fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the augmented dataset:   0%|          | 0/38918 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = train.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the train dataset\")\n",
    "eval = eval.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the eval dataset\")\n",
    "test = test.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the test dataset\")\n",
    "\n",
    "train_aug = train_aug.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the augmented dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\", num_labels=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bert-base_coarse\", logging_dir=f\"~/logs/{DATASET}/bert-base_coarse\", batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/350 02:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.734800</td>\n",
       "      <td>1.665223</td>\n",
       "      <td>0.339138</td>\n",
       "      <td>0.354753</td>\n",
       "      <td>0.259544</td>\n",
       "      <td>0.219486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.634600</td>\n",
       "      <td>1.555312</td>\n",
       "      <td>0.477544</td>\n",
       "      <td>0.353830</td>\n",
       "      <td>0.375485</td>\n",
       "      <td>0.350736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.536600</td>\n",
       "      <td>1.459618</td>\n",
       "      <td>0.505958</td>\n",
       "      <td>0.510923</td>\n",
       "      <td>0.412153</td>\n",
       "      <td>0.413852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.454400</td>\n",
       "      <td>1.391964</td>\n",
       "      <td>0.525206</td>\n",
       "      <td>0.515787</td>\n",
       "      <td>0.433672</td>\n",
       "      <td>0.441531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.390100</td>\n",
       "      <td>1.340444</td>\n",
       "      <td>0.539872</td>\n",
       "      <td>0.519181</td>\n",
       "      <td>0.448466</td>\n",
       "      <td>0.454084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.337700</td>\n",
       "      <td>1.302161</td>\n",
       "      <td>0.554537</td>\n",
       "      <td>0.532215</td>\n",
       "      <td>0.460447</td>\n",
       "      <td>0.468416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.305500</td>\n",
       "      <td>1.274034</td>\n",
       "      <td>0.570119</td>\n",
       "      <td>0.542238</td>\n",
       "      <td>0.473865</td>\n",
       "      <td>0.481685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.276300</td>\n",
       "      <td>1.253692</td>\n",
       "      <td>0.577452</td>\n",
       "      <td>0.549743</td>\n",
       "      <td>0.480515</td>\n",
       "      <td>0.488757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.263600</td>\n",
       "      <td>1.241146</td>\n",
       "      <td>0.581118</td>\n",
       "      <td>0.549899</td>\n",
       "      <td>0.483580</td>\n",
       "      <td>0.491989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.259600</td>\n",
       "      <td>1.237528</td>\n",
       "      <td>0.586618</td>\n",
       "      <td>0.554046</td>\n",
       "      <td>0.488057</td>\n",
       "      <td>0.496499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=350, training_loss=1.4193327004568916, metrics={'train_runtime': 122.269, 'train_samples_per_second': 356.672, 'train_steps_per_second': 2.863, 'total_flos': 32504922828000.0, 'train_loss': 1.4193327004568916, 'epoch': 10.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-1): 2 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=128, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.2033241987228394,\n",
       " 'eval_accuracy': 0.652,\n",
       " 'eval_precision': 0.6378523555056522,\n",
       " 'eval_recall': 0.5308106638443274,\n",
       " 'eval_f1': 0.5398035170935934,\n",
       " 'eval_runtime': 40.5007,\n",
       " 'eval_samples_per_second': 12.345,\n",
       " 'eval_steps_per_second': 0.099,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bert_coarse.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "student_model = BertForSequenceClassification.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\", num_labels=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bert-distill_coarse\", logging_dir=f\"~/logs/{DATASET}/bert-distill_coarse\", remove_unused_columns=False, batch_size=128, epochs=10, temp=5, lambda_param=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainer(\n",
    "    student_model=student_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/350 02:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.941000</td>\n",
       "      <td>3.813669</td>\n",
       "      <td>0.309808</td>\n",
       "      <td>0.373039</td>\n",
       "      <td>0.231672</td>\n",
       "      <td>0.172883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.781100</td>\n",
       "      <td>3.633712</td>\n",
       "      <td>0.469294</td>\n",
       "      <td>0.377785</td>\n",
       "      <td>0.365707</td>\n",
       "      <td>0.343194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.622800</td>\n",
       "      <td>3.475004</td>\n",
       "      <td>0.482126</td>\n",
       "      <td>0.507357</td>\n",
       "      <td>0.386129</td>\n",
       "      <td>0.370792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.484700</td>\n",
       "      <td>3.357424</td>\n",
       "      <td>0.516957</td>\n",
       "      <td>0.510199</td>\n",
       "      <td>0.425266</td>\n",
       "      <td>0.431829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.371700</td>\n",
       "      <td>3.264846</td>\n",
       "      <td>0.524290</td>\n",
       "      <td>0.506548</td>\n",
       "      <td>0.435402</td>\n",
       "      <td>0.441040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.278500</td>\n",
       "      <td>3.194957</td>\n",
       "      <td>0.532539</td>\n",
       "      <td>0.510292</td>\n",
       "      <td>0.442741</td>\n",
       "      <td>0.447755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.220700</td>\n",
       "      <td>3.143863</td>\n",
       "      <td>0.548121</td>\n",
       "      <td>0.517228</td>\n",
       "      <td>0.455053</td>\n",
       "      <td>0.458742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.169300</td>\n",
       "      <td>3.105377</td>\n",
       "      <td>0.558203</td>\n",
       "      <td>0.533418</td>\n",
       "      <td>0.463798</td>\n",
       "      <td>0.469221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.134700</td>\n",
       "      <td>3.083539</td>\n",
       "      <td>0.561870</td>\n",
       "      <td>0.530388</td>\n",
       "      <td>0.466939</td>\n",
       "      <td>0.471823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.135400</td>\n",
       "      <td>3.076430</td>\n",
       "      <td>0.561870</td>\n",
       "      <td>0.531516</td>\n",
       "      <td>0.466939</td>\n",
       "      <td>0.472294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=350, training_loss=3.413985028948103, metrics={'train_runtime': 123.9349, 'train_samples_per_second': 351.878, 'train_steps_per_second': 2.824, 'total_flos': 32504922828000.0, 'train_loss': 3.413985028948103, 'epoch': 10.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-1): 2 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=128, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.0210273265838623,\n",
       " 'eval_accuracy': 0.642,\n",
       " 'eval_precision': 0.6287450328459662,\n",
       " 'eval_recall': 0.5204954782639689,\n",
       " 'eval_f1': 0.5264013847403092,\n",
       " 'eval_runtime': 4.0791,\n",
       " 'eval_samples_per_second': 122.576,\n",
       " 'eval_steps_per_second': 0.981,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student_model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bert-distil_coarse.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\", num_labels=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bert-base-aug_coarse\", logging_dir=f\"~/logs/{DATASET}/bert-base-aug_coarse\", batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_aug,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 4)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3050' max='3050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3050/3050 07:41, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.423700</td>\n",
       "      <td>1.126349</td>\n",
       "      <td>0.632447</td>\n",
       "      <td>0.610722</td>\n",
       "      <td>0.527022</td>\n",
       "      <td>0.545799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.867900</td>\n",
       "      <td>0.792168</td>\n",
       "      <td>0.740605</td>\n",
       "      <td>0.638920</td>\n",
       "      <td>0.633929</td>\n",
       "      <td>0.635285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.571500</td>\n",
       "      <td>0.698528</td>\n",
       "      <td>0.778185</td>\n",
       "      <td>0.828345</td>\n",
       "      <td>0.704712</td>\n",
       "      <td>0.726332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.410100</td>\n",
       "      <td>0.659463</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.825186</td>\n",
       "      <td>0.760602</td>\n",
       "      <td>0.782133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.324200</td>\n",
       "      <td>0.659629</td>\n",
       "      <td>0.804766</td>\n",
       "      <td>0.824715</td>\n",
       "      <td>0.752868</td>\n",
       "      <td>0.774712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.266500</td>\n",
       "      <td>0.664385</td>\n",
       "      <td>0.810266</td>\n",
       "      <td>0.831991</td>\n",
       "      <td>0.766545</td>\n",
       "      <td>0.788426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.233600</td>\n",
       "      <td>0.665218</td>\n",
       "      <td>0.811182</td>\n",
       "      <td>0.833146</td>\n",
       "      <td>0.767079</td>\n",
       "      <td>0.789254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.209300</td>\n",
       "      <td>0.664284</td>\n",
       "      <td>0.812099</td>\n",
       "      <td>0.835697</td>\n",
       "      <td>0.767878</td>\n",
       "      <td>0.790937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.199000</td>\n",
       "      <td>0.667429</td>\n",
       "      <td>0.816682</td>\n",
       "      <td>0.838508</td>\n",
       "      <td>0.771184</td>\n",
       "      <td>0.793845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.189800</td>\n",
       "      <td>0.670568</td>\n",
       "      <td>0.816682</td>\n",
       "      <td>0.836780</td>\n",
       "      <td>0.771441</td>\n",
       "      <td>0.793259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3050, training_loss=0.4695532214055296, metrics={'train_runtime': 464.9114, 'train_samples_per_second': 837.106, 'train_steps_per_second': 6.56, 'total_flos': 290077181064000.0, 'train_loss': 0.4695532214055296, 'epoch': 10.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-1): 2 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=128, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.49601519107818604,\n",
       " 'eval_accuracy': 0.856,\n",
       " 'eval_precision': 0.876493408562744,\n",
       " 'eval_recall': 0.8472441554550786,\n",
       " 'eval_f1': 0.8584872846768654,\n",
       " 'eval_runtime': 3.7067,\n",
       " 'eval_samples_per_second': 134.892,\n",
       " 'eval_steps_per_second': 1.079,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bert-base-aug_coarse.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "student_model = BertForSequenceClassification.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\", num_labels=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bert-distill-aug_coarse\", logging_dir=f\"~/logs/{DATASET}/bert-distill-aug_coarse\", remove_unused_columns=False, batch_size=128, epochs=10, temp=5, lambda_param=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainer(\n",
    "    student_model=student_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_aug,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 4)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3050' max='3050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3050/3050 07:05, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.199300</td>\n",
       "      <td>2.811740</td>\n",
       "      <td>0.608616</td>\n",
       "      <td>0.606531</td>\n",
       "      <td>0.501452</td>\n",
       "      <td>0.517117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.129900</td>\n",
       "      <td>2.019408</td>\n",
       "      <td>0.739688</td>\n",
       "      <td>0.641102</td>\n",
       "      <td>0.632493</td>\n",
       "      <td>0.635413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.462800</td>\n",
       "      <td>1.669034</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.655168</td>\n",
       "      <td>0.655668</td>\n",
       "      <td>0.654295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.047700</td>\n",
       "      <td>1.471070</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.775410</td>\n",
       "      <td>0.691390</td>\n",
       "      <td>0.701140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.808500</td>\n",
       "      <td>1.400081</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.815862</td>\n",
       "      <td>0.734683</td>\n",
       "      <td>0.757304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.654500</td>\n",
       "      <td>1.347878</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.820297</td>\n",
       "      <td>0.740653</td>\n",
       "      <td>0.762678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.563500</td>\n",
       "      <td>1.329735</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.822075</td>\n",
       "      <td>0.749129</td>\n",
       "      <td>0.771299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.498900</td>\n",
       "      <td>1.299253</td>\n",
       "      <td>0.804766</td>\n",
       "      <td>0.830450</td>\n",
       "      <td>0.752908</td>\n",
       "      <td>0.777197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.466500</td>\n",
       "      <td>1.290551</td>\n",
       "      <td>0.805683</td>\n",
       "      <td>0.815317</td>\n",
       "      <td>0.753363</td>\n",
       "      <td>0.774220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.447700</td>\n",
       "      <td>1.293415</td>\n",
       "      <td>0.804766</td>\n",
       "      <td>0.829052</td>\n",
       "      <td>0.753253</td>\n",
       "      <td>0.776767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3050, training_loss=1.1279355058513705, metrics={'train_runtime': 426.3986, 'train_samples_per_second': 912.714, 'train_steps_per_second': 7.153, 'total_flos': 290077181064000.0, 'train_loss': 1.1279355058513705, 'epoch': 10.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-1): 2 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=128, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.1607972383499146,\n",
       " 'eval_accuracy': 0.858,\n",
       " 'eval_precision': 0.8806367437986035,\n",
       " 'eval_recall': 0.8304224336048268,\n",
       " 'eval_f1': 0.8483146240881965,\n",
       " 'eval_runtime': 3.6698,\n",
       " 'eval_samples_per_second': 136.246,\n",
       " 'eval_steps_per_second': 1.09,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student_model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bert-distil-aug_coarse.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
