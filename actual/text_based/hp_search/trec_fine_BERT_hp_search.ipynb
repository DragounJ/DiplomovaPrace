{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43fa293f",
   "metadata": {},
   "source": [
    "# Prohledávání hyperparametrů pro model BERT TINY nad datasetem TREC (fine) \n",
    "\n",
    "Tento notebook slouží k nalezení optimálních hyperparametrů nad datasetem TREC (fine) pro model BERRT TINY. Hyperparametry jsou hledány pro původní i augmentovaný dataset pro normální trénink i destilaci.\n",
    "\n",
    "K prohledávání je využito knihovny Optuna s algoritmem Hyperband. Nejlepší konfigurace je volena na základě F1-skóre, zkoušeno je 150 kombinací hyperparametrů pro každou z variant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b75149",
   "metadata": {},
   "source": [
    "## Import knihoven a základní nastavení"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7e7a26f-aa1f-4645-b3b3-4643ca8be2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, BertTokenizer, BertForSequenceClassification\n",
    "from datasets import load_from_disk\n",
    "import optuna\n",
    "import torch\n",
    "import math\n",
    "import base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4a3953",
   "metadata": {},
   "source": [
    "Resetování náhodného seedu pro replikovatelnost výsledků."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae5100e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6cc94d",
   "metadata": {},
   "source": [
    "Ověření dostupnosti GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29b9ceef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and will be used: NVIDIA A100 80GB PCIe MIG 2g.20gb\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and will be used:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24810d34",
   "metadata": {},
   "source": [
    "Načtení datasetu a jeho základní předzpracování (tokenizace pomocí učitele)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26c9d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"trec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14bfbf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_from_disk(f\"~/data/{DATASET}/train-logits_fine\")\n",
    "eval_data = load_from_disk(f\"~/data/{DATASET}/eval-logits_fine\")\n",
    "test_data = load_from_disk(f\"~/data/{DATASET}/test-logits_fine\")\n",
    "\n",
    "all_train_data = load_from_disk(f\"~/data/{DATASET}/train-logits-augmented_fine\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"ndavid/autotrain-trec-fine-bert-739422530\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bd0688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the train dataset\")\n",
    "eval = eval_data.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the eval dataset\")\n",
    "test = test_data.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the test dataset\")\n",
    "\n",
    "train_aug = all_train_data.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the augmented dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb98551",
   "metadata": {},
   "source": [
    "Základní konfigurace tréninku během prohledávání. Optuna nepracuje s epochami, ale s kroky. Níže je prováděn přepočet. \n",
    "\n",
    "Minimální délka tréninku je pět epochy, maximální 15 epoch. Maximální počet kroků pro warm up je nastaven na 10 % první epochy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65e61bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01f8400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = len(train_data)\n",
    "min_r = math.ceil(data_length/batch_size)*5\n",
    "max_r = math.ceil(data_length/batch_size)*num_epochs\n",
    "warm_up = math.ceil(data_length/batch_size/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c53f146",
   "metadata": {},
   "source": [
    "## Prohledávání s normálním tréninkem nad původním datasetem\n",
    "Definice hledaných hyperparametrů a jejich rozmezí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3574e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_space(trial):\n",
    "    params =  {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 5e-4, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0, 1e-2, step=1e-3),\n",
    "        \"warmup_steps\" : trial.suggest_int(\"warmup_steps\", 0, warm_up)\n",
    "    }   \n",
    "    print(f\"Trial {trial.number} with params: {params}\")\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a963242",
   "metadata": {},
   "source": [
    "Konfigurace Optuny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "174fff53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pruner = optuna.pruners.HyperbandPruner(min_resource=min_r, max_resource=max_r, reduction_factor=2, bootstrap_count=2)\n",
    "sampler = optuna.samplers.TPESampler(seed=42, multivariate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac334ea",
   "metadata": {},
   "source": [
    "Získání předtrénovaného modelu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ba99151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Bert():\n",
    "    return BertForSequenceClassification.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\", num_labels=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a906d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670d2cf5",
   "metadata": {},
   "source": [
    "Konfigurace jednotlivých tréninků."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4b4c462",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bert-base_fine_hp-search\", logging_dir=f\"~/logs/{DATASET}/bert-base_fine_hp-search\", epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da23cd1c",
   "metadata": {},
   "source": [
    "Konfigurace trenéra pro jednotlivé tréninky. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc752b97-d843-4919-a0fc-066d192e037b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    model_init = lambda: get_Bert(),\n",
    ")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ea0e72",
   "metadata": {},
   "source": [
    "Nastavení prohledávání."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97855619-93d5-4fc2-93d2-fee24c61b8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 08:36:11,640] A new study created in memory with name: Test-base\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 with params: {'learning_rate': 4.3284502212938785e-05, 'weight_decay': 0.01, 'warmup_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:46 < 00:23, 7.48 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.805000</td>\n",
       "      <td>3.692317</td>\n",
       "      <td>0.183318</td>\n",
       "      <td>0.011379</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>0.009180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.639400</td>\n",
       "      <td>3.555955</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.023551</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.522100</td>\n",
       "      <td>3.433531</td>\n",
       "      <td>0.188818</td>\n",
       "      <td>0.043581</td>\n",
       "      <td>0.023490</td>\n",
       "      <td>0.012242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.404000</td>\n",
       "      <td>3.322597</td>\n",
       "      <td>0.302475</td>\n",
       "      <td>0.074402</td>\n",
       "      <td>0.057608</td>\n",
       "      <td>0.051521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.320300</td>\n",
       "      <td>3.225941</td>\n",
       "      <td>0.372136</td>\n",
       "      <td>0.069201</td>\n",
       "      <td>0.078112</td>\n",
       "      <td>0.064180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.222200</td>\n",
       "      <td>3.145883</td>\n",
       "      <td>0.396884</td>\n",
       "      <td>0.079409</td>\n",
       "      <td>0.085359</td>\n",
       "      <td>0.067539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.141600</td>\n",
       "      <td>3.074114</td>\n",
       "      <td>0.409716</td>\n",
       "      <td>0.095976</td>\n",
       "      <td>0.089143</td>\n",
       "      <td>0.069005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.083900</td>\n",
       "      <td>3.012590</td>\n",
       "      <td>0.421632</td>\n",
       "      <td>0.093745</td>\n",
       "      <td>0.094901</td>\n",
       "      <td>0.075415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.024200</td>\n",
       "      <td>2.960886</td>\n",
       "      <td>0.428048</td>\n",
       "      <td>0.089753</td>\n",
       "      <td>0.099020</td>\n",
       "      <td>0.079480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.980600</td>\n",
       "      <td>2.919415</td>\n",
       "      <td>0.442713</td>\n",
       "      <td>0.088418</td>\n",
       "      <td>0.105445</td>\n",
       "      <td>0.084439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 08:36:59,929] Trial 0 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 with params: {'learning_rate': 0.00010401663679887307, 'weight_decay': 0.001, 'warmup_steps': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:47, 7.38 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.697000</td>\n",
       "      <td>3.504216</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.390000</td>\n",
       "      <td>3.226867</td>\n",
       "      <td>0.340055</td>\n",
       "      <td>0.070118</td>\n",
       "      <td>0.068843</td>\n",
       "      <td>0.059172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.151700</td>\n",
       "      <td>3.000536</td>\n",
       "      <td>0.411549</td>\n",
       "      <td>0.052382</td>\n",
       "      <td>0.088745</td>\n",
       "      <td>0.063755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.929200</td>\n",
       "      <td>2.802280</td>\n",
       "      <td>0.440880</td>\n",
       "      <td>0.086683</td>\n",
       "      <td>0.103688</td>\n",
       "      <td>0.078788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.769200</td>\n",
       "      <td>2.629229</td>\n",
       "      <td>0.464711</td>\n",
       "      <td>0.104123</td>\n",
       "      <td>0.119232</td>\n",
       "      <td>0.094620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 08:37:24,246] Trial 1 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 with params: {'learning_rate': 1.2551115172973821e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:48 < 00:24, 7.20 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.863200</td>\n",
       "      <td>3.816773</td>\n",
       "      <td>0.062328</td>\n",
       "      <td>0.006793</td>\n",
       "      <td>0.027464</td>\n",
       "      <td>0.006354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.794900</td>\n",
       "      <td>3.757700</td>\n",
       "      <td>0.175985</td>\n",
       "      <td>0.028882</td>\n",
       "      <td>0.021404</td>\n",
       "      <td>0.009876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.749300</td>\n",
       "      <td>3.709666</td>\n",
       "      <td>0.188818</td>\n",
       "      <td>0.015876</td>\n",
       "      <td>0.023822</td>\n",
       "      <td>0.011622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.704400</td>\n",
       "      <td>3.670985</td>\n",
       "      <td>0.186984</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>0.023014</td>\n",
       "      <td>0.010905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.678000</td>\n",
       "      <td>3.636500</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>0.015594</td>\n",
       "      <td>0.022466</td>\n",
       "      <td>0.010184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.640200</td>\n",
       "      <td>3.606443</td>\n",
       "      <td>0.182401</td>\n",
       "      <td>0.020710</td>\n",
       "      <td>0.021644</td>\n",
       "      <td>0.009055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.612200</td>\n",
       "      <td>3.579803</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.019561</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.592000</td>\n",
       "      <td>3.556639</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.569600</td>\n",
       "      <td>3.536597</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.554300</td>\n",
       "      <td>3.520509</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 08:38:13,454] Trial 2 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 with params: {'learning_rate': 0.00015958573588141273, 'weight_decay': 0.0, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:22 < 00:45, 7.69 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.660500</td>\n",
       "      <td>3.397073</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.233500</td>\n",
       "      <td>3.021934</td>\n",
       "      <td>0.394134</td>\n",
       "      <td>0.096931</td>\n",
       "      <td>0.085111</td>\n",
       "      <td>0.064537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.903300</td>\n",
       "      <td>2.704884</td>\n",
       "      <td>0.454629</td>\n",
       "      <td>0.102890</td>\n",
       "      <td>0.113201</td>\n",
       "      <td>0.089629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.603500</td>\n",
       "      <td>2.448021</td>\n",
       "      <td>0.508708</td>\n",
       "      <td>0.132532</td>\n",
       "      <td>0.146713</td>\n",
       "      <td>0.122680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.382900</td>\n",
       "      <td>2.238276</td>\n",
       "      <td>0.559120</td>\n",
       "      <td>0.230503</td>\n",
       "      <td>0.188159</td>\n",
       "      <td>0.173665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 08:38:36,872] Trial 3 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 with params: {'learning_rate': 0.00025959425503112657, 'weight_decay': 0.002, 'warmup_steps': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:11, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.512900</td>\n",
       "      <td>3.156248</td>\n",
       "      <td>0.316224</td>\n",
       "      <td>0.069182</td>\n",
       "      <td>0.061776</td>\n",
       "      <td>0.049671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.932200</td>\n",
       "      <td>2.653960</td>\n",
       "      <td>0.444546</td>\n",
       "      <td>0.062332</td>\n",
       "      <td>0.107967</td>\n",
       "      <td>0.077256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.486700</td>\n",
       "      <td>2.264197</td>\n",
       "      <td>0.534372</td>\n",
       "      <td>0.192541</td>\n",
       "      <td>0.166706</td>\n",
       "      <td>0.151330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.113600</td>\n",
       "      <td>1.976207</td>\n",
       "      <td>0.614115</td>\n",
       "      <td>0.248543</td>\n",
       "      <td>0.239376</td>\n",
       "      <td>0.221089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.840900</td>\n",
       "      <td>1.759768</td>\n",
       "      <td>0.683776</td>\n",
       "      <td>0.317086</td>\n",
       "      <td>0.295897</td>\n",
       "      <td>0.280459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.592900</td>\n",
       "      <td>1.593756</td>\n",
       "      <td>0.703941</td>\n",
       "      <td>0.347480</td>\n",
       "      <td>0.328189</td>\n",
       "      <td>0.313501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.402600</td>\n",
       "      <td>1.480919</td>\n",
       "      <td>0.714024</td>\n",
       "      <td>0.345746</td>\n",
       "      <td>0.334254</td>\n",
       "      <td>0.317279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.276000</td>\n",
       "      <td>1.403965</td>\n",
       "      <td>0.724106</td>\n",
       "      <td>0.354945</td>\n",
       "      <td>0.363755</td>\n",
       "      <td>0.339900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.161800</td>\n",
       "      <td>1.346276</td>\n",
       "      <td>0.725940</td>\n",
       "      <td>0.338757</td>\n",
       "      <td>0.362909</td>\n",
       "      <td>0.340740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.062600</td>\n",
       "      <td>1.304305</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.413861</td>\n",
       "      <td>0.399242</td>\n",
       "      <td>0.380763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.015000</td>\n",
       "      <td>1.275939</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.424767</td>\n",
       "      <td>0.404559</td>\n",
       "      <td>0.388643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.945800</td>\n",
       "      <td>1.252812</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.397262</td>\n",
       "      <td>0.393566</td>\n",
       "      <td>0.379601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.925300</td>\n",
       "      <td>1.234879</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.403201</td>\n",
       "      <td>0.395791</td>\n",
       "      <td>0.378218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.886800</td>\n",
       "      <td>1.221919</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.400641</td>\n",
       "      <td>0.407001</td>\n",
       "      <td>0.390213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.878700</td>\n",
       "      <td>1.222474</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.400111</td>\n",
       "      <td>0.407573</td>\n",
       "      <td>0.390626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 08:39:49,541] Trial 4 finished with value: 0.39062566689300937 and parameters: {'learning_rate': 0.00025959425503112657, 'weight_decay': 0.002, 'warmup_steps': 0}. Best is trial 4 with value: 0.39062566689300937.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 with params: {'learning_rate': 2.049268011541735e-05, 'weight_decay': 0.003, 'warmup_steps': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:22 < 00:45, 7.66 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.845300</td>\n",
       "      <td>3.777779</td>\n",
       "      <td>0.160403</td>\n",
       "      <td>0.009358</td>\n",
       "      <td>0.019167</td>\n",
       "      <td>0.008802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.746000</td>\n",
       "      <td>3.694876</td>\n",
       "      <td>0.183318</td>\n",
       "      <td>0.011392</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>0.009199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.682800</td>\n",
       "      <td>3.630813</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.019561</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.619600</td>\n",
       "      <td>3.575531</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>0.021577</td>\n",
       "      <td>0.022466</td>\n",
       "      <td>0.010407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.578300</td>\n",
       "      <td>3.519766</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.023564</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 08:40:12,936] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 with params: {'learning_rate': 5.4182823195332406e-05, 'weight_decay': 0.003, 'warmup_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:10, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.787600</td>\n",
       "      <td>3.658780</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.019554</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.594500</td>\n",
       "      <td>3.494749</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023548</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.451700</td>\n",
       "      <td>3.346353</td>\n",
       "      <td>0.254812</td>\n",
       "      <td>0.073961</td>\n",
       "      <td>0.042836</td>\n",
       "      <td>0.037371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.309800</td>\n",
       "      <td>3.215431</td>\n",
       "      <td>0.373969</td>\n",
       "      <td>0.069892</td>\n",
       "      <td>0.078417</td>\n",
       "      <td>0.064052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.209500</td>\n",
       "      <td>3.104284</td>\n",
       "      <td>0.402383</td>\n",
       "      <td>0.076904</td>\n",
       "      <td>0.086331</td>\n",
       "      <td>0.066267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.093300</td>\n",
       "      <td>3.007497</td>\n",
       "      <td>0.417965</td>\n",
       "      <td>0.093672</td>\n",
       "      <td>0.093164</td>\n",
       "      <td>0.073219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.998800</td>\n",
       "      <td>2.925731</td>\n",
       "      <td>0.435380</td>\n",
       "      <td>0.089568</td>\n",
       "      <td>0.101749</td>\n",
       "      <td>0.081346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.932000</td>\n",
       "      <td>2.855522</td>\n",
       "      <td>0.448213</td>\n",
       "      <td>0.086628</td>\n",
       "      <td>0.107758</td>\n",
       "      <td>0.085167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.861800</td>\n",
       "      <td>2.796388</td>\n",
       "      <td>0.450962</td>\n",
       "      <td>0.104554</td>\n",
       "      <td>0.109483</td>\n",
       "      <td>0.084949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.810400</td>\n",
       "      <td>2.747743</td>\n",
       "      <td>0.463795</td>\n",
       "      <td>0.103850</td>\n",
       "      <td>0.117600</td>\n",
       "      <td>0.093526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.770500</td>\n",
       "      <td>2.707914</td>\n",
       "      <td>0.469294</td>\n",
       "      <td>0.104547</td>\n",
       "      <td>0.121075</td>\n",
       "      <td>0.097437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.722600</td>\n",
       "      <td>2.677633</td>\n",
       "      <td>0.474794</td>\n",
       "      <td>0.104917</td>\n",
       "      <td>0.123753</td>\n",
       "      <td>0.099908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.713500</td>\n",
       "      <td>2.656570</td>\n",
       "      <td>0.476627</td>\n",
       "      <td>0.104516</td>\n",
       "      <td>0.125407</td>\n",
       "      <td>0.101167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.686400</td>\n",
       "      <td>2.643829</td>\n",
       "      <td>0.478460</td>\n",
       "      <td>0.104902</td>\n",
       "      <td>0.126267</td>\n",
       "      <td>0.101767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.682500</td>\n",
       "      <td>2.639587</td>\n",
       "      <td>0.478460</td>\n",
       "      <td>0.104685</td>\n",
       "      <td>0.126267</td>\n",
       "      <td>0.101588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 08:41:24,347] Trial 6 finished with value: 0.10158803772931421 and parameters: {'learning_rate': 5.4182823195332406e-05, 'weight_decay': 0.003, 'warmup_steps': 3}. Best is trial 4 with value: 0.39062566689300937.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 with params: {'learning_rate': 1.7258215396625005e-05, 'weight_decay': 0.003, 'warmup_steps': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:22 < 00:45, 7.64 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.850900</td>\n",
       "      <td>3.792056</td>\n",
       "      <td>0.127406</td>\n",
       "      <td>0.009348</td>\n",
       "      <td>0.035343</td>\n",
       "      <td>0.008686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.763700</td>\n",
       "      <td>3.717160</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>0.017794</td>\n",
       "      <td>0.022906</td>\n",
       "      <td>0.010869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.707400</td>\n",
       "      <td>3.660883</td>\n",
       "      <td>0.183318</td>\n",
       "      <td>0.014360</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>0.009344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.652400</td>\n",
       "      <td>3.612828</td>\n",
       "      <td>0.186068</td>\n",
       "      <td>0.018972</td>\n",
       "      <td>0.022740</td>\n",
       "      <td>0.010735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.617500</td>\n",
       "      <td>3.565846</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.019567</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 08:41:47,816] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 with params: {'learning_rate': 5.954553793888986e-05, 'weight_decay': 0.008, 'warmup_steps': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:46, 7.49 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.765600</td>\n",
       "      <td>3.631785</td>\n",
       "      <td>0.177819</td>\n",
       "      <td>0.023541</td>\n",
       "      <td>0.020274</td>\n",
       "      <td>0.006558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.562800</td>\n",
       "      <td>3.456809</td>\n",
       "      <td>0.178735</td>\n",
       "      <td>0.023545</td>\n",
       "      <td>0.020548</td>\n",
       "      <td>0.007089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.410500</td>\n",
       "      <td>3.298860</td>\n",
       "      <td>0.313474</td>\n",
       "      <td>0.072143</td>\n",
       "      <td>0.060396</td>\n",
       "      <td>0.053038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.259400</td>\n",
       "      <td>3.161469</td>\n",
       "      <td>0.395967</td>\n",
       "      <td>0.078367</td>\n",
       "      <td>0.085144</td>\n",
       "      <td>0.067003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.153100</td>\n",
       "      <td>3.043002</td>\n",
       "      <td>0.411549</td>\n",
       "      <td>0.095497</td>\n",
       "      <td>0.089913</td>\n",
       "      <td>0.069143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 08:42:11,791] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 with params: {'learning_rate': 7.475992999956501e-05, 'weight_decay': 0.006, 'warmup_steps': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:09, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.740500</td>\n",
       "      <td>3.586979</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.501900</td>\n",
       "      <td>3.376416</td>\n",
       "      <td>0.198900</td>\n",
       "      <td>0.058621</td>\n",
       "      <td>0.026665</td>\n",
       "      <td>0.017604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.317500</td>\n",
       "      <td>3.189541</td>\n",
       "      <td>0.373969</td>\n",
       "      <td>0.081765</td>\n",
       "      <td>0.078543</td>\n",
       "      <td>0.062526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.139300</td>\n",
       "      <td>3.029068</td>\n",
       "      <td>0.415215</td>\n",
       "      <td>0.094960</td>\n",
       "      <td>0.091252</td>\n",
       "      <td>0.070746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.012000</td>\n",
       "      <td>2.890028</td>\n",
       "      <td>0.439963</td>\n",
       "      <td>0.087973</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.084788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.868200</td>\n",
       "      <td>2.771655</td>\n",
       "      <td>0.453712</td>\n",
       "      <td>0.084862</td>\n",
       "      <td>0.111823</td>\n",
       "      <td>0.086796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.753300</td>\n",
       "      <td>2.673620</td>\n",
       "      <td>0.472044</td>\n",
       "      <td>0.105033</td>\n",
       "      <td>0.121910</td>\n",
       "      <td>0.098896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.673600</td>\n",
       "      <td>2.588367</td>\n",
       "      <td>0.483960</td>\n",
       "      <td>0.103412</td>\n",
       "      <td>0.129572</td>\n",
       "      <td>0.103953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.584200</td>\n",
       "      <td>2.515910</td>\n",
       "      <td>0.494959</td>\n",
       "      <td>0.145224</td>\n",
       "      <td>0.135276</td>\n",
       "      <td>0.110973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.516800</td>\n",
       "      <td>2.459497</td>\n",
       "      <td>0.511457</td>\n",
       "      <td>0.161099</td>\n",
       "      <td>0.146057</td>\n",
       "      <td>0.122070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.471200</td>\n",
       "      <td>2.413057</td>\n",
       "      <td>0.527039</td>\n",
       "      <td>0.190482</td>\n",
       "      <td>0.157237</td>\n",
       "      <td>0.138567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.413200</td>\n",
       "      <td>2.376831</td>\n",
       "      <td>0.534372</td>\n",
       "      <td>0.208354</td>\n",
       "      <td>0.163193</td>\n",
       "      <td>0.146392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.395600</td>\n",
       "      <td>2.353594</td>\n",
       "      <td>0.549954</td>\n",
       "      <td>0.228792</td>\n",
       "      <td>0.178510</td>\n",
       "      <td>0.164858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.369900</td>\n",
       "      <td>2.338530</td>\n",
       "      <td>0.550871</td>\n",
       "      <td>0.228972</td>\n",
       "      <td>0.178725</td>\n",
       "      <td>0.165040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.359800</td>\n",
       "      <td>2.333930</td>\n",
       "      <td>0.553621</td>\n",
       "      <td>0.215607</td>\n",
       "      <td>0.181112</td>\n",
       "      <td>0.167185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 08:43:22,770] Trial 9 finished with value: 0.16718522010599593 and parameters: {'learning_rate': 7.475992999956501e-05, 'weight_decay': 0.006, 'warmup_steps': 0}. Best is trial 4 with value: 0.39062566689300937.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 with params: {'learning_rate': 0.0004587604755149822, 'weight_decay': 0.002, 'warmup_steps': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:46 < 00:23, 7.53 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.334900</td>\n",
       "      <td>2.821038</td>\n",
       "      <td>0.428048</td>\n",
       "      <td>0.069634</td>\n",
       "      <td>0.101353</td>\n",
       "      <td>0.078215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.509800</td>\n",
       "      <td>2.169802</td>\n",
       "      <td>0.555454</td>\n",
       "      <td>0.190087</td>\n",
       "      <td>0.192818</td>\n",
       "      <td>0.174815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.923400</td>\n",
       "      <td>1.725812</td>\n",
       "      <td>0.656279</td>\n",
       "      <td>0.263669</td>\n",
       "      <td>0.279570</td>\n",
       "      <td>0.258465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.501400</td>\n",
       "      <td>1.474951</td>\n",
       "      <td>0.700275</td>\n",
       "      <td>0.321681</td>\n",
       "      <td>0.321260</td>\n",
       "      <td>0.299878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.210600</td>\n",
       "      <td>1.332409</td>\n",
       "      <td>0.730522</td>\n",
       "      <td>0.347057</td>\n",
       "      <td>0.371468</td>\n",
       "      <td>0.343010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.001700</td>\n",
       "      <td>1.205365</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.418712</td>\n",
       "      <td>0.389768</td>\n",
       "      <td>0.378645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.828000</td>\n",
       "      <td>1.154799</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.463703</td>\n",
       "      <td>0.421152</td>\n",
       "      <td>0.413087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.718900</td>\n",
       "      <td>1.116093</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.489412</td>\n",
       "      <td>0.453165</td>\n",
       "      <td>0.446063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.618500</td>\n",
       "      <td>1.082686</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.486941</td>\n",
       "      <td>0.469112</td>\n",
       "      <td>0.463983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.543700</td>\n",
       "      <td>1.058945</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.491266</td>\n",
       "      <td>0.479622</td>\n",
       "      <td>0.475020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 08:44:09,774] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 with params: {'learning_rate': 0.00023012528778943483, 'weight_decay': 0.006, 'warmup_steps': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:10, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.543900</td>\n",
       "      <td>3.215007</td>\n",
       "      <td>0.270394</td>\n",
       "      <td>0.072445</td>\n",
       "      <td>0.047599</td>\n",
       "      <td>0.040656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.008100</td>\n",
       "      <td>2.751146</td>\n",
       "      <td>0.433547</td>\n",
       "      <td>0.063026</td>\n",
       "      <td>0.103347</td>\n",
       "      <td>0.075610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.597200</td>\n",
       "      <td>2.381151</td>\n",
       "      <td>0.495875</td>\n",
       "      <td>0.162543</td>\n",
       "      <td>0.133952</td>\n",
       "      <td>0.112757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.244900</td>\n",
       "      <td>2.097574</td>\n",
       "      <td>0.582951</td>\n",
       "      <td>0.218672</td>\n",
       "      <td>0.203234</td>\n",
       "      <td>0.187191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.985700</td>\n",
       "      <td>1.881629</td>\n",
       "      <td>0.645280</td>\n",
       "      <td>0.274573</td>\n",
       "      <td>0.263001</td>\n",
       "      <td>0.247162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.738800</td>\n",
       "      <td>1.712232</td>\n",
       "      <td>0.687443</td>\n",
       "      <td>0.326792</td>\n",
       "      <td>0.298558</td>\n",
       "      <td>0.283174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.549600</td>\n",
       "      <td>1.589851</td>\n",
       "      <td>0.698442</td>\n",
       "      <td>0.332245</td>\n",
       "      <td>0.307171</td>\n",
       "      <td>0.292481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.422600</td>\n",
       "      <td>1.503094</td>\n",
       "      <td>0.710357</td>\n",
       "      <td>0.346433</td>\n",
       "      <td>0.339708</td>\n",
       "      <td>0.318357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.302800</td>\n",
       "      <td>1.437114</td>\n",
       "      <td>0.714024</td>\n",
       "      <td>0.336704</td>\n",
       "      <td>0.344451</td>\n",
       "      <td>0.326372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.202400</td>\n",
       "      <td>1.388275</td>\n",
       "      <td>0.725023</td>\n",
       "      <td>0.365034</td>\n",
       "      <td>0.365892</td>\n",
       "      <td>0.349671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.151900</td>\n",
       "      <td>1.353702</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.374610</td>\n",
       "      <td>0.379311</td>\n",
       "      <td>0.362674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.079400</td>\n",
       "      <td>1.328559</td>\n",
       "      <td>0.729606</td>\n",
       "      <td>0.367443</td>\n",
       "      <td>0.375136</td>\n",
       "      <td>0.357392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.061400</td>\n",
       "      <td>1.307684</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.370318</td>\n",
       "      <td>0.382986</td>\n",
       "      <td>0.364697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.019500</td>\n",
       "      <td>1.293509</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.379232</td>\n",
       "      <td>0.397251</td>\n",
       "      <td>0.376401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.010800</td>\n",
       "      <td>1.293095</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.403786</td>\n",
       "      <td>0.403769</td>\n",
       "      <td>0.384558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 08:45:21,547] Trial 11 finished with value: 0.38455838326622244 and parameters: {'learning_rate': 0.00023012528778943483, 'weight_decay': 0.006, 'warmup_steps': 0}. Best is trial 4 with value: 0.39062566689300937.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 with params: {'learning_rate': 0.00035174585398257074, 'weight_decay': 0.007, 'warmup_steps': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:46 < 00:23, 7.55 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.422500</td>\n",
       "      <td>2.986763</td>\n",
       "      <td>0.399633</td>\n",
       "      <td>0.055820</td>\n",
       "      <td>0.085718</td>\n",
       "      <td>0.063883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.716200</td>\n",
       "      <td>2.399333</td>\n",
       "      <td>0.497709</td>\n",
       "      <td>0.165023</td>\n",
       "      <td>0.138835</td>\n",
       "      <td>0.117694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.190200</td>\n",
       "      <td>1.967116</td>\n",
       "      <td>0.603116</td>\n",
       "      <td>0.272580</td>\n",
       "      <td>0.239140</td>\n",
       "      <td>0.230799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.781500</td>\n",
       "      <td>1.696654</td>\n",
       "      <td>0.687443</td>\n",
       "      <td>0.328724</td>\n",
       "      <td>0.316743</td>\n",
       "      <td>0.295154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.493100</td>\n",
       "      <td>1.499748</td>\n",
       "      <td>0.719523</td>\n",
       "      <td>0.352712</td>\n",
       "      <td>0.356342</td>\n",
       "      <td>0.336956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.260200</td>\n",
       "      <td>1.358392</td>\n",
       "      <td>0.723190</td>\n",
       "      <td>0.364575</td>\n",
       "      <td>0.361462</td>\n",
       "      <td>0.342009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.077300</td>\n",
       "      <td>1.279357</td>\n",
       "      <td>0.729606</td>\n",
       "      <td>0.394259</td>\n",
       "      <td>0.370530</td>\n",
       "      <td>0.355592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>1.234847</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.394353</td>\n",
       "      <td>0.409671</td>\n",
       "      <td>0.386090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.854800</td>\n",
       "      <td>1.180493</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.414718</td>\n",
       "      <td>0.421411</td>\n",
       "      <td>0.406487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.762700</td>\n",
       "      <td>1.151671</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.461944</td>\n",
       "      <td>0.414382</td>\n",
       "      <td>0.409505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 08:46:08,796] Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13 with params: {'learning_rate': 0.00021976631986270965, 'weight_decay': 0.005, 'warmup_steps': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:10, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.583900</td>\n",
       "      <td>3.259404</td>\n",
       "      <td>0.209899</td>\n",
       "      <td>0.037364</td>\n",
       "      <td>0.029397</td>\n",
       "      <td>0.020848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.055400</td>\n",
       "      <td>2.802318</td>\n",
       "      <td>0.428048</td>\n",
       "      <td>0.062495</td>\n",
       "      <td>0.100202</td>\n",
       "      <td>0.073642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.650200</td>\n",
       "      <td>2.430311</td>\n",
       "      <td>0.494042</td>\n",
       "      <td>0.125047</td>\n",
       "      <td>0.136272</td>\n",
       "      <td>0.113491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.300800</td>\n",
       "      <td>2.145451</td>\n",
       "      <td>0.572869</td>\n",
       "      <td>0.205328</td>\n",
       "      <td>0.195434</td>\n",
       "      <td>0.178796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.042000</td>\n",
       "      <td>1.926934</td>\n",
       "      <td>0.629698</td>\n",
       "      <td>0.284142</td>\n",
       "      <td>0.245843</td>\n",
       "      <td>0.232361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.793900</td>\n",
       "      <td>1.753069</td>\n",
       "      <td>0.681943</td>\n",
       "      <td>0.344908</td>\n",
       "      <td>0.298265</td>\n",
       "      <td>0.290378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.603800</td>\n",
       "      <td>1.630626</td>\n",
       "      <td>0.696609</td>\n",
       "      <td>0.365033</td>\n",
       "      <td>0.314898</td>\n",
       "      <td>0.306895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.476900</td>\n",
       "      <td>1.540251</td>\n",
       "      <td>0.707608</td>\n",
       "      <td>0.340133</td>\n",
       "      <td>0.332964</td>\n",
       "      <td>0.314228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.353200</td>\n",
       "      <td>1.469929</td>\n",
       "      <td>0.714024</td>\n",
       "      <td>0.345485</td>\n",
       "      <td>0.342928</td>\n",
       "      <td>0.325118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.252700</td>\n",
       "      <td>1.419049</td>\n",
       "      <td>0.721357</td>\n",
       "      <td>0.342666</td>\n",
       "      <td>0.356833</td>\n",
       "      <td>0.337043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.200100</td>\n",
       "      <td>1.380848</td>\n",
       "      <td>0.725940</td>\n",
       "      <td>0.359805</td>\n",
       "      <td>0.367638</td>\n",
       "      <td>0.349664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.127900</td>\n",
       "      <td>1.353604</td>\n",
       "      <td>0.725023</td>\n",
       "      <td>0.354265</td>\n",
       "      <td>0.367228</td>\n",
       "      <td>0.347462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.108300</td>\n",
       "      <td>1.332761</td>\n",
       "      <td>0.730522</td>\n",
       "      <td>0.350637</td>\n",
       "      <td>0.368831</td>\n",
       "      <td>0.349432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.067100</td>\n",
       "      <td>1.317989</td>\n",
       "      <td>0.735105</td>\n",
       "      <td>0.365908</td>\n",
       "      <td>0.378266</td>\n",
       "      <td>0.361025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.057700</td>\n",
       "      <td>1.317495</td>\n",
       "      <td>0.738772</td>\n",
       "      <td>0.363979</td>\n",
       "      <td>0.383610</td>\n",
       "      <td>0.363194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 08:47:20,275] Trial 13 finished with value: 0.36319399646392175 and parameters: {'learning_rate': 0.00021976631986270965, 'weight_decay': 0.005, 'warmup_steps': 2}. Best is trial 4 with value: 0.39062566689300937.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 with params: {'learning_rate': 0.00031411022790590827, 'weight_decay': 0.01, 'warmup_steps': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:47 < 00:23, 7.34 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.497500</td>\n",
       "      <td>3.092148</td>\n",
       "      <td>0.345555</td>\n",
       "      <td>0.067749</td>\n",
       "      <td>0.071066</td>\n",
       "      <td>0.054419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.829000</td>\n",
       "      <td>2.520367</td>\n",
       "      <td>0.489459</td>\n",
       "      <td>0.107759</td>\n",
       "      <td>0.134841</td>\n",
       "      <td>0.110561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.319500</td>\n",
       "      <td>2.087965</td>\n",
       "      <td>0.586618</td>\n",
       "      <td>0.279339</td>\n",
       "      <td>0.221655</td>\n",
       "      <td>0.213006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.912400</td>\n",
       "      <td>1.801026</td>\n",
       "      <td>0.666361</td>\n",
       "      <td>0.322480</td>\n",
       "      <td>0.291496</td>\n",
       "      <td>0.276884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.619600</td>\n",
       "      <td>1.592015</td>\n",
       "      <td>0.707608</td>\n",
       "      <td>0.369763</td>\n",
       "      <td>0.342785</td>\n",
       "      <td>0.326873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.373500</td>\n",
       "      <td>1.430977</td>\n",
       "      <td>0.720440</td>\n",
       "      <td>0.346953</td>\n",
       "      <td>0.353026</td>\n",
       "      <td>0.334875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.183800</td>\n",
       "      <td>1.340407</td>\n",
       "      <td>0.725023</td>\n",
       "      <td>0.348710</td>\n",
       "      <td>0.358275</td>\n",
       "      <td>0.338836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.061700</td>\n",
       "      <td>1.292037</td>\n",
       "      <td>0.744271</td>\n",
       "      <td>0.400734</td>\n",
       "      <td>0.398372</td>\n",
       "      <td>0.381591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.954600</td>\n",
       "      <td>1.235971</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.427310</td>\n",
       "      <td>0.409346</td>\n",
       "      <td>0.399514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.859100</td>\n",
       "      <td>1.207509</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.441660</td>\n",
       "      <td>0.425075</td>\n",
       "      <td>0.415100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 08:48:08,484] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 with params: {'learning_rate': 0.00016615243906338922, 'weight_decay': 0.0, 'warmup_steps': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.639900</td>\n",
       "      <td>3.368840</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.202200</td>\n",
       "      <td>2.986190</td>\n",
       "      <td>0.406966</td>\n",
       "      <td>0.094691</td>\n",
       "      <td>0.088316</td>\n",
       "      <td>0.065965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.865900</td>\n",
       "      <td>2.665046</td>\n",
       "      <td>0.451879</td>\n",
       "      <td>0.102819</td>\n",
       "      <td>0.111540</td>\n",
       "      <td>0.084569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.561400</td>\n",
       "      <td>2.404691</td>\n",
       "      <td>0.516040</td>\n",
       "      <td>0.148468</td>\n",
       "      <td>0.150190</td>\n",
       "      <td>0.128091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.338100</td>\n",
       "      <td>2.195745</td>\n",
       "      <td>0.572869</td>\n",
       "      <td>0.252454</td>\n",
       "      <td>0.194917</td>\n",
       "      <td>0.181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.112200</td>\n",
       "      <td>2.031802</td>\n",
       "      <td>0.600367</td>\n",
       "      <td>0.248059</td>\n",
       "      <td>0.222327</td>\n",
       "      <td>0.208100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.938700</td>\n",
       "      <td>1.905526</td>\n",
       "      <td>0.644363</td>\n",
       "      <td>0.338859</td>\n",
       "      <td>0.266221</td>\n",
       "      <td>0.259333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.817100</td>\n",
       "      <td>1.805561</td>\n",
       "      <td>0.673694</td>\n",
       "      <td>0.331242</td>\n",
       "      <td>0.291218</td>\n",
       "      <td>0.278835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.692000</td>\n",
       "      <td>1.718866</td>\n",
       "      <td>0.685610</td>\n",
       "      <td>0.337082</td>\n",
       "      <td>0.298281</td>\n",
       "      <td>0.287507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.593100</td>\n",
       "      <td>1.656978</td>\n",
       "      <td>0.695692</td>\n",
       "      <td>0.373749</td>\n",
       "      <td>0.323883</td>\n",
       "      <td>0.314621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.534800</td>\n",
       "      <td>1.606898</td>\n",
       "      <td>0.706691</td>\n",
       "      <td>0.360519</td>\n",
       "      <td>0.331353</td>\n",
       "      <td>0.318857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.461800</td>\n",
       "      <td>1.571106</td>\n",
       "      <td>0.703941</td>\n",
       "      <td>0.361821</td>\n",
       "      <td>0.331253</td>\n",
       "      <td>0.318452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.435200</td>\n",
       "      <td>1.544165</td>\n",
       "      <td>0.708524</td>\n",
       "      <td>0.365214</td>\n",
       "      <td>0.334402</td>\n",
       "      <td>0.320709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.398200</td>\n",
       "      <td>1.528892</td>\n",
       "      <td>0.711274</td>\n",
       "      <td>0.365984</td>\n",
       "      <td>0.335434</td>\n",
       "      <td>0.321812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.385600</td>\n",
       "      <td>1.526165</td>\n",
       "      <td>0.715857</td>\n",
       "      <td>0.367144</td>\n",
       "      <td>0.339138</td>\n",
       "      <td>0.325458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 08:49:21,926] Trial 15 finished with value: 0.325457686379596 and parameters: {'learning_rate': 0.00016615243906338922, 'weight_decay': 0.0, 'warmup_steps': 2}. Best is trial 4 with value: 0.39062566689300937.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16 with params: {'learning_rate': 0.00017787180744793134, 'weight_decay': 0.004, 'warmup_steps': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:46 < 00:23, 7.49 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.619500</td>\n",
       "      <td>3.337117</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.163400</td>\n",
       "      <td>2.941094</td>\n",
       "      <td>0.409716</td>\n",
       "      <td>0.072295</td>\n",
       "      <td>0.090012</td>\n",
       "      <td>0.067169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.813200</td>\n",
       "      <td>2.607853</td>\n",
       "      <td>0.461045</td>\n",
       "      <td>0.103236</td>\n",
       "      <td>0.117867</td>\n",
       "      <td>0.091296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.498100</td>\n",
       "      <td>2.341437</td>\n",
       "      <td>0.537122</td>\n",
       "      <td>0.164627</td>\n",
       "      <td>0.167441</td>\n",
       "      <td>0.150337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.267700</td>\n",
       "      <td>2.130326</td>\n",
       "      <td>0.583868</td>\n",
       "      <td>0.255458</td>\n",
       "      <td>0.206034</td>\n",
       "      <td>0.192716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.036200</td>\n",
       "      <td>1.964589</td>\n",
       "      <td>0.615949</td>\n",
       "      <td>0.259729</td>\n",
       "      <td>0.241063</td>\n",
       "      <td>0.228390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.858800</td>\n",
       "      <td>1.838026</td>\n",
       "      <td>0.655362</td>\n",
       "      <td>0.342690</td>\n",
       "      <td>0.273758</td>\n",
       "      <td>0.265795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.735100</td>\n",
       "      <td>1.738304</td>\n",
       "      <td>0.679193</td>\n",
       "      <td>0.345037</td>\n",
       "      <td>0.296771</td>\n",
       "      <td>0.281808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.608900</td>\n",
       "      <td>1.654349</td>\n",
       "      <td>0.688359</td>\n",
       "      <td>0.354263</td>\n",
       "      <td>0.314361</td>\n",
       "      <td>0.305677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.509300</td>\n",
       "      <td>1.594637</td>\n",
       "      <td>0.704858</td>\n",
       "      <td>0.357112</td>\n",
       "      <td>0.328516</td>\n",
       "      <td>0.313995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 08:50:09,394] Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17 with params: {'learning_rate': 0.00023041229790746586, 'weight_decay': 0.008, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.591500</td>\n",
       "      <td>3.256339</td>\n",
       "      <td>0.203483</td>\n",
       "      <td>0.038389</td>\n",
       "      <td>0.027443</td>\n",
       "      <td>0.018431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.044200</td>\n",
       "      <td>2.780378</td>\n",
       "      <td>0.435380</td>\n",
       "      <td>0.101650</td>\n",
       "      <td>0.105751</td>\n",
       "      <td>0.080121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.620300</td>\n",
       "      <td>2.396228</td>\n",
       "      <td>0.502291</td>\n",
       "      <td>0.142005</td>\n",
       "      <td>0.142039</td>\n",
       "      <td>0.119971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.259100</td>\n",
       "      <td>2.102841</td>\n",
       "      <td>0.579285</td>\n",
       "      <td>0.244787</td>\n",
       "      <td>0.205743</td>\n",
       "      <td>0.193100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.990700</td>\n",
       "      <td>1.878407</td>\n",
       "      <td>0.645280</td>\n",
       "      <td>0.322377</td>\n",
       "      <td>0.271610</td>\n",
       "      <td>0.260729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.737700</td>\n",
       "      <td>1.701202</td>\n",
       "      <td>0.688359</td>\n",
       "      <td>0.382197</td>\n",
       "      <td>0.310049</td>\n",
       "      <td>0.304831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.543300</td>\n",
       "      <td>1.578670</td>\n",
       "      <td>0.699358</td>\n",
       "      <td>0.356660</td>\n",
       "      <td>0.318256</td>\n",
       "      <td>0.309572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.416100</td>\n",
       "      <td>1.492959</td>\n",
       "      <td>0.719523</td>\n",
       "      <td>0.362282</td>\n",
       "      <td>0.352316</td>\n",
       "      <td>0.332748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.292600</td>\n",
       "      <td>1.425420</td>\n",
       "      <td>0.718607</td>\n",
       "      <td>0.360454</td>\n",
       "      <td>0.355252</td>\n",
       "      <td>0.339830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.190900</td>\n",
       "      <td>1.377159</td>\n",
       "      <td>0.729606</td>\n",
       "      <td>0.385118</td>\n",
       "      <td>0.374261</td>\n",
       "      <td>0.360199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.138300</td>\n",
       "      <td>1.341634</td>\n",
       "      <td>0.740605</td>\n",
       "      <td>0.393296</td>\n",
       "      <td>0.394493</td>\n",
       "      <td>0.377145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.065500</td>\n",
       "      <td>1.314740</td>\n",
       "      <td>0.730522</td>\n",
       "      <td>0.371826</td>\n",
       "      <td>0.375800</td>\n",
       "      <td>0.359735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.047400</td>\n",
       "      <td>1.295955</td>\n",
       "      <td>0.744271</td>\n",
       "      <td>0.385416</td>\n",
       "      <td>0.397384</td>\n",
       "      <td>0.377629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.005900</td>\n",
       "      <td>1.281158</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.407413</td>\n",
       "      <td>0.406567</td>\n",
       "      <td>0.391504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.995800</td>\n",
       "      <td>1.281225</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.404073</td>\n",
       "      <td>0.404749</td>\n",
       "      <td>0.386387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 08:51:23,068] Trial 17 finished with value: 0.38638693150760745 and parameters: {'learning_rate': 0.00023041229790746586, 'weight_decay': 0.008, 'warmup_steps': 4}. Best is trial 4 with value: 0.39062566689300937.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18 with params: {'learning_rate': 0.00018354219503651724, 'weight_decay': 0.007, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:09, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.635700</td>\n",
       "      <td>3.344867</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.164200</td>\n",
       "      <td>2.933316</td>\n",
       "      <td>0.411549</td>\n",
       "      <td>0.093006</td>\n",
       "      <td>0.091519</td>\n",
       "      <td>0.070240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.799800</td>\n",
       "      <td>2.587908</td>\n",
       "      <td>0.469294</td>\n",
       "      <td>0.103965</td>\n",
       "      <td>0.121768</td>\n",
       "      <td>0.097516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.474900</td>\n",
       "      <td>2.315372</td>\n",
       "      <td>0.544455</td>\n",
       "      <td>0.206883</td>\n",
       "      <td>0.172583</td>\n",
       "      <td>0.157218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.236500</td>\n",
       "      <td>2.099953</td>\n",
       "      <td>0.593034</td>\n",
       "      <td>0.295980</td>\n",
       "      <td>0.217237</td>\n",
       "      <td>0.206868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.999500</td>\n",
       "      <td>1.928801</td>\n",
       "      <td>0.622365</td>\n",
       "      <td>0.261186</td>\n",
       "      <td>0.247875</td>\n",
       "      <td>0.233943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.817500</td>\n",
       "      <td>1.800434</td>\n",
       "      <td>0.660862</td>\n",
       "      <td>0.364980</td>\n",
       "      <td>0.279537</td>\n",
       "      <td>0.273468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.690900</td>\n",
       "      <td>1.700317</td>\n",
       "      <td>0.691109</td>\n",
       "      <td>0.374723</td>\n",
       "      <td>0.322083</td>\n",
       "      <td>0.313388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.562200</td>\n",
       "      <td>1.616367</td>\n",
       "      <td>0.692026</td>\n",
       "      <td>0.357864</td>\n",
       "      <td>0.319996</td>\n",
       "      <td>0.311361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.461700</td>\n",
       "      <td>1.557776</td>\n",
       "      <td>0.707608</td>\n",
       "      <td>0.360214</td>\n",
       "      <td>0.334644</td>\n",
       "      <td>0.319948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.404800</td>\n",
       "      <td>1.511422</td>\n",
       "      <td>0.716774</td>\n",
       "      <td>0.357414</td>\n",
       "      <td>0.339278</td>\n",
       "      <td>0.324663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.331000</td>\n",
       "      <td>1.479829</td>\n",
       "      <td>0.717690</td>\n",
       "      <td>0.360791</td>\n",
       "      <td>0.345651</td>\n",
       "      <td>0.330812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.306700</td>\n",
       "      <td>1.454961</td>\n",
       "      <td>0.715857</td>\n",
       "      <td>0.361988</td>\n",
       "      <td>0.347463</td>\n",
       "      <td>0.331796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.268300</td>\n",
       "      <td>1.439760</td>\n",
       "      <td>0.721357</td>\n",
       "      <td>0.356279</td>\n",
       "      <td>0.353020</td>\n",
       "      <td>0.335702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.256800</td>\n",
       "      <td>1.437701</td>\n",
       "      <td>0.723190</td>\n",
       "      <td>0.368179</td>\n",
       "      <td>0.362491</td>\n",
       "      <td>0.345595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 08:52:34,191] Trial 18 finished with value: 0.3455949344657317 and parameters: {'learning_rate': 0.00018354219503651724, 'weight_decay': 0.007, 'warmup_steps': 4}. Best is trial 4 with value: 0.39062566689300937.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 19 with params: {'learning_rate': 4.803338746667814e-05, 'weight_decay': 0.006, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:47, 7.45 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.799900</td>\n",
       "      <td>3.679646</td>\n",
       "      <td>0.182401</td>\n",
       "      <td>0.014483</td>\n",
       "      <td>0.021644</td>\n",
       "      <td>0.008922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.621600</td>\n",
       "      <td>3.531225</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023548</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.492700</td>\n",
       "      <td>3.396883</td>\n",
       "      <td>0.201650</td>\n",
       "      <td>0.063631</td>\n",
       "      <td>0.027272</td>\n",
       "      <td>0.018130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.363700</td>\n",
       "      <td>3.275743</td>\n",
       "      <td>0.333639</td>\n",
       "      <td>0.070204</td>\n",
       "      <td>0.066654</td>\n",
       "      <td>0.057369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.271900</td>\n",
       "      <td>3.172733</td>\n",
       "      <td>0.392301</td>\n",
       "      <td>0.079549</td>\n",
       "      <td>0.083838</td>\n",
       "      <td>0.066762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 08:52:58,266] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 with params: {'learning_rate': 0.0003701999625244894, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:10, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.475700</td>\n",
       "      <td>3.024232</td>\n",
       "      <td>0.371219</td>\n",
       "      <td>0.062391</td>\n",
       "      <td>0.078619</td>\n",
       "      <td>0.059372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.728800</td>\n",
       "      <td>2.395754</td>\n",
       "      <td>0.502291</td>\n",
       "      <td>0.145110</td>\n",
       "      <td>0.147056</td>\n",
       "      <td>0.126295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.169300</td>\n",
       "      <td>1.933851</td>\n",
       "      <td>0.617782</td>\n",
       "      <td>0.288525</td>\n",
       "      <td>0.245669</td>\n",
       "      <td>0.234517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.741400</td>\n",
       "      <td>1.659887</td>\n",
       "      <td>0.695692</td>\n",
       "      <td>0.308797</td>\n",
       "      <td>0.314316</td>\n",
       "      <td>0.296645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.440600</td>\n",
       "      <td>1.466697</td>\n",
       "      <td>0.726856</td>\n",
       "      <td>0.367286</td>\n",
       "      <td>0.364935</td>\n",
       "      <td>0.343963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.202700</td>\n",
       "      <td>1.323581</td>\n",
       "      <td>0.733272</td>\n",
       "      <td>0.393560</td>\n",
       "      <td>0.376397</td>\n",
       "      <td>0.359972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.018800</td>\n",
       "      <td>1.250930</td>\n",
       "      <td>0.731439</td>\n",
       "      <td>0.392582</td>\n",
       "      <td>0.378996</td>\n",
       "      <td>0.367354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.902100</td>\n",
       "      <td>1.211282</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.473224</td>\n",
       "      <td>0.435392</td>\n",
       "      <td>0.426793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.799700</td>\n",
       "      <td>1.157365</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.465545</td>\n",
       "      <td>0.441152</td>\n",
       "      <td>0.436297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.711100</td>\n",
       "      <td>1.140239</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.493457</td>\n",
       "      <td>0.458345</td>\n",
       "      <td>0.458914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.666200</td>\n",
       "      <td>1.115551</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.473849</td>\n",
       "      <td>0.470601</td>\n",
       "      <td>0.463265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.604200</td>\n",
       "      <td>1.096284</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.503438</td>\n",
       "      <td>0.471117</td>\n",
       "      <td>0.472846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.573800</td>\n",
       "      <td>1.083697</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.496248</td>\n",
       "      <td>0.474755</td>\n",
       "      <td>0.474921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.550400</td>\n",
       "      <td>1.072173</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.502233</td>\n",
       "      <td>0.482858</td>\n",
       "      <td>0.482792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.544900</td>\n",
       "      <td>1.072704</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.505736</td>\n",
       "      <td>0.487670</td>\n",
       "      <td>0.486496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 08:54:09,772] Trial 20 finished with value: 0.48649600533906434 and parameters: {'learning_rate': 0.0003701999625244894, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 20 with value: 0.48649600533906434.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 21 with params: {'learning_rate': 0.0004794538719449015, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:10, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.401700</td>\n",
       "      <td>2.873354</td>\n",
       "      <td>0.416132</td>\n",
       "      <td>0.073138</td>\n",
       "      <td>0.095070</td>\n",
       "      <td>0.073870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.540200</td>\n",
       "      <td>2.183897</td>\n",
       "      <td>0.557287</td>\n",
       "      <td>0.204342</td>\n",
       "      <td>0.201261</td>\n",
       "      <td>0.189003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.918600</td>\n",
       "      <td>1.717810</td>\n",
       "      <td>0.661778</td>\n",
       "      <td>0.323261</td>\n",
       "      <td>0.295682</td>\n",
       "      <td>0.278947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.474100</td>\n",
       "      <td>1.454987</td>\n",
       "      <td>0.703941</td>\n",
       "      <td>0.320664</td>\n",
       "      <td>0.327614</td>\n",
       "      <td>0.309269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.178800</td>\n",
       "      <td>1.326247</td>\n",
       "      <td>0.736939</td>\n",
       "      <td>0.422215</td>\n",
       "      <td>0.394329</td>\n",
       "      <td>0.374891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.958800</td>\n",
       "      <td>1.210208</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.423347</td>\n",
       "      <td>0.403472</td>\n",
       "      <td>0.390249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.792300</td>\n",
       "      <td>1.168362</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.471726</td>\n",
       "      <td>0.432778</td>\n",
       "      <td>0.427525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.687700</td>\n",
       "      <td>1.129672</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.485004</td>\n",
       "      <td>0.465576</td>\n",
       "      <td>0.455702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>1.085122</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.491540</td>\n",
       "      <td>0.470577</td>\n",
       "      <td>0.466198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.508900</td>\n",
       "      <td>1.081150</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.494347</td>\n",
       "      <td>0.479605</td>\n",
       "      <td>0.473905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.465800</td>\n",
       "      <td>1.051537</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.502363</td>\n",
       "      <td>0.483816</td>\n",
       "      <td>0.481795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.417500</td>\n",
       "      <td>1.038762</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.504270</td>\n",
       "      <td>0.482689</td>\n",
       "      <td>0.481880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.386800</td>\n",
       "      <td>1.032303</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.517328</td>\n",
       "      <td>0.492593</td>\n",
       "      <td>0.493350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>1.020030</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.522480</td>\n",
       "      <td>0.492684</td>\n",
       "      <td>0.493222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.359500</td>\n",
       "      <td>1.020833</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.522190</td>\n",
       "      <td>0.493769</td>\n",
       "      <td>0.494156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 08:55:21,870] Trial 21 finished with value: 0.4941557351757956 and parameters: {'learning_rate': 0.0004794538719449015, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 22 with params: {'learning_rate': 0.0004866184455144315, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:11, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.397100</td>\n",
       "      <td>2.864541</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.073080</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.075822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.528800</td>\n",
       "      <td>2.171468</td>\n",
       "      <td>0.558203</td>\n",
       "      <td>0.204267</td>\n",
       "      <td>0.200698</td>\n",
       "      <td>0.188367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.903200</td>\n",
       "      <td>1.704066</td>\n",
       "      <td>0.661778</td>\n",
       "      <td>0.319037</td>\n",
       "      <td>0.296873</td>\n",
       "      <td>0.280115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.458500</td>\n",
       "      <td>1.444144</td>\n",
       "      <td>0.703941</td>\n",
       "      <td>0.318737</td>\n",
       "      <td>0.322993</td>\n",
       "      <td>0.304732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.163400</td>\n",
       "      <td>1.317177</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.423678</td>\n",
       "      <td>0.396147</td>\n",
       "      <td>0.378620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.943900</td>\n",
       "      <td>1.204490</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.425028</td>\n",
       "      <td>0.397842</td>\n",
       "      <td>0.387553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.779600</td>\n",
       "      <td>1.164753</td>\n",
       "      <td>0.747938</td>\n",
       "      <td>0.470434</td>\n",
       "      <td>0.435223</td>\n",
       "      <td>0.430689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.676300</td>\n",
       "      <td>1.123661</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.484826</td>\n",
       "      <td>0.463455</td>\n",
       "      <td>0.455272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.573700</td>\n",
       "      <td>1.080023</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.488040</td>\n",
       "      <td>0.470815</td>\n",
       "      <td>0.465763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.498800</td>\n",
       "      <td>1.078047</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.501555</td>\n",
       "      <td>0.479278</td>\n",
       "      <td>0.476078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.455300</td>\n",
       "      <td>1.047825</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.501507</td>\n",
       "      <td>0.483829</td>\n",
       "      <td>0.481716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.408100</td>\n",
       "      <td>1.035224</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.502694</td>\n",
       "      <td>0.482473</td>\n",
       "      <td>0.480572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.377100</td>\n",
       "      <td>1.029105</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.528268</td>\n",
       "      <td>0.497578</td>\n",
       "      <td>0.498709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.356900</td>\n",
       "      <td>1.016625</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.521188</td>\n",
       "      <td>0.490813</td>\n",
       "      <td>0.491542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.350100</td>\n",
       "      <td>1.017774</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.522831</td>\n",
       "      <td>0.495346</td>\n",
       "      <td>0.493697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 08:56:36,557] Trial 22 finished with value: 0.4936970922783857 and parameters: {'learning_rate': 0.0004866184455144315, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 23 with params: {'learning_rate': 0.00028990806473082564, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:46 < 00:23, 7.56 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.536900</td>\n",
       "      <td>3.148067</td>\n",
       "      <td>0.308891</td>\n",
       "      <td>0.071816</td>\n",
       "      <td>0.059392</td>\n",
       "      <td>0.048645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.896700</td>\n",
       "      <td>2.594270</td>\n",
       "      <td>0.452796</td>\n",
       "      <td>0.106064</td>\n",
       "      <td>0.112829</td>\n",
       "      <td>0.082733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.404500</td>\n",
       "      <td>2.168176</td>\n",
       "      <td>0.562786</td>\n",
       "      <td>0.224142</td>\n",
       "      <td>0.189234</td>\n",
       "      <td>0.176338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.004300</td>\n",
       "      <td>1.872677</td>\n",
       "      <td>0.647113</td>\n",
       "      <td>0.295134</td>\n",
       "      <td>0.272460</td>\n",
       "      <td>0.258460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.713500</td>\n",
       "      <td>1.656423</td>\n",
       "      <td>0.705775</td>\n",
       "      <td>0.347762</td>\n",
       "      <td>0.334801</td>\n",
       "      <td>0.320650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.464700</td>\n",
       "      <td>1.489464</td>\n",
       "      <td>0.714940</td>\n",
       "      <td>0.347344</td>\n",
       "      <td>0.343847</td>\n",
       "      <td>0.328378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.269200</td>\n",
       "      <td>1.391256</td>\n",
       "      <td>0.721357</td>\n",
       "      <td>0.343236</td>\n",
       "      <td>0.341099</td>\n",
       "      <td>0.325618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.145900</td>\n",
       "      <td>1.329510</td>\n",
       "      <td>0.732356</td>\n",
       "      <td>0.359862</td>\n",
       "      <td>0.379743</td>\n",
       "      <td>0.356260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.035000</td>\n",
       "      <td>1.275305</td>\n",
       "      <td>0.741522</td>\n",
       "      <td>0.373438</td>\n",
       "      <td>0.387411</td>\n",
       "      <td>0.367759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.938500</td>\n",
       "      <td>1.241952</td>\n",
       "      <td>0.755270</td>\n",
       "      <td>0.424962</td>\n",
       "      <td>0.413850</td>\n",
       "      <td>0.400787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 08:57:23,331] Trial 23 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 24 with params: {'learning_rate': 0.00048502028060946255, 'weight_decay': 0.008, 'warmup_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.385100</td>\n",
       "      <td>2.862287</td>\n",
       "      <td>0.416132</td>\n",
       "      <td>0.070653</td>\n",
       "      <td>0.096518</td>\n",
       "      <td>0.074809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.527700</td>\n",
       "      <td>2.179507</td>\n",
       "      <td>0.545371</td>\n",
       "      <td>0.228923</td>\n",
       "      <td>0.185154</td>\n",
       "      <td>0.175236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.912000</td>\n",
       "      <td>1.704316</td>\n",
       "      <td>0.668194</td>\n",
       "      <td>0.316980</td>\n",
       "      <td>0.294197</td>\n",
       "      <td>0.276489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.467700</td>\n",
       "      <td>1.445502</td>\n",
       "      <td>0.698442</td>\n",
       "      <td>0.309195</td>\n",
       "      <td>0.319427</td>\n",
       "      <td>0.297959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.164500</td>\n",
       "      <td>1.310141</td>\n",
       "      <td>0.727773</td>\n",
       "      <td>0.359200</td>\n",
       "      <td>0.372687</td>\n",
       "      <td>0.346193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.947700</td>\n",
       "      <td>1.192653</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.448124</td>\n",
       "      <td>0.413333</td>\n",
       "      <td>0.402683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.779400</td>\n",
       "      <td>1.145782</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.473120</td>\n",
       "      <td>0.446682</td>\n",
       "      <td>0.437179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.674800</td>\n",
       "      <td>1.109141</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.473019</td>\n",
       "      <td>0.461929</td>\n",
       "      <td>0.451493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.574900</td>\n",
       "      <td>1.059847</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.481120</td>\n",
       "      <td>0.475141</td>\n",
       "      <td>0.468308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.500400</td>\n",
       "      <td>1.059043</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.485530</td>\n",
       "      <td>0.486628</td>\n",
       "      <td>0.476271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.454800</td>\n",
       "      <td>1.037985</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.484593</td>\n",
       "      <td>0.487320</td>\n",
       "      <td>0.478854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.408000</td>\n",
       "      <td>1.027615</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.488620</td>\n",
       "      <td>0.477333</td>\n",
       "      <td>0.473356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.377200</td>\n",
       "      <td>1.021715</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.493279</td>\n",
       "      <td>0.491999</td>\n",
       "      <td>0.483146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.354900</td>\n",
       "      <td>1.002998</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.493415</td>\n",
       "      <td>0.490239</td>\n",
       "      <td>0.484040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.348900</td>\n",
       "      <td>1.007174</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.491023</td>\n",
       "      <td>0.488718</td>\n",
       "      <td>0.479638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 08:58:36,786] Trial 24 finished with value: 0.4796380766961073 and parameters: {'learning_rate': 0.00048502028060946255, 'weight_decay': 0.008, 'warmup_steps': 3}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 with params: {'learning_rate': 0.00041570382804127483, 'weight_decay': 0.01, 'warmup_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.431600</td>\n",
       "      <td>2.948727</td>\n",
       "      <td>0.380385</td>\n",
       "      <td>0.075102</td>\n",
       "      <td>0.082885</td>\n",
       "      <td>0.062711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.642000</td>\n",
       "      <td>2.302356</td>\n",
       "      <td>0.523373</td>\n",
       "      <td>0.198313</td>\n",
       "      <td>0.166124</td>\n",
       "      <td>0.151347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.062000</td>\n",
       "      <td>1.833950</td>\n",
       "      <td>0.645280</td>\n",
       "      <td>0.316163</td>\n",
       "      <td>0.269319</td>\n",
       "      <td>0.254150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.626100</td>\n",
       "      <td>1.573059</td>\n",
       "      <td>0.694775</td>\n",
       "      <td>0.317127</td>\n",
       "      <td>0.329854</td>\n",
       "      <td>0.306360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.323400</td>\n",
       "      <td>1.409988</td>\n",
       "      <td>0.721357</td>\n",
       "      <td>0.348304</td>\n",
       "      <td>0.359916</td>\n",
       "      <td>0.332752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.094400</td>\n",
       "      <td>1.261513</td>\n",
       "      <td>0.735105</td>\n",
       "      <td>0.389522</td>\n",
       "      <td>0.373305</td>\n",
       "      <td>0.355287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.915700</td>\n",
       "      <td>1.198389</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.418166</td>\n",
       "      <td>0.411108</td>\n",
       "      <td>0.395521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.804000</td>\n",
       "      <td>1.157405</td>\n",
       "      <td>0.756187</td>\n",
       "      <td>0.461649</td>\n",
       "      <td>0.442866</td>\n",
       "      <td>0.433461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.699600</td>\n",
       "      <td>1.113490</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.486120</td>\n",
       "      <td>0.465579</td>\n",
       "      <td>0.458550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.617900</td>\n",
       "      <td>1.107653</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.490361</td>\n",
       "      <td>0.481165</td>\n",
       "      <td>0.470691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.572100</td>\n",
       "      <td>1.079142</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.469583</td>\n",
       "      <td>0.479886</td>\n",
       "      <td>0.470054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.517000</td>\n",
       "      <td>1.065612</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.487741</td>\n",
       "      <td>0.478767</td>\n",
       "      <td>0.475159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.487200</td>\n",
       "      <td>1.054529</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.473088</td>\n",
       "      <td>0.485605</td>\n",
       "      <td>0.473947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.463800</td>\n",
       "      <td>1.041088</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.496854</td>\n",
       "      <td>0.486857</td>\n",
       "      <td>0.482542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.457400</td>\n",
       "      <td>1.043668</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.473881</td>\n",
       "      <td>0.486431</td>\n",
       "      <td>0.474798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 08:59:50,138] Trial 25 finished with value: 0.47479777344692564 and parameters: {'learning_rate': 0.00041570382804127483, 'weight_decay': 0.01, 'warmup_steps': 3}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 with params: {'learning_rate': 0.00037532124067673404, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.472200</td>\n",
       "      <td>3.016555</td>\n",
       "      <td>0.373052</td>\n",
       "      <td>0.061365</td>\n",
       "      <td>0.079073</td>\n",
       "      <td>0.059453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.718900</td>\n",
       "      <td>2.384310</td>\n",
       "      <td>0.503208</td>\n",
       "      <td>0.144189</td>\n",
       "      <td>0.148065</td>\n",
       "      <td>0.127263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.156000</td>\n",
       "      <td>1.921165</td>\n",
       "      <td>0.624198</td>\n",
       "      <td>0.318474</td>\n",
       "      <td>0.253591</td>\n",
       "      <td>0.244643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.726600</td>\n",
       "      <td>1.647821</td>\n",
       "      <td>0.695692</td>\n",
       "      <td>0.306633</td>\n",
       "      <td>0.314192</td>\n",
       "      <td>0.295680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.425200</td>\n",
       "      <td>1.458171</td>\n",
       "      <td>0.726856</td>\n",
       "      <td>0.361896</td>\n",
       "      <td>0.361299</td>\n",
       "      <td>0.338875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.188000</td>\n",
       "      <td>1.315199</td>\n",
       "      <td>0.735105</td>\n",
       "      <td>0.394382</td>\n",
       "      <td>0.377450</td>\n",
       "      <td>0.360797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>1.244647</td>\n",
       "      <td>0.735105</td>\n",
       "      <td>0.407044</td>\n",
       "      <td>0.391973</td>\n",
       "      <td>0.381558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.888900</td>\n",
       "      <td>1.204748</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.475938</td>\n",
       "      <td>0.439963</td>\n",
       "      <td>0.430838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.786400</td>\n",
       "      <td>1.150949</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.471533</td>\n",
       "      <td>0.449864</td>\n",
       "      <td>0.446536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.699100</td>\n",
       "      <td>1.136135</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.492336</td>\n",
       "      <td>0.463130</td>\n",
       "      <td>0.460320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.654200</td>\n",
       "      <td>1.110279</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.480592</td>\n",
       "      <td>0.475732</td>\n",
       "      <td>0.469371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.593100</td>\n",
       "      <td>1.091212</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.508195</td>\n",
       "      <td>0.470901</td>\n",
       "      <td>0.475490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.562600</td>\n",
       "      <td>1.078472</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.494503</td>\n",
       "      <td>0.475112</td>\n",
       "      <td>0.474172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.539500</td>\n",
       "      <td>1.066880</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.502817</td>\n",
       "      <td>0.483312</td>\n",
       "      <td>0.483314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.533600</td>\n",
       "      <td>1.067542</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.503522</td>\n",
       "      <td>0.486978</td>\n",
       "      <td>0.485989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:01:04,341] Trial 26 finished with value: 0.48598931076512913 and parameters: {'learning_rate': 0.00037532124067673404, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 27 with params: {'learning_rate': 0.0004960625705146884, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.391100</td>\n",
       "      <td>2.853414</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.069594</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.075040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.514600</td>\n",
       "      <td>2.155805</td>\n",
       "      <td>0.561870</td>\n",
       "      <td>0.204900</td>\n",
       "      <td>0.204580</td>\n",
       "      <td>0.191480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.883500</td>\n",
       "      <td>1.685710</td>\n",
       "      <td>0.663611</td>\n",
       "      <td>0.315538</td>\n",
       "      <td>0.296604</td>\n",
       "      <td>0.279487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.438300</td>\n",
       "      <td>1.430553</td>\n",
       "      <td>0.704858</td>\n",
       "      <td>0.339746</td>\n",
       "      <td>0.325688</td>\n",
       "      <td>0.308871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.143000</td>\n",
       "      <td>1.306513</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.402448</td>\n",
       "      <td>0.394462</td>\n",
       "      <td>0.373230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.923600</td>\n",
       "      <td>1.198707</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.425949</td>\n",
       "      <td>0.397978</td>\n",
       "      <td>0.388294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>1.160062</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.466242</td>\n",
       "      <td>0.441683</td>\n",
       "      <td>0.434849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.660900</td>\n",
       "      <td>1.116987</td>\n",
       "      <td>0.756187</td>\n",
       "      <td>0.483877</td>\n",
       "      <td>0.468307</td>\n",
       "      <td>0.460304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.558600</td>\n",
       "      <td>1.073050</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.497115</td>\n",
       "      <td>0.475613</td>\n",
       "      <td>0.471600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.484900</td>\n",
       "      <td>1.073508</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.499375</td>\n",
       "      <td>0.475766</td>\n",
       "      <td>0.473236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.441100</td>\n",
       "      <td>1.042046</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.501018</td>\n",
       "      <td>0.485266</td>\n",
       "      <td>0.482542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.395200</td>\n",
       "      <td>1.030936</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.526547</td>\n",
       "      <td>0.487668</td>\n",
       "      <td>0.492502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.364800</td>\n",
       "      <td>1.025201</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.506404</td>\n",
       "      <td>0.490515</td>\n",
       "      <td>0.487375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.344200</td>\n",
       "      <td>1.012995</td>\n",
       "      <td>0.778185</td>\n",
       "      <td>0.522815</td>\n",
       "      <td>0.492480</td>\n",
       "      <td>0.493522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.337700</td>\n",
       "      <td>1.014520</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.495115</td>\n",
       "      <td>0.487397</td>\n",
       "      <td>0.482396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:02:19,101] Trial 27 finished with value: 0.4823961180430102 and parameters: {'learning_rate': 0.0004960625705146884, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 28 with params: {'learning_rate': 0.00040721180681103567, 'weight_decay': 0.007, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:16, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.450400</td>\n",
       "      <td>2.969739</td>\n",
       "      <td>0.384968</td>\n",
       "      <td>0.058414</td>\n",
       "      <td>0.082277</td>\n",
       "      <td>0.060855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.661400</td>\n",
       "      <td>2.316953</td>\n",
       "      <td>0.517874</td>\n",
       "      <td>0.194266</td>\n",
       "      <td>0.157886</td>\n",
       "      <td>0.141780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.076800</td>\n",
       "      <td>1.847990</td>\n",
       "      <td>0.649863</td>\n",
       "      <td>0.323432</td>\n",
       "      <td>0.273491</td>\n",
       "      <td>0.262515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.640600</td>\n",
       "      <td>1.577158</td>\n",
       "      <td>0.695692</td>\n",
       "      <td>0.327643</td>\n",
       "      <td>0.329129</td>\n",
       "      <td>0.309400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.336900</td>\n",
       "      <td>1.411075</td>\n",
       "      <td>0.724106</td>\n",
       "      <td>0.357032</td>\n",
       "      <td>0.365410</td>\n",
       "      <td>0.341878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.105700</td>\n",
       "      <td>1.269354</td>\n",
       "      <td>0.733272</td>\n",
       "      <td>0.386766</td>\n",
       "      <td>0.378184</td>\n",
       "      <td>0.359508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>1.211988</td>\n",
       "      <td>0.743355</td>\n",
       "      <td>0.436540</td>\n",
       "      <td>0.406334</td>\n",
       "      <td>0.393124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.815500</td>\n",
       "      <td>1.169317</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.470987</td>\n",
       "      <td>0.449307</td>\n",
       "      <td>0.439337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.713400</td>\n",
       "      <td>1.120841</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.483231</td>\n",
       "      <td>0.466940</td>\n",
       "      <td>0.460238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.631400</td>\n",
       "      <td>1.114129</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.488932</td>\n",
       "      <td>0.480439</td>\n",
       "      <td>0.472951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.586400</td>\n",
       "      <td>1.082476</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.483195</td>\n",
       "      <td>0.477526</td>\n",
       "      <td>0.473083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.530200</td>\n",
       "      <td>1.065337</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.502279</td>\n",
       "      <td>0.481058</td>\n",
       "      <td>0.480363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.499500</td>\n",
       "      <td>1.054286</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.498640</td>\n",
       "      <td>0.479960</td>\n",
       "      <td>0.478724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.477700</td>\n",
       "      <td>1.040996</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.506708</td>\n",
       "      <td>0.481968</td>\n",
       "      <td>0.484520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.470200</td>\n",
       "      <td>1.041873</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.500021</td>\n",
       "      <td>0.483138</td>\n",
       "      <td>0.482544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:03:36,909] Trial 28 finished with value: 0.4825436951247559 and parameters: {'learning_rate': 0.00040721180681103567, 'weight_decay': 0.007, 'warmup_steps': 4}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 29 with params: {'learning_rate': 9.99180549137411e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:47 < 00:23, 7.33 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.723100</td>\n",
       "      <td>3.534925</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.421600</td>\n",
       "      <td>3.261812</td>\n",
       "      <td>0.306141</td>\n",
       "      <td>0.071986</td>\n",
       "      <td>0.058671</td>\n",
       "      <td>0.050425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.185900</td>\n",
       "      <td>3.035987</td>\n",
       "      <td>0.406966</td>\n",
       "      <td>0.074389</td>\n",
       "      <td>0.087849</td>\n",
       "      <td>0.064949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.965400</td>\n",
       "      <td>2.838049</td>\n",
       "      <td>0.439963</td>\n",
       "      <td>0.087388</td>\n",
       "      <td>0.104043</td>\n",
       "      <td>0.081393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.806100</td>\n",
       "      <td>2.666983</td>\n",
       "      <td>0.466544</td>\n",
       "      <td>0.104777</td>\n",
       "      <td>0.119899</td>\n",
       "      <td>0.096405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.631400</td>\n",
       "      <td>2.526194</td>\n",
       "      <td>0.493126</td>\n",
       "      <td>0.123551</td>\n",
       "      <td>0.135164</td>\n",
       "      <td>0.110791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.492100</td>\n",
       "      <td>2.414025</td>\n",
       "      <td>0.506874</td>\n",
       "      <td>0.152944</td>\n",
       "      <td>0.146193</td>\n",
       "      <td>0.127303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.396800</td>\n",
       "      <td>2.318798</td>\n",
       "      <td>0.557287</td>\n",
       "      <td>0.208818</td>\n",
       "      <td>0.186126</td>\n",
       "      <td>0.172247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.293300</td>\n",
       "      <td>2.238494</td>\n",
       "      <td>0.573786</td>\n",
       "      <td>0.270427</td>\n",
       "      <td>0.203152</td>\n",
       "      <td>0.192653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.210600</td>\n",
       "      <td>2.176896</td>\n",
       "      <td>0.588451</td>\n",
       "      <td>0.285000</td>\n",
       "      <td>0.215508</td>\n",
       "      <td>0.206218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:04:25,181] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 with params: {'learning_rate': 0.00015706256872557984, 'weight_decay': 0.009000000000000001, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:46 < 00:23, 7.46 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.663200</td>\n",
       "      <td>3.402663</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.241000</td>\n",
       "      <td>3.031281</td>\n",
       "      <td>0.393217</td>\n",
       "      <td>0.097589</td>\n",
       "      <td>0.084896</td>\n",
       "      <td>0.064527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.914400</td>\n",
       "      <td>2.717604</td>\n",
       "      <td>0.453712</td>\n",
       "      <td>0.103198</td>\n",
       "      <td>0.112746</td>\n",
       "      <td>0.089174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.617500</td>\n",
       "      <td>2.462946</td>\n",
       "      <td>0.505958</td>\n",
       "      <td>0.130622</td>\n",
       "      <td>0.144588</td>\n",
       "      <td>0.119452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.398900</td>\n",
       "      <td>2.253691</td>\n",
       "      <td>0.555454</td>\n",
       "      <td>0.228113</td>\n",
       "      <td>0.185628</td>\n",
       "      <td>0.170914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.177100</td>\n",
       "      <td>2.089202</td>\n",
       "      <td>0.591201</td>\n",
       "      <td>0.246839</td>\n",
       "      <td>0.212768</td>\n",
       "      <td>0.199471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.004500</td>\n",
       "      <td>1.961069</td>\n",
       "      <td>0.615032</td>\n",
       "      <td>0.298154</td>\n",
       "      <td>0.247604</td>\n",
       "      <td>0.240718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.883500</td>\n",
       "      <td>1.860010</td>\n",
       "      <td>0.661778</td>\n",
       "      <td>0.329349</td>\n",
       "      <td>0.282757</td>\n",
       "      <td>0.272667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.758200</td>\n",
       "      <td>1.771767</td>\n",
       "      <td>0.675527</td>\n",
       "      <td>0.342564</td>\n",
       "      <td>0.293282</td>\n",
       "      <td>0.284599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.660700</td>\n",
       "      <td>1.708465</td>\n",
       "      <td>0.689276</td>\n",
       "      <td>0.355629</td>\n",
       "      <td>0.313888</td>\n",
       "      <td>0.304813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:05:12,759] Trial 30 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 31 with params: {'learning_rate': 0.0003755942696637551, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:45 < 00:23, 7.58 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.472000</td>\n",
       "      <td>3.016230</td>\n",
       "      <td>0.373052</td>\n",
       "      <td>0.061365</td>\n",
       "      <td>0.079073</td>\n",
       "      <td>0.059453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.718500</td>\n",
       "      <td>2.383773</td>\n",
       "      <td>0.503208</td>\n",
       "      <td>0.144189</td>\n",
       "      <td>0.148065</td>\n",
       "      <td>0.127263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.155400</td>\n",
       "      <td>1.920595</td>\n",
       "      <td>0.625115</td>\n",
       "      <td>0.318522</td>\n",
       "      <td>0.253865</td>\n",
       "      <td>0.244784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.725800</td>\n",
       "      <td>1.647218</td>\n",
       "      <td>0.695692</td>\n",
       "      <td>0.306883</td>\n",
       "      <td>0.314192</td>\n",
       "      <td>0.296031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.424300</td>\n",
       "      <td>1.457563</td>\n",
       "      <td>0.726856</td>\n",
       "      <td>0.361244</td>\n",
       "      <td>0.361299</td>\n",
       "      <td>0.338285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.187200</td>\n",
       "      <td>1.314780</td>\n",
       "      <td>0.735105</td>\n",
       "      <td>0.394382</td>\n",
       "      <td>0.377450</td>\n",
       "      <td>0.360797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.004300</td>\n",
       "      <td>1.244310</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.407595</td>\n",
       "      <td>0.392461</td>\n",
       "      <td>0.382063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.888200</td>\n",
       "      <td>1.204416</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.475938</td>\n",
       "      <td>0.439963</td>\n",
       "      <td>0.430838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.785700</td>\n",
       "      <td>1.150665</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.470200</td>\n",
       "      <td>0.449864</td>\n",
       "      <td>0.446685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.698400</td>\n",
       "      <td>1.135947</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.492336</td>\n",
       "      <td>0.463130</td>\n",
       "      <td>0.460320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:05:59,629] Trial 31 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 32 with params: {'learning_rate': 0.00042882561463163685, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:10, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.435800</td>\n",
       "      <td>2.939557</td>\n",
       "      <td>0.394134</td>\n",
       "      <td>0.074932</td>\n",
       "      <td>0.085413</td>\n",
       "      <td>0.063976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.625100</td>\n",
       "      <td>2.277167</td>\n",
       "      <td>0.524290</td>\n",
       "      <td>0.179516</td>\n",
       "      <td>0.161961</td>\n",
       "      <td>0.145536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.027100</td>\n",
       "      <td>1.803301</td>\n",
       "      <td>0.647113</td>\n",
       "      <td>0.316898</td>\n",
       "      <td>0.277990</td>\n",
       "      <td>0.262567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.588000</td>\n",
       "      <td>1.536119</td>\n",
       "      <td>0.693859</td>\n",
       "      <td>0.322622</td>\n",
       "      <td>0.328277</td>\n",
       "      <td>0.309373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.284400</td>\n",
       "      <td>1.384767</td>\n",
       "      <td>0.725940</td>\n",
       "      <td>0.374839</td>\n",
       "      <td>0.374681</td>\n",
       "      <td>0.352117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.057300</td>\n",
       "      <td>1.246436</td>\n",
       "      <td>0.738772</td>\n",
       "      <td>0.406911</td>\n",
       "      <td>0.384094</td>\n",
       "      <td>0.366665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.884100</td>\n",
       "      <td>1.194887</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.471143</td>\n",
       "      <td>0.430302</td>\n",
       "      <td>0.422675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.773900</td>\n",
       "      <td>1.152072</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.473026</td>\n",
       "      <td>0.456682</td>\n",
       "      <td>0.446500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.671600</td>\n",
       "      <td>1.105621</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.486148</td>\n",
       "      <td>0.471983</td>\n",
       "      <td>0.464751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.590700</td>\n",
       "      <td>1.097707</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.485184</td>\n",
       "      <td>0.481640</td>\n",
       "      <td>0.473093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.547200</td>\n",
       "      <td>1.067166</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.475882</td>\n",
       "      <td>0.478233</td>\n",
       "      <td>0.469494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.492200</td>\n",
       "      <td>1.051960</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.509600</td>\n",
       "      <td>0.480096</td>\n",
       "      <td>0.482491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.461300</td>\n",
       "      <td>1.041810</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.497207</td>\n",
       "      <td>0.486739</td>\n",
       "      <td>0.484337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.439400</td>\n",
       "      <td>1.026931</td>\n",
       "      <td>0.778185</td>\n",
       "      <td>0.510037</td>\n",
       "      <td>0.487199</td>\n",
       "      <td>0.487880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.432300</td>\n",
       "      <td>1.027864</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.501021</td>\n",
       "      <td>0.487171</td>\n",
       "      <td>0.485741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:07:11,054] Trial 32 finished with value: 0.48574138414339885 and parameters: {'learning_rate': 0.00042882561463163685, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 33 with params: {'learning_rate': 0.000497203887698053, 'weight_decay': 0.008, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.390400</td>\n",
       "      <td>2.852013</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.069745</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.075134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.513200</td>\n",
       "      <td>2.154164</td>\n",
       "      <td>0.561870</td>\n",
       "      <td>0.204389</td>\n",
       "      <td>0.204820</td>\n",
       "      <td>0.191392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.881200</td>\n",
       "      <td>1.683223</td>\n",
       "      <td>0.665445</td>\n",
       "      <td>0.313179</td>\n",
       "      <td>0.297657</td>\n",
       "      <td>0.280047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.435800</td>\n",
       "      <td>1.428625</td>\n",
       "      <td>0.705775</td>\n",
       "      <td>0.340483</td>\n",
       "      <td>0.326597</td>\n",
       "      <td>0.309628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.140400</td>\n",
       "      <td>1.305566</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.402892</td>\n",
       "      <td>0.394081</td>\n",
       "      <td>0.373331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.920800</td>\n",
       "      <td>1.197471</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.427553</td>\n",
       "      <td>0.397978</td>\n",
       "      <td>0.388596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.760300</td>\n",
       "      <td>1.158910</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.487525</td>\n",
       "      <td>0.444709</td>\n",
       "      <td>0.440338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.658900</td>\n",
       "      <td>1.115855</td>\n",
       "      <td>0.757104</td>\n",
       "      <td>0.484306</td>\n",
       "      <td>0.468522</td>\n",
       "      <td>0.460678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.556800</td>\n",
       "      <td>1.071169</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.498161</td>\n",
       "      <td>0.478113</td>\n",
       "      <td>0.474863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.483300</td>\n",
       "      <td>1.072338</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.498430</td>\n",
       "      <td>0.474072</td>\n",
       "      <td>0.471928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.439500</td>\n",
       "      <td>1.040787</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.500050</td>\n",
       "      <td>0.485754</td>\n",
       "      <td>0.482068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>1.029823</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.520951</td>\n",
       "      <td>0.488031</td>\n",
       "      <td>0.490663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.363400</td>\n",
       "      <td>1.024175</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.504002</td>\n",
       "      <td>0.490515</td>\n",
       "      <td>0.485901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.342600</td>\n",
       "      <td>1.012029</td>\n",
       "      <td>0.779102</td>\n",
       "      <td>0.517264</td>\n",
       "      <td>0.492844</td>\n",
       "      <td>0.491738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.336100</td>\n",
       "      <td>1.013674</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.515456</td>\n",
       "      <td>0.489858</td>\n",
       "      <td>0.486697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:08:24,877] Trial 33 finished with value: 0.4866972638398252 and parameters: {'learning_rate': 0.000497203887698053, 'weight_decay': 0.008, 'warmup_steps': 4}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 34 with params: {'learning_rate': 0.000377653012761153, 'weight_decay': 0.006, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:11, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.470600</td>\n",
       "      <td>3.013122</td>\n",
       "      <td>0.372136</td>\n",
       "      <td>0.060973</td>\n",
       "      <td>0.078857</td>\n",
       "      <td>0.058932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.714600</td>\n",
       "      <td>2.379199</td>\n",
       "      <td>0.503208</td>\n",
       "      <td>0.144189</td>\n",
       "      <td>0.148065</td>\n",
       "      <td>0.127263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.150000</td>\n",
       "      <td>1.915567</td>\n",
       "      <td>0.626948</td>\n",
       "      <td>0.318689</td>\n",
       "      <td>0.254755</td>\n",
       "      <td>0.246067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.720000</td>\n",
       "      <td>1.642492</td>\n",
       "      <td>0.695692</td>\n",
       "      <td>0.306633</td>\n",
       "      <td>0.314192</td>\n",
       "      <td>0.295680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.418300</td>\n",
       "      <td>1.454388</td>\n",
       "      <td>0.727773</td>\n",
       "      <td>0.362310</td>\n",
       "      <td>0.361753</td>\n",
       "      <td>0.339144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.181500</td>\n",
       "      <td>1.311539</td>\n",
       "      <td>0.734189</td>\n",
       "      <td>0.382404</td>\n",
       "      <td>0.369946</td>\n",
       "      <td>0.352389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>1.241972</td>\n",
       "      <td>0.734189</td>\n",
       "      <td>0.412353</td>\n",
       "      <td>0.391735</td>\n",
       "      <td>0.381127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.883100</td>\n",
       "      <td>1.201893</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.478201</td>\n",
       "      <td>0.442820</td>\n",
       "      <td>0.434151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.780500</td>\n",
       "      <td>1.148367</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.477873</td>\n",
       "      <td>0.449626</td>\n",
       "      <td>0.445386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.693900</td>\n",
       "      <td>1.134562</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.491358</td>\n",
       "      <td>0.468260</td>\n",
       "      <td>0.464743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.648800</td>\n",
       "      <td>1.107993</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.481066</td>\n",
       "      <td>0.475836</td>\n",
       "      <td>0.469672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.588400</td>\n",
       "      <td>1.088996</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.506045</td>\n",
       "      <td>0.470663</td>\n",
       "      <td>0.474171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.557700</td>\n",
       "      <td>1.076219</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.499516</td>\n",
       "      <td>0.479983</td>\n",
       "      <td>0.479242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.534700</td>\n",
       "      <td>1.064677</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.507778</td>\n",
       "      <td>0.482403</td>\n",
       "      <td>0.484527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.528700</td>\n",
       "      <td>1.065331</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.502977</td>\n",
       "      <td>0.486978</td>\n",
       "      <td>0.485689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:09:37,612] Trial 34 finished with value: 0.48568880571462403 and parameters: {'learning_rate': 0.000377653012761153, 'weight_decay': 0.006, 'warmup_steps': 4}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 35 with params: {'learning_rate': 0.00038017331791589156, 'weight_decay': 0.008, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:48 < 00:24, 7.20 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.468800</td>\n",
       "      <td>3.009405</td>\n",
       "      <td>0.373052</td>\n",
       "      <td>0.060485</td>\n",
       "      <td>0.079073</td>\n",
       "      <td>0.058886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.709900</td>\n",
       "      <td>2.373741</td>\n",
       "      <td>0.505958</td>\n",
       "      <td>0.149540</td>\n",
       "      <td>0.149314</td>\n",
       "      <td>0.129285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.143600</td>\n",
       "      <td>1.909665</td>\n",
       "      <td>0.633364</td>\n",
       "      <td>0.320922</td>\n",
       "      <td>0.258587</td>\n",
       "      <td>0.250355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.713000</td>\n",
       "      <td>1.636817</td>\n",
       "      <td>0.697525</td>\n",
       "      <td>0.307312</td>\n",
       "      <td>0.317397</td>\n",
       "      <td>0.297982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.411000</td>\n",
       "      <td>1.450274</td>\n",
       "      <td>0.726856</td>\n",
       "      <td>0.362066</td>\n",
       "      <td>0.361650</td>\n",
       "      <td>0.338941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.174500</td>\n",
       "      <td>1.307767</td>\n",
       "      <td>0.734189</td>\n",
       "      <td>0.388912</td>\n",
       "      <td>0.374824</td>\n",
       "      <td>0.356145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>1.239114</td>\n",
       "      <td>0.736939</td>\n",
       "      <td>0.414886</td>\n",
       "      <td>0.393771</td>\n",
       "      <td>0.383449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.876900</td>\n",
       "      <td>1.198983</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.478279</td>\n",
       "      <td>0.446717</td>\n",
       "      <td>0.438784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.774200</td>\n",
       "      <td>1.145741</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.478254</td>\n",
       "      <td>0.449626</td>\n",
       "      <td>0.445577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.688100</td>\n",
       "      <td>1.132788</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.496584</td>\n",
       "      <td>0.469688</td>\n",
       "      <td>0.466947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:10:26,994] Trial 35 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 36 with params: {'learning_rate': 1.0625556226593494e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:48 < 00:24, 7.22 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.865900</td>\n",
       "      <td>3.824595</td>\n",
       "      <td>0.047663</td>\n",
       "      <td>0.012284</td>\n",
       "      <td>0.026678</td>\n",
       "      <td>0.006903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.806400</td>\n",
       "      <td>3.774522</td>\n",
       "      <td>0.158570</td>\n",
       "      <td>0.008461</td>\n",
       "      <td>0.019140</td>\n",
       "      <td>0.009051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.767300</td>\n",
       "      <td>3.730125</td>\n",
       "      <td>0.186984</td>\n",
       "      <td>0.023561</td>\n",
       "      <td>0.023454</td>\n",
       "      <td>0.011483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.726400</td>\n",
       "      <td>3.695626</td>\n",
       "      <td>0.186068</td>\n",
       "      <td>0.016315</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.010848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.703200</td>\n",
       "      <td>3.665717</td>\n",
       "      <td>0.186984</td>\n",
       "      <td>0.015833</td>\n",
       "      <td>0.023014</td>\n",
       "      <td>0.010952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.669900</td>\n",
       "      <td>3.639775</td>\n",
       "      <td>0.183318</td>\n",
       "      <td>0.014360</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>0.009344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.645900</td>\n",
       "      <td>3.616942</td>\n",
       "      <td>0.183318</td>\n",
       "      <td>0.019130</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>0.009479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.628600</td>\n",
       "      <td>3.597194</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.019561</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.609300</td>\n",
       "      <td>3.580069</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.019561</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.595700</td>\n",
       "      <td>3.566005</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.019561</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:11:16,250] Trial 36 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 37 with params: {'learning_rate': 0.0004856127413147924, 'weight_decay': 0.008, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.397800</td>\n",
       "      <td>2.865802</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.072784</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.075681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.530300</td>\n",
       "      <td>2.173166</td>\n",
       "      <td>0.558203</td>\n",
       "      <td>0.204267</td>\n",
       "      <td>0.200698</td>\n",
       "      <td>0.188367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.905400</td>\n",
       "      <td>1.706191</td>\n",
       "      <td>0.660862</td>\n",
       "      <td>0.318084</td>\n",
       "      <td>0.295444</td>\n",
       "      <td>0.278348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.460600</td>\n",
       "      <td>1.445722</td>\n",
       "      <td>0.703941</td>\n",
       "      <td>0.318737</td>\n",
       "      <td>0.322993</td>\n",
       "      <td>0.304732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.165500</td>\n",
       "      <td>1.318094</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.423368</td>\n",
       "      <td>0.396147</td>\n",
       "      <td>0.378480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.946000</td>\n",
       "      <td>1.205121</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.425380</td>\n",
       "      <td>0.397842</td>\n",
       "      <td>0.387102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.781400</td>\n",
       "      <td>1.165099</td>\n",
       "      <td>0.747938</td>\n",
       "      <td>0.470808</td>\n",
       "      <td>0.432640</td>\n",
       "      <td>0.427022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.678000</td>\n",
       "      <td>1.124420</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.485034</td>\n",
       "      <td>0.463909</td>\n",
       "      <td>0.455596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.575300</td>\n",
       "      <td>1.080755</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.489714</td>\n",
       "      <td>0.470815</td>\n",
       "      <td>0.466947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.500200</td>\n",
       "      <td>1.078417</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.500952</td>\n",
       "      <td>0.478790</td>\n",
       "      <td>0.475556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.456800</td>\n",
       "      <td>1.048554</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.501738</td>\n",
       "      <td>0.484284</td>\n",
       "      <td>0.482043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.409400</td>\n",
       "      <td>1.035651</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.503220</td>\n",
       "      <td>0.482473</td>\n",
       "      <td>0.481095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.378500</td>\n",
       "      <td>1.029751</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.528536</td>\n",
       "      <td>0.497578</td>\n",
       "      <td>0.499002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.358200</td>\n",
       "      <td>1.017187</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.519631</td>\n",
       "      <td>0.489273</td>\n",
       "      <td>0.490011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.351400</td>\n",
       "      <td>1.018301</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.524295</td>\n",
       "      <td>0.495346</td>\n",
       "      <td>0.493931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:12:32,107] Trial 37 finished with value: 0.4939308180319757 and parameters: {'learning_rate': 0.0004856127413147924, 'weight_decay': 0.008, 'warmup_steps': 4}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 38 with params: {'learning_rate': 0.00045882704483516664, 'weight_decay': 0.008, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:16, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.415400</td>\n",
       "      <td>2.899936</td>\n",
       "      <td>0.406966</td>\n",
       "      <td>0.074292</td>\n",
       "      <td>0.089886</td>\n",
       "      <td>0.068308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.574200</td>\n",
       "      <td>2.220956</td>\n",
       "      <td>0.544455</td>\n",
       "      <td>0.194986</td>\n",
       "      <td>0.180959</td>\n",
       "      <td>0.168632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.962400</td>\n",
       "      <td>1.752340</td>\n",
       "      <td>0.656279</td>\n",
       "      <td>0.323885</td>\n",
       "      <td>0.290575</td>\n",
       "      <td>0.273818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.520300</td>\n",
       "      <td>1.486891</td>\n",
       "      <td>0.699358</td>\n",
       "      <td>0.314936</td>\n",
       "      <td>0.321141</td>\n",
       "      <td>0.302079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.221000</td>\n",
       "      <td>1.351937</td>\n",
       "      <td>0.733272</td>\n",
       "      <td>0.407336</td>\n",
       "      <td>0.397178</td>\n",
       "      <td>0.377404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.998200</td>\n",
       "      <td>1.224952</td>\n",
       "      <td>0.744271</td>\n",
       "      <td>0.434515</td>\n",
       "      <td>0.399112</td>\n",
       "      <td>0.387894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.828200</td>\n",
       "      <td>1.179716</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.459363</td>\n",
       "      <td>0.431624</td>\n",
       "      <td>0.423113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.719800</td>\n",
       "      <td>1.140464</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.474774</td>\n",
       "      <td>0.460408</td>\n",
       "      <td>0.448408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.617800</td>\n",
       "      <td>1.090718</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.475426</td>\n",
       "      <td>0.470355</td>\n",
       "      <td>0.460906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.539900</td>\n",
       "      <td>1.084871</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.498143</td>\n",
       "      <td>0.477034</td>\n",
       "      <td>0.472714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.497800</td>\n",
       "      <td>1.056414</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.497028</td>\n",
       "      <td>0.479880</td>\n",
       "      <td>0.476521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.445400</td>\n",
       "      <td>1.044003</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.494289</td>\n",
       "      <td>0.482938</td>\n",
       "      <td>0.478363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.415500</td>\n",
       "      <td>1.035574</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.490522</td>\n",
       "      <td>0.483736</td>\n",
       "      <td>0.479699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.393600</td>\n",
       "      <td>1.024798</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.505341</td>\n",
       "      <td>0.487641</td>\n",
       "      <td>0.485852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.387100</td>\n",
       "      <td>1.024737</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.496078</td>\n",
       "      <td>0.488945</td>\n",
       "      <td>0.483642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:13:50,777] Trial 38 finished with value: 0.48364209495694566 and parameters: {'learning_rate': 0.00045882704483516664, 'weight_decay': 0.008, 'warmup_steps': 4}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 39 with params: {'learning_rate': 1.1310667716871232e-05, 'weight_decay': 0.002, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:49 < 00:24, 7.06 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.866700</td>\n",
       "      <td>3.823488</td>\n",
       "      <td>0.050412</td>\n",
       "      <td>0.012808</td>\n",
       "      <td>0.027340</td>\n",
       "      <td>0.007485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.803700</td>\n",
       "      <td>3.769873</td>\n",
       "      <td>0.164986</td>\n",
       "      <td>0.009308</td>\n",
       "      <td>0.020036</td>\n",
       "      <td>0.009466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.761900</td>\n",
       "      <td>3.723614</td>\n",
       "      <td>0.187901</td>\n",
       "      <td>0.036610</td>\n",
       "      <td>0.023728</td>\n",
       "      <td>0.011831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.719200</td>\n",
       "      <td>3.687466</td>\n",
       "      <td>0.186984</td>\n",
       "      <td>0.012435</td>\n",
       "      <td>0.023014</td>\n",
       "      <td>0.010641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.694700</td>\n",
       "      <td>3.655786</td>\n",
       "      <td>0.186984</td>\n",
       "      <td>0.016545</td>\n",
       "      <td>0.023014</td>\n",
       "      <td>0.010996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.659700</td>\n",
       "      <td>3.628323</td>\n",
       "      <td>0.183318</td>\n",
       "      <td>0.016311</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>0.009412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.634200</td>\n",
       "      <td>3.603974</td>\n",
       "      <td>0.181485</td>\n",
       "      <td>0.020231</td>\n",
       "      <td>0.021370</td>\n",
       "      <td>0.008582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.615700</td>\n",
       "      <td>3.582831</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.019561</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.595200</td>\n",
       "      <td>3.564559</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.019561</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.580800</td>\n",
       "      <td>3.549675</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:14:41,070] Trial 39 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 40 with params: {'learning_rate': 0.000493809491819338, 'weight_decay': 0.004, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.392500</td>\n",
       "      <td>2.856036</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.069487</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.074954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.518000</td>\n",
       "      <td>2.159417</td>\n",
       "      <td>0.560037</td>\n",
       "      <td>0.204458</td>\n",
       "      <td>0.204150</td>\n",
       "      <td>0.191075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.888100</td>\n",
       "      <td>1.690125</td>\n",
       "      <td>0.663611</td>\n",
       "      <td>0.318071</td>\n",
       "      <td>0.298810</td>\n",
       "      <td>0.282187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.443200</td>\n",
       "      <td>1.433793</td>\n",
       "      <td>0.705775</td>\n",
       "      <td>0.340223</td>\n",
       "      <td>0.325755</td>\n",
       "      <td>0.309065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.148000</td>\n",
       "      <td>1.309021</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.403164</td>\n",
       "      <td>0.394174</td>\n",
       "      <td>0.373489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.928300</td>\n",
       "      <td>1.200567</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.424878</td>\n",
       "      <td>0.397524</td>\n",
       "      <td>0.387537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.766400</td>\n",
       "      <td>1.161449</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.466242</td>\n",
       "      <td>0.441683</td>\n",
       "      <td>0.434849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.664400</td>\n",
       "      <td>1.118575</td>\n",
       "      <td>0.757104</td>\n",
       "      <td>0.484411</td>\n",
       "      <td>0.468762</td>\n",
       "      <td>0.460839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.562000</td>\n",
       "      <td>1.074578</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.497215</td>\n",
       "      <td>0.476068</td>\n",
       "      <td>0.471717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.488000</td>\n",
       "      <td>1.074532</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.498869</td>\n",
       "      <td>0.475278</td>\n",
       "      <td>0.472714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.444200</td>\n",
       "      <td>1.043271</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.500836</td>\n",
       "      <td>0.485028</td>\n",
       "      <td>0.482313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.398100</td>\n",
       "      <td>1.031828</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.521107</td>\n",
       "      <td>0.488974</td>\n",
       "      <td>0.490985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.367600</td>\n",
       "      <td>1.026284</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.527459</td>\n",
       "      <td>0.497545</td>\n",
       "      <td>0.497976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.347100</td>\n",
       "      <td>1.013777</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.520964</td>\n",
       "      <td>0.489761</td>\n",
       "      <td>0.491244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.340500</td>\n",
       "      <td>1.015278</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.495770</td>\n",
       "      <td>0.487865</td>\n",
       "      <td>0.482973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:15:56,558] Trial 40 finished with value: 0.4829726237776648 and parameters: {'learning_rate': 0.000493809491819338, 'weight_decay': 0.004, 'warmup_steps': 4}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 41 with params: {'learning_rate': 1.2431112024586663e-05, 'weight_decay': 0.0, 'warmup_steps': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:47 < 00:24, 7.29 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.859800</td>\n",
       "      <td>3.813889</td>\n",
       "      <td>0.074244</td>\n",
       "      <td>0.008795</td>\n",
       "      <td>0.029162</td>\n",
       "      <td>0.007685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.792700</td>\n",
       "      <td>3.755856</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.028741</td>\n",
       "      <td>0.021507</td>\n",
       "      <td>0.009844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.748100</td>\n",
       "      <td>3.708866</td>\n",
       "      <td>0.188818</td>\n",
       "      <td>0.015876</td>\n",
       "      <td>0.023822</td>\n",
       "      <td>0.011622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.703900</td>\n",
       "      <td>3.670822</td>\n",
       "      <td>0.186984</td>\n",
       "      <td>0.014621</td>\n",
       "      <td>0.023014</td>\n",
       "      <td>0.010863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.678100</td>\n",
       "      <td>3.636848</td>\n",
       "      <td>0.186984</td>\n",
       "      <td>0.016542</td>\n",
       "      <td>0.023014</td>\n",
       "      <td>0.010992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.640700</td>\n",
       "      <td>3.607296</td>\n",
       "      <td>0.182401</td>\n",
       "      <td>0.020710</td>\n",
       "      <td>0.021644</td>\n",
       "      <td>0.009055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.613300</td>\n",
       "      <td>3.581077</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.019561</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.593400</td>\n",
       "      <td>3.558298</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.019561</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.571300</td>\n",
       "      <td>3.538527</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.556200</td>\n",
       "      <td>3.522637</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:16:45,271] Trial 41 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 42 with params: {'learning_rate': 0.0004528082032294011, 'weight_decay': 0.009000000000000001, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:50 < 00:25, 6.87 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.419500</td>\n",
       "      <td>2.907979</td>\n",
       "      <td>0.405133</td>\n",
       "      <td>0.074402</td>\n",
       "      <td>0.089026</td>\n",
       "      <td>0.067227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.584800</td>\n",
       "      <td>2.232486</td>\n",
       "      <td>0.535289</td>\n",
       "      <td>0.187896</td>\n",
       "      <td>0.170344</td>\n",
       "      <td>0.155217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.975300</td>\n",
       "      <td>1.762247</td>\n",
       "      <td>0.653529</td>\n",
       "      <td>0.317078</td>\n",
       "      <td>0.285500</td>\n",
       "      <td>0.269344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.534400</td>\n",
       "      <td>1.497237</td>\n",
       "      <td>0.699358</td>\n",
       "      <td>0.322124</td>\n",
       "      <td>0.330074</td>\n",
       "      <td>0.311041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.233600</td>\n",
       "      <td>1.360037</td>\n",
       "      <td>0.732356</td>\n",
       "      <td>0.409573</td>\n",
       "      <td>0.393214</td>\n",
       "      <td>0.375221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.010400</td>\n",
       "      <td>1.228489</td>\n",
       "      <td>0.744271</td>\n",
       "      <td>0.427725</td>\n",
       "      <td>0.392761</td>\n",
       "      <td>0.377565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.839500</td>\n",
       "      <td>1.182731</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.468478</td>\n",
       "      <td>0.434866</td>\n",
       "      <td>0.427781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.730200</td>\n",
       "      <td>1.141786</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.477573</td>\n",
       "      <td>0.459777</td>\n",
       "      <td>0.449713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.628200</td>\n",
       "      <td>1.092634</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.472719</td>\n",
       "      <td>0.470984</td>\n",
       "      <td>0.460933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.549800</td>\n",
       "      <td>1.086638</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.488795</td>\n",
       "      <td>0.475001</td>\n",
       "      <td>0.468406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:17:36,973] Trial 42 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 43 with params: {'learning_rate': 0.00048128243053382715, 'weight_decay': 0.007, 'warmup_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.387600</td>\n",
       "      <td>2.866922</td>\n",
       "      <td>0.416132</td>\n",
       "      <td>0.071164</td>\n",
       "      <td>0.096518</td>\n",
       "      <td>0.075011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.533700</td>\n",
       "      <td>2.185558</td>\n",
       "      <td>0.537122</td>\n",
       "      <td>0.203207</td>\n",
       "      <td>0.172807</td>\n",
       "      <td>0.158928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.919400</td>\n",
       "      <td>1.709703</td>\n",
       "      <td>0.667278</td>\n",
       "      <td>0.315413</td>\n",
       "      <td>0.293742</td>\n",
       "      <td>0.275473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.475100</td>\n",
       "      <td>1.451049</td>\n",
       "      <td>0.699358</td>\n",
       "      <td>0.309178</td>\n",
       "      <td>0.321341</td>\n",
       "      <td>0.298960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.171400</td>\n",
       "      <td>1.313849</td>\n",
       "      <td>0.725940</td>\n",
       "      <td>0.374731</td>\n",
       "      <td>0.371077</td>\n",
       "      <td>0.346349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.954100</td>\n",
       "      <td>1.194206</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.441568</td>\n",
       "      <td>0.407437</td>\n",
       "      <td>0.396169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.785300</td>\n",
       "      <td>1.148916</td>\n",
       "      <td>0.757104</td>\n",
       "      <td>0.472657</td>\n",
       "      <td>0.445426</td>\n",
       "      <td>0.437271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.680100</td>\n",
       "      <td>1.112455</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.470093</td>\n",
       "      <td>0.460409</td>\n",
       "      <td>0.449332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.580100</td>\n",
       "      <td>1.062226</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.483599</td>\n",
       "      <td>0.477290</td>\n",
       "      <td>0.470874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.505500</td>\n",
       "      <td>1.062420</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.486347</td>\n",
       "      <td>0.487220</td>\n",
       "      <td>0.477122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.459700</td>\n",
       "      <td>1.038297</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.482322</td>\n",
       "      <td>0.483928</td>\n",
       "      <td>0.476081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.412400</td>\n",
       "      <td>1.027739</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.492579</td>\n",
       "      <td>0.481333</td>\n",
       "      <td>0.477717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.381400</td>\n",
       "      <td>1.022889</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.492872</td>\n",
       "      <td>0.490808</td>\n",
       "      <td>0.482273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.359300</td>\n",
       "      <td>1.003867</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.490440</td>\n",
       "      <td>0.490543</td>\n",
       "      <td>0.482278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.353400</td>\n",
       "      <td>1.007444</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.491646</td>\n",
       "      <td>0.488933</td>\n",
       "      <td>0.480095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:18:50,992] Trial 43 finished with value: 0.48009534112680624 and parameters: {'learning_rate': 0.00048128243053382715, 'weight_decay': 0.007, 'warmup_steps': 3}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 44 with params: {'learning_rate': 0.0004988643633335212, 'weight_decay': 0.008, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:50 < 00:25, 6.96 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.389400</td>\n",
       "      <td>2.850171</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.069605</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.075081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.510900</td>\n",
       "      <td>2.151657</td>\n",
       "      <td>0.561870</td>\n",
       "      <td>0.204372</td>\n",
       "      <td>0.204820</td>\n",
       "      <td>0.191388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.878000</td>\n",
       "      <td>1.680018</td>\n",
       "      <td>0.667278</td>\n",
       "      <td>0.313959</td>\n",
       "      <td>0.298973</td>\n",
       "      <td>0.281214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.432200</td>\n",
       "      <td>1.426125</td>\n",
       "      <td>0.706691</td>\n",
       "      <td>0.342357</td>\n",
       "      <td>0.328720</td>\n",
       "      <td>0.311683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.136400</td>\n",
       "      <td>1.303505</td>\n",
       "      <td>0.736939</td>\n",
       "      <td>0.401960</td>\n",
       "      <td>0.392748</td>\n",
       "      <td>0.372296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.916900</td>\n",
       "      <td>1.195810</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.426984</td>\n",
       "      <td>0.397452</td>\n",
       "      <td>0.387937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.757300</td>\n",
       "      <td>1.157375</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.488418</td>\n",
       "      <td>0.445086</td>\n",
       "      <td>0.440992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.656000</td>\n",
       "      <td>1.114802</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.487801</td>\n",
       "      <td>0.468737</td>\n",
       "      <td>0.462692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.554000</td>\n",
       "      <td>1.069286</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.498497</td>\n",
       "      <td>0.478639</td>\n",
       "      <td>0.475300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.480700</td>\n",
       "      <td>1.070981</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.498189</td>\n",
       "      <td>0.474072</td>\n",
       "      <td>0.471829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:19:41,921] Trial 44 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 45 with params: {'learning_rate': 0.00045976935310664983, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.414800</td>\n",
       "      <td>2.898626</td>\n",
       "      <td>0.406966</td>\n",
       "      <td>0.074292</td>\n",
       "      <td>0.089886</td>\n",
       "      <td>0.068308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.572600</td>\n",
       "      <td>2.219146</td>\n",
       "      <td>0.545371</td>\n",
       "      <td>0.195035</td>\n",
       "      <td>0.181414</td>\n",
       "      <td>0.168951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.960500</td>\n",
       "      <td>1.750954</td>\n",
       "      <td>0.658112</td>\n",
       "      <td>0.326724</td>\n",
       "      <td>0.293909</td>\n",
       "      <td>0.277337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.518300</td>\n",
       "      <td>1.485331</td>\n",
       "      <td>0.699358</td>\n",
       "      <td>0.318060</td>\n",
       "      <td>0.321141</td>\n",
       "      <td>0.302242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.219200</td>\n",
       "      <td>1.350712</td>\n",
       "      <td>0.733272</td>\n",
       "      <td>0.396783</td>\n",
       "      <td>0.397178</td>\n",
       "      <td>0.375999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.996500</td>\n",
       "      <td>1.224263</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.435224</td>\n",
       "      <td>0.400445</td>\n",
       "      <td>0.388860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.826500</td>\n",
       "      <td>1.179198</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.460338</td>\n",
       "      <td>0.432113</td>\n",
       "      <td>0.423779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.718300</td>\n",
       "      <td>1.140390</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.475038</td>\n",
       "      <td>0.460408</td>\n",
       "      <td>0.448551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.616300</td>\n",
       "      <td>1.090885</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.474985</td>\n",
       "      <td>0.469900</td>\n",
       "      <td>0.460468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.538400</td>\n",
       "      <td>1.084808</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.498610</td>\n",
       "      <td>0.477034</td>\n",
       "      <td>0.472989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.496200</td>\n",
       "      <td>1.056383</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.496650</td>\n",
       "      <td>0.480064</td>\n",
       "      <td>0.476469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.444100</td>\n",
       "      <td>1.044129</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.494292</td>\n",
       "      <td>0.482938</td>\n",
       "      <td>0.478402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.414100</td>\n",
       "      <td>1.035803</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.490188</td>\n",
       "      <td>0.483498</td>\n",
       "      <td>0.479399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.392300</td>\n",
       "      <td>1.025005</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.524580</td>\n",
       "      <td>0.493161</td>\n",
       "      <td>0.494736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.385800</td>\n",
       "      <td>1.024921</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.502057</td>\n",
       "      <td>0.488707</td>\n",
       "      <td>0.483873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:20:55,902] Trial 45 finished with value: 0.4838726142810639 and parameters: {'learning_rate': 0.00045976935310664983, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 46 with params: {'learning_rate': 0.00016820682795996844, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:47, 7.33 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.651500</td>\n",
       "      <td>3.377964</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.208300</td>\n",
       "      <td>2.989679</td>\n",
       "      <td>0.403300</td>\n",
       "      <td>0.096499</td>\n",
       "      <td>0.087863</td>\n",
       "      <td>0.067038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.865500</td>\n",
       "      <td>2.661681</td>\n",
       "      <td>0.462878</td>\n",
       "      <td>0.103673</td>\n",
       "      <td>0.118054</td>\n",
       "      <td>0.093982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.556100</td>\n",
       "      <td>2.398129</td>\n",
       "      <td>0.519707</td>\n",
       "      <td>0.150169</td>\n",
       "      <td>0.154023</td>\n",
       "      <td>0.132730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.328700</td>\n",
       "      <td>2.186463</td>\n",
       "      <td>0.574702</td>\n",
       "      <td>0.235376</td>\n",
       "      <td>0.200497</td>\n",
       "      <td>0.187771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:21:20,512] Trial 46 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 47 with params: {'learning_rate': 0.0003180656037351257, 'weight_decay': 0.01, 'warmup_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.504500</td>\n",
       "      <td>3.092984</td>\n",
       "      <td>0.348304</td>\n",
       "      <td>0.068804</td>\n",
       "      <td>0.071698</td>\n",
       "      <td>0.058277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.829100</td>\n",
       "      <td>2.516599</td>\n",
       "      <td>0.460128</td>\n",
       "      <td>0.116385</td>\n",
       "      <td>0.116296</td>\n",
       "      <td>0.086313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.313100</td>\n",
       "      <td>2.077429</td>\n",
       "      <td>0.574702</td>\n",
       "      <td>0.256477</td>\n",
       "      <td>0.206015</td>\n",
       "      <td>0.195886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.903100</td>\n",
       "      <td>1.792439</td>\n",
       "      <td>0.666361</td>\n",
       "      <td>0.322707</td>\n",
       "      <td>0.291247</td>\n",
       "      <td>0.277512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.611300</td>\n",
       "      <td>1.583154</td>\n",
       "      <td>0.717690</td>\n",
       "      <td>0.376160</td>\n",
       "      <td>0.354470</td>\n",
       "      <td>0.337417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.366500</td>\n",
       "      <td>1.426204</td>\n",
       "      <td>0.724106</td>\n",
       "      <td>0.350373</td>\n",
       "      <td>0.360783</td>\n",
       "      <td>0.341954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.176000</td>\n",
       "      <td>1.338154</td>\n",
       "      <td>0.726856</td>\n",
       "      <td>0.348647</td>\n",
       "      <td>0.361542</td>\n",
       "      <td>0.343174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.054300</td>\n",
       "      <td>1.285047</td>\n",
       "      <td>0.739688</td>\n",
       "      <td>0.388744</td>\n",
       "      <td>0.391529</td>\n",
       "      <td>0.370256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.949700</td>\n",
       "      <td>1.234170</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.419278</td>\n",
       "      <td>0.413890</td>\n",
       "      <td>0.397669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.853600</td>\n",
       "      <td>1.202983</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.442050</td>\n",
       "      <td>0.414522</td>\n",
       "      <td>0.405129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.809600</td>\n",
       "      <td>1.181069</td>\n",
       "      <td>0.756187</td>\n",
       "      <td>0.444045</td>\n",
       "      <td>0.431265</td>\n",
       "      <td>0.422334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.743100</td>\n",
       "      <td>1.156910</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.469359</td>\n",
       "      <td>0.434147</td>\n",
       "      <td>0.434547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.714200</td>\n",
       "      <td>1.147624</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.484495</td>\n",
       "      <td>0.446389</td>\n",
       "      <td>0.444123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.686900</td>\n",
       "      <td>1.132056</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.504288</td>\n",
       "      <td>0.458679</td>\n",
       "      <td>0.461344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.680300</td>\n",
       "      <td>1.133044</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.492254</td>\n",
       "      <td>0.458676</td>\n",
       "      <td>0.456653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:22:35,601] Trial 47 finished with value: 0.456653426586453 and parameters: {'learning_rate': 0.0003180656037351257, 'weight_decay': 0.01, 'warmup_steps': 3}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 48 with params: {'learning_rate': 0.00040801976151097626, 'weight_decay': 0.008, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:11, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.449800</td>\n",
       "      <td>2.968532</td>\n",
       "      <td>0.384968</td>\n",
       "      <td>0.058390</td>\n",
       "      <td>0.082277</td>\n",
       "      <td>0.060828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.659900</td>\n",
       "      <td>2.315238</td>\n",
       "      <td>0.516957</td>\n",
       "      <td>0.193618</td>\n",
       "      <td>0.157360</td>\n",
       "      <td>0.141184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.074900</td>\n",
       "      <td>1.846135</td>\n",
       "      <td>0.648946</td>\n",
       "      <td>0.323936</td>\n",
       "      <td>0.273217</td>\n",
       "      <td>0.262538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.638600</td>\n",
       "      <td>1.575462</td>\n",
       "      <td>0.696609</td>\n",
       "      <td>0.327832</td>\n",
       "      <td>0.329492</td>\n",
       "      <td>0.309728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.334900</td>\n",
       "      <td>1.409848</td>\n",
       "      <td>0.723190</td>\n",
       "      <td>0.354257</td>\n",
       "      <td>0.364231</td>\n",
       "      <td>0.340101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.103900</td>\n",
       "      <td>1.268127</td>\n",
       "      <td>0.733272</td>\n",
       "      <td>0.386766</td>\n",
       "      <td>0.378184</td>\n",
       "      <td>0.359508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.926300</td>\n",
       "      <td>1.211042</td>\n",
       "      <td>0.743355</td>\n",
       "      <td>0.438976</td>\n",
       "      <td>0.406334</td>\n",
       "      <td>0.394362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.813700</td>\n",
       "      <td>1.168260</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.471039</td>\n",
       "      <td>0.449307</td>\n",
       "      <td>0.439355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.711700</td>\n",
       "      <td>1.119789</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.483758</td>\n",
       "      <td>0.467428</td>\n",
       "      <td>0.460711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.629900</td>\n",
       "      <td>1.113168</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.488671</td>\n",
       "      <td>0.480894</td>\n",
       "      <td>0.473053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>1.081733</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.483184</td>\n",
       "      <td>0.477526</td>\n",
       "      <td>0.472930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.528800</td>\n",
       "      <td>1.064757</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.502279</td>\n",
       "      <td>0.481058</td>\n",
       "      <td>0.480363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.498000</td>\n",
       "      <td>1.053553</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.498777</td>\n",
       "      <td>0.479960</td>\n",
       "      <td>0.478889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.476200</td>\n",
       "      <td>1.040283</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.506928</td>\n",
       "      <td>0.482456</td>\n",
       "      <td>0.484370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.468700</td>\n",
       "      <td>1.041204</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.500434</td>\n",
       "      <td>0.483241</td>\n",
       "      <td>0.482827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:23:48,503] Trial 48 finished with value: 0.4828269144867581 and parameters: {'learning_rate': 0.00040801976151097626, 'weight_decay': 0.008, 'warmup_steps': 4}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 49 with params: {'learning_rate': 0.0004621344276435703, 'weight_decay': 0.009000000000000001, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.413100</td>\n",
       "      <td>2.895418</td>\n",
       "      <td>0.410632</td>\n",
       "      <td>0.074661</td>\n",
       "      <td>0.092036</td>\n",
       "      <td>0.071326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.568600</td>\n",
       "      <td>2.214771</td>\n",
       "      <td>0.547204</td>\n",
       "      <td>0.195101</td>\n",
       "      <td>0.183319</td>\n",
       "      <td>0.170247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.955400</td>\n",
       "      <td>1.746956</td>\n",
       "      <td>0.660862</td>\n",
       "      <td>0.323972</td>\n",
       "      <td>0.295875</td>\n",
       "      <td>0.278773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.512900</td>\n",
       "      <td>1.481451</td>\n",
       "      <td>0.699358</td>\n",
       "      <td>0.317764</td>\n",
       "      <td>0.325160</td>\n",
       "      <td>0.306400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.214300</td>\n",
       "      <td>1.347602</td>\n",
       "      <td>0.732356</td>\n",
       "      <td>0.399371</td>\n",
       "      <td>0.396940</td>\n",
       "      <td>0.377598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.991700</td>\n",
       "      <td>1.222584</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.434911</td>\n",
       "      <td>0.400445</td>\n",
       "      <td>0.388698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.822000</td>\n",
       "      <td>1.178025</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.460431</td>\n",
       "      <td>0.432113</td>\n",
       "      <td>0.423836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.714300</td>\n",
       "      <td>1.139552</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.476040</td>\n",
       "      <td>0.460648</td>\n",
       "      <td>0.449290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.612200</td>\n",
       "      <td>1.090764</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.480337</td>\n",
       "      <td>0.469612</td>\n",
       "      <td>0.460304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.534500</td>\n",
       "      <td>1.085037</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.499135</td>\n",
       "      <td>0.477034</td>\n",
       "      <td>0.473245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.492000</td>\n",
       "      <td>1.056136</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.497066</td>\n",
       "      <td>0.480168</td>\n",
       "      <td>0.476864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.440600</td>\n",
       "      <td>1.043984</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.495619</td>\n",
       "      <td>0.483176</td>\n",
       "      <td>0.479012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.410600</td>\n",
       "      <td>1.035851</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.511675</td>\n",
       "      <td>0.489638</td>\n",
       "      <td>0.489505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.388900</td>\n",
       "      <td>1.025083</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.520923</td>\n",
       "      <td>0.492634</td>\n",
       "      <td>0.492342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.382400</td>\n",
       "      <td>1.025109</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.503292</td>\n",
       "      <td>0.488707</td>\n",
       "      <td>0.484324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:25:03,721] Trial 49 finished with value: 0.48432403857028183 and parameters: {'learning_rate': 0.0004621344276435703, 'weight_decay': 0.009000000000000001, 'warmup_steps': 4}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 with params: {'learning_rate': 0.00048339295789459613, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:17, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.399200</td>\n",
       "      <td>2.868510</td>\n",
       "      <td>0.418882</td>\n",
       "      <td>0.072621</td>\n",
       "      <td>0.096599</td>\n",
       "      <td>0.075012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.533800</td>\n",
       "      <td>2.177004</td>\n",
       "      <td>0.558203</td>\n",
       "      <td>0.204267</td>\n",
       "      <td>0.200698</td>\n",
       "      <td>0.188367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.910100</td>\n",
       "      <td>1.710538</td>\n",
       "      <td>0.660862</td>\n",
       "      <td>0.318084</td>\n",
       "      <td>0.295444</td>\n",
       "      <td>0.278348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.465300</td>\n",
       "      <td>1.448992</td>\n",
       "      <td>0.704858</td>\n",
       "      <td>0.320924</td>\n",
       "      <td>0.323902</td>\n",
       "      <td>0.305495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.170300</td>\n",
       "      <td>1.320873</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.423368</td>\n",
       "      <td>0.396147</td>\n",
       "      <td>0.378480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.950800</td>\n",
       "      <td>1.206956</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.431677</td>\n",
       "      <td>0.406304</td>\n",
       "      <td>0.394044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.785300</td>\n",
       "      <td>1.166124</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.472005</td>\n",
       "      <td>0.433129</td>\n",
       "      <td>0.427842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.681500</td>\n",
       "      <td>1.126141</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.463909</td>\n",
       "      <td>0.455536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.578700</td>\n",
       "      <td>1.082352</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.489174</td>\n",
       "      <td>0.470577</td>\n",
       "      <td>0.466453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.503300</td>\n",
       "      <td>1.079544</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.499903</td>\n",
       "      <td>0.478790</td>\n",
       "      <td>0.474663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>1.049525</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.502775</td>\n",
       "      <td>0.483796</td>\n",
       "      <td>0.481972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.412300</td>\n",
       "      <td>1.036708</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.503407</td>\n",
       "      <td>0.482689</td>\n",
       "      <td>0.481305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.381400</td>\n",
       "      <td>1.030594</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.528053</td>\n",
       "      <td>0.497215</td>\n",
       "      <td>0.498448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.361100</td>\n",
       "      <td>1.018108</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.521152</td>\n",
       "      <td>0.490679</td>\n",
       "      <td>0.491462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.354200</td>\n",
       "      <td>1.019044</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.520099</td>\n",
       "      <td>0.493190</td>\n",
       "      <td>0.491840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:26:22,413] Trial 50 finished with value: 0.4918401682546774 and parameters: {'learning_rate': 0.00048339295789459613, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 51 with params: {'learning_rate': 4.412575130718341e-05, 'weight_decay': 0.007, 'warmup_steps': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:50 < 00:25, 6.86 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.801100</td>\n",
       "      <td>3.687384</td>\n",
       "      <td>0.183318</td>\n",
       "      <td>0.014353</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>0.009335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.634000</td>\n",
       "      <td>3.549369</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.023551</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.515100</td>\n",
       "      <td>3.424933</td>\n",
       "      <td>0.192484</td>\n",
       "      <td>0.043594</td>\n",
       "      <td>0.024586</td>\n",
       "      <td>0.013842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.395300</td>\n",
       "      <td>3.312511</td>\n",
       "      <td>0.311641</td>\n",
       "      <td>0.073056</td>\n",
       "      <td>0.060230</td>\n",
       "      <td>0.053325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.310400</td>\n",
       "      <td>3.215288</td>\n",
       "      <td>0.379468</td>\n",
       "      <td>0.070355</td>\n",
       "      <td>0.080050</td>\n",
       "      <td>0.065405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.211300</td>\n",
       "      <td>3.134316</td>\n",
       "      <td>0.398717</td>\n",
       "      <td>0.078671</td>\n",
       "      <td>0.086029</td>\n",
       "      <td>0.068194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.129800</td>\n",
       "      <td>3.061770</td>\n",
       "      <td>0.408799</td>\n",
       "      <td>0.095124</td>\n",
       "      <td>0.088666</td>\n",
       "      <td>0.067797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.071400</td>\n",
       "      <td>2.999783</td>\n",
       "      <td>0.423465</td>\n",
       "      <td>0.093233</td>\n",
       "      <td>0.095761</td>\n",
       "      <td>0.076178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.011100</td>\n",
       "      <td>2.947738</td>\n",
       "      <td>0.434464</td>\n",
       "      <td>0.089289</td>\n",
       "      <td>0.101773</td>\n",
       "      <td>0.081737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.966900</td>\n",
       "      <td>2.905807</td>\n",
       "      <td>0.444546</td>\n",
       "      <td>0.088429</td>\n",
       "      <td>0.106066</td>\n",
       "      <td>0.084416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:27:14,209] Trial 51 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 52 with params: {'learning_rate': 0.00048322592072392375, 'weight_decay': 0.0, 'warmup_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:20, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.386300</td>\n",
       "      <td>2.864502</td>\n",
       "      <td>0.416132</td>\n",
       "      <td>0.071169</td>\n",
       "      <td>0.096518</td>\n",
       "      <td>0.075007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.530600</td>\n",
       "      <td>2.182378</td>\n",
       "      <td>0.541705</td>\n",
       "      <td>0.226191</td>\n",
       "      <td>0.182081</td>\n",
       "      <td>0.172096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.915400</td>\n",
       "      <td>1.706740</td>\n",
       "      <td>0.668194</td>\n",
       "      <td>0.316929</td>\n",
       "      <td>0.294197</td>\n",
       "      <td>0.276212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.471200</td>\n",
       "      <td>1.448171</td>\n",
       "      <td>0.699358</td>\n",
       "      <td>0.312363</td>\n",
       "      <td>0.321341</td>\n",
       "      <td>0.299247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.167700</td>\n",
       "      <td>1.311846</td>\n",
       "      <td>0.726856</td>\n",
       "      <td>0.360581</td>\n",
       "      <td>0.372505</td>\n",
       "      <td>0.345611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.950700</td>\n",
       "      <td>1.193459</td>\n",
       "      <td>0.747938</td>\n",
       "      <td>0.434126</td>\n",
       "      <td>0.407333</td>\n",
       "      <td>0.395289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.782100</td>\n",
       "      <td>1.147598</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.475460</td>\n",
       "      <td>0.445790</td>\n",
       "      <td>0.437469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.677200</td>\n",
       "      <td>1.111119</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.471334</td>\n",
       "      <td>0.460876</td>\n",
       "      <td>0.449982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.577200</td>\n",
       "      <td>1.061705</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.481120</td>\n",
       "      <td>0.475141</td>\n",
       "      <td>0.468308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.502700</td>\n",
       "      <td>1.063396</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.485867</td>\n",
       "      <td>0.486790</td>\n",
       "      <td>0.476626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.457200</td>\n",
       "      <td>1.038518</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.482844</td>\n",
       "      <td>0.483668</td>\n",
       "      <td>0.476200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.409900</td>\n",
       "      <td>1.028254</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.492789</td>\n",
       "      <td>0.480969</td>\n",
       "      <td>0.477751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.378800</td>\n",
       "      <td>1.023406</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.493069</td>\n",
       "      <td>0.491873</td>\n",
       "      <td>0.482972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.356900</td>\n",
       "      <td>1.004067</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.491710</td>\n",
       "      <td>0.490066</td>\n",
       "      <td>0.482556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.350900</td>\n",
       "      <td>1.008007</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.484845</td>\n",
       "      <td>0.488354</td>\n",
       "      <td>0.478786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:28:36,204] Trial 52 finished with value: 0.4787857305346394 and parameters: {'learning_rate': 0.00048322592072392375, 'weight_decay': 0.0, 'warmup_steps': 3}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 53 with params: {'learning_rate': 3.5160624970107914e-05, 'weight_decay': 0.0, 'warmup_steps': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:52 < 00:26, 6.67 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.816800</td>\n",
       "      <td>3.718070</td>\n",
       "      <td>0.186984</td>\n",
       "      <td>0.020730</td>\n",
       "      <td>0.023274</td>\n",
       "      <td>0.011077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.673300</td>\n",
       "      <td>3.601305</td>\n",
       "      <td>0.181485</td>\n",
       "      <td>0.020224</td>\n",
       "      <td>0.021370</td>\n",
       "      <td>0.008572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.575900</td>\n",
       "      <td>3.499463</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023548</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.476400</td>\n",
       "      <td>3.407908</td>\n",
       "      <td>0.211732</td>\n",
       "      <td>0.083690</td>\n",
       "      <td>0.030352</td>\n",
       "      <td>0.021958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.407600</td>\n",
       "      <td>3.323691</td>\n",
       "      <td>0.305225</td>\n",
       "      <td>0.074117</td>\n",
       "      <td>0.058322</td>\n",
       "      <td>0.051992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.323400</td>\n",
       "      <td>3.253652</td>\n",
       "      <td>0.350137</td>\n",
       "      <td>0.069797</td>\n",
       "      <td>0.071954</td>\n",
       "      <td>0.061456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.254300</td>\n",
       "      <td>3.192242</td>\n",
       "      <td>0.386801</td>\n",
       "      <td>0.075399</td>\n",
       "      <td>0.082182</td>\n",
       "      <td>0.066782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.205300</td>\n",
       "      <td>3.140561</td>\n",
       "      <td>0.404216</td>\n",
       "      <td>0.078348</td>\n",
       "      <td>0.087753</td>\n",
       "      <td>0.069381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.156000</td>\n",
       "      <td>3.095836</td>\n",
       "      <td>0.402383</td>\n",
       "      <td>0.076448</td>\n",
       "      <td>0.086696</td>\n",
       "      <td>0.067029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.118700</td>\n",
       "      <td>3.059156</td>\n",
       "      <td>0.416132</td>\n",
       "      <td>0.095333</td>\n",
       "      <td>0.091946</td>\n",
       "      <td>0.072062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:29:29,332] Trial 53 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 54 with params: {'learning_rate': 0.0004991151617272938, 'weight_decay': 0.01, 'warmup_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:19, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.375900</td>\n",
       "      <td>2.843028</td>\n",
       "      <td>0.422548</td>\n",
       "      <td>0.069042</td>\n",
       "      <td>0.098602</td>\n",
       "      <td>0.075810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.505200</td>\n",
       "      <td>2.156743</td>\n",
       "      <td>0.551787</td>\n",
       "      <td>0.221227</td>\n",
       "      <td>0.196440</td>\n",
       "      <td>0.182852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.885400</td>\n",
       "      <td>1.687091</td>\n",
       "      <td>0.663611</td>\n",
       "      <td>0.309629</td>\n",
       "      <td>0.291591</td>\n",
       "      <td>0.273492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.442800</td>\n",
       "      <td>1.428530</td>\n",
       "      <td>0.699358</td>\n",
       "      <td>0.331414</td>\n",
       "      <td>0.317212</td>\n",
       "      <td>0.298908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.138900</td>\n",
       "      <td>1.298304</td>\n",
       "      <td>0.729606</td>\n",
       "      <td>0.375654</td>\n",
       "      <td>0.377573</td>\n",
       "      <td>0.353403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>1.187461</td>\n",
       "      <td>0.747938</td>\n",
       "      <td>0.434107</td>\n",
       "      <td>0.413052</td>\n",
       "      <td>0.402621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.761000</td>\n",
       "      <td>1.147781</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.472577</td>\n",
       "      <td>0.457547</td>\n",
       "      <td>0.448989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.658200</td>\n",
       "      <td>1.107459</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.476294</td>\n",
       "      <td>0.460218</td>\n",
       "      <td>0.451014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.560900</td>\n",
       "      <td>1.061358</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.474747</td>\n",
       "      <td>0.480440</td>\n",
       "      <td>0.470313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.485100</td>\n",
       "      <td>1.058946</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.482566</td>\n",
       "      <td>0.486572</td>\n",
       "      <td>0.473110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>1.041390</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.492473</td>\n",
       "      <td>0.491018</td>\n",
       "      <td>0.484617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.393900</td>\n",
       "      <td>1.032960</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.489525</td>\n",
       "      <td>0.481880</td>\n",
       "      <td>0.476446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.363900</td>\n",
       "      <td>1.024229</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.495453</td>\n",
       "      <td>0.491910</td>\n",
       "      <td>0.483918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.340700</td>\n",
       "      <td>1.009196</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.489337</td>\n",
       "      <td>0.484351</td>\n",
       "      <td>0.478561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.333900</td>\n",
       "      <td>1.013847</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.479088</td>\n",
       "      <td>0.492113</td>\n",
       "      <td>0.480020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:30:51,095] Trial 54 finished with value: 0.48001965941076447 and parameters: {'learning_rate': 0.0004991151617272938, 'weight_decay': 0.01, 'warmup_steps': 3}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 55 with params: {'learning_rate': 0.0004835938854895277, 'weight_decay': 0.009000000000000001, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:18, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.399100</td>\n",
       "      <td>2.868231</td>\n",
       "      <td>0.418882</td>\n",
       "      <td>0.072621</td>\n",
       "      <td>0.096599</td>\n",
       "      <td>0.075012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.533500</td>\n",
       "      <td>2.176640</td>\n",
       "      <td>0.558203</td>\n",
       "      <td>0.204267</td>\n",
       "      <td>0.200698</td>\n",
       "      <td>0.188367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.909700</td>\n",
       "      <td>1.710060</td>\n",
       "      <td>0.660862</td>\n",
       "      <td>0.318084</td>\n",
       "      <td>0.295444</td>\n",
       "      <td>0.278348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.464900</td>\n",
       "      <td>1.448666</td>\n",
       "      <td>0.704858</td>\n",
       "      <td>0.320924</td>\n",
       "      <td>0.323902</td>\n",
       "      <td>0.305495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.169800</td>\n",
       "      <td>1.320541</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.423368</td>\n",
       "      <td>0.396147</td>\n",
       "      <td>0.378480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.950200</td>\n",
       "      <td>1.206679</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.431677</td>\n",
       "      <td>0.406304</td>\n",
       "      <td>0.394044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.784900</td>\n",
       "      <td>1.166004</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.472005</td>\n",
       "      <td>0.433129</td>\n",
       "      <td>0.427842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.681100</td>\n",
       "      <td>1.126030</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.484367</td>\n",
       "      <td>0.463909</td>\n",
       "      <td>0.455573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.578300</td>\n",
       "      <td>1.081939</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.489174</td>\n",
       "      <td>0.470577</td>\n",
       "      <td>0.466453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.503000</td>\n",
       "      <td>1.079233</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.499903</td>\n",
       "      <td>0.478790</td>\n",
       "      <td>0.475057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.459600</td>\n",
       "      <td>1.049314</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.502998</td>\n",
       "      <td>0.484284</td>\n",
       "      <td>0.482308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.412000</td>\n",
       "      <td>1.036430</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.503407</td>\n",
       "      <td>0.482689</td>\n",
       "      <td>0.481305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.381100</td>\n",
       "      <td>1.030293</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.528195</td>\n",
       "      <td>0.497215</td>\n",
       "      <td>0.498661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.360800</td>\n",
       "      <td>1.017817</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.519924</td>\n",
       "      <td>0.489626</td>\n",
       "      <td>0.490328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.354000</td>\n",
       "      <td>1.018833</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.520448</td>\n",
       "      <td>0.493554</td>\n",
       "      <td>0.492408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:32:11,295] Trial 55 finished with value: 0.4924077988464638 and parameters: {'learning_rate': 0.0004835938854895277, 'weight_decay': 0.009000000000000001, 'warmup_steps': 4}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 56 with params: {'learning_rate': 0.0004559917486250674, 'weight_decay': 0.008, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:49 < 00:24, 7.01 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.417300</td>\n",
       "      <td>2.903767</td>\n",
       "      <td>0.406049</td>\n",
       "      <td>0.074713</td>\n",
       "      <td>0.089241</td>\n",
       "      <td>0.067467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.579200</td>\n",
       "      <td>2.226501</td>\n",
       "      <td>0.542621</td>\n",
       "      <td>0.194224</td>\n",
       "      <td>0.179519</td>\n",
       "      <td>0.167210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.968600</td>\n",
       "      <td>1.757105</td>\n",
       "      <td>0.655362</td>\n",
       "      <td>0.319740</td>\n",
       "      <td>0.289666</td>\n",
       "      <td>0.272824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.526900</td>\n",
       "      <td>1.491687</td>\n",
       "      <td>0.699358</td>\n",
       "      <td>0.314411</td>\n",
       "      <td>0.320528</td>\n",
       "      <td>0.301436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.227000</td>\n",
       "      <td>1.355630</td>\n",
       "      <td>0.731439</td>\n",
       "      <td>0.408282</td>\n",
       "      <td>0.394035</td>\n",
       "      <td>0.375608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.004000</td>\n",
       "      <td>1.226462</td>\n",
       "      <td>0.743355</td>\n",
       "      <td>0.429891</td>\n",
       "      <td>0.394112</td>\n",
       "      <td>0.380944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.833400</td>\n",
       "      <td>1.180883</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.472098</td>\n",
       "      <td>0.434703</td>\n",
       "      <td>0.427843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.724600</td>\n",
       "      <td>1.140702</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.476231</td>\n",
       "      <td>0.460967</td>\n",
       "      <td>0.449176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.622500</td>\n",
       "      <td>1.091219</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.472394</td>\n",
       "      <td>0.470458</td>\n",
       "      <td>0.460487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.544400</td>\n",
       "      <td>1.085677</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.494717</td>\n",
       "      <td>0.475001</td>\n",
       "      <td>0.470708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:33:01,843] Trial 56 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 57 with params: {'learning_rate': 0.0004987902977163654, 'weight_decay': 0.008, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.389400</td>\n",
       "      <td>2.850225</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.069605</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.075081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.511000</td>\n",
       "      <td>2.151697</td>\n",
       "      <td>0.561870</td>\n",
       "      <td>0.204372</td>\n",
       "      <td>0.204820</td>\n",
       "      <td>0.191388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.878100</td>\n",
       "      <td>1.680200</td>\n",
       "      <td>0.668194</td>\n",
       "      <td>0.314228</td>\n",
       "      <td>0.300002</td>\n",
       "      <td>0.281998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.432400</td>\n",
       "      <td>1.426306</td>\n",
       "      <td>0.706691</td>\n",
       "      <td>0.342156</td>\n",
       "      <td>0.328720</td>\n",
       "      <td>0.311509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.136700</td>\n",
       "      <td>1.303592</td>\n",
       "      <td>0.736939</td>\n",
       "      <td>0.401960</td>\n",
       "      <td>0.392748</td>\n",
       "      <td>0.372296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.917100</td>\n",
       "      <td>1.195813</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.426984</td>\n",
       "      <td>0.397452</td>\n",
       "      <td>0.387937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.757400</td>\n",
       "      <td>1.157368</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.487946</td>\n",
       "      <td>0.444982</td>\n",
       "      <td>0.440703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.656100</td>\n",
       "      <td>1.114834</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.487801</td>\n",
       "      <td>0.468737</td>\n",
       "      <td>0.462692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.554100</td>\n",
       "      <td>1.069220</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.498497</td>\n",
       "      <td>0.478639</td>\n",
       "      <td>0.475300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.480800</td>\n",
       "      <td>1.071012</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.497727</td>\n",
       "      <td>0.473617</td>\n",
       "      <td>0.471398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.437200</td>\n",
       "      <td>1.039671</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.501011</td>\n",
       "      <td>0.486572</td>\n",
       "      <td>0.482780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.391500</td>\n",
       "      <td>1.028679</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.521823</td>\n",
       "      <td>0.488519</td>\n",
       "      <td>0.491312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.361300</td>\n",
       "      <td>1.023261</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.498509</td>\n",
       "      <td>0.489324</td>\n",
       "      <td>0.483643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.340500</td>\n",
       "      <td>1.010996</td>\n",
       "      <td>0.779102</td>\n",
       "      <td>0.496246</td>\n",
       "      <td>0.486392</td>\n",
       "      <td>0.481524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.334000</td>\n",
       "      <td>1.012780</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.514277</td>\n",
       "      <td>0.489370</td>\n",
       "      <td>0.485867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:34:17,119] Trial 57 finished with value: 0.4858672535150261 and parameters: {'learning_rate': 0.0004987902977163654, 'weight_decay': 0.008, 'warmup_steps': 4}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 58 with params: {'learning_rate': 0.00047895074665422327, 'weight_decay': 0.009000000000000001, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.402100</td>\n",
       "      <td>2.873928</td>\n",
       "      <td>0.416132</td>\n",
       "      <td>0.073266</td>\n",
       "      <td>0.095070</td>\n",
       "      <td>0.073949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.541000</td>\n",
       "      <td>2.184784</td>\n",
       "      <td>0.557287</td>\n",
       "      <td>0.204342</td>\n",
       "      <td>0.201261</td>\n",
       "      <td>0.189003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.919600</td>\n",
       "      <td>1.718619</td>\n",
       "      <td>0.661778</td>\n",
       "      <td>0.323261</td>\n",
       "      <td>0.295682</td>\n",
       "      <td>0.278947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.475100</td>\n",
       "      <td>1.455713</td>\n",
       "      <td>0.703941</td>\n",
       "      <td>0.320664</td>\n",
       "      <td>0.327614</td>\n",
       "      <td>0.309269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.179800</td>\n",
       "      <td>1.326803</td>\n",
       "      <td>0.736939</td>\n",
       "      <td>0.422487</td>\n",
       "      <td>0.394329</td>\n",
       "      <td>0.375017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.959700</td>\n",
       "      <td>1.210347</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.423344</td>\n",
       "      <td>0.403472</td>\n",
       "      <td>0.390289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.793100</td>\n",
       "      <td>1.168407</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.471726</td>\n",
       "      <td>0.432778</td>\n",
       "      <td>0.427525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.688400</td>\n",
       "      <td>1.130100</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.485004</td>\n",
       "      <td>0.465576</td>\n",
       "      <td>0.455702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.585600</td>\n",
       "      <td>1.085029</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.491730</td>\n",
       "      <td>0.470577</td>\n",
       "      <td>0.466264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.509600</td>\n",
       "      <td>1.081293</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.495610</td>\n",
       "      <td>0.479605</td>\n",
       "      <td>0.474606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.466500</td>\n",
       "      <td>1.051684</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.501886</td>\n",
       "      <td>0.484135</td>\n",
       "      <td>0.481776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.418100</td>\n",
       "      <td>1.038825</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.498257</td>\n",
       "      <td>0.482689</td>\n",
       "      <td>0.479673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.387400</td>\n",
       "      <td>1.032411</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.517328</td>\n",
       "      <td>0.492593</td>\n",
       "      <td>0.493350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.367000</td>\n",
       "      <td>1.020144</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.523870</td>\n",
       "      <td>0.493107</td>\n",
       "      <td>0.493830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.360100</td>\n",
       "      <td>1.020864</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.521865</td>\n",
       "      <td>0.494132</td>\n",
       "      <td>0.493836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:35:33,083] Trial 58 finished with value: 0.49383561910564167 and parameters: {'learning_rate': 0.00047895074665422327, 'weight_decay': 0.009000000000000001, 'warmup_steps': 4}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 59 with params: {'learning_rate': 0.000488100307012158, 'weight_decay': 0.01, 'warmup_steps': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:50 < 00:25, 6.89 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.315500</td>\n",
       "      <td>2.785380</td>\n",
       "      <td>0.433547</td>\n",
       "      <td>0.066307</td>\n",
       "      <td>0.105201</td>\n",
       "      <td>0.078387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.463400</td>\n",
       "      <td>2.122011</td>\n",
       "      <td>0.564620</td>\n",
       "      <td>0.196040</td>\n",
       "      <td>0.196344</td>\n",
       "      <td>0.176392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.861000</td>\n",
       "      <td>1.672881</td>\n",
       "      <td>0.669111</td>\n",
       "      <td>0.289201</td>\n",
       "      <td>0.288776</td>\n",
       "      <td>0.266438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.432900</td>\n",
       "      <td>1.422630</td>\n",
       "      <td>0.698442</td>\n",
       "      <td>0.288413</td>\n",
       "      <td>0.313763</td>\n",
       "      <td>0.288882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.144800</td>\n",
       "      <td>1.297298</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.354585</td>\n",
       "      <td>0.376015</td>\n",
       "      <td>0.349071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.939600</td>\n",
       "      <td>1.176829</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.424943</td>\n",
       "      <td>0.397503</td>\n",
       "      <td>0.384695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.774500</td>\n",
       "      <td>1.141194</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.465776</td>\n",
       "      <td>0.435763</td>\n",
       "      <td>0.428928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.671900</td>\n",
       "      <td>1.096997</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.462658</td>\n",
       "      <td>0.449302</td>\n",
       "      <td>0.438619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>1.069403</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.502966</td>\n",
       "      <td>0.485589</td>\n",
       "      <td>0.479754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.499700</td>\n",
       "      <td>1.045480</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.480307</td>\n",
       "      <td>0.474137</td>\n",
       "      <td>0.467153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:36:24,521] Trial 59 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 60 with params: {'learning_rate': 0.00020829754141218318, 'weight_decay': 0.008, 'warmup_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:49 < 00:25, 6.98 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.604200</td>\n",
       "      <td>3.289712</td>\n",
       "      <td>0.181485</td>\n",
       "      <td>0.043554</td>\n",
       "      <td>0.021262</td>\n",
       "      <td>0.008482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.093000</td>\n",
       "      <td>2.845417</td>\n",
       "      <td>0.424381</td>\n",
       "      <td>0.062844</td>\n",
       "      <td>0.099022</td>\n",
       "      <td>0.073424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.698000</td>\n",
       "      <td>2.479123</td>\n",
       "      <td>0.494042</td>\n",
       "      <td>0.128819</td>\n",
       "      <td>0.137496</td>\n",
       "      <td>0.115308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.354100</td>\n",
       "      <td>2.196081</td>\n",
       "      <td>0.562786</td>\n",
       "      <td>0.204248</td>\n",
       "      <td>0.189064</td>\n",
       "      <td>0.174469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.099900</td>\n",
       "      <td>1.976115</td>\n",
       "      <td>0.616865</td>\n",
       "      <td>0.260873</td>\n",
       "      <td>0.231150</td>\n",
       "      <td>0.215370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.853300</td>\n",
       "      <td>1.800540</td>\n",
       "      <td>0.664528</td>\n",
       "      <td>0.294787</td>\n",
       "      <td>0.274390</td>\n",
       "      <td>0.260382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.664800</td>\n",
       "      <td>1.674917</td>\n",
       "      <td>0.684693</td>\n",
       "      <td>0.361024</td>\n",
       "      <td>0.308406</td>\n",
       "      <td>0.302447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.537000</td>\n",
       "      <td>1.580776</td>\n",
       "      <td>0.705775</td>\n",
       "      <td>0.360757</td>\n",
       "      <td>0.333245</td>\n",
       "      <td>0.320436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.411000</td>\n",
       "      <td>1.506524</td>\n",
       "      <td>0.711274</td>\n",
       "      <td>0.342759</td>\n",
       "      <td>0.334489</td>\n",
       "      <td>0.318468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.309800</td>\n",
       "      <td>1.451842</td>\n",
       "      <td>0.719523</td>\n",
       "      <td>0.373365</td>\n",
       "      <td>0.348911</td>\n",
       "      <td>0.332223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:37:15,568] Trial 60 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 61 with params: {'learning_rate': 0.00048529426982403095, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:17, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.398000</td>\n",
       "      <td>2.866196</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.072935</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.075732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.530800</td>\n",
       "      <td>2.173715</td>\n",
       "      <td>0.558203</td>\n",
       "      <td>0.204267</td>\n",
       "      <td>0.200698</td>\n",
       "      <td>0.188367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.906000</td>\n",
       "      <td>1.706685</td>\n",
       "      <td>0.660862</td>\n",
       "      <td>0.318084</td>\n",
       "      <td>0.295444</td>\n",
       "      <td>0.278348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.461200</td>\n",
       "      <td>1.446126</td>\n",
       "      <td>0.703941</td>\n",
       "      <td>0.318737</td>\n",
       "      <td>0.322993</td>\n",
       "      <td>0.304732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.166100</td>\n",
       "      <td>1.318361</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.423368</td>\n",
       "      <td>0.396147</td>\n",
       "      <td>0.378480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.946600</td>\n",
       "      <td>1.205321</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.424959</td>\n",
       "      <td>0.397842</td>\n",
       "      <td>0.386679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.782000</td>\n",
       "      <td>1.165175</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.469926</td>\n",
       "      <td>0.432366</td>\n",
       "      <td>0.426433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.678500</td>\n",
       "      <td>1.124534</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.485034</td>\n",
       "      <td>0.463909</td>\n",
       "      <td>0.455596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.575900</td>\n",
       "      <td>1.080729</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.489423</td>\n",
       "      <td>0.470815</td>\n",
       "      <td>0.466713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.500600</td>\n",
       "      <td>1.078487</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.500952</td>\n",
       "      <td>0.478790</td>\n",
       "      <td>0.475556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.457200</td>\n",
       "      <td>1.048572</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.501507</td>\n",
       "      <td>0.483829</td>\n",
       "      <td>0.481716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.409800</td>\n",
       "      <td>1.035765</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.503220</td>\n",
       "      <td>0.482473</td>\n",
       "      <td>0.481095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.378900</td>\n",
       "      <td>1.029609</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.528536</td>\n",
       "      <td>0.497578</td>\n",
       "      <td>0.499002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.358700</td>\n",
       "      <td>1.017122</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.519495</td>\n",
       "      <td>0.489035</td>\n",
       "      <td>0.489820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.351800</td>\n",
       "      <td>1.018210</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.524174</td>\n",
       "      <td>0.495346</td>\n",
       "      <td>0.493867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:38:34,444] Trial 61 finished with value: 0.49386700141077666 and parameters: {'learning_rate': 0.00048529426982403095, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 62 with params: {'learning_rate': 0.0004042204591106829, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.452400</td>\n",
       "      <td>2.974175</td>\n",
       "      <td>0.383135</td>\n",
       "      <td>0.058315</td>\n",
       "      <td>0.081847</td>\n",
       "      <td>0.060415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.666700</td>\n",
       "      <td>2.323149</td>\n",
       "      <td>0.517874</td>\n",
       "      <td>0.195563</td>\n",
       "      <td>0.157886</td>\n",
       "      <td>0.141917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.084000</td>\n",
       "      <td>1.854537</td>\n",
       "      <td>0.648029</td>\n",
       "      <td>0.322341</td>\n",
       "      <td>0.272405</td>\n",
       "      <td>0.261898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.648200</td>\n",
       "      <td>1.583420</td>\n",
       "      <td>0.695692</td>\n",
       "      <td>0.327934</td>\n",
       "      <td>0.328706</td>\n",
       "      <td>0.309221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.344600</td>\n",
       "      <td>1.415047</td>\n",
       "      <td>0.722273</td>\n",
       "      <td>0.348121</td>\n",
       "      <td>0.362648</td>\n",
       "      <td>0.337914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.112800</td>\n",
       "      <td>1.273406</td>\n",
       "      <td>0.732356</td>\n",
       "      <td>0.384500</td>\n",
       "      <td>0.376850</td>\n",
       "      <td>0.357697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.934600</td>\n",
       "      <td>1.214909</td>\n",
       "      <td>0.743355</td>\n",
       "      <td>0.436430</td>\n",
       "      <td>0.406334</td>\n",
       "      <td>0.393210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.821900</td>\n",
       "      <td>1.171805</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.471006</td>\n",
       "      <td>0.449307</td>\n",
       "      <td>0.439393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.719900</td>\n",
       "      <td>1.123815</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.481011</td>\n",
       "      <td>0.465840</td>\n",
       "      <td>0.459154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.637400</td>\n",
       "      <td>1.116780</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.487867</td>\n",
       "      <td>0.478177</td>\n",
       "      <td>0.471061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.592300</td>\n",
       "      <td>1.085048</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.484546</td>\n",
       "      <td>0.478171</td>\n",
       "      <td>0.473967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.535900</td>\n",
       "      <td>1.067347</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.501746</td>\n",
       "      <td>0.481058</td>\n",
       "      <td>0.480040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.505200</td>\n",
       "      <td>1.056452</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.498064</td>\n",
       "      <td>0.479960</td>\n",
       "      <td>0.478443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.483400</td>\n",
       "      <td>1.043254</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.506708</td>\n",
       "      <td>0.481968</td>\n",
       "      <td>0.484520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.475800</td>\n",
       "      <td>1.044104</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.500794</td>\n",
       "      <td>0.483768</td>\n",
       "      <td>0.483260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:39:49,737] Trial 62 finished with value: 0.4832600395945819 and parameters: {'learning_rate': 0.0004042204591106829, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 63 with params: {'learning_rate': 0.00028128766321431964, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:24 < 00:49, 7.10 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.544500</td>\n",
       "      <td>3.163717</td>\n",
       "      <td>0.297892</td>\n",
       "      <td>0.071948</td>\n",
       "      <td>0.055997</td>\n",
       "      <td>0.046409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.917100</td>\n",
       "      <td>2.618862</td>\n",
       "      <td>0.452796</td>\n",
       "      <td>0.106915</td>\n",
       "      <td>0.112829</td>\n",
       "      <td>0.082683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.433400</td>\n",
       "      <td>2.197815</td>\n",
       "      <td>0.557287</td>\n",
       "      <td>0.225435</td>\n",
       "      <td>0.185448</td>\n",
       "      <td>0.172123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.037800</td>\n",
       "      <td>1.901154</td>\n",
       "      <td>0.641613</td>\n",
       "      <td>0.291164</td>\n",
       "      <td>0.268602</td>\n",
       "      <td>0.255058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.748400</td>\n",
       "      <td>1.682342</td>\n",
       "      <td>0.702108</td>\n",
       "      <td>0.353649</td>\n",
       "      <td>0.330106</td>\n",
       "      <td>0.318390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:40:15,185] Trial 63 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 64 with params: {'learning_rate': 0.0003835965347689684, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.466500</td>\n",
       "      <td>3.004269</td>\n",
       "      <td>0.374885</td>\n",
       "      <td>0.059988</td>\n",
       "      <td>0.079503</td>\n",
       "      <td>0.059011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.703600</td>\n",
       "      <td>2.366359</td>\n",
       "      <td>0.509624</td>\n",
       "      <td>0.152197</td>\n",
       "      <td>0.151389</td>\n",
       "      <td>0.131559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.134900</td>\n",
       "      <td>1.901414</td>\n",
       "      <td>0.638863</td>\n",
       "      <td>0.318682</td>\n",
       "      <td>0.263496</td>\n",
       "      <td>0.255553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.703500</td>\n",
       "      <td>1.629198</td>\n",
       "      <td>0.697525</td>\n",
       "      <td>0.306318</td>\n",
       "      <td>0.317397</td>\n",
       "      <td>0.297823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.401200</td>\n",
       "      <td>1.444980</td>\n",
       "      <td>0.725023</td>\n",
       "      <td>0.363340</td>\n",
       "      <td>0.360109</td>\n",
       "      <td>0.336492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.165100</td>\n",
       "      <td>1.302728</td>\n",
       "      <td>0.733272</td>\n",
       "      <td>0.384971</td>\n",
       "      <td>0.368158</td>\n",
       "      <td>0.350375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.983800</td>\n",
       "      <td>1.235370</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.416117</td>\n",
       "      <td>0.394226</td>\n",
       "      <td>0.384260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.868500</td>\n",
       "      <td>1.194982</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.478088</td>\n",
       "      <td>0.447205</td>\n",
       "      <td>0.439431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.765900</td>\n",
       "      <td>1.142384</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.484929</td>\n",
       "      <td>0.458536</td>\n",
       "      <td>0.454253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.680500</td>\n",
       "      <td>1.130463</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.496632</td>\n",
       "      <td>0.469688</td>\n",
       "      <td>0.466960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.635300</td>\n",
       "      <td>1.103035</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.481313</td>\n",
       "      <td>0.475109</td>\n",
       "      <td>0.469724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.576100</td>\n",
       "      <td>1.083886</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.496862</td>\n",
       "      <td>0.471566</td>\n",
       "      <td>0.472812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.545400</td>\n",
       "      <td>1.071352</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.497868</td>\n",
       "      <td>0.479425</td>\n",
       "      <td>0.478322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.522700</td>\n",
       "      <td>1.059751</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.505920</td>\n",
       "      <td>0.482691</td>\n",
       "      <td>0.483957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.516000</td>\n",
       "      <td>1.060353</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.499428</td>\n",
       "      <td>0.485446</td>\n",
       "      <td>0.482935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:41:30,641] Trial 64 finished with value: 0.48293505167971773 and parameters: {'learning_rate': 0.0003835965347689684, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 65 with params: {'learning_rate': 1.8851658776032287e-05, 'weight_decay': 0.008, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:47, 7.32 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.851200</td>\n",
       "      <td>3.788128</td>\n",
       "      <td>0.138405</td>\n",
       "      <td>0.009175</td>\n",
       "      <td>0.036587</td>\n",
       "      <td>0.008752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.757300</td>\n",
       "      <td>3.707941</td>\n",
       "      <td>0.183318</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>0.022178</td>\n",
       "      <td>0.009776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.696700</td>\n",
       "      <td>3.647385</td>\n",
       "      <td>0.181485</td>\n",
       "      <td>0.012675</td>\n",
       "      <td>0.021370</td>\n",
       "      <td>0.008460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.637400</td>\n",
       "      <td>3.595562</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>0.021577</td>\n",
       "      <td>0.022466</td>\n",
       "      <td>0.010407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.599000</td>\n",
       "      <td>3.543805</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.023564</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:41:55,166] Trial 65 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 66 with params: {'learning_rate': 0.0004903441684092179, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.394800</td>\n",
       "      <td>2.860147</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.069788</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.075065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.523100</td>\n",
       "      <td>2.165082</td>\n",
       "      <td>0.558203</td>\n",
       "      <td>0.203576</td>\n",
       "      <td>0.200698</td>\n",
       "      <td>0.188060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.895300</td>\n",
       "      <td>1.696767</td>\n",
       "      <td>0.661778</td>\n",
       "      <td>0.317307</td>\n",
       "      <td>0.296783</td>\n",
       "      <td>0.280560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.450600</td>\n",
       "      <td>1.438924</td>\n",
       "      <td>0.705775</td>\n",
       "      <td>0.340495</td>\n",
       "      <td>0.325755</td>\n",
       "      <td>0.309223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.155500</td>\n",
       "      <td>1.312948</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.402891</td>\n",
       "      <td>0.394174</td>\n",
       "      <td>0.373847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.935800</td>\n",
       "      <td>1.202665</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.424952</td>\n",
       "      <td>0.397524</td>\n",
       "      <td>0.387323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.772600</td>\n",
       "      <td>1.163166</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.474008</td>\n",
       "      <td>0.440335</td>\n",
       "      <td>0.435657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>1.120962</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.484122</td>\n",
       "      <td>0.464906</td>\n",
       "      <td>0.456348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.567500</td>\n",
       "      <td>1.077509</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.493125</td>\n",
       "      <td>0.472068</td>\n",
       "      <td>0.467750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.493100</td>\n",
       "      <td>1.076074</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.498145</td>\n",
       "      <td>0.475278</td>\n",
       "      <td>0.472348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.449300</td>\n",
       "      <td>1.045667</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.500539</td>\n",
       "      <td>0.484193</td>\n",
       "      <td>0.481659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.402900</td>\n",
       "      <td>1.033539</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.506141</td>\n",
       "      <td>0.482762</td>\n",
       "      <td>0.482631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.372000</td>\n",
       "      <td>1.027621</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.527121</td>\n",
       "      <td>0.497454</td>\n",
       "      <td>0.497761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.351700</td>\n",
       "      <td>1.015072</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.520343</td>\n",
       "      <td>0.489761</td>\n",
       "      <td>0.490675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>1.016486</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.520894</td>\n",
       "      <td>0.494077</td>\n",
       "      <td>0.492073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:43:11,308] Trial 66 finished with value: 0.4920728027120156 and parameters: {'learning_rate': 0.0004903441684092179, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 67 with params: {'learning_rate': 0.00047284803693767644, 'weight_decay': 0.01, 'warmup_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.393200</td>\n",
       "      <td>2.877563</td>\n",
       "      <td>0.412466</td>\n",
       "      <td>0.071540</td>\n",
       "      <td>0.095658</td>\n",
       "      <td>0.074498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.547600</td>\n",
       "      <td>2.199779</td>\n",
       "      <td>0.535289</td>\n",
       "      <td>0.204393</td>\n",
       "      <td>0.172770</td>\n",
       "      <td>0.158855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.936600</td>\n",
       "      <td>1.723357</td>\n",
       "      <td>0.665445</td>\n",
       "      <td>0.316540</td>\n",
       "      <td>0.290899</td>\n",
       "      <td>0.272115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.493000</td>\n",
       "      <td>1.464839</td>\n",
       "      <td>0.702108</td>\n",
       "      <td>0.313940</td>\n",
       "      <td>0.324296</td>\n",
       "      <td>0.302541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.187900</td>\n",
       "      <td>1.323156</td>\n",
       "      <td>0.723190</td>\n",
       "      <td>0.375722</td>\n",
       "      <td>0.368980</td>\n",
       "      <td>0.345179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.969900</td>\n",
       "      <td>1.199636</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.449031</td>\n",
       "      <td>0.401648</td>\n",
       "      <td>0.389803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.800700</td>\n",
       "      <td>1.151457</td>\n",
       "      <td>0.755270</td>\n",
       "      <td>0.481712</td>\n",
       "      <td>0.439929</td>\n",
       "      <td>0.433289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.694600</td>\n",
       "      <td>1.115017</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.468209</td>\n",
       "      <td>0.463273</td>\n",
       "      <td>0.452502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.593400</td>\n",
       "      <td>1.066974</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.484116</td>\n",
       "      <td>0.476538</td>\n",
       "      <td>0.470464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.518000</td>\n",
       "      <td>1.067490</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.484148</td>\n",
       "      <td>0.486843</td>\n",
       "      <td>0.475725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.472300</td>\n",
       "      <td>1.040859</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.480722</td>\n",
       "      <td>0.484063</td>\n",
       "      <td>0.475322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.423600</td>\n",
       "      <td>1.030706</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.495222</td>\n",
       "      <td>0.483869</td>\n",
       "      <td>0.480560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.392400</td>\n",
       "      <td>1.025293</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.489942</td>\n",
       "      <td>0.488308</td>\n",
       "      <td>0.479762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.370700</td>\n",
       "      <td>1.007086</td>\n",
       "      <td>0.779102</td>\n",
       "      <td>0.491748</td>\n",
       "      <td>0.490152</td>\n",
       "      <td>0.480980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.364200</td>\n",
       "      <td>1.010111</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.490986</td>\n",
       "      <td>0.489171</td>\n",
       "      <td>0.480227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:44:25,847] Trial 67 finished with value: 0.48022710362500504 and parameters: {'learning_rate': 0.00047284803693767644, 'weight_decay': 0.01, 'warmup_steps': 3}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 68 with params: {'learning_rate': 0.00040020752135845226, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:24 < 00:50, 6.93 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.455100</td>\n",
       "      <td>2.979875</td>\n",
       "      <td>0.380385</td>\n",
       "      <td>0.058705</td>\n",
       "      <td>0.081202</td>\n",
       "      <td>0.059816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.673600</td>\n",
       "      <td>2.331261</td>\n",
       "      <td>0.515124</td>\n",
       "      <td>0.174051</td>\n",
       "      <td>0.155917</td>\n",
       "      <td>0.138177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.093600</td>\n",
       "      <td>1.863199</td>\n",
       "      <td>0.646196</td>\n",
       "      <td>0.320044</td>\n",
       "      <td>0.270341</td>\n",
       "      <td>0.260043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.658600</td>\n",
       "      <td>1.592125</td>\n",
       "      <td>0.696609</td>\n",
       "      <td>0.326385</td>\n",
       "      <td>0.329070</td>\n",
       "      <td>0.309140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.355200</td>\n",
       "      <td>1.420557</td>\n",
       "      <td>0.720440</td>\n",
       "      <td>0.347250</td>\n",
       "      <td>0.361208</td>\n",
       "      <td>0.337085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:44:51,731] Trial 68 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 69 with params: {'learning_rate': 0.0002158221755884315, 'weight_decay': 0.008, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:48 < 00:24, 7.16 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.605000</td>\n",
       "      <td>3.283001</td>\n",
       "      <td>0.183318</td>\n",
       "      <td>0.043561</td>\n",
       "      <td>0.021738</td>\n",
       "      <td>0.009359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.081000</td>\n",
       "      <td>2.828342</td>\n",
       "      <td>0.426214</td>\n",
       "      <td>0.103051</td>\n",
       "      <td>0.101138</td>\n",
       "      <td>0.077044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.675600</td>\n",
       "      <td>2.454337</td>\n",
       "      <td>0.497709</td>\n",
       "      <td>0.128102</td>\n",
       "      <td>0.139628</td>\n",
       "      <td>0.117036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.324300</td>\n",
       "      <td>2.166302</td>\n",
       "      <td>0.566453</td>\n",
       "      <td>0.222409</td>\n",
       "      <td>0.194732</td>\n",
       "      <td>0.179598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.064400</td>\n",
       "      <td>1.943241</td>\n",
       "      <td>0.622365</td>\n",
       "      <td>0.293238</td>\n",
       "      <td>0.244452</td>\n",
       "      <td>0.231625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.814600</td>\n",
       "      <td>1.765617</td>\n",
       "      <td>0.675527</td>\n",
       "      <td>0.344379</td>\n",
       "      <td>0.296665</td>\n",
       "      <td>0.289572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.623100</td>\n",
       "      <td>1.640222</td>\n",
       "      <td>0.694775</td>\n",
       "      <td>0.360978</td>\n",
       "      <td>0.315991</td>\n",
       "      <td>0.308408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.495000</td>\n",
       "      <td>1.549388</td>\n",
       "      <td>0.712191</td>\n",
       "      <td>0.371888</td>\n",
       "      <td>0.345028</td>\n",
       "      <td>0.331071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.370000</td>\n",
       "      <td>1.476985</td>\n",
       "      <td>0.711274</td>\n",
       "      <td>0.344996</td>\n",
       "      <td>0.345903</td>\n",
       "      <td>0.328344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.268300</td>\n",
       "      <td>1.424232</td>\n",
       "      <td>0.723190</td>\n",
       "      <td>0.362816</td>\n",
       "      <td>0.361583</td>\n",
       "      <td>0.344350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:45:41,247] Trial 69 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 70 with params: {'learning_rate': 0.000499752359065925, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.388800</td>\n",
       "      <td>2.849096</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.069468</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.075029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.509600</td>\n",
       "      <td>2.150357</td>\n",
       "      <td>0.561870</td>\n",
       "      <td>0.204292</td>\n",
       "      <td>0.204820</td>\n",
       "      <td>0.191348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.876200</td>\n",
       "      <td>1.678373</td>\n",
       "      <td>0.669111</td>\n",
       "      <td>0.314300</td>\n",
       "      <td>0.300366</td>\n",
       "      <td>0.282353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.430400</td>\n",
       "      <td>1.424935</td>\n",
       "      <td>0.707608</td>\n",
       "      <td>0.329694</td>\n",
       "      <td>0.329084</td>\n",
       "      <td>0.311705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.134400</td>\n",
       "      <td>1.302712</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.400878</td>\n",
       "      <td>0.391414</td>\n",
       "      <td>0.370880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.914900</td>\n",
       "      <td>1.194897</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.426857</td>\n",
       "      <td>0.397452</td>\n",
       "      <td>0.387732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.755800</td>\n",
       "      <td>1.156682</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.487391</td>\n",
       "      <td>0.444946</td>\n",
       "      <td>0.440355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.654500</td>\n",
       "      <td>1.114518</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.487756</td>\n",
       "      <td>0.468737</td>\n",
       "      <td>0.462510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.552600</td>\n",
       "      <td>1.068286</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.498596</td>\n",
       "      <td>0.478788</td>\n",
       "      <td>0.475435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.479400</td>\n",
       "      <td>1.070370</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.497727</td>\n",
       "      <td>0.473617</td>\n",
       "      <td>0.471398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.435900</td>\n",
       "      <td>1.039207</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.501639</td>\n",
       "      <td>0.487027</td>\n",
       "      <td>0.483321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.390200</td>\n",
       "      <td>1.028192</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.520900</td>\n",
       "      <td>0.488416</td>\n",
       "      <td>0.490805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>1.022897</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.498509</td>\n",
       "      <td>0.489324</td>\n",
       "      <td>0.483643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.339200</td>\n",
       "      <td>1.010601</td>\n",
       "      <td>0.779102</td>\n",
       "      <td>0.498343</td>\n",
       "      <td>0.489904</td>\n",
       "      <td>0.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.332700</td>\n",
       "      <td>1.012544</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.515419</td>\n",
       "      <td>0.489155</td>\n",
       "      <td>0.486192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:46:56,180] Trial 70 finished with value: 0.4861917323142149 and parameters: {'learning_rate': 0.000499752359065925, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 71 with params: {'learning_rate': 0.00046924068881510023, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:50 < 00:25, 6.84 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.408400</td>\n",
       "      <td>2.885947</td>\n",
       "      <td>0.411549</td>\n",
       "      <td>0.073970</td>\n",
       "      <td>0.092682</td>\n",
       "      <td>0.071857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.557100</td>\n",
       "      <td>2.202250</td>\n",
       "      <td>0.553621</td>\n",
       "      <td>0.195044</td>\n",
       "      <td>0.189851</td>\n",
       "      <td>0.176802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.940900</td>\n",
       "      <td>1.735910</td>\n",
       "      <td>0.659945</td>\n",
       "      <td>0.320783</td>\n",
       "      <td>0.294831</td>\n",
       "      <td>0.277903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.497100</td>\n",
       "      <td>1.470665</td>\n",
       "      <td>0.702108</td>\n",
       "      <td>0.319815</td>\n",
       "      <td>0.326341</td>\n",
       "      <td>0.308155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.200600</td>\n",
       "      <td>1.338844</td>\n",
       "      <td>0.734189</td>\n",
       "      <td>0.401674</td>\n",
       "      <td>0.398314</td>\n",
       "      <td>0.378957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.979200</td>\n",
       "      <td>1.217407</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.430110</td>\n",
       "      <td>0.402634</td>\n",
       "      <td>0.389384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.810100</td>\n",
       "      <td>1.173893</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.456922</td>\n",
       "      <td>0.434166</td>\n",
       "      <td>0.425318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.703600</td>\n",
       "      <td>1.136667</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.488319</td>\n",
       "      <td>0.462737</td>\n",
       "      <td>0.452773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.601100</td>\n",
       "      <td>1.090220</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.490264</td>\n",
       "      <td>0.469920</td>\n",
       "      <td>0.464268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.524000</td>\n",
       "      <td>1.084486</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.491458</td>\n",
       "      <td>0.474443</td>\n",
       "      <td>0.470855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:47:47,981] Trial 71 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 72 with params: {'learning_rate': 1.847006633877252e-05, 'weight_decay': 0.005, 'warmup_steps': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:47 < 00:24, 7.29 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.845700</td>\n",
       "      <td>3.783500</td>\n",
       "      <td>0.146654</td>\n",
       "      <td>0.009458</td>\n",
       "      <td>0.017793</td>\n",
       "      <td>0.008953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.754400</td>\n",
       "      <td>3.706388</td>\n",
       "      <td>0.183318</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>0.022178</td>\n",
       "      <td>0.009776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.696100</td>\n",
       "      <td>3.647616</td>\n",
       "      <td>0.182401</td>\n",
       "      <td>0.013587</td>\n",
       "      <td>0.021644</td>\n",
       "      <td>0.008907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.638300</td>\n",
       "      <td>3.597261</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>0.019944</td>\n",
       "      <td>0.022466</td>\n",
       "      <td>0.010360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.601300</td>\n",
       "      <td>3.547011</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.023564</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.550600</td>\n",
       "      <td>3.505750</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.023564</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.511200</td>\n",
       "      <td>3.468730</td>\n",
       "      <td>0.183318</td>\n",
       "      <td>0.023581</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>0.009574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.483200</td>\n",
       "      <td>3.437335</td>\n",
       "      <td>0.193401</td>\n",
       "      <td>0.063618</td>\n",
       "      <td>0.024801</td>\n",
       "      <td>0.014301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.453600</td>\n",
       "      <td>3.410389</td>\n",
       "      <td>0.208983</td>\n",
       "      <td>0.083687</td>\n",
       "      <td>0.029476</td>\n",
       "      <td>0.020556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.432700</td>\n",
       "      <td>3.387177</td>\n",
       "      <td>0.227314</td>\n",
       "      <td>0.076444</td>\n",
       "      <td>0.034892</td>\n",
       "      <td>0.028131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:48:36,721] Trial 72 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 73 with params: {'learning_rate': 6.1000955731656155e-05, 'weight_decay': 0.001, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:48, 7.24 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.780300</td>\n",
       "      <td>3.641916</td>\n",
       "      <td>0.177819</td>\n",
       "      <td>0.013545</td>\n",
       "      <td>0.020274</td>\n",
       "      <td>0.006555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.569700</td>\n",
       "      <td>3.460017</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023548</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.411100</td>\n",
       "      <td>3.296248</td>\n",
       "      <td>0.314390</td>\n",
       "      <td>0.071914</td>\n",
       "      <td>0.060545</td>\n",
       "      <td>0.052884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.255000</td>\n",
       "      <td>3.154732</td>\n",
       "      <td>0.396884</td>\n",
       "      <td>0.078753</td>\n",
       "      <td>0.085359</td>\n",
       "      <td>0.067347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.144700</td>\n",
       "      <td>3.032179</td>\n",
       "      <td>0.413382</td>\n",
       "      <td>0.095132</td>\n",
       "      <td>0.090343</td>\n",
       "      <td>0.069160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:49:01,720] Trial 73 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 74 with params: {'learning_rate': 0.0004889447518022103, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.395700</td>\n",
       "      <td>2.861760</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.070584</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.075237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.525200</td>\n",
       "      <td>2.167434</td>\n",
       "      <td>0.558203</td>\n",
       "      <td>0.203463</td>\n",
       "      <td>0.200698</td>\n",
       "      <td>0.187992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.898200</td>\n",
       "      <td>1.699468</td>\n",
       "      <td>0.662695</td>\n",
       "      <td>0.319027</td>\n",
       "      <td>0.298450</td>\n",
       "      <td>0.282462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.453600</td>\n",
       "      <td>1.440982</td>\n",
       "      <td>0.704858</td>\n",
       "      <td>0.338758</td>\n",
       "      <td>0.324326</td>\n",
       "      <td>0.307207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.158600</td>\n",
       "      <td>1.314555</td>\n",
       "      <td>0.738772</td>\n",
       "      <td>0.423432</td>\n",
       "      <td>0.396674</td>\n",
       "      <td>0.378628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.938900</td>\n",
       "      <td>1.203373</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.425223</td>\n",
       "      <td>0.397627</td>\n",
       "      <td>0.387535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.775300</td>\n",
       "      <td>1.163926</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.474008</td>\n",
       "      <td>0.440335</td>\n",
       "      <td>0.435657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.672400</td>\n",
       "      <td>1.121870</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.484038</td>\n",
       "      <td>0.463455</td>\n",
       "      <td>0.455290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>1.078430</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.492598</td>\n",
       "      <td>0.471580</td>\n",
       "      <td>0.467286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.495300</td>\n",
       "      <td>1.076767</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.498145</td>\n",
       "      <td>0.475278</td>\n",
       "      <td>0.472348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.451600</td>\n",
       "      <td>1.046470</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.500539</td>\n",
       "      <td>0.484193</td>\n",
       "      <td>0.481659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.404900</td>\n",
       "      <td>1.034132</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.505805</td>\n",
       "      <td>0.482398</td>\n",
       "      <td>0.482293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.373900</td>\n",
       "      <td>1.028181</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.523650</td>\n",
       "      <td>0.497090</td>\n",
       "      <td>0.495955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.353700</td>\n",
       "      <td>1.015585</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.519989</td>\n",
       "      <td>0.489761</td>\n",
       "      <td>0.490360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.347000</td>\n",
       "      <td>1.016887</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.521873</td>\n",
       "      <td>0.495129</td>\n",
       "      <td>0.493321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:50:16,266] Trial 74 finished with value: 0.4933209616956229 and parameters: {'learning_rate': 0.0004889447518022103, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 75 with params: {'learning_rate': 0.0004928703331115589, 'weight_decay': 0.008, 'warmup_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.380000</td>\n",
       "      <td>2.852261</td>\n",
       "      <td>0.417049</td>\n",
       "      <td>0.069731</td>\n",
       "      <td>0.096733</td>\n",
       "      <td>0.074754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.514700</td>\n",
       "      <td>2.166527</td>\n",
       "      <td>0.549038</td>\n",
       "      <td>0.231765</td>\n",
       "      <td>0.192074</td>\n",
       "      <td>0.181710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.896900</td>\n",
       "      <td>1.694638</td>\n",
       "      <td>0.665445</td>\n",
       "      <td>0.307226</td>\n",
       "      <td>0.291606</td>\n",
       "      <td>0.273776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.453000</td>\n",
       "      <td>1.434914</td>\n",
       "      <td>0.702108</td>\n",
       "      <td>0.328310</td>\n",
       "      <td>0.320984</td>\n",
       "      <td>0.300324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>1.304522</td>\n",
       "      <td>0.730522</td>\n",
       "      <td>0.376182</td>\n",
       "      <td>0.377190</td>\n",
       "      <td>0.352480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.934700</td>\n",
       "      <td>1.189385</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.443533</td>\n",
       "      <td>0.413966</td>\n",
       "      <td>0.403542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.768400</td>\n",
       "      <td>1.145531</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.456314</td>\n",
       "      <td>0.450053</td>\n",
       "      <td>0.438244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.664900</td>\n",
       "      <td>1.106858</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.469371</td>\n",
       "      <td>0.460728</td>\n",
       "      <td>0.449860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.566700</td>\n",
       "      <td>1.060932</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.472848</td>\n",
       "      <td>0.474304</td>\n",
       "      <td>0.464740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.491800</td>\n",
       "      <td>1.058014</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.485481</td>\n",
       "      <td>0.486312</td>\n",
       "      <td>0.475860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.446300</td>\n",
       "      <td>1.039222</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.482873</td>\n",
       "      <td>0.482408</td>\n",
       "      <td>0.475094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.400400</td>\n",
       "      <td>1.031537</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.489183</td>\n",
       "      <td>0.478151</td>\n",
       "      <td>0.474094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.370100</td>\n",
       "      <td>1.023470</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.494938</td>\n",
       "      <td>0.491456</td>\n",
       "      <td>0.483395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.346900</td>\n",
       "      <td>1.007912</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.488545</td>\n",
       "      <td>0.485889</td>\n",
       "      <td>0.478708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.340300</td>\n",
       "      <td>1.011836</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.490141</td>\n",
       "      <td>0.493618</td>\n",
       "      <td>0.484722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:51:32,665] Trial 75 finished with value: 0.48472228234703374 and parameters: {'learning_rate': 0.0004928703331115589, 'weight_decay': 0.008, 'warmup_steps': 3}. Best is trial 21 with value: 0.4941557351757956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 76 with params: {'learning_rate': 0.00047612995586855563, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.403900</td>\n",
       "      <td>2.877421</td>\n",
       "      <td>0.414299</td>\n",
       "      <td>0.073256</td>\n",
       "      <td>0.094210</td>\n",
       "      <td>0.073154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.545700</td>\n",
       "      <td>2.189941</td>\n",
       "      <td>0.557287</td>\n",
       "      <td>0.204342</td>\n",
       "      <td>0.201261</td>\n",
       "      <td>0.189003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.925800</td>\n",
       "      <td>1.723883</td>\n",
       "      <td>0.660862</td>\n",
       "      <td>0.324082</td>\n",
       "      <td>0.294254</td>\n",
       "      <td>0.276990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.481400</td>\n",
       "      <td>1.459874</td>\n",
       "      <td>0.703941</td>\n",
       "      <td>0.320664</td>\n",
       "      <td>0.327614</td>\n",
       "      <td>0.309269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.185800</td>\n",
       "      <td>1.330277</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.422646</td>\n",
       "      <td>0.393965</td>\n",
       "      <td>0.374772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.965200</td>\n",
       "      <td>1.212445</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.425314</td>\n",
       "      <td>0.403998</td>\n",
       "      <td>0.391065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.798000</td>\n",
       "      <td>1.169914</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.470136</td>\n",
       "      <td>0.430892</td>\n",
       "      <td>0.425342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.692700</td>\n",
       "      <td>1.132273</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.485332</td>\n",
       "      <td>0.465679</td>\n",
       "      <td>0.455927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.589900</td>\n",
       "      <td>1.086637</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.491568</td>\n",
       "      <td>0.469453</td>\n",
       "      <td>0.464948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.513700</td>\n",
       "      <td>1.082238</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.486008</td>\n",
       "      <td>0.475073</td>\n",
       "      <td>0.470392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.470600</td>\n",
       "      <td>1.052893</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.501584</td>\n",
       "      <td>0.484519</td>\n",
       "      <td>0.481798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.421900</td>\n",
       "      <td>1.040129</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.496816</td>\n",
       "      <td>0.482162</td>\n",
       "      <td>0.478685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.391300</td>\n",
       "      <td>1.033185</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.517530</td>\n",
       "      <td>0.492831</td>\n",
       "      <td>0.493583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.370700</td>\n",
       "      <td>1.021294</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.518889</td>\n",
       "      <td>0.487776</td>\n",
       "      <td>0.488651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.363800</td>\n",
       "      <td>1.021823</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.523183</td>\n",
       "      <td>0.494659</td>\n",
       "      <td>0.495126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:52:47,859] Trial 76 finished with value: 0.49512573819371475 and parameters: {'learning_rate': 0.00047612995586855563, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 76 with value: 0.49512573819371475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 77 with params: {'learning_rate': 0.0001975196754254445, 'weight_decay': 0.01, 'warmup_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:24 < 00:49, 7.09 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.614900</td>\n",
       "      <td>3.310712</td>\n",
       "      <td>0.178735</td>\n",
       "      <td>0.023545</td>\n",
       "      <td>0.020476</td>\n",
       "      <td>0.006952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.121600</td>\n",
       "      <td>2.881856</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.085610</td>\n",
       "      <td>0.096896</td>\n",
       "      <td>0.073722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.740200</td>\n",
       "      <td>2.524101</td>\n",
       "      <td>0.486709</td>\n",
       "      <td>0.127296</td>\n",
       "      <td>0.132943</td>\n",
       "      <td>0.110068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.404200</td>\n",
       "      <td>2.245338</td>\n",
       "      <td>0.556370</td>\n",
       "      <td>0.206678</td>\n",
       "      <td>0.183870</td>\n",
       "      <td>0.169196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.156700</td>\n",
       "      <td>2.026995</td>\n",
       "      <td>0.605866</td>\n",
       "      <td>0.293097</td>\n",
       "      <td>0.227978</td>\n",
       "      <td>0.217181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:53:13,275] Trial 77 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 78 with params: {'learning_rate': 0.0002253508677540182, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:47, 7.31 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.596200</td>\n",
       "      <td>3.265530</td>\n",
       "      <td>0.196150</td>\n",
       "      <td>0.038621</td>\n",
       "      <td>0.025323</td>\n",
       "      <td>0.015322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.057000</td>\n",
       "      <td>2.797117</td>\n",
       "      <td>0.430797</td>\n",
       "      <td>0.102147</td>\n",
       "      <td>0.103415</td>\n",
       "      <td>0.077735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.639600</td>\n",
       "      <td>2.416522</td>\n",
       "      <td>0.500458</td>\n",
       "      <td>0.136230</td>\n",
       "      <td>0.140910</td>\n",
       "      <td>0.118284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.281900</td>\n",
       "      <td>2.125012</td>\n",
       "      <td>0.572869</td>\n",
       "      <td>0.223192</td>\n",
       "      <td>0.198138</td>\n",
       "      <td>0.183374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.016400</td>\n",
       "      <td>1.900874</td>\n",
       "      <td>0.637030</td>\n",
       "      <td>0.319819</td>\n",
       "      <td>0.263962</td>\n",
       "      <td>0.252040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:53:38,690] Trial 78 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 79 with params: {'learning_rate': 0.0002478881905648277, 'weight_decay': 0.008, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:47 < 00:23, 7.35 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.575400</td>\n",
       "      <td>3.225302</td>\n",
       "      <td>0.244730</td>\n",
       "      <td>0.058259</td>\n",
       "      <td>0.039431</td>\n",
       "      <td>0.032436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.000600</td>\n",
       "      <td>2.723456</td>\n",
       "      <td>0.445463</td>\n",
       "      <td>0.102622</td>\n",
       "      <td>0.111929</td>\n",
       "      <td>0.083752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.554600</td>\n",
       "      <td>2.325396</td>\n",
       "      <td>0.515124</td>\n",
       "      <td>0.157747</td>\n",
       "      <td>0.152720</td>\n",
       "      <td>0.133250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.180100</td>\n",
       "      <td>2.027538</td>\n",
       "      <td>0.604033</td>\n",
       "      <td>0.263806</td>\n",
       "      <td>0.229246</td>\n",
       "      <td>0.213411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.902500</td>\n",
       "      <td>1.802718</td>\n",
       "      <td>0.671861</td>\n",
       "      <td>0.340285</td>\n",
       "      <td>0.296111</td>\n",
       "      <td>0.288280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.648300</td>\n",
       "      <td>1.628891</td>\n",
       "      <td>0.699358</td>\n",
       "      <td>0.376841</td>\n",
       "      <td>0.321876</td>\n",
       "      <td>0.314342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.452000</td>\n",
       "      <td>1.510914</td>\n",
       "      <td>0.706691</td>\n",
       "      <td>0.343911</td>\n",
       "      <td>0.328322</td>\n",
       "      <td>0.314353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.324300</td>\n",
       "      <td>1.430447</td>\n",
       "      <td>0.725940</td>\n",
       "      <td>0.350905</td>\n",
       "      <td>0.359051</td>\n",
       "      <td>0.338152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.202700</td>\n",
       "      <td>1.367634</td>\n",
       "      <td>0.729606</td>\n",
       "      <td>0.356541</td>\n",
       "      <td>0.367877</td>\n",
       "      <td>0.348622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.102400</td>\n",
       "      <td>1.325800</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.409806</td>\n",
       "      <td>0.396251</td>\n",
       "      <td>0.379899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:54:26,982] Trial 79 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 80 with params: {'learning_rate': 0.0004997002486542191, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:50 < 00:25, 6.88 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.388900</td>\n",
       "      <td>2.849130</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.069600</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.075105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.509700</td>\n",
       "      <td>2.150355</td>\n",
       "      <td>0.561870</td>\n",
       "      <td>0.204292</td>\n",
       "      <td>0.204820</td>\n",
       "      <td>0.191348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.876300</td>\n",
       "      <td>1.678547</td>\n",
       "      <td>0.669111</td>\n",
       "      <td>0.314499</td>\n",
       "      <td>0.300366</td>\n",
       "      <td>0.282516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.430500</td>\n",
       "      <td>1.424955</td>\n",
       "      <td>0.706691</td>\n",
       "      <td>0.327956</td>\n",
       "      <td>0.327655</td>\n",
       "      <td>0.309689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.134500</td>\n",
       "      <td>1.302668</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.401640</td>\n",
       "      <td>0.391414</td>\n",
       "      <td>0.371554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>1.194955</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.427181</td>\n",
       "      <td>0.397452</td>\n",
       "      <td>0.387904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.755800</td>\n",
       "      <td>1.156766</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.487208</td>\n",
       "      <td>0.444946</td>\n",
       "      <td>0.440245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.654500</td>\n",
       "      <td>1.114794</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.487756</td>\n",
       "      <td>0.468737</td>\n",
       "      <td>0.462510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.552600</td>\n",
       "      <td>1.068362</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.498771</td>\n",
       "      <td>0.479003</td>\n",
       "      <td>0.475639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.479500</td>\n",
       "      <td>1.070223</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.497727</td>\n",
       "      <td>0.473617</td>\n",
       "      <td>0.471398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:55:18,498] Trial 80 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 81 with params: {'learning_rate': 0.000466748580049297, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.410000</td>\n",
       "      <td>2.889289</td>\n",
       "      <td>0.411549</td>\n",
       "      <td>0.073974</td>\n",
       "      <td>0.092682</td>\n",
       "      <td>0.071863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.561200</td>\n",
       "      <td>2.206781</td>\n",
       "      <td>0.551787</td>\n",
       "      <td>0.194310</td>\n",
       "      <td>0.187086</td>\n",
       "      <td>0.173253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.946200</td>\n",
       "      <td>1.740095</td>\n",
       "      <td>0.659945</td>\n",
       "      <td>0.320518</td>\n",
       "      <td>0.295417</td>\n",
       "      <td>0.278389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.502800</td>\n",
       "      <td>1.474415</td>\n",
       "      <td>0.702108</td>\n",
       "      <td>0.319498</td>\n",
       "      <td>0.326341</td>\n",
       "      <td>0.307896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.205500</td>\n",
       "      <td>1.341983</td>\n",
       "      <td>0.734189</td>\n",
       "      <td>0.401962</td>\n",
       "      <td>0.397139</td>\n",
       "      <td>0.378488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.983700</td>\n",
       "      <td>1.219099</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.430472</td>\n",
       "      <td>0.402634</td>\n",
       "      <td>0.389645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.814300</td>\n",
       "      <td>1.175585</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.461115</td>\n",
       "      <td>0.432348</td>\n",
       "      <td>0.425122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.707200</td>\n",
       "      <td>1.138255</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.488391</td>\n",
       "      <td>0.462737</td>\n",
       "      <td>0.452831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.604900</td>\n",
       "      <td>1.090913</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.489955</td>\n",
       "      <td>0.469795</td>\n",
       "      <td>0.464082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.527600</td>\n",
       "      <td>1.085286</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.492305</td>\n",
       "      <td>0.475982</td>\n",
       "      <td>0.471981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.484900</td>\n",
       "      <td>1.056118</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.497329</td>\n",
       "      <td>0.478162</td>\n",
       "      <td>0.475639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.434600</td>\n",
       "      <td>1.043948</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.495618</td>\n",
       "      <td>0.483176</td>\n",
       "      <td>0.478949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.404400</td>\n",
       "      <td>1.035867</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.515594</td>\n",
       "      <td>0.493650</td>\n",
       "      <td>0.492612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.383200</td>\n",
       "      <td>1.024897</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.523337</td>\n",
       "      <td>0.492963</td>\n",
       "      <td>0.493477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.376400</td>\n",
       "      <td>1.025084</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.517775</td>\n",
       "      <td>0.495022</td>\n",
       "      <td>0.494731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:56:32,574] Trial 81 finished with value: 0.4947309199146923 and parameters: {'learning_rate': 0.000466748580049297, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 76 with value: 0.49512573819371475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 82 with params: {'learning_rate': 0.0004583601020505076, 'weight_decay': 0.01, 'warmup_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.402900</td>\n",
       "      <td>2.896107</td>\n",
       "      <td>0.407883</td>\n",
       "      <td>0.073533</td>\n",
       "      <td>0.093167</td>\n",
       "      <td>0.072746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.571700</td>\n",
       "      <td>2.224407</td>\n",
       "      <td>0.532539</td>\n",
       "      <td>0.199160</td>\n",
       "      <td>0.170892</td>\n",
       "      <td>0.155785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.967900</td>\n",
       "      <td>1.749473</td>\n",
       "      <td>0.659945</td>\n",
       "      <td>0.313153</td>\n",
       "      <td>0.281316</td>\n",
       "      <td>0.263723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.526400</td>\n",
       "      <td>1.491183</td>\n",
       "      <td>0.702108</td>\n",
       "      <td>0.337994</td>\n",
       "      <td>0.333765</td>\n",
       "      <td>0.312175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.220200</td>\n",
       "      <td>1.344835</td>\n",
       "      <td>0.725023</td>\n",
       "      <td>0.371987</td>\n",
       "      <td>0.367861</td>\n",
       "      <td>0.343281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>1.212319</td>\n",
       "      <td>0.739688</td>\n",
       "      <td>0.444000</td>\n",
       "      <td>0.389216</td>\n",
       "      <td>0.379435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.828800</td>\n",
       "      <td>1.158887</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.441145</td>\n",
       "      <td>0.436871</td>\n",
       "      <td>0.426104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.721000</td>\n",
       "      <td>1.122881</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.458494</td>\n",
       "      <td>0.455102</td>\n",
       "      <td>0.441611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.618900</td>\n",
       "      <td>1.077683</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.487437</td>\n",
       "      <td>0.475063</td>\n",
       "      <td>0.469269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.542200</td>\n",
       "      <td>1.077562</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.483769</td>\n",
       "      <td>0.485327</td>\n",
       "      <td>0.474976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.496200</td>\n",
       "      <td>1.048331</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.482248</td>\n",
       "      <td>0.486197</td>\n",
       "      <td>0.476931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.445100</td>\n",
       "      <td>1.039455</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.490538</td>\n",
       "      <td>0.481434</td>\n",
       "      <td>0.476649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.414100</td>\n",
       "      <td>1.031153</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.489906</td>\n",
       "      <td>0.486972</td>\n",
       "      <td>0.479399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.392200</td>\n",
       "      <td>1.014628</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.493022</td>\n",
       "      <td>0.489444</td>\n",
       "      <td>0.481732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.385300</td>\n",
       "      <td>1.017627</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.488800</td>\n",
       "      <td>0.489410</td>\n",
       "      <td>0.479419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:57:48,460] Trial 82 finished with value: 0.4794185783682232 and parameters: {'learning_rate': 0.0004583601020505076, 'weight_decay': 0.01, 'warmup_steps': 3}. Best is trial 76 with value: 0.49512573819371475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 83 with params: {'learning_rate': 0.00045585643905809184, 'weight_decay': 0.008, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:25, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.417400</td>\n",
       "      <td>2.903936</td>\n",
       "      <td>0.406049</td>\n",
       "      <td>0.074713</td>\n",
       "      <td>0.089241</td>\n",
       "      <td>0.067467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.579400</td>\n",
       "      <td>2.226751</td>\n",
       "      <td>0.541705</td>\n",
       "      <td>0.193688</td>\n",
       "      <td>0.178567</td>\n",
       "      <td>0.166292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.968900</td>\n",
       "      <td>1.757299</td>\n",
       "      <td>0.654445</td>\n",
       "      <td>0.318970</td>\n",
       "      <td>0.287166</td>\n",
       "      <td>0.271381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.527300</td>\n",
       "      <td>1.491902</td>\n",
       "      <td>0.699358</td>\n",
       "      <td>0.314411</td>\n",
       "      <td>0.320528</td>\n",
       "      <td>0.301436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.227200</td>\n",
       "      <td>1.355674</td>\n",
       "      <td>0.731439</td>\n",
       "      <td>0.408282</td>\n",
       "      <td>0.394035</td>\n",
       "      <td>0.375608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.004200</td>\n",
       "      <td>1.226498</td>\n",
       "      <td>0.744271</td>\n",
       "      <td>0.431878</td>\n",
       "      <td>0.394476</td>\n",
       "      <td>0.381225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.833700</td>\n",
       "      <td>1.180923</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.472098</td>\n",
       "      <td>0.434703</td>\n",
       "      <td>0.427843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.724700</td>\n",
       "      <td>1.140689</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.476231</td>\n",
       "      <td>0.460967</td>\n",
       "      <td>0.449176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.622600</td>\n",
       "      <td>1.091231</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.472394</td>\n",
       "      <td>0.470458</td>\n",
       "      <td>0.460487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.544600</td>\n",
       "      <td>1.085639</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.494717</td>\n",
       "      <td>0.475001</td>\n",
       "      <td>0.470708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.502800</td>\n",
       "      <td>1.057282</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.490247</td>\n",
       "      <td>0.479188</td>\n",
       "      <td>0.475751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.449600</td>\n",
       "      <td>1.044520</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.496103</td>\n",
       "      <td>0.478790</td>\n",
       "      <td>0.475077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.419800</td>\n",
       "      <td>1.035894</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.490522</td>\n",
       "      <td>0.483736</td>\n",
       "      <td>0.479699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.397900</td>\n",
       "      <td>1.024934</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.505880</td>\n",
       "      <td>0.486246</td>\n",
       "      <td>0.485242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.391400</td>\n",
       "      <td>1.024742</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.495330</td>\n",
       "      <td>0.488945</td>\n",
       "      <td>0.483287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 09:59:15,378] Trial 83 finished with value: 0.4832865107939125 and parameters: {'learning_rate': 0.00045585643905809184, 'weight_decay': 0.008, 'warmup_steps': 4}. Best is trial 76 with value: 0.49512573819371475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 84 with params: {'learning_rate': 0.00047960083104339106, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:17, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.401600</td>\n",
       "      <td>2.873136</td>\n",
       "      <td>0.416132</td>\n",
       "      <td>0.073138</td>\n",
       "      <td>0.095070</td>\n",
       "      <td>0.073870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.539900</td>\n",
       "      <td>2.183604</td>\n",
       "      <td>0.557287</td>\n",
       "      <td>0.204342</td>\n",
       "      <td>0.201261</td>\n",
       "      <td>0.189003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.918200</td>\n",
       "      <td>1.717427</td>\n",
       "      <td>0.661778</td>\n",
       "      <td>0.318419</td>\n",
       "      <td>0.295682</td>\n",
       "      <td>0.278669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.473700</td>\n",
       "      <td>1.454749</td>\n",
       "      <td>0.704858</td>\n",
       "      <td>0.324502</td>\n",
       "      <td>0.330114</td>\n",
       "      <td>0.310749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.178400</td>\n",
       "      <td>1.325935</td>\n",
       "      <td>0.736939</td>\n",
       "      <td>0.422487</td>\n",
       "      <td>0.394329</td>\n",
       "      <td>0.375017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.958400</td>\n",
       "      <td>1.210055</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.423347</td>\n",
       "      <td>0.403472</td>\n",
       "      <td>0.390249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.791900</td>\n",
       "      <td>1.168174</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.472172</td>\n",
       "      <td>0.433233</td>\n",
       "      <td>0.427990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.687300</td>\n",
       "      <td>1.129322</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.484358</td>\n",
       "      <td>0.463909</td>\n",
       "      <td>0.454785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.584500</td>\n",
       "      <td>1.084709</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.491341</td>\n",
       "      <td>0.470474</td>\n",
       "      <td>0.466041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.508700</td>\n",
       "      <td>1.080993</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.495176</td>\n",
       "      <td>0.479843</td>\n",
       "      <td>0.474416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.465500</td>\n",
       "      <td>1.051301</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.502550</td>\n",
       "      <td>0.483816</td>\n",
       "      <td>0.481883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.417200</td>\n",
       "      <td>1.038515</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.504270</td>\n",
       "      <td>0.482689</td>\n",
       "      <td>0.481880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.386500</td>\n",
       "      <td>1.032146</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.517530</td>\n",
       "      <td>0.492831</td>\n",
       "      <td>0.493583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.366100</td>\n",
       "      <td>1.019794</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.522480</td>\n",
       "      <td>0.492684</td>\n",
       "      <td>0.493222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.359300</td>\n",
       "      <td>1.020687</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.522190</td>\n",
       "      <td>0.493769</td>\n",
       "      <td>0.494156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:00:33,949] Trial 84 finished with value: 0.4941557351757956 and parameters: {'learning_rate': 0.00047960083104339106, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 76 with value: 0.49512573819371475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 85 with params: {'learning_rate': 0.0004504462285923686, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:20, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.421100</td>\n",
       "      <td>2.911146</td>\n",
       "      <td>0.404216</td>\n",
       "      <td>0.074356</td>\n",
       "      <td>0.088787</td>\n",
       "      <td>0.067151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.588900</td>\n",
       "      <td>2.236980</td>\n",
       "      <td>0.535289</td>\n",
       "      <td>0.191229</td>\n",
       "      <td>0.170344</td>\n",
       "      <td>0.155340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.980400</td>\n",
       "      <td>1.766363</td>\n",
       "      <td>0.653529</td>\n",
       "      <td>0.317197</td>\n",
       "      <td>0.285500</td>\n",
       "      <td>0.269348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.539900</td>\n",
       "      <td>1.501110</td>\n",
       "      <td>0.699358</td>\n",
       "      <td>0.319177</td>\n",
       "      <td>0.330074</td>\n",
       "      <td>0.310083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.238500</td>\n",
       "      <td>1.362696</td>\n",
       "      <td>0.732356</td>\n",
       "      <td>0.410145</td>\n",
       "      <td>0.393547</td>\n",
       "      <td>0.375603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.015200</td>\n",
       "      <td>1.230260</td>\n",
       "      <td>0.744271</td>\n",
       "      <td>0.427764</td>\n",
       "      <td>0.392761</td>\n",
       "      <td>0.377585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>1.184253</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.468781</td>\n",
       "      <td>0.434866</td>\n",
       "      <td>0.427943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.734500</td>\n",
       "      <td>1.142835</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.478426</td>\n",
       "      <td>0.461316</td>\n",
       "      <td>0.450820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.632600</td>\n",
       "      <td>1.093915</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.473476</td>\n",
       "      <td>0.471586</td>\n",
       "      <td>0.461711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.553900</td>\n",
       "      <td>1.087768</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.488837</td>\n",
       "      <td>0.475105</td>\n",
       "      <td>0.468451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.511900</td>\n",
       "      <td>1.059327</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.488350</td>\n",
       "      <td>0.478618</td>\n",
       "      <td>0.474579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.458200</td>\n",
       "      <td>1.046228</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.498033</td>\n",
       "      <td>0.479412</td>\n",
       "      <td>0.476464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.428100</td>\n",
       "      <td>1.037219</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.494904</td>\n",
       "      <td>0.483723</td>\n",
       "      <td>0.480449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.406400</td>\n",
       "      <td>1.025635</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.507107</td>\n",
       "      <td>0.485958</td>\n",
       "      <td>0.485319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.399700</td>\n",
       "      <td>1.025522</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.495350</td>\n",
       "      <td>0.487804</td>\n",
       "      <td>0.482954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:01:55,588] Trial 85 finished with value: 0.48295363502244654 and parameters: {'learning_rate': 0.0004504462285923686, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 76 with value: 0.49512573819371475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 86 with params: {'learning_rate': 4.0534446710776905e-05, 'weight_decay': 0.01, 'warmup_steps': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:26 < 00:53, 6.53 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.804800</td>\n",
       "      <td>3.697174</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>0.012607</td>\n",
       "      <td>0.022466</td>\n",
       "      <td>0.009983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.647600</td>\n",
       "      <td>3.568282</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.023551</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.537700</td>\n",
       "      <td>3.452966</td>\n",
       "      <td>0.181485</td>\n",
       "      <td>0.023554</td>\n",
       "      <td>0.021370</td>\n",
       "      <td>0.008600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.426200</td>\n",
       "      <td>3.348852</td>\n",
       "      <td>0.274977</td>\n",
       "      <td>0.075659</td>\n",
       "      <td>0.049545</td>\n",
       "      <td>0.043865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.347700</td>\n",
       "      <td>3.256502</td>\n",
       "      <td>0.358387</td>\n",
       "      <td>0.069593</td>\n",
       "      <td>0.074302</td>\n",
       "      <td>0.062718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:02:23,043] Trial 86 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 87 with params: {'learning_rate': 0.00020640839054860755, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:48 < 00:24, 7.12 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.613800</td>\n",
       "      <td>3.300375</td>\n",
       "      <td>0.178735</td>\n",
       "      <td>0.023545</td>\n",
       "      <td>0.020476</td>\n",
       "      <td>0.006952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.104700</td>\n",
       "      <td>2.858563</td>\n",
       "      <td>0.423465</td>\n",
       "      <td>0.083463</td>\n",
       "      <td>0.099158</td>\n",
       "      <td>0.074432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.710800</td>\n",
       "      <td>2.491558</td>\n",
       "      <td>0.493126</td>\n",
       "      <td>0.129101</td>\n",
       "      <td>0.136966</td>\n",
       "      <td>0.114938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.366400</td>\n",
       "      <td>2.207397</td>\n",
       "      <td>0.560037</td>\n",
       "      <td>0.205071</td>\n",
       "      <td>0.187686</td>\n",
       "      <td>0.172887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.112000</td>\n",
       "      <td>1.985918</td>\n",
       "      <td>0.613199</td>\n",
       "      <td>0.281450</td>\n",
       "      <td>0.234254</td>\n",
       "      <td>0.221572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>1.809112</td>\n",
       "      <td>0.664528</td>\n",
       "      <td>0.295206</td>\n",
       "      <td>0.275176</td>\n",
       "      <td>0.262563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.675700</td>\n",
       "      <td>1.682260</td>\n",
       "      <td>0.686526</td>\n",
       "      <td>0.360895</td>\n",
       "      <td>0.308964</td>\n",
       "      <td>0.302828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.547000</td>\n",
       "      <td>1.587507</td>\n",
       "      <td>0.705775</td>\n",
       "      <td>0.373479</td>\n",
       "      <td>0.337236</td>\n",
       "      <td>0.327508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.420300</td>\n",
       "      <td>1.512000</td>\n",
       "      <td>0.710357</td>\n",
       "      <td>0.342735</td>\n",
       "      <td>0.332686</td>\n",
       "      <td>0.316991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.319000</td>\n",
       "      <td>1.457126</td>\n",
       "      <td>0.718607</td>\n",
       "      <td>0.355360</td>\n",
       "      <td>0.347352</td>\n",
       "      <td>0.330168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:03:12,893] Trial 87 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 88 with params: {'learning_rate': 7.076325261453758e-05, 'weight_decay': 0.004, 'warmup_steps': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:49 < 00:24, 7.05 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.759100</td>\n",
       "      <td>3.609309</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.526600</td>\n",
       "      <td>3.404759</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>0.043567</td>\n",
       "      <td>0.022394</td>\n",
       "      <td>0.010485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.348300</td>\n",
       "      <td>3.223050</td>\n",
       "      <td>0.362053</td>\n",
       "      <td>0.063667</td>\n",
       "      <td>0.074947</td>\n",
       "      <td>0.060811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.175500</td>\n",
       "      <td>3.067666</td>\n",
       "      <td>0.407883</td>\n",
       "      <td>0.074791</td>\n",
       "      <td>0.087895</td>\n",
       "      <td>0.066215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.052300</td>\n",
       "      <td>2.931618</td>\n",
       "      <td>0.431714</td>\n",
       "      <td>0.089597</td>\n",
       "      <td>0.100075</td>\n",
       "      <td>0.080149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.912300</td>\n",
       "      <td>2.817206</td>\n",
       "      <td>0.447296</td>\n",
       "      <td>0.084184</td>\n",
       "      <td>0.108399</td>\n",
       "      <td>0.084182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.801100</td>\n",
       "      <td>2.722059</td>\n",
       "      <td>0.457379</td>\n",
       "      <td>0.104357</td>\n",
       "      <td>0.113237</td>\n",
       "      <td>0.088294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.722900</td>\n",
       "      <td>2.638457</td>\n",
       "      <td>0.476627</td>\n",
       "      <td>0.103610</td>\n",
       "      <td>0.125860</td>\n",
       "      <td>0.100681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.636500</td>\n",
       "      <td>2.567607</td>\n",
       "      <td>0.484876</td>\n",
       "      <td>0.103677</td>\n",
       "      <td>0.128491</td>\n",
       "      <td>0.102569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.571700</td>\n",
       "      <td>2.511946</td>\n",
       "      <td>0.501375</td>\n",
       "      <td>0.126735</td>\n",
       "      <td>0.139712</td>\n",
       "      <td>0.115057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:04:03,306] Trial 88 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 89 with params: {'learning_rate': 0.0004894091180005273, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:49 < 00:24, 7.07 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.395400</td>\n",
       "      <td>2.861219</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.070584</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.075237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.524400</td>\n",
       "      <td>2.166587</td>\n",
       "      <td>0.558203</td>\n",
       "      <td>0.203576</td>\n",
       "      <td>0.200698</td>\n",
       "      <td>0.188060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.897200</td>\n",
       "      <td>1.698675</td>\n",
       "      <td>0.662695</td>\n",
       "      <td>0.319027</td>\n",
       "      <td>0.298450</td>\n",
       "      <td>0.282462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.452700</td>\n",
       "      <td>1.440380</td>\n",
       "      <td>0.704858</td>\n",
       "      <td>0.338667</td>\n",
       "      <td>0.324326</td>\n",
       "      <td>0.307210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.157600</td>\n",
       "      <td>1.314144</td>\n",
       "      <td>0.738772</td>\n",
       "      <td>0.423122</td>\n",
       "      <td>0.396674</td>\n",
       "      <td>0.378488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.938000</td>\n",
       "      <td>1.203286</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.425223</td>\n",
       "      <td>0.397627</td>\n",
       "      <td>0.387535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.774500</td>\n",
       "      <td>1.163654</td>\n",
       "      <td>0.747938</td>\n",
       "      <td>0.473494</td>\n",
       "      <td>0.437478</td>\n",
       "      <td>0.431398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.671700</td>\n",
       "      <td>1.121604</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.484449</td>\n",
       "      <td>0.463455</td>\n",
       "      <td>0.455722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.569200</td>\n",
       "      <td>1.078324</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.492598</td>\n",
       "      <td>0.471580</td>\n",
       "      <td>0.467286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.494600</td>\n",
       "      <td>1.076611</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.498016</td>\n",
       "      <td>0.475278</td>\n",
       "      <td>0.472287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:04:53,648] Trial 89 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 90 with params: {'learning_rate': 0.0004741937479140062, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:47 < 00:23, 7.32 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.405100</td>\n",
       "      <td>2.879817</td>\n",
       "      <td>0.413382</td>\n",
       "      <td>0.073578</td>\n",
       "      <td>0.093565</td>\n",
       "      <td>0.072541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.548900</td>\n",
       "      <td>2.193315</td>\n",
       "      <td>0.557287</td>\n",
       "      <td>0.195008</td>\n",
       "      <td>0.193816</td>\n",
       "      <td>0.179808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.930100</td>\n",
       "      <td>1.727408</td>\n",
       "      <td>0.660862</td>\n",
       "      <td>0.323667</td>\n",
       "      <td>0.295319</td>\n",
       "      <td>0.278259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.485800</td>\n",
       "      <td>1.462934</td>\n",
       "      <td>0.703025</td>\n",
       "      <td>0.320021</td>\n",
       "      <td>0.326705</td>\n",
       "      <td>0.308551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.190000</td>\n",
       "      <td>1.332866</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.422670</td>\n",
       "      <td>0.393965</td>\n",
       "      <td>0.374813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.969400</td>\n",
       "      <td>1.214021</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.429682</td>\n",
       "      <td>0.402180</td>\n",
       "      <td>0.388804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.801500</td>\n",
       "      <td>1.170931</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.457095</td>\n",
       "      <td>0.428022</td>\n",
       "      <td>0.418655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.695800</td>\n",
       "      <td>1.133717</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.484291</td>\n",
       "      <td>0.464225</td>\n",
       "      <td>0.454470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.593100</td>\n",
       "      <td>1.087570</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.491887</td>\n",
       "      <td>0.469557</td>\n",
       "      <td>0.465154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.516600</td>\n",
       "      <td>1.082722</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.485781</td>\n",
       "      <td>0.474547</td>\n",
       "      <td>0.469967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:05:42,236] Trial 90 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 91 with params: {'learning_rate': 0.0004949145994118729, 'weight_decay': 0.009000000000000001, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.391900</td>\n",
       "      <td>2.854751</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.069485</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.074950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.516400</td>\n",
       "      <td>2.157598</td>\n",
       "      <td>0.560037</td>\n",
       "      <td>0.204309</td>\n",
       "      <td>0.204150</td>\n",
       "      <td>0.190990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.885800</td>\n",
       "      <td>1.687967</td>\n",
       "      <td>0.665445</td>\n",
       "      <td>0.318400</td>\n",
       "      <td>0.299700</td>\n",
       "      <td>0.283232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.440800</td>\n",
       "      <td>1.432213</td>\n",
       "      <td>0.704858</td>\n",
       "      <td>0.339763</td>\n",
       "      <td>0.325688</td>\n",
       "      <td>0.308979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.145500</td>\n",
       "      <td>1.307761</td>\n",
       "      <td>0.736939</td>\n",
       "      <td>0.402636</td>\n",
       "      <td>0.393936</td>\n",
       "      <td>0.373109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.926000</td>\n",
       "      <td>1.199835</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.425949</td>\n",
       "      <td>0.397978</td>\n",
       "      <td>0.388294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.764300</td>\n",
       "      <td>1.160894</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.466242</td>\n",
       "      <td>0.441683</td>\n",
       "      <td>0.434849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.662600</td>\n",
       "      <td>1.117915</td>\n",
       "      <td>0.757104</td>\n",
       "      <td>0.484411</td>\n",
       "      <td>0.468762</td>\n",
       "      <td>0.460839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.560300</td>\n",
       "      <td>1.074147</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.497215</td>\n",
       "      <td>0.476068</td>\n",
       "      <td>0.471717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.486600</td>\n",
       "      <td>1.074198</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.498869</td>\n",
       "      <td>0.475278</td>\n",
       "      <td>0.472714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.442700</td>\n",
       "      <td>1.042876</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.500836</td>\n",
       "      <td>0.485028</td>\n",
       "      <td>0.482313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.396700</td>\n",
       "      <td>1.031577</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.525216</td>\n",
       "      <td>0.488031</td>\n",
       "      <td>0.491898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.366200</td>\n",
       "      <td>1.025955</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.527118</td>\n",
       "      <td>0.497181</td>\n",
       "      <td>0.497636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.345700</td>\n",
       "      <td>1.013631</td>\n",
       "      <td>0.778185</td>\n",
       "      <td>0.522815</td>\n",
       "      <td>0.492480</td>\n",
       "      <td>0.493522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>1.015191</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.495436</td>\n",
       "      <td>0.487501</td>\n",
       "      <td>0.482633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:06:56,122] Trial 91 finished with value: 0.48263297400373917 and parameters: {'learning_rate': 0.0004949145994118729, 'weight_decay': 0.009000000000000001, 'warmup_steps': 4}. Best is trial 76 with value: 0.49512573819371475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 92 with params: {'learning_rate': 0.00025569988534885664, 'weight_decay': 0.009000000000000001, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:48, 7.23 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.568100</td>\n",
       "      <td>3.211849</td>\n",
       "      <td>0.264895</td>\n",
       "      <td>0.054291</td>\n",
       "      <td>0.045691</td>\n",
       "      <td>0.038428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.981500</td>\n",
       "      <td>2.699388</td>\n",
       "      <td>0.446379</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>0.112144</td>\n",
       "      <td>0.083702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.526600</td>\n",
       "      <td>2.294776</td>\n",
       "      <td>0.521540</td>\n",
       "      <td>0.184713</td>\n",
       "      <td>0.158035</td>\n",
       "      <td>0.141430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.146000</td>\n",
       "      <td>1.996227</td>\n",
       "      <td>0.614115</td>\n",
       "      <td>0.270426</td>\n",
       "      <td>0.239685</td>\n",
       "      <td>0.224631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.864100</td>\n",
       "      <td>1.771764</td>\n",
       "      <td>0.677360</td>\n",
       "      <td>0.341888</td>\n",
       "      <td>0.303413</td>\n",
       "      <td>0.294524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:07:21,065] Trial 92 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 93 with params: {'learning_rate': 0.00047159518812246964, 'weight_decay': 0.008, 'warmup_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.393900</td>\n",
       "      <td>2.879185</td>\n",
       "      <td>0.412466</td>\n",
       "      <td>0.072657</td>\n",
       "      <td>0.095658</td>\n",
       "      <td>0.074841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.549600</td>\n",
       "      <td>2.201767</td>\n",
       "      <td>0.533456</td>\n",
       "      <td>0.201910</td>\n",
       "      <td>0.171602</td>\n",
       "      <td>0.157311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.939100</td>\n",
       "      <td>1.725411</td>\n",
       "      <td>0.665445</td>\n",
       "      <td>0.316540</td>\n",
       "      <td>0.290899</td>\n",
       "      <td>0.272115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.495800</td>\n",
       "      <td>1.467122</td>\n",
       "      <td>0.701192</td>\n",
       "      <td>0.313243</td>\n",
       "      <td>0.323841</td>\n",
       "      <td>0.301859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.190600</td>\n",
       "      <td>1.324724</td>\n",
       "      <td>0.723190</td>\n",
       "      <td>0.375596</td>\n",
       "      <td>0.368980</td>\n",
       "      <td>0.345118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.972400</td>\n",
       "      <td>1.200426</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.448886</td>\n",
       "      <td>0.401648</td>\n",
       "      <td>0.389694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.803000</td>\n",
       "      <td>1.152056</td>\n",
       "      <td>0.757104</td>\n",
       "      <td>0.483814</td>\n",
       "      <td>0.440566</td>\n",
       "      <td>0.434351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.696900</td>\n",
       "      <td>1.115727</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.469101</td>\n",
       "      <td>0.464182</td>\n",
       "      <td>0.453404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.595500</td>\n",
       "      <td>1.067989</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.484514</td>\n",
       "      <td>0.477207</td>\n",
       "      <td>0.470915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>1.068514</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.484148</td>\n",
       "      <td>0.486843</td>\n",
       "      <td>0.475725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.474300</td>\n",
       "      <td>1.041540</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.480722</td>\n",
       "      <td>0.484063</td>\n",
       "      <td>0.475322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.425400</td>\n",
       "      <td>1.031474</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.493920</td>\n",
       "      <td>0.483766</td>\n",
       "      <td>0.479872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>1.026078</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.489942</td>\n",
       "      <td>0.488308</td>\n",
       "      <td>0.479762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>1.008029</td>\n",
       "      <td>0.779102</td>\n",
       "      <td>0.491518</td>\n",
       "      <td>0.490152</td>\n",
       "      <td>0.480915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.366000</td>\n",
       "      <td>1.011005</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.490673</td>\n",
       "      <td>0.489410</td>\n",
       "      <td>0.480156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:08:35,466] Trial 93 finished with value: 0.480156444559878 and parameters: {'learning_rate': 0.00047159518812246964, 'weight_decay': 0.008, 'warmup_steps': 3}. Best is trial 76 with value: 0.49512573819371475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 94 with params: {'learning_rate': 0.0004657598377890262, 'weight_decay': 0.008, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:47 < 00:24, 7.28 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.410700</td>\n",
       "      <td>2.890473</td>\n",
       "      <td>0.411549</td>\n",
       "      <td>0.074158</td>\n",
       "      <td>0.092682</td>\n",
       "      <td>0.071924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.562700</td>\n",
       "      <td>2.208370</td>\n",
       "      <td>0.551787</td>\n",
       "      <td>0.194567</td>\n",
       "      <td>0.187086</td>\n",
       "      <td>0.173419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.948100</td>\n",
       "      <td>1.741512</td>\n",
       "      <td>0.659028</td>\n",
       "      <td>0.321400</td>\n",
       "      <td>0.295202</td>\n",
       "      <td>0.278388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.504900</td>\n",
       "      <td>1.475850</td>\n",
       "      <td>0.702108</td>\n",
       "      <td>0.319337</td>\n",
       "      <td>0.326341</td>\n",
       "      <td>0.307849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.207500</td>\n",
       "      <td>1.343088</td>\n",
       "      <td>0.734189</td>\n",
       "      <td>0.401962</td>\n",
       "      <td>0.397139</td>\n",
       "      <td>0.378488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.985500</td>\n",
       "      <td>1.219933</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.429945</td>\n",
       "      <td>0.402634</td>\n",
       "      <td>0.389274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>1.176131</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.465364</td>\n",
       "      <td>0.432348</td>\n",
       "      <td>0.425524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.708800</td>\n",
       "      <td>1.138652</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.475079</td>\n",
       "      <td>0.460522</td>\n",
       "      <td>0.449528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.606500</td>\n",
       "      <td>1.090976</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.489975</td>\n",
       "      <td>0.469795</td>\n",
       "      <td>0.464073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.529100</td>\n",
       "      <td>1.085325</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.491990</td>\n",
       "      <td>0.475982</td>\n",
       "      <td>0.471733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:09:24,157] Trial 94 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 95 with params: {'learning_rate': 0.0004769585927044506, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.403400</td>\n",
       "      <td>2.876386</td>\n",
       "      <td>0.415215</td>\n",
       "      <td>0.073270</td>\n",
       "      <td>0.094855</td>\n",
       "      <td>0.073856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.544300</td>\n",
       "      <td>2.188382</td>\n",
       "      <td>0.557287</td>\n",
       "      <td>0.204342</td>\n",
       "      <td>0.201261</td>\n",
       "      <td>0.189003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.924100</td>\n",
       "      <td>1.722416</td>\n",
       "      <td>0.661778</td>\n",
       "      <td>0.324121</td>\n",
       "      <td>0.295682</td>\n",
       "      <td>0.279361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.479600</td>\n",
       "      <td>1.458800</td>\n",
       "      <td>0.703941</td>\n",
       "      <td>0.320664</td>\n",
       "      <td>0.327614</td>\n",
       "      <td>0.309269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.184200</td>\n",
       "      <td>1.329448</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.422106</td>\n",
       "      <td>0.393965</td>\n",
       "      <td>0.374588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.963700</td>\n",
       "      <td>1.211916</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.424947</td>\n",
       "      <td>0.403472</td>\n",
       "      <td>0.390590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.796600</td>\n",
       "      <td>1.169444</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.471802</td>\n",
       "      <td>0.432926</td>\n",
       "      <td>0.427596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.691500</td>\n",
       "      <td>1.131598</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.485004</td>\n",
       "      <td>0.465576</td>\n",
       "      <td>0.455702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.588700</td>\n",
       "      <td>1.086339</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.492386</td>\n",
       "      <td>0.470123</td>\n",
       "      <td>0.465707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>1.081951</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.493896</td>\n",
       "      <td>0.476580</td>\n",
       "      <td>0.472499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.469400</td>\n",
       "      <td>1.052618</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.502102</td>\n",
       "      <td>0.484623</td>\n",
       "      <td>0.482107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.420700</td>\n",
       "      <td>1.039937</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.496837</td>\n",
       "      <td>0.482162</td>\n",
       "      <td>0.478691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.390100</td>\n",
       "      <td>1.033079</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.517530</td>\n",
       "      <td>0.492831</td>\n",
       "      <td>0.493583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.369600</td>\n",
       "      <td>1.021112</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.519773</td>\n",
       "      <td>0.489594</td>\n",
       "      <td>0.490039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.362700</td>\n",
       "      <td>1.021762</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.523183</td>\n",
       "      <td>0.494659</td>\n",
       "      <td>0.495126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:10:38,086] Trial 95 finished with value: 0.49512573819371475 and parameters: {'learning_rate': 0.0004769585927044506, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 76 with value: 0.49512573819371475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 96 with params: {'learning_rate': 0.000260765287717221, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:47, 7.44 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.563400</td>\n",
       "      <td>3.202812</td>\n",
       "      <td>0.272227</td>\n",
       "      <td>0.052264</td>\n",
       "      <td>0.047937</td>\n",
       "      <td>0.039965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.968800</td>\n",
       "      <td>2.683421</td>\n",
       "      <td>0.446379</td>\n",
       "      <td>0.088664</td>\n",
       "      <td>0.112215</td>\n",
       "      <td>0.083538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.508100</td>\n",
       "      <td>2.274837</td>\n",
       "      <td>0.537122</td>\n",
       "      <td>0.217373</td>\n",
       "      <td>0.170631</td>\n",
       "      <td>0.157455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.123800</td>\n",
       "      <td>1.976311</td>\n",
       "      <td>0.618698</td>\n",
       "      <td>0.300879</td>\n",
       "      <td>0.253125</td>\n",
       "      <td>0.242502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.839800</td>\n",
       "      <td>1.752609</td>\n",
       "      <td>0.682860</td>\n",
       "      <td>0.341580</td>\n",
       "      <td>0.307600</td>\n",
       "      <td>0.297941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:11:02,275] Trial 96 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 97 with params: {'learning_rate': 0.0004910817625469622, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.394300</td>\n",
       "      <td>2.859261</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.069788</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.075065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.521900</td>\n",
       "      <td>2.163796</td>\n",
       "      <td>0.559120</td>\n",
       "      <td>0.203731</td>\n",
       "      <td>0.203198</td>\n",
       "      <td>0.190175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.893800</td>\n",
       "      <td>1.695439</td>\n",
       "      <td>0.661778</td>\n",
       "      <td>0.317476</td>\n",
       "      <td>0.296783</td>\n",
       "      <td>0.280638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.449200</td>\n",
       "      <td>1.437913</td>\n",
       "      <td>0.705775</td>\n",
       "      <td>0.340143</td>\n",
       "      <td>0.325755</td>\n",
       "      <td>0.309033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.154000</td>\n",
       "      <td>1.312078</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.403040</td>\n",
       "      <td>0.394174</td>\n",
       "      <td>0.373753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.934400</td>\n",
       "      <td>1.202306</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.424536</td>\n",
       "      <td>0.397524</td>\n",
       "      <td>0.387185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.771300</td>\n",
       "      <td>1.162846</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.474008</td>\n",
       "      <td>0.440335</td>\n",
       "      <td>0.435657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.668800</td>\n",
       "      <td>1.120351</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.483404</td>\n",
       "      <td>0.464452</td>\n",
       "      <td>0.455797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.566300</td>\n",
       "      <td>1.076873</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.493009</td>\n",
       "      <td>0.472068</td>\n",
       "      <td>0.467673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.492000</td>\n",
       "      <td>1.075673</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.498145</td>\n",
       "      <td>0.475278</td>\n",
       "      <td>0.472348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.448200</td>\n",
       "      <td>1.045019</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.500539</td>\n",
       "      <td>0.484193</td>\n",
       "      <td>0.481659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.401900</td>\n",
       "      <td>1.033080</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.505723</td>\n",
       "      <td>0.482307</td>\n",
       "      <td>0.482443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.371000</td>\n",
       "      <td>1.027286</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.527121</td>\n",
       "      <td>0.497454</td>\n",
       "      <td>0.497761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.350800</td>\n",
       "      <td>1.014726</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.520343</td>\n",
       "      <td>0.489761</td>\n",
       "      <td>0.490675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.344100</td>\n",
       "      <td>1.016146</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.521607</td>\n",
       "      <td>0.494077</td>\n",
       "      <td>0.492819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:12:16,521] Trial 97 finished with value: 0.4928190274687641 and parameters: {'learning_rate': 0.0004910817625469622, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 76 with value: 0.49512573819371475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 98 with params: {'learning_rate': 0.00048420804645289174, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.398700</td>\n",
       "      <td>2.867554</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.072784</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.075681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.532500</td>\n",
       "      <td>2.175591</td>\n",
       "      <td>0.558203</td>\n",
       "      <td>0.204267</td>\n",
       "      <td>0.200698</td>\n",
       "      <td>0.188367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.908300</td>\n",
       "      <td>1.708828</td>\n",
       "      <td>0.660862</td>\n",
       "      <td>0.318084</td>\n",
       "      <td>0.295444</td>\n",
       "      <td>0.278348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.463500</td>\n",
       "      <td>1.447744</td>\n",
       "      <td>0.703941</td>\n",
       "      <td>0.318829</td>\n",
       "      <td>0.322993</td>\n",
       "      <td>0.304729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.168400</td>\n",
       "      <td>1.319812</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.423368</td>\n",
       "      <td>0.396147</td>\n",
       "      <td>0.378480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.948900</td>\n",
       "      <td>1.206146</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.424959</td>\n",
       "      <td>0.397842</td>\n",
       "      <td>0.386679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.783900</td>\n",
       "      <td>1.165832</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.472005</td>\n",
       "      <td>0.433129</td>\n",
       "      <td>0.427842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.680200</td>\n",
       "      <td>1.125629</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.484477</td>\n",
       "      <td>0.463909</td>\n",
       "      <td>0.455633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>1.081648</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.489174</td>\n",
       "      <td>0.470577</td>\n",
       "      <td>0.466453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.502200</td>\n",
       "      <td>1.079064</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.500049</td>\n",
       "      <td>0.478790</td>\n",
       "      <td>0.475122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.458800</td>\n",
       "      <td>1.049200</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.503086</td>\n",
       "      <td>0.484284</td>\n",
       "      <td>0.482339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.411200</td>\n",
       "      <td>1.036301</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.503220</td>\n",
       "      <td>0.482473</td>\n",
       "      <td>0.481095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.380400</td>\n",
       "      <td>1.030244</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.528497</td>\n",
       "      <td>0.497215</td>\n",
       "      <td>0.498830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.360100</td>\n",
       "      <td>1.017656</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.520817</td>\n",
       "      <td>0.490191</td>\n",
       "      <td>0.491064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.353200</td>\n",
       "      <td>1.018741</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.523495</td>\n",
       "      <td>0.493917</td>\n",
       "      <td>0.492789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:13:32,424] Trial 98 finished with value: 0.4927893408163375 and parameters: {'learning_rate': 0.00048420804645289174, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 76 with value: 0.49512573819371475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 99 with params: {'learning_rate': 0.00022815292178642897, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:47, 7.40 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.593600</td>\n",
       "      <td>3.260383</td>\n",
       "      <td>0.197984</td>\n",
       "      <td>0.037749</td>\n",
       "      <td>0.025871</td>\n",
       "      <td>0.016137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.049900</td>\n",
       "      <td>2.787820</td>\n",
       "      <td>0.433547</td>\n",
       "      <td>0.101722</td>\n",
       "      <td>0.104688</td>\n",
       "      <td>0.079209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.628900</td>\n",
       "      <td>2.405306</td>\n",
       "      <td>0.502291</td>\n",
       "      <td>0.144395</td>\n",
       "      <td>0.142350</td>\n",
       "      <td>0.120777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.269200</td>\n",
       "      <td>2.112741</td>\n",
       "      <td>0.574702</td>\n",
       "      <td>0.223545</td>\n",
       "      <td>0.201164</td>\n",
       "      <td>0.185981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.002200</td>\n",
       "      <td>1.888370</td>\n",
       "      <td>0.640697</td>\n",
       "      <td>0.320896</td>\n",
       "      <td>0.268758</td>\n",
       "      <td>0.257609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:13:56,867] Trial 99 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 with params: {'learning_rate': 0.0003524736859308233, 'weight_decay': 0.01, 'warmup_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:47, 7.35 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.478100</td>\n",
       "      <td>3.041611</td>\n",
       "      <td>0.371219</td>\n",
       "      <td>0.063347</td>\n",
       "      <td>0.078619</td>\n",
       "      <td>0.060112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.755700</td>\n",
       "      <td>2.431396</td>\n",
       "      <td>0.497709</td>\n",
       "      <td>0.158886</td>\n",
       "      <td>0.144390</td>\n",
       "      <td>0.124257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.211800</td>\n",
       "      <td>1.976980</td>\n",
       "      <td>0.604033</td>\n",
       "      <td>0.292187</td>\n",
       "      <td>0.235610</td>\n",
       "      <td>0.225075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.790400</td>\n",
       "      <td>1.702494</td>\n",
       "      <td>0.684693</td>\n",
       "      <td>0.309638</td>\n",
       "      <td>0.303895</td>\n",
       "      <td>0.287610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.493600</td>\n",
       "      <td>1.502443</td>\n",
       "      <td>0.715857</td>\n",
       "      <td>0.368847</td>\n",
       "      <td>0.356926</td>\n",
       "      <td>0.336900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:14:21,417] Trial 100 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 101 with params: {'learning_rate': 0.0004903536318893038, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.394700</td>\n",
       "      <td>2.860117</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.069788</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.075065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.523000</td>\n",
       "      <td>2.164997</td>\n",
       "      <td>0.558203</td>\n",
       "      <td>0.203463</td>\n",
       "      <td>0.200698</td>\n",
       "      <td>0.187992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.895200</td>\n",
       "      <td>1.696679</td>\n",
       "      <td>0.661778</td>\n",
       "      <td>0.317767</td>\n",
       "      <td>0.296783</td>\n",
       "      <td>0.280791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.450600</td>\n",
       "      <td>1.438818</td>\n",
       "      <td>0.704858</td>\n",
       "      <td>0.338758</td>\n",
       "      <td>0.324326</td>\n",
       "      <td>0.307207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.155500</td>\n",
       "      <td>1.312894</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.402619</td>\n",
       "      <td>0.394174</td>\n",
       "      <td>0.373721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.935800</td>\n",
       "      <td>1.202537</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.424952</td>\n",
       "      <td>0.397524</td>\n",
       "      <td>0.387323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.772600</td>\n",
       "      <td>1.163026</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.474008</td>\n",
       "      <td>0.440335</td>\n",
       "      <td>0.435657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.669900</td>\n",
       "      <td>1.120805</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.483995</td>\n",
       "      <td>0.463240</td>\n",
       "      <td>0.455366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.567500</td>\n",
       "      <td>1.077348</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.493125</td>\n",
       "      <td>0.472068</td>\n",
       "      <td>0.467750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.493100</td>\n",
       "      <td>1.076036</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.498145</td>\n",
       "      <td>0.475278</td>\n",
       "      <td>0.472348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.449300</td>\n",
       "      <td>1.045444</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.500539</td>\n",
       "      <td>0.484193</td>\n",
       "      <td>0.481659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.402900</td>\n",
       "      <td>1.033440</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.504959</td>\n",
       "      <td>0.482762</td>\n",
       "      <td>0.482151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.372000</td>\n",
       "      <td>1.027555</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.527121</td>\n",
       "      <td>0.497454</td>\n",
       "      <td>0.497761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.351700</td>\n",
       "      <td>1.014932</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.520343</td>\n",
       "      <td>0.489761</td>\n",
       "      <td>0.490675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>1.016269</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.521505</td>\n",
       "      <td>0.494077</td>\n",
       "      <td>0.492769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:15:36,706] Trial 101 finished with value: 0.4927688811433882 and parameters: {'learning_rate': 0.0004903536318893038, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 76 with value: 0.49512573819371475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 102 with params: {'learning_rate': 0.00043456777714885706, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:49 < 00:24, 7.04 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.431900</td>\n",
       "      <td>2.931890</td>\n",
       "      <td>0.397800</td>\n",
       "      <td>0.074897</td>\n",
       "      <td>0.086422</td>\n",
       "      <td>0.064601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.615700</td>\n",
       "      <td>2.267116</td>\n",
       "      <td>0.527956</td>\n",
       "      <td>0.180882</td>\n",
       "      <td>0.164311</td>\n",
       "      <td>0.147838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.014500</td>\n",
       "      <td>1.793206</td>\n",
       "      <td>0.648946</td>\n",
       "      <td>0.315845</td>\n",
       "      <td>0.278755</td>\n",
       "      <td>0.263570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.575200</td>\n",
       "      <td>1.526486</td>\n",
       "      <td>0.698442</td>\n",
       "      <td>0.325759</td>\n",
       "      <td>0.331958</td>\n",
       "      <td>0.313155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.271700</td>\n",
       "      <td>1.379780</td>\n",
       "      <td>0.728689</td>\n",
       "      <td>0.405937</td>\n",
       "      <td>0.387162</td>\n",
       "      <td>0.369864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.046000</td>\n",
       "      <td>1.241865</td>\n",
       "      <td>0.743355</td>\n",
       "      <td>0.439662</td>\n",
       "      <td>0.394382</td>\n",
       "      <td>0.381486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.873100</td>\n",
       "      <td>1.192084</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.474880</td>\n",
       "      <td>0.436821</td>\n",
       "      <td>0.431021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.763000</td>\n",
       "      <td>1.149675</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.466131</td>\n",
       "      <td>0.453251</td>\n",
       "      <td>0.441921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.660900</td>\n",
       "      <td>1.103553</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.482542</td>\n",
       "      <td>0.471619</td>\n",
       "      <td>0.463426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.580400</td>\n",
       "      <td>1.095940</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.486274</td>\n",
       "      <td>0.475215</td>\n",
       "      <td>0.467290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:16:27,082] Trial 102 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 103 with params: {'learning_rate': 0.000448014133753709, 'weight_decay': 0.009000000000000001, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.422700</td>\n",
       "      <td>2.914295</td>\n",
       "      <td>0.402383</td>\n",
       "      <td>0.074484</td>\n",
       "      <td>0.087927</td>\n",
       "      <td>0.065991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.593100</td>\n",
       "      <td>2.241637</td>\n",
       "      <td>0.532539</td>\n",
       "      <td>0.188304</td>\n",
       "      <td>0.167972</td>\n",
       "      <td>0.152470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.985500</td>\n",
       "      <td>1.770180</td>\n",
       "      <td>0.653529</td>\n",
       "      <td>0.317357</td>\n",
       "      <td>0.285461</td>\n",
       "      <td>0.269546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.545300</td>\n",
       "      <td>1.504905</td>\n",
       "      <td>0.699358</td>\n",
       "      <td>0.319107</td>\n",
       "      <td>0.330074</td>\n",
       "      <td>0.310143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.243300</td>\n",
       "      <td>1.365524</td>\n",
       "      <td>0.730522</td>\n",
       "      <td>0.391675</td>\n",
       "      <td>0.385984</td>\n",
       "      <td>0.366835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.019900</td>\n",
       "      <td>1.231640</td>\n",
       "      <td>0.744271</td>\n",
       "      <td>0.425953</td>\n",
       "      <td>0.392670</td>\n",
       "      <td>0.377224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.848500</td>\n",
       "      <td>1.185344</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.468181</td>\n",
       "      <td>0.435140</td>\n",
       "      <td>0.428927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.738800</td>\n",
       "      <td>1.143458</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.474977</td>\n",
       "      <td>0.456531</td>\n",
       "      <td>0.447493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.637000</td>\n",
       "      <td>1.094866</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.472917</td>\n",
       "      <td>0.471119</td>\n",
       "      <td>0.461024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.557800</td>\n",
       "      <td>1.088723</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.488832</td>\n",
       "      <td>0.475105</td>\n",
       "      <td>0.468299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.515600</td>\n",
       "      <td>1.059872</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.489425</td>\n",
       "      <td>0.479041</td>\n",
       "      <td>0.475287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.461700</td>\n",
       "      <td>1.046580</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.498549</td>\n",
       "      <td>0.480743</td>\n",
       "      <td>0.477806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.431600</td>\n",
       "      <td>1.037405</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.495063</td>\n",
       "      <td>0.483723</td>\n",
       "      <td>0.480584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.409900</td>\n",
       "      <td>1.025546</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.506775</td>\n",
       "      <td>0.485854</td>\n",
       "      <td>0.484932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.403200</td>\n",
       "      <td>1.025388</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.495661</td>\n",
       "      <td>0.487804</td>\n",
       "      <td>0.483246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:17:44,038] Trial 103 finished with value: 0.48324648858550234 and parameters: {'learning_rate': 0.000448014133753709, 'weight_decay': 0.009000000000000001, 'warmup_steps': 4}. Best is trial 76 with value: 0.49512573819371475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 104 with params: {'learning_rate': 1.1873161138364599e-05, 'weight_decay': 0.006, 'warmup_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:47, 7.34 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.864700</td>\n",
       "      <td>3.819999</td>\n",
       "      <td>0.056829</td>\n",
       "      <td>0.008467</td>\n",
       "      <td>0.027544</td>\n",
       "      <td>0.007037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.799400</td>\n",
       "      <td>3.763962</td>\n",
       "      <td>0.172319</td>\n",
       "      <td>0.009675</td>\n",
       "      <td>0.021216</td>\n",
       "      <td>0.009971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.755800</td>\n",
       "      <td>3.716954</td>\n",
       "      <td>0.188818</td>\n",
       "      <td>0.015684</td>\n",
       "      <td>0.023822</td>\n",
       "      <td>0.011584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.712200</td>\n",
       "      <td>3.679777</td>\n",
       "      <td>0.186984</td>\n",
       "      <td>0.013624</td>\n",
       "      <td>0.023014</td>\n",
       "      <td>0.010768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.686900</td>\n",
       "      <td>3.646876</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>0.015597</td>\n",
       "      <td>0.022466</td>\n",
       "      <td>0.010189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:18:08,534] Trial 104 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 105 with params: {'learning_rate': 0.00047549851929469956, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.404300</td>\n",
       "      <td>2.878247</td>\n",
       "      <td>0.414299</td>\n",
       "      <td>0.073420</td>\n",
       "      <td>0.094210</td>\n",
       "      <td>0.073212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.546700</td>\n",
       "      <td>2.191033</td>\n",
       "      <td>0.557287</td>\n",
       "      <td>0.204325</td>\n",
       "      <td>0.201261</td>\n",
       "      <td>0.188999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.927200</td>\n",
       "      <td>1.725059</td>\n",
       "      <td>0.661778</td>\n",
       "      <td>0.324258</td>\n",
       "      <td>0.295682</td>\n",
       "      <td>0.278925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.482800</td>\n",
       "      <td>1.460971</td>\n",
       "      <td>0.704858</td>\n",
       "      <td>0.321851</td>\n",
       "      <td>0.328069</td>\n",
       "      <td>0.310056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.187200</td>\n",
       "      <td>1.331135</td>\n",
       "      <td>0.735105</td>\n",
       "      <td>0.422437</td>\n",
       "      <td>0.393727</td>\n",
       "      <td>0.374698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.966600</td>\n",
       "      <td>1.213017</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.425314</td>\n",
       "      <td>0.403998</td>\n",
       "      <td>0.391065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.799200</td>\n",
       "      <td>1.170205</td>\n",
       "      <td>0.747938</td>\n",
       "      <td>0.468690</td>\n",
       "      <td>0.429840</td>\n",
       "      <td>0.424057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.693700</td>\n",
       "      <td>1.132875</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.485332</td>\n",
       "      <td>0.465679</td>\n",
       "      <td>0.455927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.590900</td>\n",
       "      <td>1.086952</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.491568</td>\n",
       "      <td>0.469453</td>\n",
       "      <td>0.464948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.514500</td>\n",
       "      <td>1.082442</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.485762</td>\n",
       "      <td>0.474547</td>\n",
       "      <td>0.469967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.471600</td>\n",
       "      <td>1.053241</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.501678</td>\n",
       "      <td>0.484519</td>\n",
       "      <td>0.481852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.422700</td>\n",
       "      <td>1.040474</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.496816</td>\n",
       "      <td>0.482162</td>\n",
       "      <td>0.478685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.392200</td>\n",
       "      <td>1.033517</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.517530</td>\n",
       "      <td>0.492831</td>\n",
       "      <td>0.493583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.371500</td>\n",
       "      <td>1.021606</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.519985</td>\n",
       "      <td>0.487776</td>\n",
       "      <td>0.488856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.364700</td>\n",
       "      <td>1.022117</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.523183</td>\n",
       "      <td>0.494659</td>\n",
       "      <td>0.495126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:19:24,293] Trial 105 finished with value: 0.49512573819371475 and parameters: {'learning_rate': 0.00047549851929469956, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 76 with value: 0.49512573819371475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 106 with params: {'learning_rate': 0.00042340575293188244, 'weight_decay': 0.01, 'warmup_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:47, 7.43 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.426400</td>\n",
       "      <td>2.939136</td>\n",
       "      <td>0.384051</td>\n",
       "      <td>0.074993</td>\n",
       "      <td>0.084324</td>\n",
       "      <td>0.064095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.629100</td>\n",
       "      <td>2.287687</td>\n",
       "      <td>0.527039</td>\n",
       "      <td>0.198606</td>\n",
       "      <td>0.167736</td>\n",
       "      <td>0.152769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.045300</td>\n",
       "      <td>1.818323</td>\n",
       "      <td>0.652612</td>\n",
       "      <td>0.318321</td>\n",
       "      <td>0.276093</td>\n",
       "      <td>0.261404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.608600</td>\n",
       "      <td>1.558016</td>\n",
       "      <td>0.694775</td>\n",
       "      <td>0.315541</td>\n",
       "      <td>0.329309</td>\n",
       "      <td>0.305785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.305100</td>\n",
       "      <td>1.399441</td>\n",
       "      <td>0.719523</td>\n",
       "      <td>0.347455</td>\n",
       "      <td>0.358902</td>\n",
       "      <td>0.332263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:19:48,525] Trial 106 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 107 with params: {'learning_rate': 0.000499408831202765, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:15, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.389100</td>\n",
       "      <td>2.849584</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.069468</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.075029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.510200</td>\n",
       "      <td>2.150933</td>\n",
       "      <td>0.561870</td>\n",
       "      <td>0.204292</td>\n",
       "      <td>0.204820</td>\n",
       "      <td>0.191348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.876900</td>\n",
       "      <td>1.678954</td>\n",
       "      <td>0.669111</td>\n",
       "      <td>0.314300</td>\n",
       "      <td>0.300366</td>\n",
       "      <td>0.282353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.431100</td>\n",
       "      <td>1.425422</td>\n",
       "      <td>0.705775</td>\n",
       "      <td>0.330825</td>\n",
       "      <td>0.326117</td>\n",
       "      <td>0.308447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.135100</td>\n",
       "      <td>1.302993</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.398658</td>\n",
       "      <td>0.391414</td>\n",
       "      <td>0.369751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.915400</td>\n",
       "      <td>1.195227</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.426857</td>\n",
       "      <td>0.397452</td>\n",
       "      <td>0.387732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.756300</td>\n",
       "      <td>1.156968</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.487391</td>\n",
       "      <td>0.444946</td>\n",
       "      <td>0.440355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>1.114769</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.487756</td>\n",
       "      <td>0.468737</td>\n",
       "      <td>0.462510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.553100</td>\n",
       "      <td>1.068350</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.498611</td>\n",
       "      <td>0.478788</td>\n",
       "      <td>0.475424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.479900</td>\n",
       "      <td>1.070426</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.497727</td>\n",
       "      <td>0.473617</td>\n",
       "      <td>0.471398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.436300</td>\n",
       "      <td>1.039333</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.501639</td>\n",
       "      <td>0.487027</td>\n",
       "      <td>0.483321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.390600</td>\n",
       "      <td>1.028257</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.526831</td>\n",
       "      <td>0.488416</td>\n",
       "      <td>0.492979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.360400</td>\n",
       "      <td>1.022924</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.498509</td>\n",
       "      <td>0.489324</td>\n",
       "      <td>0.483643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.339500</td>\n",
       "      <td>1.010645</td>\n",
       "      <td>0.779102</td>\n",
       "      <td>0.498343</td>\n",
       "      <td>0.489904</td>\n",
       "      <td>0.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.333100</td>\n",
       "      <td>1.012570</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.515419</td>\n",
       "      <td>0.489155</td>\n",
       "      <td>0.486192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:21:05,913] Trial 107 finished with value: 0.4861917323142149 and parameters: {'learning_rate': 0.000499408831202765, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 76 with value: 0.49512573819371475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 108 with params: {'learning_rate': 0.00022466446675269706, 'weight_decay': 0.008, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:48 < 00:24, 7.18 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.596800</td>\n",
       "      <td>3.266782</td>\n",
       "      <td>0.196150</td>\n",
       "      <td>0.038621</td>\n",
       "      <td>0.025323</td>\n",
       "      <td>0.015322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.058700</td>\n",
       "      <td>2.799362</td>\n",
       "      <td>0.428964</td>\n",
       "      <td>0.101733</td>\n",
       "      <td>0.102532</td>\n",
       "      <td>0.077136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.642200</td>\n",
       "      <td>2.419271</td>\n",
       "      <td>0.500458</td>\n",
       "      <td>0.136230</td>\n",
       "      <td>0.140910</td>\n",
       "      <td>0.118284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.284900</td>\n",
       "      <td>2.127923</td>\n",
       "      <td>0.571952</td>\n",
       "      <td>0.222723</td>\n",
       "      <td>0.197774</td>\n",
       "      <td>0.182597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.019800</td>\n",
       "      <td>1.903769</td>\n",
       "      <td>0.636114</td>\n",
       "      <td>0.319721</td>\n",
       "      <td>0.263599</td>\n",
       "      <td>0.251510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.767800</td>\n",
       "      <td>1.726031</td>\n",
       "      <td>0.684693</td>\n",
       "      <td>0.366909</td>\n",
       "      <td>0.306616</td>\n",
       "      <td>0.301081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.574300</td>\n",
       "      <td>1.602150</td>\n",
       "      <td>0.696609</td>\n",
       "      <td>0.356370</td>\n",
       "      <td>0.316815</td>\n",
       "      <td>0.308051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.446600</td>\n",
       "      <td>1.514430</td>\n",
       "      <td>0.717690</td>\n",
       "      <td>0.362957</td>\n",
       "      <td>0.349741</td>\n",
       "      <td>0.332088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.322700</td>\n",
       "      <td>1.445040</td>\n",
       "      <td>0.717690</td>\n",
       "      <td>0.359940</td>\n",
       "      <td>0.353585</td>\n",
       "      <td>0.338581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.220900</td>\n",
       "      <td>1.394933</td>\n",
       "      <td>0.727773</td>\n",
       "      <td>0.358977</td>\n",
       "      <td>0.369398</td>\n",
       "      <td>0.350056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:21:55,396] Trial 108 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 109 with params: {'learning_rate': 0.0004750920561240741, 'weight_decay': 0.008, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:48 < 00:24, 7.14 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.404500</td>\n",
       "      <td>2.878686</td>\n",
       "      <td>0.414299</td>\n",
       "      <td>0.073427</td>\n",
       "      <td>0.094210</td>\n",
       "      <td>0.073224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.547400</td>\n",
       "      <td>2.191712</td>\n",
       "      <td>0.558203</td>\n",
       "      <td>0.204852</td>\n",
       "      <td>0.202213</td>\n",
       "      <td>0.189769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.928100</td>\n",
       "      <td>1.725806</td>\n",
       "      <td>0.660862</td>\n",
       "      <td>0.323667</td>\n",
       "      <td>0.295319</td>\n",
       "      <td>0.278259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.483800</td>\n",
       "      <td>1.461540</td>\n",
       "      <td>0.703941</td>\n",
       "      <td>0.320955</td>\n",
       "      <td>0.327614</td>\n",
       "      <td>0.309567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.188200</td>\n",
       "      <td>1.331767</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.423004</td>\n",
       "      <td>0.393965</td>\n",
       "      <td>0.375083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.967500</td>\n",
       "      <td>1.213403</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.425314</td>\n",
       "      <td>0.403998</td>\n",
       "      <td>0.391065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.799900</td>\n",
       "      <td>1.170374</td>\n",
       "      <td>0.747938</td>\n",
       "      <td>0.458690</td>\n",
       "      <td>0.429840</td>\n",
       "      <td>0.420723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.694400</td>\n",
       "      <td>1.133077</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.483520</td>\n",
       "      <td>0.462796</td>\n",
       "      <td>0.453490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.591600</td>\n",
       "      <td>1.087189</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.491455</td>\n",
       "      <td>0.469453</td>\n",
       "      <td>0.464871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.515200</td>\n",
       "      <td>1.082521</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.485762</td>\n",
       "      <td>0.474547</td>\n",
       "      <td>0.469967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:22:45,167] Trial 109 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 110 with params: {'learning_rate': 0.00024102013405689706, 'weight_decay': 0.009000000000000001, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:46, 7.46 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.581700</td>\n",
       "      <td>3.237311</td>\n",
       "      <td>0.224565</td>\n",
       "      <td>0.057088</td>\n",
       "      <td>0.033637</td>\n",
       "      <td>0.026337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.017500</td>\n",
       "      <td>2.745327</td>\n",
       "      <td>0.442713</td>\n",
       "      <td>0.102886</td>\n",
       "      <td>0.110539</td>\n",
       "      <td>0.083156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.579900</td>\n",
       "      <td>2.353059</td>\n",
       "      <td>0.511457</td>\n",
       "      <td>0.160065</td>\n",
       "      <td>0.150479</td>\n",
       "      <td>0.131614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.210900</td>\n",
       "      <td>2.056427</td>\n",
       "      <td>0.593951</td>\n",
       "      <td>0.242461</td>\n",
       "      <td>0.218267</td>\n",
       "      <td>0.204398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.936800</td>\n",
       "      <td>1.831587</td>\n",
       "      <td>0.670027</td>\n",
       "      <td>0.341423</td>\n",
       "      <td>0.293918</td>\n",
       "      <td>0.287191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:23:09,338] Trial 110 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 111 with params: {'learning_rate': 0.0004382225933607684, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.429500</td>\n",
       "      <td>2.927171</td>\n",
       "      <td>0.398717</td>\n",
       "      <td>0.075085</td>\n",
       "      <td>0.086637</td>\n",
       "      <td>0.064833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.609800</td>\n",
       "      <td>2.260418</td>\n",
       "      <td>0.528873</td>\n",
       "      <td>0.185310</td>\n",
       "      <td>0.165263</td>\n",
       "      <td>0.149358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.006600</td>\n",
       "      <td>1.786970</td>\n",
       "      <td>0.649863</td>\n",
       "      <td>0.316333</td>\n",
       "      <td>0.280798</td>\n",
       "      <td>0.265356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.567000</td>\n",
       "      <td>1.520569</td>\n",
       "      <td>0.696609</td>\n",
       "      <td>0.321407</td>\n",
       "      <td>0.328407</td>\n",
       "      <td>0.309038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.263900</td>\n",
       "      <td>1.376361</td>\n",
       "      <td>0.727773</td>\n",
       "      <td>0.406115</td>\n",
       "      <td>0.386708</td>\n",
       "      <td>0.369632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.039200</td>\n",
       "      <td>1.238982</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.447488</td>\n",
       "      <td>0.396668</td>\n",
       "      <td>0.383644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.866500</td>\n",
       "      <td>1.190572</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.474831</td>\n",
       "      <td>0.433276</td>\n",
       "      <td>0.428277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.756400</td>\n",
       "      <td>1.148309</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.465319</td>\n",
       "      <td>0.452556</td>\n",
       "      <td>0.441204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.654500</td>\n",
       "      <td>1.101532</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.490535</td>\n",
       "      <td>0.473470</td>\n",
       "      <td>0.467553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.574400</td>\n",
       "      <td>1.094042</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.487418</td>\n",
       "      <td>0.475215</td>\n",
       "      <td>0.467846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.531500</td>\n",
       "      <td>1.062933</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.491181</td>\n",
       "      <td>0.477915</td>\n",
       "      <td>0.474326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.477000</td>\n",
       "      <td>1.048740</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.502113</td>\n",
       "      <td>0.480957</td>\n",
       "      <td>0.479832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.446300</td>\n",
       "      <td>1.038755</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.496440</td>\n",
       "      <td>0.484029</td>\n",
       "      <td>0.481960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.424400</td>\n",
       "      <td>1.024583</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.505482</td>\n",
       "      <td>0.485785</td>\n",
       "      <td>0.484218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.417500</td>\n",
       "      <td>1.024992</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.493047</td>\n",
       "      <td>0.485428</td>\n",
       "      <td>0.481140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:24:25,113] Trial 111 finished with value: 0.4811397270126018 and parameters: {'learning_rate': 0.0004382225933607684, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 76 with value: 0.49512573819371475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 112 with params: {'learning_rate': 0.00011817202461154217, 'weight_decay': 0.009000000000000001, 'warmup_steps': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:24 < 00:48, 7.19 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.677500</td>\n",
       "      <td>3.465125</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.339200</td>\n",
       "      <td>3.163355</td>\n",
       "      <td>0.367553</td>\n",
       "      <td>0.061644</td>\n",
       "      <td>0.076980</td>\n",
       "      <td>0.061103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.078900</td>\n",
       "      <td>2.916276</td>\n",
       "      <td>0.425298</td>\n",
       "      <td>0.071065</td>\n",
       "      <td>0.095093</td>\n",
       "      <td>0.070916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.836200</td>\n",
       "      <td>2.702029</td>\n",
       "      <td>0.449129</td>\n",
       "      <td>0.093432</td>\n",
       "      <td>0.108095</td>\n",
       "      <td>0.081493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.660200</td>\n",
       "      <td>2.515345</td>\n",
       "      <td>0.485793</td>\n",
       "      <td>0.103619</td>\n",
       "      <td>0.130782</td>\n",
       "      <td>0.106173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:24:50,221] Trial 112 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 113 with params: {'learning_rate': 0.00046353462963312427, 'weight_decay': 0.01, 'warmup_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.399400</td>\n",
       "      <td>2.889542</td>\n",
       "      <td>0.408799</td>\n",
       "      <td>0.072206</td>\n",
       "      <td>0.093507</td>\n",
       "      <td>0.072723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.563100</td>\n",
       "      <td>2.215429</td>\n",
       "      <td>0.532539</td>\n",
       "      <td>0.199129</td>\n",
       "      <td>0.170610</td>\n",
       "      <td>0.155833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.956400</td>\n",
       "      <td>1.739833</td>\n",
       "      <td>0.664528</td>\n",
       "      <td>0.317566</td>\n",
       "      <td>0.290627</td>\n",
       "      <td>0.271956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.514100</td>\n",
       "      <td>1.481449</td>\n",
       "      <td>0.704858</td>\n",
       "      <td>0.339829</td>\n",
       "      <td>0.335310</td>\n",
       "      <td>0.313769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.208100</td>\n",
       "      <td>1.336276</td>\n",
       "      <td>0.725940</td>\n",
       "      <td>0.381953</td>\n",
       "      <td>0.369038</td>\n",
       "      <td>0.344519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.988700</td>\n",
       "      <td>1.207406</td>\n",
       "      <td>0.741522</td>\n",
       "      <td>0.448707</td>\n",
       "      <td>0.397433</td>\n",
       "      <td>0.387004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.818400</td>\n",
       "      <td>1.156215</td>\n",
       "      <td>0.755270</td>\n",
       "      <td>0.465460</td>\n",
       "      <td>0.438917</td>\n",
       "      <td>0.431643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.711500</td>\n",
       "      <td>1.119901</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.468032</td>\n",
       "      <td>0.460102</td>\n",
       "      <td>0.447820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.609700</td>\n",
       "      <td>1.073786</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.483591</td>\n",
       "      <td>0.477184</td>\n",
       "      <td>0.470078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.533600</td>\n",
       "      <td>1.074701</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.484314</td>\n",
       "      <td>0.485645</td>\n",
       "      <td>0.475521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.487800</td>\n",
       "      <td>1.045681</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.481145</td>\n",
       "      <td>0.484344</td>\n",
       "      <td>0.475419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.437400</td>\n",
       "      <td>1.036348</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.482707</td>\n",
       "      <td>0.481486</td>\n",
       "      <td>0.474221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.406300</td>\n",
       "      <td>1.029099</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.488399</td>\n",
       "      <td>0.489042</td>\n",
       "      <td>0.479046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.384500</td>\n",
       "      <td>1.012090</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.493041</td>\n",
       "      <td>0.489444</td>\n",
       "      <td>0.481606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.377600</td>\n",
       "      <td>1.014947</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.490823</td>\n",
       "      <td>0.489410</td>\n",
       "      <td>0.480322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:26:04,196] Trial 113 finished with value: 0.48032163599691813 and parameters: {'learning_rate': 0.00046353462963312427, 'weight_decay': 0.01, 'warmup_steps': 3}. Best is trial 76 with value: 0.49512573819371475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 114 with params: {'learning_rate': 0.0004945026061552231, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:26, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.392100</td>\n",
       "      <td>2.855276</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.069487</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.074954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.516900</td>\n",
       "      <td>2.158192</td>\n",
       "      <td>0.560953</td>\n",
       "      <td>0.204346</td>\n",
       "      <td>0.204365</td>\n",
       "      <td>0.191093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.886700</td>\n",
       "      <td>1.688871</td>\n",
       "      <td>0.663611</td>\n",
       "      <td>0.317956</td>\n",
       "      <td>0.298810</td>\n",
       "      <td>0.282154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.441800</td>\n",
       "      <td>1.433057</td>\n",
       "      <td>0.704858</td>\n",
       "      <td>0.339954</td>\n",
       "      <td>0.325540</td>\n",
       "      <td>0.308843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.146700</td>\n",
       "      <td>1.308578</td>\n",
       "      <td>0.736939</td>\n",
       "      <td>0.402908</td>\n",
       "      <td>0.393936</td>\n",
       "      <td>0.373236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.927200</td>\n",
       "      <td>1.200456</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.424773</td>\n",
       "      <td>0.397524</td>\n",
       "      <td>0.387342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.765300</td>\n",
       "      <td>1.161206</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.466654</td>\n",
       "      <td>0.441898</td>\n",
       "      <td>0.435175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.663400</td>\n",
       "      <td>1.118216</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.484968</td>\n",
       "      <td>0.468977</td>\n",
       "      <td>0.461270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.561000</td>\n",
       "      <td>1.074441</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.498167</td>\n",
       "      <td>0.478568</td>\n",
       "      <td>0.474920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.487100</td>\n",
       "      <td>1.074346</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.498869</td>\n",
       "      <td>0.475278</td>\n",
       "      <td>0.472714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.443200</td>\n",
       "      <td>1.043162</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.500836</td>\n",
       "      <td>0.485028</td>\n",
       "      <td>0.482313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.397300</td>\n",
       "      <td>1.031739</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.526694</td>\n",
       "      <td>0.488519</td>\n",
       "      <td>0.492769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.366700</td>\n",
       "      <td>1.026155</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.527459</td>\n",
       "      <td>0.497545</td>\n",
       "      <td>0.497976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.346300</td>\n",
       "      <td>1.013803</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.521832</td>\n",
       "      <td>0.491954</td>\n",
       "      <td>0.492613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.339600</td>\n",
       "      <td>1.015288</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.522431</td>\n",
       "      <td>0.494531</td>\n",
       "      <td>0.493685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:27:32,006] Trial 114 finished with value: 0.49368548676919993 and parameters: {'learning_rate': 0.0004945026061552231, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 76 with value: 0.49512573819371475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 115 with params: {'learning_rate': 0.00026416703012146944, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:47 < 00:24, 7.25 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.560200</td>\n",
       "      <td>3.196414</td>\n",
       "      <td>0.280477</td>\n",
       "      <td>0.052879</td>\n",
       "      <td>0.050474</td>\n",
       "      <td>0.042164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.960100</td>\n",
       "      <td>2.672429</td>\n",
       "      <td>0.445463</td>\n",
       "      <td>0.088480</td>\n",
       "      <td>0.111977</td>\n",
       "      <td>0.083375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.495500</td>\n",
       "      <td>2.261434</td>\n",
       "      <td>0.543538</td>\n",
       "      <td>0.224037</td>\n",
       "      <td>0.175602</td>\n",
       "      <td>0.162423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.108900</td>\n",
       "      <td>1.963060</td>\n",
       "      <td>0.618698</td>\n",
       "      <td>0.297387</td>\n",
       "      <td>0.254450</td>\n",
       "      <td>0.244191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.823700</td>\n",
       "      <td>1.740118</td>\n",
       "      <td>0.687443</td>\n",
       "      <td>0.343676</td>\n",
       "      <td>0.310678</td>\n",
       "      <td>0.300505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.570900</td>\n",
       "      <td>1.568848</td>\n",
       "      <td>0.709441</td>\n",
       "      <td>0.349397</td>\n",
       "      <td>0.334214</td>\n",
       "      <td>0.319070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.374500</td>\n",
       "      <td>1.457842</td>\n",
       "      <td>0.715857</td>\n",
       "      <td>0.328214</td>\n",
       "      <td>0.326805</td>\n",
       "      <td>0.310457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.247900</td>\n",
       "      <td>1.385273</td>\n",
       "      <td>0.733272</td>\n",
       "      <td>0.356894</td>\n",
       "      <td>0.370347</td>\n",
       "      <td>0.349510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.130400</td>\n",
       "      <td>1.325227</td>\n",
       "      <td>0.733272</td>\n",
       "      <td>0.358044</td>\n",
       "      <td>0.373017</td>\n",
       "      <td>0.354390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.031700</td>\n",
       "      <td>1.287468</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.400837</td>\n",
       "      <td>0.400018</td>\n",
       "      <td>0.382145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:28:21,059] Trial 115 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 116 with params: {'learning_rate': 0.0004916800693220012, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.393900</td>\n",
       "      <td>2.858529</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.069635</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.075009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.521100</td>\n",
       "      <td>2.162836</td>\n",
       "      <td>0.559120</td>\n",
       "      <td>0.203697</td>\n",
       "      <td>0.203198</td>\n",
       "      <td>0.190146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.892400</td>\n",
       "      <td>1.694171</td>\n",
       "      <td>0.663611</td>\n",
       "      <td>0.318071</td>\n",
       "      <td>0.298810</td>\n",
       "      <td>0.282187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.447800</td>\n",
       "      <td>1.437011</td>\n",
       "      <td>0.705775</td>\n",
       "      <td>0.340223</td>\n",
       "      <td>0.325755</td>\n",
       "      <td>0.309065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.152800</td>\n",
       "      <td>1.311699</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.403040</td>\n",
       "      <td>0.394174</td>\n",
       "      <td>0.373753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.933000</td>\n",
       "      <td>1.202207</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.424536</td>\n",
       "      <td>0.397524</td>\n",
       "      <td>0.387185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.770300</td>\n",
       "      <td>1.162640</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.466777</td>\n",
       "      <td>0.441898</td>\n",
       "      <td>0.435244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.667900</td>\n",
       "      <td>1.119958</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.485712</td>\n",
       "      <td>0.469705</td>\n",
       "      <td>0.462099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.565500</td>\n",
       "      <td>1.076307</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.493125</td>\n",
       "      <td>0.472068</td>\n",
       "      <td>0.467750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.491200</td>\n",
       "      <td>1.075393</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.498145</td>\n",
       "      <td>0.475278</td>\n",
       "      <td>0.472348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.447400</td>\n",
       "      <td>1.044599</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.500539</td>\n",
       "      <td>0.484193</td>\n",
       "      <td>0.481659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.401100</td>\n",
       "      <td>1.032688</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.505723</td>\n",
       "      <td>0.482307</td>\n",
       "      <td>0.482443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.370400</td>\n",
       "      <td>1.026899</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.527479</td>\n",
       "      <td>0.497909</td>\n",
       "      <td>0.498161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>1.014460</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.519989</td>\n",
       "      <td>0.489761</td>\n",
       "      <td>0.490360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.343400</td>\n",
       "      <td>1.015839</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.522004</td>\n",
       "      <td>0.494531</td>\n",
       "      <td>0.493501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:29:36,237] Trial 116 finished with value: 0.49350096410753225 and parameters: {'learning_rate': 0.0004916800693220012, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 76 with value: 0.49512573819371475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 117 with params: {'learning_rate': 0.0004992299509401581, 'weight_decay': 0.01, 'warmup_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.375800</td>\n",
       "      <td>2.842826</td>\n",
       "      <td>0.422548</td>\n",
       "      <td>0.069045</td>\n",
       "      <td>0.098602</td>\n",
       "      <td>0.075809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.505100</td>\n",
       "      <td>2.156591</td>\n",
       "      <td>0.551787</td>\n",
       "      <td>0.221227</td>\n",
       "      <td>0.196440</td>\n",
       "      <td>0.182852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.885200</td>\n",
       "      <td>1.686922</td>\n",
       "      <td>0.664528</td>\n",
       "      <td>0.309956</td>\n",
       "      <td>0.292118</td>\n",
       "      <td>0.273914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.442700</td>\n",
       "      <td>1.428576</td>\n",
       "      <td>0.699358</td>\n",
       "      <td>0.331414</td>\n",
       "      <td>0.317212</td>\n",
       "      <td>0.298908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.138800</td>\n",
       "      <td>1.298303</td>\n",
       "      <td>0.729606</td>\n",
       "      <td>0.375654</td>\n",
       "      <td>0.377573</td>\n",
       "      <td>0.353403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.924700</td>\n",
       "      <td>1.187511</td>\n",
       "      <td>0.747938</td>\n",
       "      <td>0.434147</td>\n",
       "      <td>0.413052</td>\n",
       "      <td>0.402580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.760900</td>\n",
       "      <td>1.147887</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.490556</td>\n",
       "      <td>0.461495</td>\n",
       "      <td>0.457366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.658100</td>\n",
       "      <td>1.107538</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.476980</td>\n",
       "      <td>0.460492</td>\n",
       "      <td>0.451546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.560800</td>\n",
       "      <td>1.061445</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.475030</td>\n",
       "      <td>0.480804</td>\n",
       "      <td>0.470651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.484900</td>\n",
       "      <td>1.058895</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.481667</td>\n",
       "      <td>0.486357</td>\n",
       "      <td>0.472574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.439800</td>\n",
       "      <td>1.041447</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.492473</td>\n",
       "      <td>0.491018</td>\n",
       "      <td>0.484617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.393800</td>\n",
       "      <td>1.032865</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.489516</td>\n",
       "      <td>0.481880</td>\n",
       "      <td>0.476453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.363800</td>\n",
       "      <td>1.024299</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.495833</td>\n",
       "      <td>0.492365</td>\n",
       "      <td>0.484327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.340600</td>\n",
       "      <td>1.009318</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.490223</td>\n",
       "      <td>0.484839</td>\n",
       "      <td>0.479287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.333700</td>\n",
       "      <td>1.013932</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.479456</td>\n",
       "      <td>0.492568</td>\n",
       "      <td>0.480425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:30:51,774] Trial 117 finished with value: 0.4804248634263685 and parameters: {'learning_rate': 0.0004992299509401581, 'weight_decay': 0.01, 'warmup_steps': 3}. Best is trial 76 with value: 0.49512573819371475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 118 with params: {'learning_rate': 0.0004786243541734559, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.402300</td>\n",
       "      <td>2.874341</td>\n",
       "      <td>0.416132</td>\n",
       "      <td>0.073266</td>\n",
       "      <td>0.095070</td>\n",
       "      <td>0.073949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.541500</td>\n",
       "      <td>2.185417</td>\n",
       "      <td>0.557287</td>\n",
       "      <td>0.204342</td>\n",
       "      <td>0.201261</td>\n",
       "      <td>0.189003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.920400</td>\n",
       "      <td>1.719289</td>\n",
       "      <td>0.661778</td>\n",
       "      <td>0.323261</td>\n",
       "      <td>0.295682</td>\n",
       "      <td>0.278947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.475800</td>\n",
       "      <td>1.456142</td>\n",
       "      <td>0.703941</td>\n",
       "      <td>0.320664</td>\n",
       "      <td>0.327614</td>\n",
       "      <td>0.309269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.180500</td>\n",
       "      <td>1.327179</td>\n",
       "      <td>0.736939</td>\n",
       "      <td>0.422487</td>\n",
       "      <td>0.394329</td>\n",
       "      <td>0.375017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.960300</td>\n",
       "      <td>1.210731</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.423344</td>\n",
       "      <td>0.403472</td>\n",
       "      <td>0.390289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.793700</td>\n",
       "      <td>1.168683</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.471726</td>\n",
       "      <td>0.432778</td>\n",
       "      <td>0.427525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.688900</td>\n",
       "      <td>1.130394</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.485004</td>\n",
       "      <td>0.465576</td>\n",
       "      <td>0.455702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.586100</td>\n",
       "      <td>1.085466</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.492553</td>\n",
       "      <td>0.470577</td>\n",
       "      <td>0.466042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.510200</td>\n",
       "      <td>1.081427</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.495043</td>\n",
       "      <td>0.479605</td>\n",
       "      <td>0.474287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.467000</td>\n",
       "      <td>1.051869</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.501886</td>\n",
       "      <td>0.484135</td>\n",
       "      <td>0.481776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.418600</td>\n",
       "      <td>1.039094</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.498257</td>\n",
       "      <td>0.482689</td>\n",
       "      <td>0.479673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.387900</td>\n",
       "      <td>1.032475</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.517328</td>\n",
       "      <td>0.492593</td>\n",
       "      <td>0.493350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.367400</td>\n",
       "      <td>1.020259</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.519760</td>\n",
       "      <td>0.489594</td>\n",
       "      <td>0.490279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.360500</td>\n",
       "      <td>1.021071</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.521865</td>\n",
       "      <td>0.494132</td>\n",
       "      <td>0.493836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:32:06,337] Trial 118 finished with value: 0.49383561910564167 and parameters: {'learning_rate': 0.0004786243541734559, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 76 with value: 0.49512573819371475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 119 with params: {'learning_rate': 0.00040445359844411326, 'weight_decay': 0.008, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:24 < 00:48, 7.16 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.452300</td>\n",
       "      <td>2.973830</td>\n",
       "      <td>0.383135</td>\n",
       "      <td>0.058315</td>\n",
       "      <td>0.081847</td>\n",
       "      <td>0.060415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.666200</td>\n",
       "      <td>2.322635</td>\n",
       "      <td>0.517874</td>\n",
       "      <td>0.195563</td>\n",
       "      <td>0.157886</td>\n",
       "      <td>0.141917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.083500</td>\n",
       "      <td>1.854123</td>\n",
       "      <td>0.648946</td>\n",
       "      <td>0.322769</td>\n",
       "      <td>0.272620</td>\n",
       "      <td>0.262265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.647700</td>\n",
       "      <td>1.583000</td>\n",
       "      <td>0.694775</td>\n",
       "      <td>0.327569</td>\n",
       "      <td>0.328603</td>\n",
       "      <td>0.309047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.344000</td>\n",
       "      <td>1.414740</td>\n",
       "      <td>0.722273</td>\n",
       "      <td>0.348121</td>\n",
       "      <td>0.362648</td>\n",
       "      <td>0.337914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:32:31,492] Trial 119 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 120 with params: {'learning_rate': 0.00024478411375852566, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:51 < 00:25, 6.74 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.578300</td>\n",
       "      <td>3.230712</td>\n",
       "      <td>0.236480</td>\n",
       "      <td>0.057807</td>\n",
       "      <td>0.036983</td>\n",
       "      <td>0.029795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.008200</td>\n",
       "      <td>2.733180</td>\n",
       "      <td>0.444546</td>\n",
       "      <td>0.102438</td>\n",
       "      <td>0.111399</td>\n",
       "      <td>0.083169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.565900</td>\n",
       "      <td>2.337779</td>\n",
       "      <td>0.513291</td>\n",
       "      <td>0.161138</td>\n",
       "      <td>0.151182</td>\n",
       "      <td>0.132538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.193900</td>\n",
       "      <td>2.040452</td>\n",
       "      <td>0.600367</td>\n",
       "      <td>0.265057</td>\n",
       "      <td>0.224762</td>\n",
       "      <td>0.211012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.917900</td>\n",
       "      <td>1.815497</td>\n",
       "      <td>0.671861</td>\n",
       "      <td>0.341920</td>\n",
       "      <td>0.296111</td>\n",
       "      <td>0.288936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.663700</td>\n",
       "      <td>1.641236</td>\n",
       "      <td>0.694775</td>\n",
       "      <td>0.372852</td>\n",
       "      <td>0.317620</td>\n",
       "      <td>0.309977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.467800</td>\n",
       "      <td>1.522181</td>\n",
       "      <td>0.705775</td>\n",
       "      <td>0.354919</td>\n",
       "      <td>0.327958</td>\n",
       "      <td>0.314816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.340200</td>\n",
       "      <td>1.440637</td>\n",
       "      <td>0.725023</td>\n",
       "      <td>0.351831</td>\n",
       "      <td>0.358146</td>\n",
       "      <td>0.338073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.218000</td>\n",
       "      <td>1.377206</td>\n",
       "      <td>0.726856</td>\n",
       "      <td>0.357916</td>\n",
       "      <td>0.364490</td>\n",
       "      <td>0.346889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.117400</td>\n",
       "      <td>1.334143</td>\n",
       "      <td>0.742438</td>\n",
       "      <td>0.388714</td>\n",
       "      <td>0.392359</td>\n",
       "      <td>0.374888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:33:24,074] Trial 120 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 121 with params: {'learning_rate': 0.00048378175700342476, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.399000</td>\n",
       "      <td>2.868060</td>\n",
       "      <td>0.418882</td>\n",
       "      <td>0.072621</td>\n",
       "      <td>0.096599</td>\n",
       "      <td>0.075012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.533300</td>\n",
       "      <td>2.176404</td>\n",
       "      <td>0.558203</td>\n",
       "      <td>0.204267</td>\n",
       "      <td>0.200698</td>\n",
       "      <td>0.188367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.909300</td>\n",
       "      <td>1.709809</td>\n",
       "      <td>0.660862</td>\n",
       "      <td>0.318084</td>\n",
       "      <td>0.295444</td>\n",
       "      <td>0.278348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.464500</td>\n",
       "      <td>1.448442</td>\n",
       "      <td>0.703941</td>\n",
       "      <td>0.318829</td>\n",
       "      <td>0.322993</td>\n",
       "      <td>0.304729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.169400</td>\n",
       "      <td>1.320303</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.423368</td>\n",
       "      <td>0.396147</td>\n",
       "      <td>0.378480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.949800</td>\n",
       "      <td>1.206619</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.431677</td>\n",
       "      <td>0.406304</td>\n",
       "      <td>0.394044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.784500</td>\n",
       "      <td>1.165980</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.472005</td>\n",
       "      <td>0.433129</td>\n",
       "      <td>0.427842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.680800</td>\n",
       "      <td>1.125892</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.463909</td>\n",
       "      <td>0.455536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.578100</td>\n",
       "      <td>1.081894</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.489174</td>\n",
       "      <td>0.470577</td>\n",
       "      <td>0.466453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.502700</td>\n",
       "      <td>1.079244</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.499903</td>\n",
       "      <td>0.478790</td>\n",
       "      <td>0.474663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.459400</td>\n",
       "      <td>1.049362</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.502998</td>\n",
       "      <td>0.484284</td>\n",
       "      <td>0.482308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.411700</td>\n",
       "      <td>1.036484</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.503220</td>\n",
       "      <td>0.482473</td>\n",
       "      <td>0.481095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.380900</td>\n",
       "      <td>1.030343</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.528497</td>\n",
       "      <td>0.497215</td>\n",
       "      <td>0.498830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.360600</td>\n",
       "      <td>1.017829</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.520612</td>\n",
       "      <td>0.490087</td>\n",
       "      <td>0.490907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.353700</td>\n",
       "      <td>1.018911</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.520769</td>\n",
       "      <td>0.493917</td>\n",
       "      <td>0.492747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:34:38,541] Trial 121 finished with value: 0.49274666962222324 and parameters: {'learning_rate': 0.00048378175700342476, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 76 with value: 0.49512573819371475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 122 with params: {'learning_rate': 0.0004856841372806926, 'weight_decay': 0.009000000000000001, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.397700</td>\n",
       "      <td>2.865701</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.072784</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.075681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.530200</td>\n",
       "      <td>2.173035</td>\n",
       "      <td>0.558203</td>\n",
       "      <td>0.204267</td>\n",
       "      <td>0.200698</td>\n",
       "      <td>0.188367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.905200</td>\n",
       "      <td>1.706056</td>\n",
       "      <td>0.660862</td>\n",
       "      <td>0.318084</td>\n",
       "      <td>0.295444</td>\n",
       "      <td>0.278348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.460300</td>\n",
       "      <td>1.445594</td>\n",
       "      <td>0.703941</td>\n",
       "      <td>0.318829</td>\n",
       "      <td>0.322993</td>\n",
       "      <td>0.304729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.165300</td>\n",
       "      <td>1.318086</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.423368</td>\n",
       "      <td>0.396147</td>\n",
       "      <td>0.378480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.946000</td>\n",
       "      <td>1.205174</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.424959</td>\n",
       "      <td>0.397842</td>\n",
       "      <td>0.386679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.781300</td>\n",
       "      <td>1.165063</td>\n",
       "      <td>0.747938</td>\n",
       "      <td>0.470808</td>\n",
       "      <td>0.432640</td>\n",
       "      <td>0.427022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.677900</td>\n",
       "      <td>1.124496</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.485034</td>\n",
       "      <td>0.463909</td>\n",
       "      <td>0.455596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.575200</td>\n",
       "      <td>1.080860</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.489714</td>\n",
       "      <td>0.470815</td>\n",
       "      <td>0.466947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.078531</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.500952</td>\n",
       "      <td>0.478790</td>\n",
       "      <td>0.475556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.456600</td>\n",
       "      <td>1.048295</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.501284</td>\n",
       "      <td>0.483341</td>\n",
       "      <td>0.481381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.409200</td>\n",
       "      <td>1.035459</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.503220</td>\n",
       "      <td>0.482473</td>\n",
       "      <td>0.481095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.378300</td>\n",
       "      <td>1.029560</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.528536</td>\n",
       "      <td>0.497578</td>\n",
       "      <td>0.499002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.358100</td>\n",
       "      <td>1.016946</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.519604</td>\n",
       "      <td>0.489523</td>\n",
       "      <td>0.490111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.351200</td>\n",
       "      <td>1.018152</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.524295</td>\n",
       "      <td>0.495346</td>\n",
       "      <td>0.493931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:35:52,643] Trial 122 finished with value: 0.4939308180319757 and parameters: {'learning_rate': 0.0004856841372806926, 'weight_decay': 0.009000000000000001, 'warmup_steps': 4}. Best is trial 76 with value: 0.49512573819371475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 123 with params: {'learning_rate': 0.0004503996218356186, 'weight_decay': 0.007, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:47 < 00:24, 7.28 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.421100</td>\n",
       "      <td>2.911178</td>\n",
       "      <td>0.404216</td>\n",
       "      <td>0.074356</td>\n",
       "      <td>0.088787</td>\n",
       "      <td>0.067151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.588900</td>\n",
       "      <td>2.237041</td>\n",
       "      <td>0.535289</td>\n",
       "      <td>0.191229</td>\n",
       "      <td>0.170344</td>\n",
       "      <td>0.155340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.980500</td>\n",
       "      <td>1.766498</td>\n",
       "      <td>0.653529</td>\n",
       "      <td>0.317197</td>\n",
       "      <td>0.285500</td>\n",
       "      <td>0.269348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.540000</td>\n",
       "      <td>1.501245</td>\n",
       "      <td>0.699358</td>\n",
       "      <td>0.319688</td>\n",
       "      <td>0.330074</td>\n",
       "      <td>0.310374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.238600</td>\n",
       "      <td>1.362768</td>\n",
       "      <td>0.732356</td>\n",
       "      <td>0.403279</td>\n",
       "      <td>0.393547</td>\n",
       "      <td>0.376189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.015300</td>\n",
       "      <td>1.230258</td>\n",
       "      <td>0.744271</td>\n",
       "      <td>0.427764</td>\n",
       "      <td>0.392761</td>\n",
       "      <td>0.377585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.844100</td>\n",
       "      <td>1.184173</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.468781</td>\n",
       "      <td>0.434866</td>\n",
       "      <td>0.427943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.734400</td>\n",
       "      <td>1.142923</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.478159</td>\n",
       "      <td>0.461078</td>\n",
       "      <td>0.450575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.632500</td>\n",
       "      <td>1.093905</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.472806</td>\n",
       "      <td>0.471586</td>\n",
       "      <td>0.461346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.553900</td>\n",
       "      <td>1.087588</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.488917</td>\n",
       "      <td>0.475105</td>\n",
       "      <td>0.468478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:36:41,363] Trial 123 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 124 with params: {'learning_rate': 0.00047790473433313534, 'weight_decay': 0.009000000000000001, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.402700</td>\n",
       "      <td>2.875190</td>\n",
       "      <td>0.416132</td>\n",
       "      <td>0.073324</td>\n",
       "      <td>0.095070</td>\n",
       "      <td>0.073998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.542700</td>\n",
       "      <td>2.186659</td>\n",
       "      <td>0.557287</td>\n",
       "      <td>0.204342</td>\n",
       "      <td>0.201261</td>\n",
       "      <td>0.189003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.921900</td>\n",
       "      <td>1.720538</td>\n",
       "      <td>0.661778</td>\n",
       "      <td>0.323261</td>\n",
       "      <td>0.295682</td>\n",
       "      <td>0.278947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.477400</td>\n",
       "      <td>1.457179</td>\n",
       "      <td>0.703941</td>\n",
       "      <td>0.320664</td>\n",
       "      <td>0.327614</td>\n",
       "      <td>0.309269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.182100</td>\n",
       "      <td>1.328163</td>\n",
       "      <td>0.736939</td>\n",
       "      <td>0.422487</td>\n",
       "      <td>0.394329</td>\n",
       "      <td>0.375017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.961800</td>\n",
       "      <td>1.211097</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.423344</td>\n",
       "      <td>0.403472</td>\n",
       "      <td>0.390289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.795000</td>\n",
       "      <td>1.168859</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.471270</td>\n",
       "      <td>0.432324</td>\n",
       "      <td>0.427053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>1.130732</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.485004</td>\n",
       "      <td>0.465576</td>\n",
       "      <td>0.455702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.587200</td>\n",
       "      <td>1.085546</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.492330</td>\n",
       "      <td>0.470123</td>\n",
       "      <td>0.465686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.511100</td>\n",
       "      <td>1.081478</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.496111</td>\n",
       "      <td>0.480330</td>\n",
       "      <td>0.475565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.468000</td>\n",
       "      <td>1.051963</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.501886</td>\n",
       "      <td>0.484135</td>\n",
       "      <td>0.481776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.419500</td>\n",
       "      <td>1.039197</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.498257</td>\n",
       "      <td>0.482689</td>\n",
       "      <td>0.479673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.388900</td>\n",
       "      <td>1.032524</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.517530</td>\n",
       "      <td>0.492831</td>\n",
       "      <td>0.493583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.368300</td>\n",
       "      <td>1.020433</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.519760</td>\n",
       "      <td>0.489594</td>\n",
       "      <td>0.490279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.361500</td>\n",
       "      <td>1.021134</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.523183</td>\n",
       "      <td>0.494659</td>\n",
       "      <td>0.495126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:37:56,028] Trial 124 finished with value: 0.49512573819371475 and parameters: {'learning_rate': 0.00047790473433313534, 'weight_decay': 0.009000000000000001, 'warmup_steps': 4}. Best is trial 76 with value: 0.49512573819371475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 125 with params: {'learning_rate': 0.0003123229260555052, 'weight_decay': 0.007, 'warmup_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:24 < 00:49, 7.12 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.509000</td>\n",
       "      <td>3.101861</td>\n",
       "      <td>0.344638</td>\n",
       "      <td>0.069685</td>\n",
       "      <td>0.070690</td>\n",
       "      <td>0.057467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.841500</td>\n",
       "      <td>2.531314</td>\n",
       "      <td>0.457379</td>\n",
       "      <td>0.118427</td>\n",
       "      <td>0.115340</td>\n",
       "      <td>0.084898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.330800</td>\n",
       "      <td>2.095087</td>\n",
       "      <td>0.571036</td>\n",
       "      <td>0.244782</td>\n",
       "      <td>0.196157</td>\n",
       "      <td>0.185201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.923000</td>\n",
       "      <td>1.808116</td>\n",
       "      <td>0.665445</td>\n",
       "      <td>0.325007</td>\n",
       "      <td>0.290044</td>\n",
       "      <td>0.277391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.631600</td>\n",
       "      <td>1.597876</td>\n",
       "      <td>0.715857</td>\n",
       "      <td>0.375561</td>\n",
       "      <td>0.352731</td>\n",
       "      <td>0.336322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:38:21,190] Trial 125 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 126 with params: {'learning_rate': 0.00016493249354712237, 'weight_decay': 0.003, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:52 < 00:26, 6.60 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.654900</td>\n",
       "      <td>3.385263</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.217900</td>\n",
       "      <td>3.001925</td>\n",
       "      <td>0.397800</td>\n",
       "      <td>0.096155</td>\n",
       "      <td>0.086424</td>\n",
       "      <td>0.065903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.879900</td>\n",
       "      <td>2.678030</td>\n",
       "      <td>0.459212</td>\n",
       "      <td>0.103277</td>\n",
       "      <td>0.115855</td>\n",
       "      <td>0.092144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.574000</td>\n",
       "      <td>2.416856</td>\n",
       "      <td>0.515124</td>\n",
       "      <td>0.135860</td>\n",
       "      <td>0.151612</td>\n",
       "      <td>0.129451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.349200</td>\n",
       "      <td>2.205925</td>\n",
       "      <td>0.568286</td>\n",
       "      <td>0.234598</td>\n",
       "      <td>0.192913</td>\n",
       "      <td>0.178294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.122600</td>\n",
       "      <td>2.039168</td>\n",
       "      <td>0.597617</td>\n",
       "      <td>0.248448</td>\n",
       "      <td>0.222096</td>\n",
       "      <td>0.207890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.946800</td>\n",
       "      <td>1.910382</td>\n",
       "      <td>0.637030</td>\n",
       "      <td>0.333950</td>\n",
       "      <td>0.261839</td>\n",
       "      <td>0.254531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.823500</td>\n",
       "      <td>1.809226</td>\n",
       "      <td>0.671861</td>\n",
       "      <td>0.351870</td>\n",
       "      <td>0.291112</td>\n",
       "      <td>0.280710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.696400</td>\n",
       "      <td>1.721316</td>\n",
       "      <td>0.686526</td>\n",
       "      <td>0.358326</td>\n",
       "      <td>0.305196</td>\n",
       "      <td>0.296959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.597800</td>\n",
       "      <td>1.659485</td>\n",
       "      <td>0.696609</td>\n",
       "      <td>0.375801</td>\n",
       "      <td>0.324410</td>\n",
       "      <td>0.315528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:39:15,002] Trial 126 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 127 with params: {'learning_rate': 0.0004766896385689301, 'weight_decay': 0.008, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:48 < 00:24, 7.21 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.403500</td>\n",
       "      <td>2.876704</td>\n",
       "      <td>0.415215</td>\n",
       "      <td>0.073270</td>\n",
       "      <td>0.094855</td>\n",
       "      <td>0.073856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.544700</td>\n",
       "      <td>2.188869</td>\n",
       "      <td>0.557287</td>\n",
       "      <td>0.204342</td>\n",
       "      <td>0.201261</td>\n",
       "      <td>0.189003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.924600</td>\n",
       "      <td>1.722777</td>\n",
       "      <td>0.660862</td>\n",
       "      <td>0.324082</td>\n",
       "      <td>0.294254</td>\n",
       "      <td>0.276990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.480100</td>\n",
       "      <td>1.459115</td>\n",
       "      <td>0.704858</td>\n",
       "      <td>0.321851</td>\n",
       "      <td>0.328069</td>\n",
       "      <td>0.310056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.184700</td>\n",
       "      <td>1.329719</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.422646</td>\n",
       "      <td>0.393965</td>\n",
       "      <td>0.374772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.964300</td>\n",
       "      <td>1.212033</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.425314</td>\n",
       "      <td>0.403998</td>\n",
       "      <td>0.391065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.797100</td>\n",
       "      <td>1.169610</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.471361</td>\n",
       "      <td>0.432711</td>\n",
       "      <td>0.427201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.691900</td>\n",
       "      <td>1.131784</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.485114</td>\n",
       "      <td>0.465576</td>\n",
       "      <td>0.455763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.589100</td>\n",
       "      <td>1.086402</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.492386</td>\n",
       "      <td>0.470123</td>\n",
       "      <td>0.465707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.512900</td>\n",
       "      <td>1.082123</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.486008</td>\n",
       "      <td>0.475073</td>\n",
       "      <td>0.470392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:40:04,261] Trial 127 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 128 with params: {'learning_rate': 0.000493278523740113, 'weight_decay': 0.008, 'warmup_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.379700</td>\n",
       "      <td>2.851677</td>\n",
       "      <td>0.417049</td>\n",
       "      <td>0.069731</td>\n",
       "      <td>0.096733</td>\n",
       "      <td>0.074754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.514000</td>\n",
       "      <td>2.165776</td>\n",
       "      <td>0.549954</td>\n",
       "      <td>0.231910</td>\n",
       "      <td>0.193026</td>\n",
       "      <td>0.182253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.896100</td>\n",
       "      <td>1.694144</td>\n",
       "      <td>0.666361</td>\n",
       "      <td>0.307872</td>\n",
       "      <td>0.292515</td>\n",
       "      <td>0.274638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.452300</td>\n",
       "      <td>1.434355</td>\n",
       "      <td>0.703025</td>\n",
       "      <td>0.335061</td>\n",
       "      <td>0.322318</td>\n",
       "      <td>0.302572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.149200</td>\n",
       "      <td>1.304049</td>\n",
       "      <td>0.731439</td>\n",
       "      <td>0.367310</td>\n",
       "      <td>0.377677</td>\n",
       "      <td>0.352540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.933900</td>\n",
       "      <td>1.189078</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.444403</td>\n",
       "      <td>0.413966</td>\n",
       "      <td>0.403576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.767800</td>\n",
       "      <td>1.145568</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.456534</td>\n",
       "      <td>0.450053</td>\n",
       "      <td>0.438433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.664300</td>\n",
       "      <td>1.106674</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.469371</td>\n",
       "      <td>0.460728</td>\n",
       "      <td>0.449860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.566400</td>\n",
       "      <td>1.060920</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.473290</td>\n",
       "      <td>0.474407</td>\n",
       "      <td>0.464983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.491300</td>\n",
       "      <td>1.057953</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.485180</td>\n",
       "      <td>0.486312</td>\n",
       "      <td>0.475717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.446000</td>\n",
       "      <td>1.039333</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.483822</td>\n",
       "      <td>0.482408</td>\n",
       "      <td>0.475527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.031621</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.489183</td>\n",
       "      <td>0.478151</td>\n",
       "      <td>0.474094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.369700</td>\n",
       "      <td>1.023361</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.494938</td>\n",
       "      <td>0.491456</td>\n",
       "      <td>0.483395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.346500</td>\n",
       "      <td>1.007655</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.488545</td>\n",
       "      <td>0.485889</td>\n",
       "      <td>0.478708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.339900</td>\n",
       "      <td>1.011707</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.490141</td>\n",
       "      <td>0.493618</td>\n",
       "      <td>0.484722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:41:18,373] Trial 128 finished with value: 0.48472228234703374 and parameters: {'learning_rate': 0.000493278523740113, 'weight_decay': 0.008, 'warmup_steps': 3}. Best is trial 76 with value: 0.49512573819371475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 129 with params: {'learning_rate': 0.0004549691178367605, 'weight_decay': 0.008, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.418000</td>\n",
       "      <td>2.905128</td>\n",
       "      <td>0.405133</td>\n",
       "      <td>0.074470</td>\n",
       "      <td>0.089026</td>\n",
       "      <td>0.067183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.581000</td>\n",
       "      <td>2.228410</td>\n",
       "      <td>0.539872</td>\n",
       "      <td>0.192726</td>\n",
       "      <td>0.176076</td>\n",
       "      <td>0.162951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.970700</td>\n",
       "      <td>1.758725</td>\n",
       "      <td>0.654445</td>\n",
       "      <td>0.319288</td>\n",
       "      <td>0.287166</td>\n",
       "      <td>0.271520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.529400</td>\n",
       "      <td>1.493522</td>\n",
       "      <td>0.699358</td>\n",
       "      <td>0.314411</td>\n",
       "      <td>0.320528</td>\n",
       "      <td>0.301436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.229100</td>\n",
       "      <td>1.357176</td>\n",
       "      <td>0.731439</td>\n",
       "      <td>0.409601</td>\n",
       "      <td>0.392940</td>\n",
       "      <td>0.375134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.006000</td>\n",
       "      <td>1.227088</td>\n",
       "      <td>0.744271</td>\n",
       "      <td>0.430262</td>\n",
       "      <td>0.392761</td>\n",
       "      <td>0.378316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.835400</td>\n",
       "      <td>1.181456</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.472014</td>\n",
       "      <td>0.434703</td>\n",
       "      <td>0.427736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.726400</td>\n",
       "      <td>1.141078</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.477854</td>\n",
       "      <td>0.460967</td>\n",
       "      <td>0.449671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.624300</td>\n",
       "      <td>1.091576</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.472394</td>\n",
       "      <td>0.470458</td>\n",
       "      <td>0.460487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.546100</td>\n",
       "      <td>1.085747</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.494780</td>\n",
       "      <td>0.475001</td>\n",
       "      <td>0.470778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.504300</td>\n",
       "      <td>1.057502</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.491213</td>\n",
       "      <td>0.479107</td>\n",
       "      <td>0.476090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.451000</td>\n",
       "      <td>1.044659</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.497304</td>\n",
       "      <td>0.479316</td>\n",
       "      <td>0.475998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.421200</td>\n",
       "      <td>1.035976</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.490522</td>\n",
       "      <td>0.483736</td>\n",
       "      <td>0.479699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.399300</td>\n",
       "      <td>1.024940</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.505880</td>\n",
       "      <td>0.486246</td>\n",
       "      <td>0.485242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.392800</td>\n",
       "      <td>1.024747</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.494685</td>\n",
       "      <td>0.487278</td>\n",
       "      <td>0.482344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:42:33,814] Trial 129 finished with value: 0.4823436487486139 and parameters: {'learning_rate': 0.0004549691178367605, 'weight_decay': 0.008, 'warmup_steps': 4}. Best is trial 76 with value: 0.49512573819371475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 130 with params: {'learning_rate': 0.00023807843458688047, 'weight_decay': 0.008, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:48 < 00:24, 7.13 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.584400</td>\n",
       "      <td>3.242517</td>\n",
       "      <td>0.219982</td>\n",
       "      <td>0.057301</td>\n",
       "      <td>0.032374</td>\n",
       "      <td>0.024981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.024900</td>\n",
       "      <td>2.754919</td>\n",
       "      <td>0.441797</td>\n",
       "      <td>0.102391</td>\n",
       "      <td>0.109703</td>\n",
       "      <td>0.083101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.591000</td>\n",
       "      <td>2.365017</td>\n",
       "      <td>0.509624</td>\n",
       "      <td>0.145469</td>\n",
       "      <td>0.145952</td>\n",
       "      <td>0.124114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.224200</td>\n",
       "      <td>2.069152</td>\n",
       "      <td>0.587534</td>\n",
       "      <td>0.249377</td>\n",
       "      <td>0.213992</td>\n",
       "      <td>0.201064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.951700</td>\n",
       "      <td>1.844462</td>\n",
       "      <td>0.659945</td>\n",
       "      <td>0.343028</td>\n",
       "      <td>0.289832</td>\n",
       "      <td>0.283872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.697900</td>\n",
       "      <td>1.668775</td>\n",
       "      <td>0.692942</td>\n",
       "      <td>0.373803</td>\n",
       "      <td>0.315035</td>\n",
       "      <td>0.309227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.502600</td>\n",
       "      <td>1.548050</td>\n",
       "      <td>0.700275</td>\n",
       "      <td>0.363330</td>\n",
       "      <td>0.322359</td>\n",
       "      <td>0.313557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.375600</td>\n",
       "      <td>1.464579</td>\n",
       "      <td>0.722273</td>\n",
       "      <td>0.362740</td>\n",
       "      <td>0.355773</td>\n",
       "      <td>0.335587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.252600</td>\n",
       "      <td>1.399572</td>\n",
       "      <td>0.722273</td>\n",
       "      <td>0.354188</td>\n",
       "      <td>0.358438</td>\n",
       "      <td>0.341383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.151400</td>\n",
       "      <td>1.353789</td>\n",
       "      <td>0.736939</td>\n",
       "      <td>0.395128</td>\n",
       "      <td>0.387592</td>\n",
       "      <td>0.374138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:43:23,537] Trial 130 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 131 with params: {'learning_rate': 0.00049949628158781, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:48 < 00:24, 7.15 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.389000</td>\n",
       "      <td>2.849451</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.069605</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.075081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.510000</td>\n",
       "      <td>2.150704</td>\n",
       "      <td>0.561870</td>\n",
       "      <td>0.204292</td>\n",
       "      <td>0.204820</td>\n",
       "      <td>0.191348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.876800</td>\n",
       "      <td>1.678876</td>\n",
       "      <td>0.669111</td>\n",
       "      <td>0.314499</td>\n",
       "      <td>0.300366</td>\n",
       "      <td>0.282516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.430900</td>\n",
       "      <td>1.425327</td>\n",
       "      <td>0.706691</td>\n",
       "      <td>0.332563</td>\n",
       "      <td>0.328720</td>\n",
       "      <td>0.311374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.135100</td>\n",
       "      <td>1.302924</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.401236</td>\n",
       "      <td>0.391414</td>\n",
       "      <td>0.371324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.915500</td>\n",
       "      <td>1.195235</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.426857</td>\n",
       "      <td>0.397452</td>\n",
       "      <td>0.387732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.756200</td>\n",
       "      <td>1.156881</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.487391</td>\n",
       "      <td>0.444946</td>\n",
       "      <td>0.440355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.654900</td>\n",
       "      <td>1.114696</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.487801</td>\n",
       "      <td>0.468737</td>\n",
       "      <td>0.462692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.553000</td>\n",
       "      <td>1.068600</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.498785</td>\n",
       "      <td>0.479003</td>\n",
       "      <td>0.475628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.479800</td>\n",
       "      <td>1.070531</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.497727</td>\n",
       "      <td>0.473617</td>\n",
       "      <td>0.471398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:44:13,156] Trial 131 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 132 with params: {'learning_rate': 0.0004675471848767979, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:11, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.409500</td>\n",
       "      <td>2.888221</td>\n",
       "      <td>0.411549</td>\n",
       "      <td>0.073970</td>\n",
       "      <td>0.092682</td>\n",
       "      <td>0.071857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.559900</td>\n",
       "      <td>2.205234</td>\n",
       "      <td>0.552704</td>\n",
       "      <td>0.194681</td>\n",
       "      <td>0.188624</td>\n",
       "      <td>0.175186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.944400</td>\n",
       "      <td>1.738576</td>\n",
       "      <td>0.660862</td>\n",
       "      <td>0.320815</td>\n",
       "      <td>0.296369</td>\n",
       "      <td>0.278890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.500900</td>\n",
       "      <td>1.473160</td>\n",
       "      <td>0.702108</td>\n",
       "      <td>0.319815</td>\n",
       "      <td>0.326341</td>\n",
       "      <td>0.308155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.203900</td>\n",
       "      <td>1.341038</td>\n",
       "      <td>0.734189</td>\n",
       "      <td>0.401697</td>\n",
       "      <td>0.397139</td>\n",
       "      <td>0.378235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.982100</td>\n",
       "      <td>1.218439</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.430428</td>\n",
       "      <td>0.402634</td>\n",
       "      <td>0.389604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.812900</td>\n",
       "      <td>1.174995</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.461115</td>\n",
       "      <td>0.432348</td>\n",
       "      <td>0.425122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.706000</td>\n",
       "      <td>1.137654</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.488717</td>\n",
       "      <td>0.462737</td>\n",
       "      <td>0.453068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.603700</td>\n",
       "      <td>1.090633</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.490293</td>\n",
       "      <td>0.470158</td>\n",
       "      <td>0.464413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.526500</td>\n",
       "      <td>1.084952</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.492305</td>\n",
       "      <td>0.475982</td>\n",
       "      <td>0.471981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.483700</td>\n",
       "      <td>1.055800</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.496886</td>\n",
       "      <td>0.477708</td>\n",
       "      <td>0.475201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.433600</td>\n",
       "      <td>1.043575</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.496758</td>\n",
       "      <td>0.483176</td>\n",
       "      <td>0.479596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.403300</td>\n",
       "      <td>1.035591</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.514880</td>\n",
       "      <td>0.493650</td>\n",
       "      <td>0.492446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.382100</td>\n",
       "      <td>1.024538</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.523649</td>\n",
       "      <td>0.492963</td>\n",
       "      <td>0.493645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.375400</td>\n",
       "      <td>1.024778</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.524676</td>\n",
       "      <td>0.495477</td>\n",
       "      <td>0.495787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:45:26,822] Trial 132 finished with value: 0.49578714001038604 and parameters: {'learning_rate': 0.0004675471848767979, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 132 with value: 0.49578714001038604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 133 with params: {'learning_rate': 0.0004933610668245446, 'weight_decay': 0.008, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.392900</td>\n",
       "      <td>2.856595</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.069635</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.075009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.518700</td>\n",
       "      <td>2.160136</td>\n",
       "      <td>0.560037</td>\n",
       "      <td>0.204100</td>\n",
       "      <td>0.204150</td>\n",
       "      <td>0.190879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.889000</td>\n",
       "      <td>1.690896</td>\n",
       "      <td>0.663611</td>\n",
       "      <td>0.317747</td>\n",
       "      <td>0.298810</td>\n",
       "      <td>0.282198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.444200</td>\n",
       "      <td>1.434391</td>\n",
       "      <td>0.705775</td>\n",
       "      <td>0.340223</td>\n",
       "      <td>0.325755</td>\n",
       "      <td>0.309065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.149000</td>\n",
       "      <td>1.309461</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.403436</td>\n",
       "      <td>0.394174</td>\n",
       "      <td>0.373616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.929300</td>\n",
       "      <td>1.200730</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.424838</td>\n",
       "      <td>0.397524</td>\n",
       "      <td>0.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.767200</td>\n",
       "      <td>1.161730</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.466654</td>\n",
       "      <td>0.441898</td>\n",
       "      <td>0.435175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.665200</td>\n",
       "      <td>1.118586</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.484968</td>\n",
       "      <td>0.468977</td>\n",
       "      <td>0.461270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.562800</td>\n",
       "      <td>1.074739</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.498167</td>\n",
       "      <td>0.478568</td>\n",
       "      <td>0.474920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.488800</td>\n",
       "      <td>1.074812</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.498869</td>\n",
       "      <td>0.475278</td>\n",
       "      <td>0.472714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.444900</td>\n",
       "      <td>1.043463</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.501059</td>\n",
       "      <td>0.485516</td>\n",
       "      <td>0.482648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.398800</td>\n",
       "      <td>1.031984</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.521107</td>\n",
       "      <td>0.488974</td>\n",
       "      <td>0.490985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.368200</td>\n",
       "      <td>1.026333</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.527865</td>\n",
       "      <td>0.497909</td>\n",
       "      <td>0.498354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.347700</td>\n",
       "      <td>1.014037</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.520956</td>\n",
       "      <td>0.489761</td>\n",
       "      <td>0.491236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.341100</td>\n",
       "      <td>1.015504</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.495444</td>\n",
       "      <td>0.487501</td>\n",
       "      <td>0.482858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:46:41,348] Trial 133 finished with value: 0.48285814794428317 and parameters: {'learning_rate': 0.0004933610668245446, 'weight_decay': 0.008, 'warmup_steps': 4}. Best is trial 132 with value: 0.49578714001038604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 134 with params: {'learning_rate': 0.00026163044533641407, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:48 < 00:24, 7.17 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.562600</td>\n",
       "      <td>3.201240</td>\n",
       "      <td>0.275894</td>\n",
       "      <td>0.052406</td>\n",
       "      <td>0.048997</td>\n",
       "      <td>0.040694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.966600</td>\n",
       "      <td>2.680697</td>\n",
       "      <td>0.446379</td>\n",
       "      <td>0.088603</td>\n",
       "      <td>0.112215</td>\n",
       "      <td>0.083507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.505000</td>\n",
       "      <td>2.271494</td>\n",
       "      <td>0.540788</td>\n",
       "      <td>0.225197</td>\n",
       "      <td>0.173210</td>\n",
       "      <td>0.160181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.120100</td>\n",
       "      <td>1.972983</td>\n",
       "      <td>0.618698</td>\n",
       "      <td>0.300965</td>\n",
       "      <td>0.253125</td>\n",
       "      <td>0.242533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.835700</td>\n",
       "      <td>1.749437</td>\n",
       "      <td>0.683776</td>\n",
       "      <td>0.342600</td>\n",
       "      <td>0.308054</td>\n",
       "      <td>0.298627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.582400</td>\n",
       "      <td>1.577621</td>\n",
       "      <td>0.706691</td>\n",
       "      <td>0.347171</td>\n",
       "      <td>0.330967</td>\n",
       "      <td>0.316112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.385900</td>\n",
       "      <td>1.465477</td>\n",
       "      <td>0.714024</td>\n",
       "      <td>0.328567</td>\n",
       "      <td>0.324424</td>\n",
       "      <td>0.307413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.258900</td>\n",
       "      <td>1.391637</td>\n",
       "      <td>0.732356</td>\n",
       "      <td>0.358871</td>\n",
       "      <td>0.368680</td>\n",
       "      <td>0.348624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.140900</td>\n",
       "      <td>1.331168</td>\n",
       "      <td>0.730522</td>\n",
       "      <td>0.355510</td>\n",
       "      <td>0.370775</td>\n",
       "      <td>0.351909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.041900</td>\n",
       "      <td>1.292896</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.409533</td>\n",
       "      <td>0.397897</td>\n",
       "      <td>0.380615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:47:31,132] Trial 134 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 135 with params: {'learning_rate': 0.00030066582407411676, 'weight_decay': 0.0, 'warmup_steps': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:47, 7.39 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.471500</td>\n",
       "      <td>3.079023</td>\n",
       "      <td>0.362970</td>\n",
       "      <td>0.064193</td>\n",
       "      <td>0.075872</td>\n",
       "      <td>0.059196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.833800</td>\n",
       "      <td>2.534681</td>\n",
       "      <td>0.458295</td>\n",
       "      <td>0.102480</td>\n",
       "      <td>0.115284</td>\n",
       "      <td>0.085854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.347500</td>\n",
       "      <td>2.119664</td>\n",
       "      <td>0.566453</td>\n",
       "      <td>0.252127</td>\n",
       "      <td>0.195513</td>\n",
       "      <td>0.183027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.951700</td>\n",
       "      <td>1.835075</td>\n",
       "      <td>0.660862</td>\n",
       "      <td>0.303987</td>\n",
       "      <td>0.290429</td>\n",
       "      <td>0.273408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.668400</td>\n",
       "      <td>1.624766</td>\n",
       "      <td>0.704858</td>\n",
       "      <td>0.318372</td>\n",
       "      <td>0.333300</td>\n",
       "      <td>0.311360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:47:55,632] Trial 135 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 136 with params: {'learning_rate': 0.0004961775342162183, 'weight_decay': 0.009000000000000001, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.391100</td>\n",
       "      <td>2.853329</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.069746</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.075138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.514700</td>\n",
       "      <td>2.155771</td>\n",
       "      <td>0.560953</td>\n",
       "      <td>0.204655</td>\n",
       "      <td>0.204365</td>\n",
       "      <td>0.191268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.883300</td>\n",
       "      <td>1.685282</td>\n",
       "      <td>0.664528</td>\n",
       "      <td>0.315859</td>\n",
       "      <td>0.297131</td>\n",
       "      <td>0.279914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.438000</td>\n",
       "      <td>1.430247</td>\n",
       "      <td>0.704858</td>\n",
       "      <td>0.340380</td>\n",
       "      <td>0.325688</td>\n",
       "      <td>0.309137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.142700</td>\n",
       "      <td>1.306573</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.403511</td>\n",
       "      <td>0.395986</td>\n",
       "      <td>0.376479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.923100</td>\n",
       "      <td>1.198587</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.427553</td>\n",
       "      <td>0.397978</td>\n",
       "      <td>0.388596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.762200</td>\n",
       "      <td>1.159909</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.466242</td>\n",
       "      <td>0.441683</td>\n",
       "      <td>0.434849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.660600</td>\n",
       "      <td>1.116778</td>\n",
       "      <td>0.757104</td>\n",
       "      <td>0.484107</td>\n",
       "      <td>0.468522</td>\n",
       "      <td>0.460526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.558500</td>\n",
       "      <td>1.072493</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.497246</td>\n",
       "      <td>0.475613</td>\n",
       "      <td>0.471668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.484800</td>\n",
       "      <td>1.073292</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.498111</td>\n",
       "      <td>0.473584</td>\n",
       "      <td>0.471520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.440900</td>\n",
       "      <td>1.041724</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.501241</td>\n",
       "      <td>0.485754</td>\n",
       "      <td>0.482877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.395000</td>\n",
       "      <td>1.030723</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.524880</td>\n",
       "      <td>0.487668</td>\n",
       "      <td>0.491562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.364700</td>\n",
       "      <td>1.024997</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.504002</td>\n",
       "      <td>0.490515</td>\n",
       "      <td>0.485901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.344000</td>\n",
       "      <td>1.012778</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.522566</td>\n",
       "      <td>0.491954</td>\n",
       "      <td>0.493124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>1.014353</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.495373</td>\n",
       "      <td>0.487635</td>\n",
       "      <td>0.482653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:49:09,797] Trial 136 finished with value: 0.48265287481239383 and parameters: {'learning_rate': 0.0004961775342162183, 'weight_decay': 0.009000000000000001, 'warmup_steps': 4}. Best is trial 132 with value: 0.49578714001038604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 137 with params: {'learning_rate': 0.00024563915235833295, 'weight_decay': 0.01, 'warmup_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:47, 7.37 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.567700</td>\n",
       "      <td>3.219443</td>\n",
       "      <td>0.252979</td>\n",
       "      <td>0.057361</td>\n",
       "      <td>0.041825</td>\n",
       "      <td>0.034175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.996700</td>\n",
       "      <td>2.723921</td>\n",
       "      <td>0.437214</td>\n",
       "      <td>0.081500</td>\n",
       "      <td>0.105918</td>\n",
       "      <td>0.077144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.557100</td>\n",
       "      <td>2.329564</td>\n",
       "      <td>0.511457</td>\n",
       "      <td>0.160030</td>\n",
       "      <td>0.150489</td>\n",
       "      <td>0.131474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.187600</td>\n",
       "      <td>2.036695</td>\n",
       "      <td>0.598533</td>\n",
       "      <td>0.247818</td>\n",
       "      <td>0.218699</td>\n",
       "      <td>0.201192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.913000</td>\n",
       "      <td>1.814748</td>\n",
       "      <td>0.674610</td>\n",
       "      <td>0.338216</td>\n",
       "      <td>0.295420</td>\n",
       "      <td>0.286773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:49:34,190] Trial 137 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 138 with params: {'learning_rate': 0.0004890656805517279, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.395600</td>\n",
       "      <td>2.861651</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.070584</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.075237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.525000</td>\n",
       "      <td>2.167234</td>\n",
       "      <td>0.558203</td>\n",
       "      <td>0.203576</td>\n",
       "      <td>0.200698</td>\n",
       "      <td>0.188060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.898000</td>\n",
       "      <td>1.699414</td>\n",
       "      <td>0.662695</td>\n",
       "      <td>0.318927</td>\n",
       "      <td>0.298450</td>\n",
       "      <td>0.282437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.453500</td>\n",
       "      <td>1.440872</td>\n",
       "      <td>0.704858</td>\n",
       "      <td>0.338758</td>\n",
       "      <td>0.324326</td>\n",
       "      <td>0.307207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.158400</td>\n",
       "      <td>1.314498</td>\n",
       "      <td>0.738772</td>\n",
       "      <td>0.423492</td>\n",
       "      <td>0.396674</td>\n",
       "      <td>0.378865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.938700</td>\n",
       "      <td>1.203434</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.425223</td>\n",
       "      <td>0.397627</td>\n",
       "      <td>0.387535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.775100</td>\n",
       "      <td>1.163663</td>\n",
       "      <td>0.747938</td>\n",
       "      <td>0.473950</td>\n",
       "      <td>0.440120</td>\n",
       "      <td>0.435552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.672200</td>\n",
       "      <td>1.121691</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.484269</td>\n",
       "      <td>0.463455</td>\n",
       "      <td>0.455437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.569700</td>\n",
       "      <td>1.078430</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.492400</td>\n",
       "      <td>0.471342</td>\n",
       "      <td>0.467045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.495100</td>\n",
       "      <td>1.076642</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.498016</td>\n",
       "      <td>0.475278</td>\n",
       "      <td>0.472287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.451300</td>\n",
       "      <td>1.046470</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.500539</td>\n",
       "      <td>0.484193</td>\n",
       "      <td>0.481659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.404700</td>\n",
       "      <td>1.034041</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.503870</td>\n",
       "      <td>0.482398</td>\n",
       "      <td>0.481201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.373700</td>\n",
       "      <td>1.028210</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.526473</td>\n",
       "      <td>0.497090</td>\n",
       "      <td>0.497529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.353500</td>\n",
       "      <td>1.015567</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.519989</td>\n",
       "      <td>0.489761</td>\n",
       "      <td>0.490360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.346800</td>\n",
       "      <td>1.016918</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.522824</td>\n",
       "      <td>0.495346</td>\n",
       "      <td>0.493472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:50:48,561] Trial 138 finished with value: 0.4934719183378417 and parameters: {'learning_rate': 0.0004890656805517279, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 132 with value: 0.49578714001038604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 139 with params: {'learning_rate': 2.930023125468448e-05, 'weight_decay': 0.002, 'warmup_steps': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:50 < 00:25, 6.90 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.822100</td>\n",
       "      <td>3.734516</td>\n",
       "      <td>0.184235</td>\n",
       "      <td>0.013499</td>\n",
       "      <td>0.022452</td>\n",
       "      <td>0.009866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.696300</td>\n",
       "      <td>3.632925</td>\n",
       "      <td>0.181485</td>\n",
       "      <td>0.020224</td>\n",
       "      <td>0.021370</td>\n",
       "      <td>0.008572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.613700</td>\n",
       "      <td>3.546848</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023548</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.528500</td>\n",
       "      <td>3.470025</td>\n",
       "      <td>0.189734</td>\n",
       "      <td>0.023591</td>\n",
       "      <td>0.023836</td>\n",
       "      <td>0.012525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.471500</td>\n",
       "      <td>3.397675</td>\n",
       "      <td>0.221815</td>\n",
       "      <td>0.076119</td>\n",
       "      <td>0.033401</td>\n",
       "      <td>0.026167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.399200</td>\n",
       "      <td>3.336673</td>\n",
       "      <td>0.283226</td>\n",
       "      <td>0.075469</td>\n",
       "      <td>0.051883</td>\n",
       "      <td>0.046804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.339400</td>\n",
       "      <td>3.281438</td>\n",
       "      <td>0.337305</td>\n",
       "      <td>0.071495</td>\n",
       "      <td>0.067673</td>\n",
       "      <td>0.059487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.296500</td>\n",
       "      <td>3.236298</td>\n",
       "      <td>0.371219</td>\n",
       "      <td>0.070144</td>\n",
       "      <td>0.077874</td>\n",
       "      <td>0.064581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.254500</td>\n",
       "      <td>3.198483</td>\n",
       "      <td>0.378552</td>\n",
       "      <td>0.080542</td>\n",
       "      <td>0.079503</td>\n",
       "      <td>0.064352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.223000</td>\n",
       "      <td>3.166936</td>\n",
       "      <td>0.394134</td>\n",
       "      <td>0.078899</td>\n",
       "      <td>0.084417</td>\n",
       "      <td>0.067028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:51:39,901] Trial 139 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 140 with params: {'learning_rate': 0.00010458865274842525, 'weight_decay': 0.0, 'warmup_steps': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:47, 7.36 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.707400</td>\n",
       "      <td>3.514256</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.397900</td>\n",
       "      <td>3.234144</td>\n",
       "      <td>0.331806</td>\n",
       "      <td>0.070146</td>\n",
       "      <td>0.066611</td>\n",
       "      <td>0.056455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.156200</td>\n",
       "      <td>3.003327</td>\n",
       "      <td>0.409716</td>\n",
       "      <td>0.093559</td>\n",
       "      <td>0.088948</td>\n",
       "      <td>0.065923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.930400</td>\n",
       "      <td>2.801327</td>\n",
       "      <td>0.442713</td>\n",
       "      <td>0.086981</td>\n",
       "      <td>0.104836</td>\n",
       "      <td>0.081401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.767100</td>\n",
       "      <td>2.626106</td>\n",
       "      <td>0.473877</td>\n",
       "      <td>0.104787</td>\n",
       "      <td>0.123943</td>\n",
       "      <td>0.099372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:52:04,468] Trial 140 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 141 with params: {'learning_rate': 0.00046777951373956557, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.409400</td>\n",
       "      <td>2.887951</td>\n",
       "      <td>0.411549</td>\n",
       "      <td>0.073970</td>\n",
       "      <td>0.092682</td>\n",
       "      <td>0.071857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.559600</td>\n",
       "      <td>2.204983</td>\n",
       "      <td>0.551787</td>\n",
       "      <td>0.194078</td>\n",
       "      <td>0.188098</td>\n",
       "      <td>0.174609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.944000</td>\n",
       "      <td>1.738290</td>\n",
       "      <td>0.659945</td>\n",
       "      <td>0.320383</td>\n",
       "      <td>0.295417</td>\n",
       "      <td>0.278249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.500400</td>\n",
       "      <td>1.472903</td>\n",
       "      <td>0.702108</td>\n",
       "      <td>0.319815</td>\n",
       "      <td>0.326341</td>\n",
       "      <td>0.308155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.203500</td>\n",
       "      <td>1.340961</td>\n",
       "      <td>0.734189</td>\n",
       "      <td>0.401697</td>\n",
       "      <td>0.397139</td>\n",
       "      <td>0.378235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.981700</td>\n",
       "      <td>1.218353</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.430472</td>\n",
       "      <td>0.402634</td>\n",
       "      <td>0.389645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.812600</td>\n",
       "      <td>1.174815</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.455503</td>\n",
       "      <td>0.432348</td>\n",
       "      <td>0.423172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.705700</td>\n",
       "      <td>1.137512</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.489216</td>\n",
       "      <td>0.463011</td>\n",
       "      <td>0.453536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.603300</td>\n",
       "      <td>1.090465</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.489813</td>\n",
       "      <td>0.469671</td>\n",
       "      <td>0.463929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.526100</td>\n",
       "      <td>1.084877</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.492305</td>\n",
       "      <td>0.475982</td>\n",
       "      <td>0.471981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.483400</td>\n",
       "      <td>1.055689</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.496792</td>\n",
       "      <td>0.477708</td>\n",
       "      <td>0.475138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.433300</td>\n",
       "      <td>1.043459</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.497111</td>\n",
       "      <td>0.483176</td>\n",
       "      <td>0.479785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.403000</td>\n",
       "      <td>1.035432</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.514880</td>\n",
       "      <td>0.493650</td>\n",
       "      <td>0.492446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.381900</td>\n",
       "      <td>1.024371</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.523649</td>\n",
       "      <td>0.492963</td>\n",
       "      <td>0.493645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.375200</td>\n",
       "      <td>1.024663</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.517775</td>\n",
       "      <td>0.495022</td>\n",
       "      <td>0.494731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:53:19,813] Trial 141 finished with value: 0.4947309199146923 and parameters: {'learning_rate': 0.00046777951373956557, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 132 with value: 0.49578714001038604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 142 with params: {'learning_rate': 0.0002262274050533502, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:48, 7.27 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.595400</td>\n",
       "      <td>3.263930</td>\n",
       "      <td>0.196150</td>\n",
       "      <td>0.038621</td>\n",
       "      <td>0.025323</td>\n",
       "      <td>0.015322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.054800</td>\n",
       "      <td>2.794199</td>\n",
       "      <td>0.430797</td>\n",
       "      <td>0.101511</td>\n",
       "      <td>0.103415</td>\n",
       "      <td>0.077352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.636300</td>\n",
       "      <td>2.413028</td>\n",
       "      <td>0.500458</td>\n",
       "      <td>0.136230</td>\n",
       "      <td>0.140910</td>\n",
       "      <td>0.118284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.277900</td>\n",
       "      <td>2.121135</td>\n",
       "      <td>0.573786</td>\n",
       "      <td>0.223230</td>\n",
       "      <td>0.200638</td>\n",
       "      <td>0.185455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.012000</td>\n",
       "      <td>1.896913</td>\n",
       "      <td>0.637030</td>\n",
       "      <td>0.319594</td>\n",
       "      <td>0.263962</td>\n",
       "      <td>0.251945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:53:44,629] Trial 142 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 143 with params: {'learning_rate': 0.00048428307531783873, 'weight_decay': 0.009000000000000001, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.398700</td>\n",
       "      <td>2.867469</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.072784</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.075681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.532400</td>\n",
       "      <td>2.175511</td>\n",
       "      <td>0.558203</td>\n",
       "      <td>0.204267</td>\n",
       "      <td>0.200698</td>\n",
       "      <td>0.188367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.908300</td>\n",
       "      <td>1.708814</td>\n",
       "      <td>0.660862</td>\n",
       "      <td>0.318084</td>\n",
       "      <td>0.295444</td>\n",
       "      <td>0.278348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.463400</td>\n",
       "      <td>1.447688</td>\n",
       "      <td>0.703941</td>\n",
       "      <td>0.318829</td>\n",
       "      <td>0.322993</td>\n",
       "      <td>0.304729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.168300</td>\n",
       "      <td>1.319729</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.423368</td>\n",
       "      <td>0.396147</td>\n",
       "      <td>0.378480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.948800</td>\n",
       "      <td>1.206169</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.431677</td>\n",
       "      <td>0.406304</td>\n",
       "      <td>0.394044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.783700</td>\n",
       "      <td>1.165707</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.472005</td>\n",
       "      <td>0.433129</td>\n",
       "      <td>0.427842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.680100</td>\n",
       "      <td>1.125183</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.484923</td>\n",
       "      <td>0.463909</td>\n",
       "      <td>0.455536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.577400</td>\n",
       "      <td>1.081793</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.489174</td>\n",
       "      <td>0.470577</td>\n",
       "      <td>0.466453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.502000</td>\n",
       "      <td>1.078950</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.500767</td>\n",
       "      <td>0.478790</td>\n",
       "      <td>0.475153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.458700</td>\n",
       "      <td>1.049076</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.502863</td>\n",
       "      <td>0.483796</td>\n",
       "      <td>0.482004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.411100</td>\n",
       "      <td>1.036291</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.503220</td>\n",
       "      <td>0.482473</td>\n",
       "      <td>0.481095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.380200</td>\n",
       "      <td>1.030189</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.528292</td>\n",
       "      <td>0.496976</td>\n",
       "      <td>0.498594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>1.017677</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.519809</td>\n",
       "      <td>0.489626</td>\n",
       "      <td>0.490269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.353100</td>\n",
       "      <td>1.018678</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.520761</td>\n",
       "      <td>0.493917</td>\n",
       "      <td>0.492521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:54:59,006] Trial 143 finished with value: 0.49252149568167924 and parameters: {'learning_rate': 0.00048428307531783873, 'weight_decay': 0.009000000000000001, 'warmup_steps': 4}. Best is trial 132 with value: 0.49578714001038604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 144 with params: {'learning_rate': 0.000492396450081582, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.393500</td>\n",
       "      <td>2.857728</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.069635</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.075009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.520000</td>\n",
       "      <td>2.161645</td>\n",
       "      <td>0.559120</td>\n",
       "      <td>0.203449</td>\n",
       "      <td>0.203198</td>\n",
       "      <td>0.190062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.891000</td>\n",
       "      <td>1.692889</td>\n",
       "      <td>0.663611</td>\n",
       "      <td>0.318287</td>\n",
       "      <td>0.298810</td>\n",
       "      <td>0.282355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.446300</td>\n",
       "      <td>1.436004</td>\n",
       "      <td>0.705775</td>\n",
       "      <td>0.340223</td>\n",
       "      <td>0.325755</td>\n",
       "      <td>0.309065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.151200</td>\n",
       "      <td>1.310771</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.403040</td>\n",
       "      <td>0.394174</td>\n",
       "      <td>0.373753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.931600</td>\n",
       "      <td>1.201804</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.424773</td>\n",
       "      <td>0.397524</td>\n",
       "      <td>0.387342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.768900</td>\n",
       "      <td>1.162169</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.466084</td>\n",
       "      <td>0.441660</td>\n",
       "      <td>0.434867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.666600</td>\n",
       "      <td>1.119345</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.484909</td>\n",
       "      <td>0.469036</td>\n",
       "      <td>0.461323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.564300</td>\n",
       "      <td>1.075928</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.493962</td>\n",
       "      <td>0.474568</td>\n",
       "      <td>0.470876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.490200</td>\n",
       "      <td>1.074912</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.498212</td>\n",
       "      <td>0.475278</td>\n",
       "      <td>0.472371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.446300</td>\n",
       "      <td>1.044166</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.500539</td>\n",
       "      <td>0.484193</td>\n",
       "      <td>0.481659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.400100</td>\n",
       "      <td>1.032387</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.505723</td>\n",
       "      <td>0.482307</td>\n",
       "      <td>0.482443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.369400</td>\n",
       "      <td>1.026743</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.527865</td>\n",
       "      <td>0.497909</td>\n",
       "      <td>0.498354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.349000</td>\n",
       "      <td>1.014172</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.520612</td>\n",
       "      <td>0.490287</td>\n",
       "      <td>0.490956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.342400</td>\n",
       "      <td>1.015653</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.522444</td>\n",
       "      <td>0.494531</td>\n",
       "      <td>0.493925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:56:13,723] Trial 144 finished with value: 0.49392507044548145 and parameters: {'learning_rate': 0.000492396450081582, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 132 with value: 0.49578714001038604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 145 with params: {'learning_rate': 0.0004909740599334299, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:15, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.394400</td>\n",
       "      <td>2.859439</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.069788</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.075065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.522100</td>\n",
       "      <td>2.163976</td>\n",
       "      <td>0.559120</td>\n",
       "      <td>0.203810</td>\n",
       "      <td>0.203198</td>\n",
       "      <td>0.190214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.893900</td>\n",
       "      <td>1.695677</td>\n",
       "      <td>0.661778</td>\n",
       "      <td>0.317476</td>\n",
       "      <td>0.296783</td>\n",
       "      <td>0.280638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.449400</td>\n",
       "      <td>1.438079</td>\n",
       "      <td>0.705775</td>\n",
       "      <td>0.340143</td>\n",
       "      <td>0.325755</td>\n",
       "      <td>0.309033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.154200</td>\n",
       "      <td>1.312299</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.402768</td>\n",
       "      <td>0.394174</td>\n",
       "      <td>0.373626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.934600</td>\n",
       "      <td>1.202417</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.424952</td>\n",
       "      <td>0.397524</td>\n",
       "      <td>0.387323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.771500</td>\n",
       "      <td>1.162883</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.474008</td>\n",
       "      <td>0.440335</td>\n",
       "      <td>0.435657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.669000</td>\n",
       "      <td>1.120500</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.483404</td>\n",
       "      <td>0.464452</td>\n",
       "      <td>0.455797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.566500</td>\n",
       "      <td>1.077065</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.493009</td>\n",
       "      <td>0.472068</td>\n",
       "      <td>0.467673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.492200</td>\n",
       "      <td>1.075704</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.498145</td>\n",
       "      <td>0.475278</td>\n",
       "      <td>0.472348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.448300</td>\n",
       "      <td>1.045176</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.500539</td>\n",
       "      <td>0.484193</td>\n",
       "      <td>0.481659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.402000</td>\n",
       "      <td>1.033163</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.505723</td>\n",
       "      <td>0.482307</td>\n",
       "      <td>0.482443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.371200</td>\n",
       "      <td>1.027400</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.527423</td>\n",
       "      <td>0.497454</td>\n",
       "      <td>0.497929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.350900</td>\n",
       "      <td>1.014774</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.520343</td>\n",
       "      <td>0.489761</td>\n",
       "      <td>0.490675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.344200</td>\n",
       "      <td>1.016230</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.521607</td>\n",
       "      <td>0.494077</td>\n",
       "      <td>0.492819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:57:30,527] Trial 145 finished with value: 0.4928190274687641 and parameters: {'learning_rate': 0.0004909740599334299, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 132 with value: 0.49578714001038604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 146 with params: {'learning_rate': 0.00027227806674792895, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:47, 7.36 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.552700</td>\n",
       "      <td>3.180876</td>\n",
       "      <td>0.293309</td>\n",
       "      <td>0.072405</td>\n",
       "      <td>0.054394</td>\n",
       "      <td>0.045248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.939400</td>\n",
       "      <td>2.646488</td>\n",
       "      <td>0.446379</td>\n",
       "      <td>0.088192</td>\n",
       "      <td>0.111638</td>\n",
       "      <td>0.082222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.465400</td>\n",
       "      <td>2.230405</td>\n",
       "      <td>0.549038</td>\n",
       "      <td>0.221097</td>\n",
       "      <td>0.180269</td>\n",
       "      <td>0.165922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.074200</td>\n",
       "      <td>1.932677</td>\n",
       "      <td>0.626031</td>\n",
       "      <td>0.290212</td>\n",
       "      <td>0.259240</td>\n",
       "      <td>0.246193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.786800</td>\n",
       "      <td>1.711620</td>\n",
       "      <td>0.693859</td>\n",
       "      <td>0.350720</td>\n",
       "      <td>0.319279</td>\n",
       "      <td>0.307603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:57:54,962] Trial 146 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 147 with params: {'learning_rate': 0.0004985795475783355, 'weight_decay': 0.01, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.389600</td>\n",
       "      <td>2.850571</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.069605</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.075081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.511300</td>\n",
       "      <td>2.152169</td>\n",
       "      <td>0.561870</td>\n",
       "      <td>0.204372</td>\n",
       "      <td>0.204820</td>\n",
       "      <td>0.191388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.878600</td>\n",
       "      <td>1.680641</td>\n",
       "      <td>0.667278</td>\n",
       "      <td>0.313959</td>\n",
       "      <td>0.298973</td>\n",
       "      <td>0.281214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.432800</td>\n",
       "      <td>1.426522</td>\n",
       "      <td>0.705775</td>\n",
       "      <td>0.340553</td>\n",
       "      <td>0.327291</td>\n",
       "      <td>0.309842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.137100</td>\n",
       "      <td>1.303748</td>\n",
       "      <td>0.736939</td>\n",
       "      <td>0.401960</td>\n",
       "      <td>0.392748</td>\n",
       "      <td>0.372296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.917600</td>\n",
       "      <td>1.196183</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.427335</td>\n",
       "      <td>0.397978</td>\n",
       "      <td>0.388413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.757800</td>\n",
       "      <td>1.157718</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.487946</td>\n",
       "      <td>0.444982</td>\n",
       "      <td>0.440703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.656400</td>\n",
       "      <td>1.115189</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.487962</td>\n",
       "      <td>0.468737</td>\n",
       "      <td>0.462821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.554500</td>\n",
       "      <td>1.069561</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.498497</td>\n",
       "      <td>0.478639</td>\n",
       "      <td>0.475300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.481200</td>\n",
       "      <td>1.071465</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.498025</td>\n",
       "      <td>0.473617</td>\n",
       "      <td>0.471556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.039949</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.500287</td>\n",
       "      <td>0.486209</td>\n",
       "      <td>0.482396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.391800</td>\n",
       "      <td>1.029065</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.521093</td>\n",
       "      <td>0.488156</td>\n",
       "      <td>0.490798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.361600</td>\n",
       "      <td>1.023593</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.498509</td>\n",
       "      <td>0.489324</td>\n",
       "      <td>0.483643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.340800</td>\n",
       "      <td>1.011368</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.520491</td>\n",
       "      <td>0.497059</td>\n",
       "      <td>0.495516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.334300</td>\n",
       "      <td>1.013024</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.514257</td>\n",
       "      <td>0.489370</td>\n",
       "      <td>0.485851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 10:59:10,706] Trial 147 finished with value: 0.4858513231737946 and parameters: {'learning_rate': 0.0004985795475783355, 'weight_decay': 0.01, 'warmup_steps': 4}. Best is trial 132 with value: 0.49578714001038604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 148 with params: {'learning_rate': 2.579669642889317e-05, 'weight_decay': 0.003, 'warmup_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:48 < 00:24, 7.19 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.836400</td>\n",
       "      <td>3.755167</td>\n",
       "      <td>0.182401</td>\n",
       "      <td>0.032313</td>\n",
       "      <td>0.022255</td>\n",
       "      <td>0.010211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.719100</td>\n",
       "      <td>3.660502</td>\n",
       "      <td>0.181485</td>\n",
       "      <td>0.012668</td>\n",
       "      <td>0.021370</td>\n",
       "      <td>0.008450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.643800</td>\n",
       "      <td>3.582736</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.018551</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.566500</td>\n",
       "      <td>3.513790</td>\n",
       "      <td>0.182401</td>\n",
       "      <td>0.023564</td>\n",
       "      <td>0.021644</td>\n",
       "      <td>0.009088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.515200</td>\n",
       "      <td>3.447174</td>\n",
       "      <td>0.191567</td>\n",
       "      <td>0.043607</td>\n",
       "      <td>0.024312</td>\n",
       "      <td>0.013479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.449500</td>\n",
       "      <td>3.392573</td>\n",
       "      <td>0.217232</td>\n",
       "      <td>0.075407</td>\n",
       "      <td>0.031906</td>\n",
       "      <td>0.024579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.395800</td>\n",
       "      <td>3.341892</td>\n",
       "      <td>0.285060</td>\n",
       "      <td>0.075920</td>\n",
       "      <td>0.051913</td>\n",
       "      <td>0.047296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.356800</td>\n",
       "      <td>3.299406</td>\n",
       "      <td>0.326306</td>\n",
       "      <td>0.072226</td>\n",
       "      <td>0.064017</td>\n",
       "      <td>0.057151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.318100</td>\n",
       "      <td>3.264440</td>\n",
       "      <td>0.343721</td>\n",
       "      <td>0.068664</td>\n",
       "      <td>0.069079</td>\n",
       "      <td>0.060126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.289400</td>\n",
       "      <td>3.235104</td>\n",
       "      <td>0.366636</td>\n",
       "      <td>0.071101</td>\n",
       "      <td>0.076432</td>\n",
       "      <td>0.064504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:00:00,073] Trial 148 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 149 with params: {'learning_rate': 0.00032676157417641373, 'weight_decay': 0.009000000000000001, 'warmup_steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:47, 7.29 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.497700</td>\n",
       "      <td>3.079931</td>\n",
       "      <td>0.354720</td>\n",
       "      <td>0.067490</td>\n",
       "      <td>0.073719</td>\n",
       "      <td>0.058914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.810400</td>\n",
       "      <td>2.494599</td>\n",
       "      <td>0.466544</td>\n",
       "      <td>0.141277</td>\n",
       "      <td>0.123796</td>\n",
       "      <td>0.098519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.286700</td>\n",
       "      <td>2.051042</td>\n",
       "      <td>0.582035</td>\n",
       "      <td>0.274789</td>\n",
       "      <td>0.218098</td>\n",
       "      <td>0.209279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.873700</td>\n",
       "      <td>1.769104</td>\n",
       "      <td>0.670944</td>\n",
       "      <td>0.314039</td>\n",
       "      <td>0.293602</td>\n",
       "      <td>0.279259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.581000</td>\n",
       "      <td>1.561745</td>\n",
       "      <td>0.716774</td>\n",
       "      <td>0.371025</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.335868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:00:25,314] Trial 149 pruned. \n"
     ]
    }
   ],
   "source": [
    "best_trial_normal = trainer.hyperparameter_search(\n",
    "    direction=\"maximize\",\n",
    "    backend=\"optuna\",\n",
    "    hp_space=hp_space,\n",
    "    compute_objective=lambda metrics: metrics[\"eval_f1\"],\n",
    "    pruner=pruner,\n",
    "    sampler=sampler,\n",
    "    study_name=\"Test-base\",\n",
    "    n_trials=150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43d41e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BestRun(run_id='132', objective=0.49578714001038604, hyperparameters={'learning_rate': 0.0004675471848767979, 'weight_decay': 0.01, 'warmup_steps': 4}, run_summary=None)\n"
     ]
    }
   ],
   "source": [
    "print(best_trial_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff001c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eb4d05",
   "metadata": {},
   "source": [
    "## Prohledávání s destilací nad původním datasetem\n",
    "Konfigurace jednotlivých tréninků."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f49758d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bert-distill_fine_hp-search\", logging_dir=f\"~/logs/{DATASET}/bert-distill_fine_hp-search\", remove_unused_columns=False, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fc705e",
   "metadata": {},
   "source": [
    "Definice hledaných hyperparametrů a jejich rozmezí, rozšířeno o hyperparametry destilace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb876364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_space(trial):\n",
    "    params =  {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 5e-4, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0, 1e-2, step=1e-3),\n",
    "        \"warmup_steps\" : trial.suggest_int(\"warmup_steps\", 0, warm_up),\n",
    "        \"lambda_param\": trial.suggest_float(\"lambda_param\",0,1,step=.1),\n",
    "        \"temperature\": trial.suggest_float(\"temperature\", 2,7, step=.5)\n",
    "    }\n",
    "    print(f\"Trial {trial.number} with params: {params}\")\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce72960",
   "metadata": {},
   "source": [
    "Konfigurace Optuny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6858ab65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pruner = optuna.pruners.HyperbandPruner(min_resource=min_r, max_resource=max_r, reduction_factor=2, bootstrap_count=2)\n",
    "sampler = optuna.samplers.TPESampler(seed=42, multivariate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3b6fbc",
   "metadata": {},
   "source": [
    "Konfigurace destilačního trenéra pro jednotlivé tréninky. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "511a945b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer = base.DistilTrainer(\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    model_init = lambda: get_Bert(),\n",
    ")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b06a13a",
   "metadata": {},
   "source": [
    "Nastavení prohledávání."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7091f8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:00:25,776] A new study created in memory with name: Distilation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 with params: {'learning_rate': 4.3284502212938785e-05, 'weight_decay': 0.01, 'warmup_steps': 3, 'lambda_param': 0.6000000000000001, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:52 < 00:26, 6.68 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.417800</td>\n",
       "      <td>2.340572</td>\n",
       "      <td>0.182401</td>\n",
       "      <td>0.013581</td>\n",
       "      <td>0.021644</td>\n",
       "      <td>0.008897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.312900</td>\n",
       "      <td>2.253278</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023548</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.238600</td>\n",
       "      <td>2.177167</td>\n",
       "      <td>0.189734</td>\n",
       "      <td>0.063584</td>\n",
       "      <td>0.023705</td>\n",
       "      <td>0.012673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.169100</td>\n",
       "      <td>2.110003</td>\n",
       "      <td>0.328139</td>\n",
       "      <td>0.072231</td>\n",
       "      <td>0.064126</td>\n",
       "      <td>0.057706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.113300</td>\n",
       "      <td>2.051637</td>\n",
       "      <td>0.387718</td>\n",
       "      <td>0.079887</td>\n",
       "      <td>0.081690</td>\n",
       "      <td>0.065101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.054500</td>\n",
       "      <td>2.001357</td>\n",
       "      <td>0.400550</td>\n",
       "      <td>0.075740</td>\n",
       "      <td>0.085787</td>\n",
       "      <td>0.064986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.006300</td>\n",
       "      <td>1.956808</td>\n",
       "      <td>0.410632</td>\n",
       "      <td>0.093163</td>\n",
       "      <td>0.089287</td>\n",
       "      <td>0.067112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.967700</td>\n",
       "      <td>1.917731</td>\n",
       "      <td>0.429881</td>\n",
       "      <td>0.090969</td>\n",
       "      <td>0.098607</td>\n",
       "      <td>0.077087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.931100</td>\n",
       "      <td>1.884372</td>\n",
       "      <td>0.439047</td>\n",
       "      <td>0.087489</td>\n",
       "      <td>0.103874</td>\n",
       "      <td>0.081015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.903500</td>\n",
       "      <td>1.857554</td>\n",
       "      <td>0.448213</td>\n",
       "      <td>0.105830</td>\n",
       "      <td>0.108713</td>\n",
       "      <td>0.085917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:01:18,897] Trial 0 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 with params: {'learning_rate': 1.8408992080552506e-05, 'weight_decay': 0.0, 'warmup_steps': 4, 'lambda_param': 0.6000000000000001, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:24 < 00:49, 7.14 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.449100</td>\n",
       "      <td>2.405171</td>\n",
       "      <td>0.132906</td>\n",
       "      <td>0.009243</td>\n",
       "      <td>0.035965</td>\n",
       "      <td>0.008626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.391100</td>\n",
       "      <td>2.352340</td>\n",
       "      <td>0.183318</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>0.022178</td>\n",
       "      <td>0.009776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.350100</td>\n",
       "      <td>2.313332</td>\n",
       "      <td>0.181485</td>\n",
       "      <td>0.013577</td>\n",
       "      <td>0.021370</td>\n",
       "      <td>0.008479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.315100</td>\n",
       "      <td>2.280843</td>\n",
       "      <td>0.181485</td>\n",
       "      <td>0.020231</td>\n",
       "      <td>0.021370</td>\n",
       "      <td>0.008582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.285400</td>\n",
       "      <td>2.248202</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023554</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:01:44,177] Trial 1 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 with params: {'learning_rate': 1.0838581269344744e-05, 'weight_decay': 0.01, 'warmup_steps': 4, 'lambda_param': 0.2, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:48 < 00:24, 7.14 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.459600</td>\n",
       "      <td>2.429218</td>\n",
       "      <td>0.043080</td>\n",
       "      <td>0.009669</td>\n",
       "      <td>0.026341</td>\n",
       "      <td>0.006411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.422800</td>\n",
       "      <td>2.394165</td>\n",
       "      <td>0.160403</td>\n",
       "      <td>0.009152</td>\n",
       "      <td>0.019518</td>\n",
       "      <td>0.009359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.393600</td>\n",
       "      <td>2.364072</td>\n",
       "      <td>0.188818</td>\n",
       "      <td>0.024161</td>\n",
       "      <td>0.024002</td>\n",
       "      <td>0.012103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.368700</td>\n",
       "      <td>2.340714</td>\n",
       "      <td>0.184235</td>\n",
       "      <td>0.015572</td>\n",
       "      <td>0.022452</td>\n",
       "      <td>0.010131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.347200</td>\n",
       "      <td>2.320631</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>0.015597</td>\n",
       "      <td>0.022466</td>\n",
       "      <td>0.010189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.327900</td>\n",
       "      <td>2.303330</td>\n",
       "      <td>0.182401</td>\n",
       "      <td>0.014490</td>\n",
       "      <td>0.021644</td>\n",
       "      <td>0.008931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.313700</td>\n",
       "      <td>2.288213</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.300400</td>\n",
       "      <td>2.275064</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.288600</td>\n",
       "      <td>2.263793</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.280300</td>\n",
       "      <td>2.254771</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023554</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:02:33,954] Trial 2 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 with params: {'learning_rate': 2.049268011541735e-05, 'weight_decay': 0.003, 'warmup_steps': 2, 'lambda_param': 0.4, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:24 < 00:49, 7.05 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.444600</td>\n",
       "      <td>2.396842</td>\n",
       "      <td>0.161320</td>\n",
       "      <td>0.010212</td>\n",
       "      <td>0.019622</td>\n",
       "      <td>0.009401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.381900</td>\n",
       "      <td>2.341642</td>\n",
       "      <td>0.182401</td>\n",
       "      <td>0.010666</td>\n",
       "      <td>0.021644</td>\n",
       "      <td>0.008779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.338800</td>\n",
       "      <td>2.299941</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.300700</td>\n",
       "      <td>2.264565</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.019561</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.269000</td>\n",
       "      <td>2.229339</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023554</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:02:59,647] Trial 3 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 with params: {'learning_rate': 0.00010952662748632558, 'weight_decay': 0.001, 'warmup_steps': 1, 'lambda_param': 0.4, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.350800</td>\n",
       "      <td>2.220122</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.155700</td>\n",
       "      <td>2.047526</td>\n",
       "      <td>0.364803</td>\n",
       "      <td>0.062614</td>\n",
       "      <td>0.075557</td>\n",
       "      <td>0.061409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.005500</td>\n",
       "      <td>1.898824</td>\n",
       "      <td>0.420715</td>\n",
       "      <td>0.071078</td>\n",
       "      <td>0.093699</td>\n",
       "      <td>0.069640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.859300</td>\n",
       "      <td>1.765021</td>\n",
       "      <td>0.461962</td>\n",
       "      <td>0.100274</td>\n",
       "      <td>0.118160</td>\n",
       "      <td>0.095519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.743600</td>\n",
       "      <td>1.650736</td>\n",
       "      <td>0.495875</td>\n",
       "      <td>0.101965</td>\n",
       "      <td>0.138579</td>\n",
       "      <td>0.111908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.628000</td>\n",
       "      <td>1.559110</td>\n",
       "      <td>0.518790</td>\n",
       "      <td>0.183257</td>\n",
       "      <td>0.155762</td>\n",
       "      <td>0.135304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.538500</td>\n",
       "      <td>1.487768</td>\n",
       "      <td>0.538038</td>\n",
       "      <td>0.193764</td>\n",
       "      <td>0.173843</td>\n",
       "      <td>0.158051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.472600</td>\n",
       "      <td>1.427020</td>\n",
       "      <td>0.584785</td>\n",
       "      <td>0.246785</td>\n",
       "      <td>0.202487</td>\n",
       "      <td>0.187214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.408100</td>\n",
       "      <td>1.375973</td>\n",
       "      <td>0.595784</td>\n",
       "      <td>0.244687</td>\n",
       "      <td>0.212790</td>\n",
       "      <td>0.199596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.354600</td>\n",
       "      <td>1.337041</td>\n",
       "      <td>0.605866</td>\n",
       "      <td>0.243515</td>\n",
       "      <td>0.223661</td>\n",
       "      <td>0.206439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.321200</td>\n",
       "      <td>1.304440</td>\n",
       "      <td>0.633364</td>\n",
       "      <td>0.264813</td>\n",
       "      <td>0.240748</td>\n",
       "      <td>0.228449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.279600</td>\n",
       "      <td>1.278919</td>\n",
       "      <td>0.642530</td>\n",
       "      <td>0.267466</td>\n",
       "      <td>0.248015</td>\n",
       "      <td>0.237208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.263400</td>\n",
       "      <td>1.263087</td>\n",
       "      <td>0.643446</td>\n",
       "      <td>0.264436</td>\n",
       "      <td>0.248580</td>\n",
       "      <td>0.236033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.246800</td>\n",
       "      <td>1.252796</td>\n",
       "      <td>0.645280</td>\n",
       "      <td>0.264456</td>\n",
       "      <td>0.249620</td>\n",
       "      <td>0.237388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.235300</td>\n",
       "      <td>1.249831</td>\n",
       "      <td>0.648029</td>\n",
       "      <td>0.284433</td>\n",
       "      <td>0.252342</td>\n",
       "      <td>0.240661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:04:15,470] Trial 4 finished with value: 0.24066060153297905 and parameters: {'learning_rate': 0.00010952662748632558, 'weight_decay': 0.001, 'warmup_steps': 1, 'lambda_param': 0.4, 'temperature': 4.5}. Best is trial 4 with value: 0.24066060153297905.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 with params: {'learning_rate': 0.0002157696745589684, 'weight_decay': 0.002, 'warmup_steps': 2, 'lambda_param': 0.6000000000000001, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:49 < 00:25, 6.99 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.283200</td>\n",
       "      <td>2.086134</td>\n",
       "      <td>0.231897</td>\n",
       "      <td>0.056644</td>\n",
       "      <td>0.035160</td>\n",
       "      <td>0.026963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.969900</td>\n",
       "      <td>1.804505</td>\n",
       "      <td>0.435380</td>\n",
       "      <td>0.081878</td>\n",
       "      <td>0.105958</td>\n",
       "      <td>0.079230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.714500</td>\n",
       "      <td>1.567026</td>\n",
       "      <td>0.505041</td>\n",
       "      <td>0.140108</td>\n",
       "      <td>0.144831</td>\n",
       "      <td>0.121585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.490200</td>\n",
       "      <td>1.385216</td>\n",
       "      <td>0.563703</td>\n",
       "      <td>0.197337</td>\n",
       "      <td>0.184623</td>\n",
       "      <td>0.164027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.323600</td>\n",
       "      <td>1.248885</td>\n",
       "      <td>0.626948</td>\n",
       "      <td>0.264374</td>\n",
       "      <td>0.232544</td>\n",
       "      <td>0.217568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.173800</td>\n",
       "      <td>1.145206</td>\n",
       "      <td>0.672777</td>\n",
       "      <td>0.265153</td>\n",
       "      <td>0.268516</td>\n",
       "      <td>0.250031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.061100</td>\n",
       "      <td>1.068329</td>\n",
       "      <td>0.683776</td>\n",
       "      <td>0.266275</td>\n",
       "      <td>0.283067</td>\n",
       "      <td>0.262633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.982600</td>\n",
       "      <td>1.012111</td>\n",
       "      <td>0.698442</td>\n",
       "      <td>0.284563</td>\n",
       "      <td>0.296401</td>\n",
       "      <td>0.272103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.911900</td>\n",
       "      <td>0.972303</td>\n",
       "      <td>0.705775</td>\n",
       "      <td>0.294829</td>\n",
       "      <td>0.306633</td>\n",
       "      <td>0.284542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.850300</td>\n",
       "      <td>0.939513</td>\n",
       "      <td>0.717690</td>\n",
       "      <td>0.308791</td>\n",
       "      <td>0.321317</td>\n",
       "      <td>0.300245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:05:06,204] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 with params: {'learning_rate': 0.00010769622478263136, 'weight_decay': 0.001, 'warmup_steps': 0, 'lambda_param': 1.0, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.344700</td>\n",
       "      <td>2.214878</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.153100</td>\n",
       "      <td>2.046734</td>\n",
       "      <td>0.365720</td>\n",
       "      <td>0.062883</td>\n",
       "      <td>0.075749</td>\n",
       "      <td>0.061892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.006800</td>\n",
       "      <td>1.902232</td>\n",
       "      <td>0.421632</td>\n",
       "      <td>0.070570</td>\n",
       "      <td>0.093484</td>\n",
       "      <td>0.068620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.863900</td>\n",
       "      <td>1.770794</td>\n",
       "      <td>0.457379</td>\n",
       "      <td>0.100146</td>\n",
       "      <td>0.115887</td>\n",
       "      <td>0.091599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.750100</td>\n",
       "      <td>1.658052</td>\n",
       "      <td>0.491292</td>\n",
       "      <td>0.101964</td>\n",
       "      <td>0.136546</td>\n",
       "      <td>0.110118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.636400</td>\n",
       "      <td>1.567724</td>\n",
       "      <td>0.516040</td>\n",
       "      <td>0.181803</td>\n",
       "      <td>0.153561</td>\n",
       "      <td>0.132550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.548300</td>\n",
       "      <td>1.497696</td>\n",
       "      <td>0.536205</td>\n",
       "      <td>0.189856</td>\n",
       "      <td>0.172273</td>\n",
       "      <td>0.156230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.483400</td>\n",
       "      <td>1.437581</td>\n",
       "      <td>0.579285</td>\n",
       "      <td>0.247355</td>\n",
       "      <td>0.199462</td>\n",
       "      <td>0.183521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.420200</td>\n",
       "      <td>1.387370</td>\n",
       "      <td>0.592117</td>\n",
       "      <td>0.244948</td>\n",
       "      <td>0.207488</td>\n",
       "      <td>0.191945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.367300</td>\n",
       "      <td>1.348756</td>\n",
       "      <td>0.604033</td>\n",
       "      <td>0.241933</td>\n",
       "      <td>0.219446</td>\n",
       "      <td>0.203480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.334800</td>\n",
       "      <td>1.316868</td>\n",
       "      <td>0.623281</td>\n",
       "      <td>0.245995</td>\n",
       "      <td>0.226740</td>\n",
       "      <td>0.210946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.293500</td>\n",
       "      <td>1.291541</td>\n",
       "      <td>0.632447</td>\n",
       "      <td>0.244216</td>\n",
       "      <td>0.238489</td>\n",
       "      <td>0.223621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.277500</td>\n",
       "      <td>1.275923</td>\n",
       "      <td>0.639780</td>\n",
       "      <td>0.264252</td>\n",
       "      <td>0.245659</td>\n",
       "      <td>0.232896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.261000</td>\n",
       "      <td>1.265604</td>\n",
       "      <td>0.641613</td>\n",
       "      <td>0.264946</td>\n",
       "      <td>0.247447</td>\n",
       "      <td>0.235894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.249700</td>\n",
       "      <td>1.262699</td>\n",
       "      <td>0.644363</td>\n",
       "      <td>0.266502</td>\n",
       "      <td>0.248991</td>\n",
       "      <td>0.236798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:06:21,777] Trial 6 finished with value: 0.23679842199748216 and parameters: {'learning_rate': 0.00010769622478263136, 'weight_decay': 0.001, 'warmup_steps': 0, 'lambda_param': 1.0, 'temperature': 7.0}. Best is trial 4 with value: 0.24066060153297905.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 with params: {'learning_rate': 0.000236288641842364, 'weight_decay': 0.003, 'warmup_steps': 0, 'lambda_param': 0.7000000000000001, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:48 < 00:24, 7.23 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.253000</td>\n",
       "      <td>2.050192</td>\n",
       "      <td>0.306141</td>\n",
       "      <td>0.069261</td>\n",
       "      <td>0.056665</td>\n",
       "      <td>0.047826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.926000</td>\n",
       "      <td>1.750690</td>\n",
       "      <td>0.444546</td>\n",
       "      <td>0.081624</td>\n",
       "      <td>0.110171</td>\n",
       "      <td>0.080723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.657500</td>\n",
       "      <td>1.509693</td>\n",
       "      <td>0.517874</td>\n",
       "      <td>0.188050</td>\n",
       "      <td>0.151446</td>\n",
       "      <td>0.130888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.427300</td>\n",
       "      <td>1.328247</td>\n",
       "      <td>0.587534</td>\n",
       "      <td>0.205296</td>\n",
       "      <td>0.200035</td>\n",
       "      <td>0.178475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.259000</td>\n",
       "      <td>1.194351</td>\n",
       "      <td>0.654445</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.252652</td>\n",
       "      <td>0.235116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.108100</td>\n",
       "      <td>1.091788</td>\n",
       "      <td>0.679193</td>\n",
       "      <td>0.265087</td>\n",
       "      <td>0.274121</td>\n",
       "      <td>0.255957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.994800</td>\n",
       "      <td>1.018273</td>\n",
       "      <td>0.695692</td>\n",
       "      <td>0.266289</td>\n",
       "      <td>0.289993</td>\n",
       "      <td>0.266849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.915700</td>\n",
       "      <td>0.963571</td>\n",
       "      <td>0.706691</td>\n",
       "      <td>0.297169</td>\n",
       "      <td>0.305238</td>\n",
       "      <td>0.282413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.848400</td>\n",
       "      <td>0.929126</td>\n",
       "      <td>0.710357</td>\n",
       "      <td>0.321894</td>\n",
       "      <td>0.313918</td>\n",
       "      <td>0.292715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.787000</td>\n",
       "      <td>0.898313</td>\n",
       "      <td>0.721357</td>\n",
       "      <td>0.314316</td>\n",
       "      <td>0.322957</td>\n",
       "      <td>0.299784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:07:10,927] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 with params: {'learning_rate': 1.6119044727609182e-05, 'weight_decay': 0.005, 'warmup_steps': 0, 'lambda_param': 1.0, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:47, 7.29 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.448400</td>\n",
       "      <td>2.408619</td>\n",
       "      <td>0.120073</td>\n",
       "      <td>0.009018</td>\n",
       "      <td>0.034514</td>\n",
       "      <td>0.008578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.397000</td>\n",
       "      <td>2.360924</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>0.015188</td>\n",
       "      <td>0.022906</td>\n",
       "      <td>0.010735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.359900</td>\n",
       "      <td>2.325730</td>\n",
       "      <td>0.181485</td>\n",
       "      <td>0.012675</td>\n",
       "      <td>0.021370</td>\n",
       "      <td>0.008460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.328700</td>\n",
       "      <td>2.296499</td>\n",
       "      <td>0.184235</td>\n",
       "      <td>0.016917</td>\n",
       "      <td>0.022192</td>\n",
       "      <td>0.009843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.302000</td>\n",
       "      <td>2.267933</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.019564</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:07:36,658] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 with params: {'learning_rate': 0.00013353819088790598, 'weight_decay': 0.003, 'warmup_steps': 2, 'lambda_param': 0.6000000000000001, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.336300</td>\n",
       "      <td>2.186799</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.110500</td>\n",
       "      <td>1.989481</td>\n",
       "      <td>0.395050</td>\n",
       "      <td>0.057949</td>\n",
       "      <td>0.084131</td>\n",
       "      <td>0.063933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.934100</td>\n",
       "      <td>1.811707</td>\n",
       "      <td>0.448213</td>\n",
       "      <td>0.100223</td>\n",
       "      <td>0.111363</td>\n",
       "      <td>0.086988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.763900</td>\n",
       "      <td>1.663582</td>\n",
       "      <td>0.494042</td>\n",
       "      <td>0.118812</td>\n",
       "      <td>0.137533</td>\n",
       "      <td>0.110771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.632700</td>\n",
       "      <td>1.538570</td>\n",
       "      <td>0.526123</td>\n",
       "      <td>0.185006</td>\n",
       "      <td>0.165043</td>\n",
       "      <td>0.146854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.505200</td>\n",
       "      <td>1.441350</td>\n",
       "      <td>0.557287</td>\n",
       "      <td>0.243346</td>\n",
       "      <td>0.186254</td>\n",
       "      <td>0.170935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.406500</td>\n",
       "      <td>1.363968</td>\n",
       "      <td>0.582951</td>\n",
       "      <td>0.247709</td>\n",
       "      <td>0.205525</td>\n",
       "      <td>0.192850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.334000</td>\n",
       "      <td>1.301796</td>\n",
       "      <td>0.632447</td>\n",
       "      <td>0.286393</td>\n",
       "      <td>0.243904</td>\n",
       "      <td>0.234491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.264500</td>\n",
       "      <td>1.248725</td>\n",
       "      <td>0.647113</td>\n",
       "      <td>0.288806</td>\n",
       "      <td>0.257147</td>\n",
       "      <td>0.246156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.206600</td>\n",
       "      <td>1.209024</td>\n",
       "      <td>0.659945</td>\n",
       "      <td>0.283833</td>\n",
       "      <td>0.268200</td>\n",
       "      <td>0.254502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.171200</td>\n",
       "      <td>1.175791</td>\n",
       "      <td>0.673694</td>\n",
       "      <td>0.284599</td>\n",
       "      <td>0.273387</td>\n",
       "      <td>0.257383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.128300</td>\n",
       "      <td>1.151766</td>\n",
       "      <td>0.674610</td>\n",
       "      <td>0.285211</td>\n",
       "      <td>0.275720</td>\n",
       "      <td>0.261387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.111600</td>\n",
       "      <td>1.135707</td>\n",
       "      <td>0.677360</td>\n",
       "      <td>0.264514</td>\n",
       "      <td>0.276658</td>\n",
       "      <td>0.257282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.093100</td>\n",
       "      <td>1.125764</td>\n",
       "      <td>0.681943</td>\n",
       "      <td>0.267170</td>\n",
       "      <td>0.278705</td>\n",
       "      <td>0.259716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.082000</td>\n",
       "      <td>1.123015</td>\n",
       "      <td>0.684693</td>\n",
       "      <td>0.265805</td>\n",
       "      <td>0.282645</td>\n",
       "      <td>0.261510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:08:52,114] Trial 9 finished with value: 0.26150970153790776 and parameters: {'learning_rate': 0.00013353819088790598, 'weight_decay': 0.003, 'warmup_steps': 2, 'lambda_param': 0.6000000000000001, 'temperature': 3.0}. Best is trial 9 with value: 0.26150970153790776.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 with params: {'learning_rate': 0.00022653365944687691, 'weight_decay': 0.004, 'warmup_steps': 4, 'lambda_param': 0.4, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.288200</td>\n",
       "      <td>2.085122</td>\n",
       "      <td>0.225481</td>\n",
       "      <td>0.077473</td>\n",
       "      <td>0.033780</td>\n",
       "      <td>0.026729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.961800</td>\n",
       "      <td>1.788522</td>\n",
       "      <td>0.448213</td>\n",
       "      <td>0.102168</td>\n",
       "      <td>0.114176</td>\n",
       "      <td>0.087086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.693100</td>\n",
       "      <td>1.541627</td>\n",
       "      <td>0.515124</td>\n",
       "      <td>0.164761</td>\n",
       "      <td>0.153381</td>\n",
       "      <td>0.133594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.461400</td>\n",
       "      <td>1.355830</td>\n",
       "      <td>0.574702</td>\n",
       "      <td>0.201914</td>\n",
       "      <td>0.192353</td>\n",
       "      <td>0.171933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.289800</td>\n",
       "      <td>1.216897</td>\n",
       "      <td>0.654445</td>\n",
       "      <td>0.269720</td>\n",
       "      <td>0.255174</td>\n",
       "      <td>0.241548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.136500</td>\n",
       "      <td>1.111592</td>\n",
       "      <td>0.677360</td>\n",
       "      <td>0.268374</td>\n",
       "      <td>0.276495</td>\n",
       "      <td>0.258516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.021400</td>\n",
       "      <td>1.036226</td>\n",
       "      <td>0.694775</td>\n",
       "      <td>0.278614</td>\n",
       "      <td>0.290291</td>\n",
       "      <td>0.270664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.943100</td>\n",
       "      <td>0.981014</td>\n",
       "      <td>0.707608</td>\n",
       "      <td>0.291746</td>\n",
       "      <td>0.305156</td>\n",
       "      <td>0.280601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.873000</td>\n",
       "      <td>0.944546</td>\n",
       "      <td>0.711274</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.313319</td>\n",
       "      <td>0.291473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.811500</td>\n",
       "      <td>0.913108</td>\n",
       "      <td>0.717690</td>\n",
       "      <td>0.329446</td>\n",
       "      <td>0.321717</td>\n",
       "      <td>0.301011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.777900</td>\n",
       "      <td>0.889133</td>\n",
       "      <td>0.716774</td>\n",
       "      <td>0.300346</td>\n",
       "      <td>0.319033</td>\n",
       "      <td>0.296325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.735500</td>\n",
       "      <td>0.872579</td>\n",
       "      <td>0.717690</td>\n",
       "      <td>0.319899</td>\n",
       "      <td>0.324299</td>\n",
       "      <td>0.301109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.726100</td>\n",
       "      <td>0.861511</td>\n",
       "      <td>0.717690</td>\n",
       "      <td>0.312559</td>\n",
       "      <td>0.324164</td>\n",
       "      <td>0.301180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.702400</td>\n",
       "      <td>0.852704</td>\n",
       "      <td>0.722273</td>\n",
       "      <td>0.320951</td>\n",
       "      <td>0.327486</td>\n",
       "      <td>0.305248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.696600</td>\n",
       "      <td>0.852306</td>\n",
       "      <td>0.721357</td>\n",
       "      <td>0.321807</td>\n",
       "      <td>0.328786</td>\n",
       "      <td>0.307568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:10:07,551] Trial 10 finished with value: 0.3075680022838695 and parameters: {'learning_rate': 0.00022653365944687691, 'weight_decay': 0.004, 'warmup_steps': 4, 'lambda_param': 0.4, 'temperature': 4.5}. Best is trial 10 with value: 0.3075680022838695.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 with params: {'learning_rate': 0.0001238942211364432, 'weight_decay': 0.005, 'warmup_steps': 4, 'lambda_param': 0.5, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>2.206977</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.133900</td>\n",
       "      <td>2.017157</td>\n",
       "      <td>0.387718</td>\n",
       "      <td>0.061364</td>\n",
       "      <td>0.082170</td>\n",
       "      <td>0.064704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.967100</td>\n",
       "      <td>1.850075</td>\n",
       "      <td>0.432631</td>\n",
       "      <td>0.065698</td>\n",
       "      <td>0.100685</td>\n",
       "      <td>0.075051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.804900</td>\n",
       "      <td>1.705754</td>\n",
       "      <td>0.483960</td>\n",
       "      <td>0.101446</td>\n",
       "      <td>0.132508</td>\n",
       "      <td>0.106113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.678300</td>\n",
       "      <td>1.583165</td>\n",
       "      <td>0.505958</td>\n",
       "      <td>0.127774</td>\n",
       "      <td>0.147325</td>\n",
       "      <td>0.121941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.554000</td>\n",
       "      <td>1.487370</td>\n",
       "      <td>0.538038</td>\n",
       "      <td>0.216887</td>\n",
       "      <td>0.168767</td>\n",
       "      <td>0.151593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.458200</td>\n",
       "      <td>1.411960</td>\n",
       "      <td>0.561870</td>\n",
       "      <td>0.245601</td>\n",
       "      <td>0.189278</td>\n",
       "      <td>0.176221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.387900</td>\n",
       "      <td>1.350164</td>\n",
       "      <td>0.603116</td>\n",
       "      <td>0.261635</td>\n",
       "      <td>0.222797</td>\n",
       "      <td>0.207815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.320100</td>\n",
       "      <td>1.297256</td>\n",
       "      <td>0.632447</td>\n",
       "      <td>0.288024</td>\n",
       "      <td>0.242886</td>\n",
       "      <td>0.234187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.263300</td>\n",
       "      <td>1.257276</td>\n",
       "      <td>0.648029</td>\n",
       "      <td>0.288201</td>\n",
       "      <td>0.256283</td>\n",
       "      <td>0.246275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.228400</td>\n",
       "      <td>1.223844</td>\n",
       "      <td>0.660862</td>\n",
       "      <td>0.282754</td>\n",
       "      <td>0.263455</td>\n",
       "      <td>0.249846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.185600</td>\n",
       "      <td>1.198987</td>\n",
       "      <td>0.661778</td>\n",
       "      <td>0.282086</td>\n",
       "      <td>0.266709</td>\n",
       "      <td>0.253848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.169000</td>\n",
       "      <td>1.182955</td>\n",
       "      <td>0.667278</td>\n",
       "      <td>0.286735</td>\n",
       "      <td>0.271734</td>\n",
       "      <td>0.258578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.151100</td>\n",
       "      <td>1.172776</td>\n",
       "      <td>0.670944</td>\n",
       "      <td>0.283449</td>\n",
       "      <td>0.272925</td>\n",
       "      <td>0.258984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.139700</td>\n",
       "      <td>1.169922</td>\n",
       "      <td>0.670944</td>\n",
       "      <td>0.283570</td>\n",
       "      <td>0.274038</td>\n",
       "      <td>0.259694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:11:24,140] Trial 11 finished with value: 0.25969440039476316 and parameters: {'learning_rate': 0.0001238942211364432, 'weight_decay': 0.005, 'warmup_steps': 4, 'lambda_param': 0.5, 'temperature': 5.0}. Best is trial 10 with value: 0.3075680022838695.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 with params: {'learning_rate': 0.0004297370115180055, 'weight_decay': 0.002, 'warmup_steps': 3, 'lambda_param': 0.0, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.190800</td>\n",
       "      <td>1.891071</td>\n",
       "      <td>0.417049</td>\n",
       "      <td>0.072386</td>\n",
       "      <td>0.095998</td>\n",
       "      <td>0.074860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.691800</td>\n",
       "      <td>1.465970</td>\n",
       "      <td>0.540788</td>\n",
       "      <td>0.167815</td>\n",
       "      <td>0.173703</td>\n",
       "      <td>0.154061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.314000</td>\n",
       "      <td>1.169860</td>\n",
       "      <td>0.648946</td>\n",
       "      <td>0.239484</td>\n",
       "      <td>0.252380</td>\n",
       "      <td>0.232507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.042500</td>\n",
       "      <td>1.004065</td>\n",
       "      <td>0.682860</td>\n",
       "      <td>0.264426</td>\n",
       "      <td>0.285225</td>\n",
       "      <td>0.260594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.856700</td>\n",
       "      <td>0.905390</td>\n",
       "      <td>0.715857</td>\n",
       "      <td>0.316084</td>\n",
       "      <td>0.323639</td>\n",
       "      <td>0.300841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.830315</td>\n",
       "      <td>0.722273</td>\n",
       "      <td>0.340203</td>\n",
       "      <td>0.337802</td>\n",
       "      <td>0.317957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.620300</td>\n",
       "      <td>0.804056</td>\n",
       "      <td>0.727773</td>\n",
       "      <td>0.374812</td>\n",
       "      <td>0.351488</td>\n",
       "      <td>0.337476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.559200</td>\n",
       "      <td>0.773652</td>\n",
       "      <td>0.747938</td>\n",
       "      <td>0.393343</td>\n",
       "      <td>0.388945</td>\n",
       "      <td>0.373866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.505300</td>\n",
       "      <td>0.753080</td>\n",
       "      <td>0.755270</td>\n",
       "      <td>0.437854</td>\n",
       "      <td>0.407170</td>\n",
       "      <td>0.403307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.456500</td>\n",
       "      <td>0.747204</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.429512</td>\n",
       "      <td>0.402067</td>\n",
       "      <td>0.392221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.429100</td>\n",
       "      <td>0.725522</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.446912</td>\n",
       "      <td>0.422055</td>\n",
       "      <td>0.415737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.397600</td>\n",
       "      <td>0.714215</td>\n",
       "      <td>0.756187</td>\n",
       "      <td>0.463308</td>\n",
       "      <td>0.427392</td>\n",
       "      <td>0.425379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.380600</td>\n",
       "      <td>0.705774</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.459911</td>\n",
       "      <td>0.433233</td>\n",
       "      <td>0.428718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.367700</td>\n",
       "      <td>0.701015</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.485001</td>\n",
       "      <td>0.445627</td>\n",
       "      <td>0.441427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.364800</td>\n",
       "      <td>0.702268</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.499473</td>\n",
       "      <td>0.455611</td>\n",
       "      <td>0.453797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:12:40,567] Trial 12 finished with value: 0.4537973075064203 and parameters: {'learning_rate': 0.0004297370115180055, 'weight_decay': 0.002, 'warmup_steps': 3, 'lambda_param': 0.0, 'temperature': 5.0}. Best is trial 12 with value: 0.4537973075064203.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13 with params: {'learning_rate': 0.0003287279860635089, 'weight_decay': 0.002, 'warmup_steps': 3, 'lambda_param': 0.0, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.232000</td>\n",
       "      <td>1.977442</td>\n",
       "      <td>0.384968</td>\n",
       "      <td>0.063085</td>\n",
       "      <td>0.081534</td>\n",
       "      <td>0.064047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.809300</td>\n",
       "      <td>1.598877</td>\n",
       "      <td>0.500458</td>\n",
       "      <td>0.126072</td>\n",
       "      <td>0.144453</td>\n",
       "      <td>0.120127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.470500</td>\n",
       "      <td>1.316373</td>\n",
       "      <td>0.593034</td>\n",
       "      <td>0.226357</td>\n",
       "      <td>0.207701</td>\n",
       "      <td>0.191757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.210500</td>\n",
       "      <td>1.139363</td>\n",
       "      <td>0.663611</td>\n",
       "      <td>0.259354</td>\n",
       "      <td>0.268539</td>\n",
       "      <td>0.251444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.029000</td>\n",
       "      <td>1.016660</td>\n",
       "      <td>0.694775</td>\n",
       "      <td>0.288821</td>\n",
       "      <td>0.294101</td>\n",
       "      <td>0.270620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.880600</td>\n",
       "      <td>0.921803</td>\n",
       "      <td>0.712191</td>\n",
       "      <td>0.299406</td>\n",
       "      <td>0.312454</td>\n",
       "      <td>0.291786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.769900</td>\n",
       "      <td>0.869387</td>\n",
       "      <td>0.710357</td>\n",
       "      <td>0.300381</td>\n",
       "      <td>0.313423</td>\n",
       "      <td>0.292577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.698600</td>\n",
       "      <td>0.835389</td>\n",
       "      <td>0.727773</td>\n",
       "      <td>0.314749</td>\n",
       "      <td>0.341589</td>\n",
       "      <td>0.315834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.639700</td>\n",
       "      <td>0.809206</td>\n",
       "      <td>0.730522</td>\n",
       "      <td>0.364781</td>\n",
       "      <td>0.352378</td>\n",
       "      <td>0.337784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.583200</td>\n",
       "      <td>0.796446</td>\n",
       "      <td>0.744271</td>\n",
       "      <td>0.376778</td>\n",
       "      <td>0.369908</td>\n",
       "      <td>0.354173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.554600</td>\n",
       "      <td>0.775059</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.414368</td>\n",
       "      <td>0.376158</td>\n",
       "      <td>0.364206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.517200</td>\n",
       "      <td>0.760005</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.414670</td>\n",
       "      <td>0.394257</td>\n",
       "      <td>0.384414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.503300</td>\n",
       "      <td>0.754537</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.430600</td>\n",
       "      <td>0.390259</td>\n",
       "      <td>0.381451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.487600</td>\n",
       "      <td>0.748066</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.452348</td>\n",
       "      <td>0.412339</td>\n",
       "      <td>0.405348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.483100</td>\n",
       "      <td>0.749710</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.428107</td>\n",
       "      <td>0.404438</td>\n",
       "      <td>0.393000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:13:55,273] Trial 13 finished with value: 0.3930004795924375 and parameters: {'learning_rate': 0.0003287279860635089, 'weight_decay': 0.002, 'warmup_steps': 3, 'lambda_param': 0.0, 'temperature': 6.0}. Best is trial 12 with value: 0.4537973075064203.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 with params: {'learning_rate': 0.00014690077743882243, 'weight_decay': 0.004, 'warmup_steps': 3, 'lambda_param': 0.0, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:24 < 00:49, 7.10 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.330800</td>\n",
       "      <td>2.171867</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.088500</td>\n",
       "      <td>1.960178</td>\n",
       "      <td>0.403300</td>\n",
       "      <td>0.054664</td>\n",
       "      <td>0.086638</td>\n",
       "      <td>0.063682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.897000</td>\n",
       "      <td>1.767560</td>\n",
       "      <td>0.454629</td>\n",
       "      <td>0.099905</td>\n",
       "      <td>0.116476</td>\n",
       "      <td>0.090907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.714700</td>\n",
       "      <td>1.610514</td>\n",
       "      <td>0.502291</td>\n",
       "      <td>0.128261</td>\n",
       "      <td>0.144916</td>\n",
       "      <td>0.120919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.575700</td>\n",
       "      <td>1.482816</td>\n",
       "      <td>0.549954</td>\n",
       "      <td>0.231415</td>\n",
       "      <td>0.183315</td>\n",
       "      <td>0.166147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:14:20,826] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 with params: {'learning_rate': 0.00037789891348026413, 'weight_decay': 0.0, 'warmup_steps': 2, 'lambda_param': 0.0, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.203000</td>\n",
       "      <td>1.924946</td>\n",
       "      <td>0.400550</td>\n",
       "      <td>0.074459</td>\n",
       "      <td>0.086372</td>\n",
       "      <td>0.064034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.743900</td>\n",
       "      <td>1.527955</td>\n",
       "      <td>0.522456</td>\n",
       "      <td>0.181123</td>\n",
       "      <td>0.162966</td>\n",
       "      <td>0.145819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.387800</td>\n",
       "      <td>1.241255</td>\n",
       "      <td>0.629698</td>\n",
       "      <td>0.227244</td>\n",
       "      <td>0.230616</td>\n",
       "      <td>0.211435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.123500</td>\n",
       "      <td>1.074671</td>\n",
       "      <td>0.677360</td>\n",
       "      <td>0.266058</td>\n",
       "      <td>0.280077</td>\n",
       "      <td>0.259012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.941100</td>\n",
       "      <td>0.961317</td>\n",
       "      <td>0.703941</td>\n",
       "      <td>0.288708</td>\n",
       "      <td>0.305741</td>\n",
       "      <td>0.281788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.798100</td>\n",
       "      <td>0.871703</td>\n",
       "      <td>0.715857</td>\n",
       "      <td>0.331682</td>\n",
       "      <td>0.323188</td>\n",
       "      <td>0.304167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.691300</td>\n",
       "      <td>0.834034</td>\n",
       "      <td>0.710357</td>\n",
       "      <td>0.306275</td>\n",
       "      <td>0.319193</td>\n",
       "      <td>0.298351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.805097</td>\n",
       "      <td>0.739688</td>\n",
       "      <td>0.382933</td>\n",
       "      <td>0.368958</td>\n",
       "      <td>0.350424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.568900</td>\n",
       "      <td>0.782214</td>\n",
       "      <td>0.740605</td>\n",
       "      <td>0.398314</td>\n",
       "      <td>0.384029</td>\n",
       "      <td>0.373404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.516000</td>\n",
       "      <td>0.771054</td>\n",
       "      <td>0.747938</td>\n",
       "      <td>0.413240</td>\n",
       "      <td>0.399741</td>\n",
       "      <td>0.388339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.487300</td>\n",
       "      <td>0.748736</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.432757</td>\n",
       "      <td>0.410197</td>\n",
       "      <td>0.404510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.452800</td>\n",
       "      <td>0.733982</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.445191</td>\n",
       "      <td>0.411981</td>\n",
       "      <td>0.405662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.435600</td>\n",
       "      <td>0.725980</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.437169</td>\n",
       "      <td>0.413406</td>\n",
       "      <td>0.406502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.424000</td>\n",
       "      <td>0.720047</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.440817</td>\n",
       "      <td>0.417678</td>\n",
       "      <td>0.408965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.418900</td>\n",
       "      <td>0.721180</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.456954</td>\n",
       "      <td>0.432161</td>\n",
       "      <td>0.423860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:15:35,860] Trial 15 finished with value: 0.4238603320278003 and parameters: {'learning_rate': 0.00037789891348026413, 'weight_decay': 0.0, 'warmup_steps': 2, 'lambda_param': 0.0, 'temperature': 5.5}. Best is trial 12 with value: 0.4537973075064203.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16 with params: {'learning_rate': 0.00043218919289894907, 'weight_decay': 0.002, 'warmup_steps': 3, 'lambda_param': 0.0, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.189800</td>\n",
       "      <td>1.888986</td>\n",
       "      <td>0.417965</td>\n",
       "      <td>0.071218</td>\n",
       "      <td>0.096213</td>\n",
       "      <td>0.074753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.689200</td>\n",
       "      <td>1.463129</td>\n",
       "      <td>0.540788</td>\n",
       "      <td>0.166682</td>\n",
       "      <td>0.173482</td>\n",
       "      <td>0.153322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.310400</td>\n",
       "      <td>1.166918</td>\n",
       "      <td>0.649863</td>\n",
       "      <td>0.240158</td>\n",
       "      <td>0.252744</td>\n",
       "      <td>0.233149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.038700</td>\n",
       "      <td>1.001279</td>\n",
       "      <td>0.684693</td>\n",
       "      <td>0.265087</td>\n",
       "      <td>0.286408</td>\n",
       "      <td>0.261446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.853000</td>\n",
       "      <td>0.903162</td>\n",
       "      <td>0.716774</td>\n",
       "      <td>0.316176</td>\n",
       "      <td>0.324457</td>\n",
       "      <td>0.300804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.716800</td>\n",
       "      <td>0.828738</td>\n",
       "      <td>0.723190</td>\n",
       "      <td>0.361486</td>\n",
       "      <td>0.342802</td>\n",
       "      <td>0.326439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.617400</td>\n",
       "      <td>0.803076</td>\n",
       "      <td>0.727773</td>\n",
       "      <td>0.362047</td>\n",
       "      <td>0.351748</td>\n",
       "      <td>0.337083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.556400</td>\n",
       "      <td>0.772461</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.394291</td>\n",
       "      <td>0.389921</td>\n",
       "      <td>0.375113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.502700</td>\n",
       "      <td>0.751024</td>\n",
       "      <td>0.757104</td>\n",
       "      <td>0.434832</td>\n",
       "      <td>0.408837</td>\n",
       "      <td>0.403829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.453700</td>\n",
       "      <td>0.746630</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.430585</td>\n",
       "      <td>0.402067</td>\n",
       "      <td>0.392922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.426300</td>\n",
       "      <td>0.723857</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.439439</td>\n",
       "      <td>0.422022</td>\n",
       "      <td>0.412719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.394900</td>\n",
       "      <td>0.712394</td>\n",
       "      <td>0.756187</td>\n",
       "      <td>0.463581</td>\n",
       "      <td>0.427631</td>\n",
       "      <td>0.425756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.377600</td>\n",
       "      <td>0.704101</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.460260</td>\n",
       "      <td>0.433687</td>\n",
       "      <td>0.429116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.364800</td>\n",
       "      <td>0.699510</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.485591</td>\n",
       "      <td>0.447329</td>\n",
       "      <td>0.442534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.362000</td>\n",
       "      <td>0.700762</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.498059</td>\n",
       "      <td>0.455084</td>\n",
       "      <td>0.452650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:16:51,964] Trial 16 finished with value: 0.45265026045659323 and parameters: {'learning_rate': 0.00043218919289894907, 'weight_decay': 0.002, 'warmup_steps': 3, 'lambda_param': 0.0, 'temperature': 3.5}. Best is trial 12 with value: 0.4537973075064203.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17 with params: {'learning_rate': 0.00020632163595140406, 'weight_decay': 0.001, 'warmup_steps': 2, 'lambda_param': 0.0, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:15, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.288800</td>\n",
       "      <td>2.096345</td>\n",
       "      <td>0.207149</td>\n",
       "      <td>0.058288</td>\n",
       "      <td>0.028301</td>\n",
       "      <td>0.019587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.984700</td>\n",
       "      <td>1.824282</td>\n",
       "      <td>0.428964</td>\n",
       "      <td>0.061831</td>\n",
       "      <td>0.101070</td>\n",
       "      <td>0.073720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.737500</td>\n",
       "      <td>1.590943</td>\n",
       "      <td>0.498625</td>\n",
       "      <td>0.125411</td>\n",
       "      <td>0.141597</td>\n",
       "      <td>0.117680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.517300</td>\n",
       "      <td>1.411305</td>\n",
       "      <td>0.560953</td>\n",
       "      <td>0.202674</td>\n",
       "      <td>0.183186</td>\n",
       "      <td>0.163048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.353800</td>\n",
       "      <td>1.275693</td>\n",
       "      <td>0.613199</td>\n",
       "      <td>0.244613</td>\n",
       "      <td>0.220876</td>\n",
       "      <td>0.204115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.205900</td>\n",
       "      <td>1.172037</td>\n",
       "      <td>0.665445</td>\n",
       "      <td>0.264205</td>\n",
       "      <td>0.262075</td>\n",
       "      <td>0.244800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.093900</td>\n",
       "      <td>1.094072</td>\n",
       "      <td>0.677360</td>\n",
       "      <td>0.266649</td>\n",
       "      <td>0.278401</td>\n",
       "      <td>0.258072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.015300</td>\n",
       "      <td>1.036958</td>\n",
       "      <td>0.694775</td>\n",
       "      <td>0.264670</td>\n",
       "      <td>0.293586</td>\n",
       "      <td>0.268487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.943800</td>\n",
       "      <td>0.995043</td>\n",
       "      <td>0.702108</td>\n",
       "      <td>0.291887</td>\n",
       "      <td>0.303314</td>\n",
       "      <td>0.280814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.882100</td>\n",
       "      <td>0.960888</td>\n",
       "      <td>0.710357</td>\n",
       "      <td>0.293098</td>\n",
       "      <td>0.310305</td>\n",
       "      <td>0.286986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.847400</td>\n",
       "      <td>0.934108</td>\n",
       "      <td>0.706691</td>\n",
       "      <td>0.284165</td>\n",
       "      <td>0.309855</td>\n",
       "      <td>0.286279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.804400</td>\n",
       "      <td>0.916855</td>\n",
       "      <td>0.714940</td>\n",
       "      <td>0.287213</td>\n",
       "      <td>0.315554</td>\n",
       "      <td>0.291282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.793100</td>\n",
       "      <td>0.904313</td>\n",
       "      <td>0.712191</td>\n",
       "      <td>0.285036</td>\n",
       "      <td>0.314496</td>\n",
       "      <td>0.290236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.770400</td>\n",
       "      <td>0.894421</td>\n",
       "      <td>0.715857</td>\n",
       "      <td>0.306566</td>\n",
       "      <td>0.317273</td>\n",
       "      <td>0.294339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.764000</td>\n",
       "      <td>0.893705</td>\n",
       "      <td>0.714024</td>\n",
       "      <td>0.290526</td>\n",
       "      <td>0.315643</td>\n",
       "      <td>0.291936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:18:08,686] Trial 17 finished with value: 0.2919364435836574 and parameters: {'learning_rate': 0.00020632163595140406, 'weight_decay': 0.001, 'warmup_steps': 2, 'lambda_param': 0.0, 'temperature': 2.0}. Best is trial 12 with value: 0.4537973075064203.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18 with params: {'learning_rate': 0.000462586328422914, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 0.0, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.185700</td>\n",
       "      <td>1.866588</td>\n",
       "      <td>0.421632</td>\n",
       "      <td>0.065934</td>\n",
       "      <td>0.098534</td>\n",
       "      <td>0.074369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.656700</td>\n",
       "      <td>1.419832</td>\n",
       "      <td>0.558203</td>\n",
       "      <td>0.200100</td>\n",
       "      <td>0.190231</td>\n",
       "      <td>0.169880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.261800</td>\n",
       "      <td>1.129464</td>\n",
       "      <td>0.654445</td>\n",
       "      <td>0.255383</td>\n",
       "      <td>0.261069</td>\n",
       "      <td>0.240716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.993400</td>\n",
       "      <td>0.969516</td>\n",
       "      <td>0.687443</td>\n",
       "      <td>0.259138</td>\n",
       "      <td>0.291344</td>\n",
       "      <td>0.267576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.812100</td>\n",
       "      <td>0.880368</td>\n",
       "      <td>0.716774</td>\n",
       "      <td>0.327198</td>\n",
       "      <td>0.328050</td>\n",
       "      <td>0.305906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.682700</td>\n",
       "      <td>0.814717</td>\n",
       "      <td>0.725023</td>\n",
       "      <td>0.378382</td>\n",
       "      <td>0.353075</td>\n",
       "      <td>0.341835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.585800</td>\n",
       "      <td>0.793198</td>\n",
       "      <td>0.731439</td>\n",
       "      <td>0.402244</td>\n",
       "      <td>0.375111</td>\n",
       "      <td>0.363843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.525700</td>\n",
       "      <td>0.760167</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.402863</td>\n",
       "      <td>0.392513</td>\n",
       "      <td>0.377140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.471500</td>\n",
       "      <td>0.742734</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.460135</td>\n",
       "      <td>0.420536</td>\n",
       "      <td>0.416400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.422700</td>\n",
       "      <td>0.729394</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.472068</td>\n",
       "      <td>0.428736</td>\n",
       "      <td>0.426212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.394300</td>\n",
       "      <td>0.714451</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.483704</td>\n",
       "      <td>0.439783</td>\n",
       "      <td>0.436630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.699423</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.522443</td>\n",
       "      <td>0.445577</td>\n",
       "      <td>0.452020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.346700</td>\n",
       "      <td>0.693017</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.479210</td>\n",
       "      <td>0.454068</td>\n",
       "      <td>0.452945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.335800</td>\n",
       "      <td>0.688320</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.501269</td>\n",
       "      <td>0.456468</td>\n",
       "      <td>0.456209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.333200</td>\n",
       "      <td>0.689795</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.506318</td>\n",
       "      <td>0.458129</td>\n",
       "      <td>0.459479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:19:23,278] Trial 18 finished with value: 0.45947921384572155 and parameters: {'learning_rate': 0.000462586328422914, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 0.0, 'temperature': 2.0}. Best is trial 18 with value: 0.45947921384572155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 19 with params: {'learning_rate': 0.0004392564949386537, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.0, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:16, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.194600</td>\n",
       "      <td>1.887239</td>\n",
       "      <td>0.416132</td>\n",
       "      <td>0.070492</td>\n",
       "      <td>0.095182</td>\n",
       "      <td>0.073007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.682700</td>\n",
       "      <td>1.448741</td>\n",
       "      <td>0.555454</td>\n",
       "      <td>0.184139</td>\n",
       "      <td>0.187613</td>\n",
       "      <td>0.168167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.295100</td>\n",
       "      <td>1.154936</td>\n",
       "      <td>0.650779</td>\n",
       "      <td>0.256180</td>\n",
       "      <td>0.255126</td>\n",
       "      <td>0.236275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.025800</td>\n",
       "      <td>0.992144</td>\n",
       "      <td>0.693859</td>\n",
       "      <td>0.278319</td>\n",
       "      <td>0.300242</td>\n",
       "      <td>0.278692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.842100</td>\n",
       "      <td>0.897182</td>\n",
       "      <td>0.716774</td>\n",
       "      <td>0.338521</td>\n",
       "      <td>0.327387</td>\n",
       "      <td>0.306282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.709900</td>\n",
       "      <td>0.826725</td>\n",
       "      <td>0.722273</td>\n",
       "      <td>0.372297</td>\n",
       "      <td>0.344677</td>\n",
       "      <td>0.329236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.610100</td>\n",
       "      <td>0.799507</td>\n",
       "      <td>0.733272</td>\n",
       "      <td>0.372214</td>\n",
       "      <td>0.364816</td>\n",
       "      <td>0.348089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.549300</td>\n",
       "      <td>0.767925</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.409311</td>\n",
       "      <td>0.396169</td>\n",
       "      <td>0.380251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.493800</td>\n",
       "      <td>0.750237</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.430352</td>\n",
       "      <td>0.408861</td>\n",
       "      <td>0.398882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.444400</td>\n",
       "      <td>0.740099</td>\n",
       "      <td>0.756187</td>\n",
       "      <td>0.439644</td>\n",
       "      <td>0.413017</td>\n",
       "      <td>0.405397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.416300</td>\n",
       "      <td>0.722802</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.459458</td>\n",
       "      <td>0.426376</td>\n",
       "      <td>0.421423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.386600</td>\n",
       "      <td>0.708279</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.488569</td>\n",
       "      <td>0.433131</td>\n",
       "      <td>0.435256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.367700</td>\n",
       "      <td>0.701450</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.476954</td>\n",
       "      <td>0.444101</td>\n",
       "      <td>0.440690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.355800</td>\n",
       "      <td>0.695844</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.492786</td>\n",
       "      <td>0.457588</td>\n",
       "      <td>0.453122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.353200</td>\n",
       "      <td>0.697294</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.485984</td>\n",
       "      <td>0.451237</td>\n",
       "      <td>0.445417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:20:41,232] Trial 19 finished with value: 0.445417028736355 and parameters: {'learning_rate': 0.0004392564949386537, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.0, 'temperature': 2.0}. Best is trial 18 with value: 0.45947921384572155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 with params: {'learning_rate': 0.000418311875401925, 'weight_decay': 0.0, 'warmup_steps': 4, 'lambda_param': 0.2, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.202600</td>\n",
       "      <td>1.905834</td>\n",
       "      <td>0.403300</td>\n",
       "      <td>0.073732</td>\n",
       "      <td>0.088277</td>\n",
       "      <td>0.065812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.706100</td>\n",
       "      <td>1.476558</td>\n",
       "      <td>0.540788</td>\n",
       "      <td>0.174127</td>\n",
       "      <td>0.172028</td>\n",
       "      <td>0.153064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.325700</td>\n",
       "      <td>1.180012</td>\n",
       "      <td>0.651696</td>\n",
       "      <td>0.257067</td>\n",
       "      <td>0.253489</td>\n",
       "      <td>0.233793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.056500</td>\n",
       "      <td>1.018214</td>\n",
       "      <td>0.684693</td>\n",
       "      <td>0.259493</td>\n",
       "      <td>0.287168</td>\n",
       "      <td>0.263807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.872600</td>\n",
       "      <td>0.916705</td>\n",
       "      <td>0.713107</td>\n",
       "      <td>0.314899</td>\n",
       "      <td>0.319719</td>\n",
       "      <td>0.300048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.735800</td>\n",
       "      <td>0.840112</td>\n",
       "      <td>0.723190</td>\n",
       "      <td>0.363084</td>\n",
       "      <td>0.338025</td>\n",
       "      <td>0.320886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.634200</td>\n",
       "      <td>0.808881</td>\n",
       "      <td>0.727773</td>\n",
       "      <td>0.378891</td>\n",
       "      <td>0.350098</td>\n",
       "      <td>0.339506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.571400</td>\n",
       "      <td>0.779014</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.386680</td>\n",
       "      <td>0.392159</td>\n",
       "      <td>0.374386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.515400</td>\n",
       "      <td>0.758218</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.407715</td>\n",
       "      <td>0.389580</td>\n",
       "      <td>0.378649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.465600</td>\n",
       "      <td>0.749496</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.438800</td>\n",
       "      <td>0.406638</td>\n",
       "      <td>0.399811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.437200</td>\n",
       "      <td>0.730208</td>\n",
       "      <td>0.756187</td>\n",
       "      <td>0.456826</td>\n",
       "      <td>0.419838</td>\n",
       "      <td>0.414706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.405100</td>\n",
       "      <td>0.716782</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.474781</td>\n",
       "      <td>0.425860</td>\n",
       "      <td>0.426343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.387800</td>\n",
       "      <td>0.710869</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.475060</td>\n",
       "      <td>0.432153</td>\n",
       "      <td>0.429235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.375800</td>\n",
       "      <td>0.705501</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.478601</td>\n",
       "      <td>0.445915</td>\n",
       "      <td>0.441156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.372400</td>\n",
       "      <td>0.707052</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.493780</td>\n",
       "      <td>0.450795</td>\n",
       "      <td>0.450121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:21:57,330] Trial 20 finished with value: 0.4501210336948468 and parameters: {'learning_rate': 0.000418311875401925, 'weight_decay': 0.0, 'warmup_steps': 4, 'lambda_param': 0.2, 'temperature': 2.0}. Best is trial 18 with value: 0.45947921384572155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 21 with params: {'learning_rate': 0.0003962948462538969, 'weight_decay': 0.0, 'warmup_steps': 4, 'lambda_param': 0.1, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:50 < 00:25, 6.91 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.211000</td>\n",
       "      <td>1.924031</td>\n",
       "      <td>0.397800</td>\n",
       "      <td>0.074607</td>\n",
       "      <td>0.085978</td>\n",
       "      <td>0.063571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.730700</td>\n",
       "      <td>1.504362</td>\n",
       "      <td>0.529789</td>\n",
       "      <td>0.170163</td>\n",
       "      <td>0.165481</td>\n",
       "      <td>0.146195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.358700</td>\n",
       "      <td>1.208310</td>\n",
       "      <td>0.641613</td>\n",
       "      <td>0.225670</td>\n",
       "      <td>0.242872</td>\n",
       "      <td>0.220785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.091100</td>\n",
       "      <td>1.044652</td>\n",
       "      <td>0.683776</td>\n",
       "      <td>0.271126</td>\n",
       "      <td>0.284644</td>\n",
       "      <td>0.264734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.907800</td>\n",
       "      <td>0.937786</td>\n",
       "      <td>0.709441</td>\n",
       "      <td>0.299702</td>\n",
       "      <td>0.311690</td>\n",
       "      <td>0.289932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.766500</td>\n",
       "      <td>0.852584</td>\n",
       "      <td>0.725023</td>\n",
       "      <td>0.357673</td>\n",
       "      <td>0.333842</td>\n",
       "      <td>0.316860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.660900</td>\n",
       "      <td>0.815803</td>\n",
       "      <td>0.724106</td>\n",
       "      <td>0.355343</td>\n",
       "      <td>0.342654</td>\n",
       "      <td>0.327300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.595800</td>\n",
       "      <td>0.787293</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.393035</td>\n",
       "      <td>0.379415</td>\n",
       "      <td>0.363065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.764593</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.408950</td>\n",
       "      <td>0.386698</td>\n",
       "      <td>0.375912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.488800</td>\n",
       "      <td>0.758265</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.439012</td>\n",
       "      <td>0.399474</td>\n",
       "      <td>0.391057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:22:48,702] Trial 21 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 22 with params: {'learning_rate': 0.0004472927966194536, 'weight_decay': 0.004, 'warmup_steps': 2, 'lambda_param': 0.1, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.172000</td>\n",
       "      <td>1.861190</td>\n",
       "      <td>0.423465</td>\n",
       "      <td>0.063210</td>\n",
       "      <td>0.099076</td>\n",
       "      <td>0.073623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.660200</td>\n",
       "      <td>1.434152</td>\n",
       "      <td>0.552704</td>\n",
       "      <td>0.214218</td>\n",
       "      <td>0.189398</td>\n",
       "      <td>0.171931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.280900</td>\n",
       "      <td>1.151746</td>\n",
       "      <td>0.647113</td>\n",
       "      <td>0.255225</td>\n",
       "      <td>0.250180</td>\n",
       "      <td>0.232757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.017700</td>\n",
       "      <td>0.990915</td>\n",
       "      <td>0.696609</td>\n",
       "      <td>0.264238</td>\n",
       "      <td>0.293701</td>\n",
       "      <td>0.269662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.837400</td>\n",
       "      <td>0.894149</td>\n",
       "      <td>0.714024</td>\n",
       "      <td>0.325997</td>\n",
       "      <td>0.325795</td>\n",
       "      <td>0.303925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.706400</td>\n",
       "      <td>0.825621</td>\n",
       "      <td>0.718607</td>\n",
       "      <td>0.352011</td>\n",
       "      <td>0.336042</td>\n",
       "      <td>0.322043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.607600</td>\n",
       "      <td>0.803365</td>\n",
       "      <td>0.732356</td>\n",
       "      <td>0.395217</td>\n",
       "      <td>0.372308</td>\n",
       "      <td>0.355438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.546500</td>\n",
       "      <td>0.769490</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.428380</td>\n",
       "      <td>0.399547</td>\n",
       "      <td>0.388971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.492300</td>\n",
       "      <td>0.752295</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.445620</td>\n",
       "      <td>0.413195</td>\n",
       "      <td>0.406179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.442300</td>\n",
       "      <td>0.735858</td>\n",
       "      <td>0.756187</td>\n",
       "      <td>0.445012</td>\n",
       "      <td>0.418632</td>\n",
       "      <td>0.412858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.413500</td>\n",
       "      <td>0.718042</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.466686</td>\n",
       "      <td>0.434470</td>\n",
       "      <td>0.429724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.383900</td>\n",
       "      <td>0.703383</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.468524</td>\n",
       "      <td>0.430899</td>\n",
       "      <td>0.430695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.366800</td>\n",
       "      <td>0.698594</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.492816</td>\n",
       "      <td>0.447036</td>\n",
       "      <td>0.445557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.353900</td>\n",
       "      <td>0.694609</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.490835</td>\n",
       "      <td>0.446794</td>\n",
       "      <td>0.443474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.351400</td>\n",
       "      <td>0.695463</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.496340</td>\n",
       "      <td>0.454149</td>\n",
       "      <td>0.449443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:24:05,095] Trial 22 finished with value: 0.44944255910489334 and parameters: {'learning_rate': 0.0004472927966194536, 'weight_decay': 0.004, 'warmup_steps': 2, 'lambda_param': 0.1, 'temperature': 4.5}. Best is trial 18 with value: 0.45947921384572155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 23 with params: {'learning_rate': 0.00012789838339807573, 'weight_decay': 0.0, 'warmup_steps': 4, 'lambda_param': 0.0, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:48, 7.26 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>2.201322</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.126400</td>\n",
       "      <td>2.007705</td>\n",
       "      <td>0.389551</td>\n",
       "      <td>0.059545</td>\n",
       "      <td>0.082818</td>\n",
       "      <td>0.063850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.955200</td>\n",
       "      <td>1.835473</td>\n",
       "      <td>0.437214</td>\n",
       "      <td>0.082669</td>\n",
       "      <td>0.104127</td>\n",
       "      <td>0.078796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.789100</td>\n",
       "      <td>1.689087</td>\n",
       "      <td>0.488543</td>\n",
       "      <td>0.099987</td>\n",
       "      <td>0.134972</td>\n",
       "      <td>0.107650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>1.564951</td>\n",
       "      <td>0.510541</td>\n",
       "      <td>0.147847</td>\n",
       "      <td>0.150052</td>\n",
       "      <td>0.125313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:24:29,949] Trial 23 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 24 with params: {'learning_rate': 0.00019834397434131536, 'weight_decay': 0.004, 'warmup_steps': 3, 'lambda_param': 0.0, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:49 < 00:24, 7.04 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.298800</td>\n",
       "      <td>2.109601</td>\n",
       "      <td>0.184235</td>\n",
       "      <td>0.040234</td>\n",
       "      <td>0.022012</td>\n",
       "      <td>0.009856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.001200</td>\n",
       "      <td>1.843523</td>\n",
       "      <td>0.424381</td>\n",
       "      <td>0.061142</td>\n",
       "      <td>0.099268</td>\n",
       "      <td>0.072452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.758700</td>\n",
       "      <td>1.612601</td>\n",
       "      <td>0.497709</td>\n",
       "      <td>0.145642</td>\n",
       "      <td>0.144688</td>\n",
       "      <td>0.123712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.541400</td>\n",
       "      <td>1.434249</td>\n",
       "      <td>0.554537</td>\n",
       "      <td>0.220936</td>\n",
       "      <td>0.179438</td>\n",
       "      <td>0.160281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.380400</td>\n",
       "      <td>1.299175</td>\n",
       "      <td>0.607699</td>\n",
       "      <td>0.243361</td>\n",
       "      <td>0.216878</td>\n",
       "      <td>0.200311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.233200</td>\n",
       "      <td>1.194234</td>\n",
       "      <td>0.659945</td>\n",
       "      <td>0.263308</td>\n",
       "      <td>0.259061</td>\n",
       "      <td>0.242589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.121400</td>\n",
       "      <td>1.115353</td>\n",
       "      <td>0.674610</td>\n",
       "      <td>0.269436</td>\n",
       "      <td>0.275963</td>\n",
       "      <td>0.257306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.042700</td>\n",
       "      <td>1.057074</td>\n",
       "      <td>0.687443</td>\n",
       "      <td>0.256203</td>\n",
       "      <td>0.286874</td>\n",
       "      <td>0.262040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.969900</td>\n",
       "      <td>1.012904</td>\n",
       "      <td>0.698442</td>\n",
       "      <td>0.293704</td>\n",
       "      <td>0.299340</td>\n",
       "      <td>0.277165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.907900</td>\n",
       "      <td>0.977776</td>\n",
       "      <td>0.703941</td>\n",
       "      <td>0.295022</td>\n",
       "      <td>0.304544</td>\n",
       "      <td>0.281879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:25:20,485] Trial 24 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 with params: {'learning_rate': 0.0004548883029411888, 'weight_decay': 0.001, 'warmup_steps': 3, 'lambda_param': 0.4, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.180500</td>\n",
       "      <td>1.869206</td>\n",
       "      <td>0.422548</td>\n",
       "      <td>0.066028</td>\n",
       "      <td>0.098579</td>\n",
       "      <td>0.074761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.664900</td>\n",
       "      <td>1.438095</td>\n",
       "      <td>0.549038</td>\n",
       "      <td>0.196747</td>\n",
       "      <td>0.182228</td>\n",
       "      <td>0.163658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.278800</td>\n",
       "      <td>1.142094</td>\n",
       "      <td>0.652612</td>\n",
       "      <td>0.240361</td>\n",
       "      <td>0.256435</td>\n",
       "      <td>0.234318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.006300</td>\n",
       "      <td>0.978491</td>\n",
       "      <td>0.686526</td>\n",
       "      <td>0.271548</td>\n",
       "      <td>0.288104</td>\n",
       "      <td>0.262795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.821700</td>\n",
       "      <td>0.884826</td>\n",
       "      <td>0.714024</td>\n",
       "      <td>0.299063</td>\n",
       "      <td>0.320099</td>\n",
       "      <td>0.295102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.690300</td>\n",
       "      <td>0.816499</td>\n",
       "      <td>0.725023</td>\n",
       "      <td>0.367540</td>\n",
       "      <td>0.345978</td>\n",
       "      <td>0.329801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.593500</td>\n",
       "      <td>0.797207</td>\n",
       "      <td>0.728689</td>\n",
       "      <td>0.363053</td>\n",
       "      <td>0.361625</td>\n",
       "      <td>0.344725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.534300</td>\n",
       "      <td>0.763246</td>\n",
       "      <td>0.747938</td>\n",
       "      <td>0.412830</td>\n",
       "      <td>0.400175</td>\n",
       "      <td>0.388660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.482200</td>\n",
       "      <td>0.745007</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.428331</td>\n",
       "      <td>0.407578</td>\n",
       "      <td>0.401389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.432400</td>\n",
       "      <td>0.734170</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.438311</td>\n",
       "      <td>0.417913</td>\n",
       "      <td>0.408510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.406100</td>\n",
       "      <td>0.713210</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.445398</td>\n",
       "      <td>0.426265</td>\n",
       "      <td>0.418756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.375300</td>\n",
       "      <td>0.702357</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.471008</td>\n",
       "      <td>0.430847</td>\n",
       "      <td>0.430061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.357700</td>\n",
       "      <td>0.695488</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.471957</td>\n",
       "      <td>0.441957</td>\n",
       "      <td>0.439786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.345500</td>\n",
       "      <td>0.692445</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.465268</td>\n",
       "      <td>0.449256</td>\n",
       "      <td>0.442708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.343300</td>\n",
       "      <td>0.693140</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.506101</td>\n",
       "      <td>0.464793</td>\n",
       "      <td>0.464530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:26:36,311] Trial 25 finished with value: 0.46453030960093045 and parameters: {'learning_rate': 0.0004548883029411888, 'weight_decay': 0.001, 'warmup_steps': 3, 'lambda_param': 0.4, 'temperature': 3.5}. Best is trial 25 with value: 0.46453030960093045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 with params: {'learning_rate': 1.7944110405218628e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 1, 'lambda_param': 0.4, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:48 < 00:24, 7.13 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.447300</td>\n",
       "      <td>2.404163</td>\n",
       "      <td>0.137489</td>\n",
       "      <td>0.009553</td>\n",
       "      <td>0.036653</td>\n",
       "      <td>0.009047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.390900</td>\n",
       "      <td>2.352963</td>\n",
       "      <td>0.184235</td>\n",
       "      <td>0.020650</td>\n",
       "      <td>0.022632</td>\n",
       "      <td>0.010578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.351300</td>\n",
       "      <td>2.315023</td>\n",
       "      <td>0.182401</td>\n",
       "      <td>0.014490</td>\n",
       "      <td>0.021644</td>\n",
       "      <td>0.008931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.317200</td>\n",
       "      <td>2.283427</td>\n",
       "      <td>0.181485</td>\n",
       "      <td>0.020231</td>\n",
       "      <td>0.021370</td>\n",
       "      <td>0.008582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.288300</td>\n",
       "      <td>2.251740</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023554</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.259600</td>\n",
       "      <td>2.226571</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023554</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.237400</td>\n",
       "      <td>2.204318</td>\n",
       "      <td>0.182401</td>\n",
       "      <td>0.043567</td>\n",
       "      <td>0.021585</td>\n",
       "      <td>0.009045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.218800</td>\n",
       "      <td>2.185188</td>\n",
       "      <td>0.192484</td>\n",
       "      <td>0.063604</td>\n",
       "      <td>0.024527</td>\n",
       "      <td>0.013900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.202100</td>\n",
       "      <td>2.169127</td>\n",
       "      <td>0.216315</td>\n",
       "      <td>0.061468</td>\n",
       "      <td>0.031081</td>\n",
       "      <td>0.023561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.189800</td>\n",
       "      <td>2.155197</td>\n",
       "      <td>0.231897</td>\n",
       "      <td>0.073110</td>\n",
       "      <td>0.035539</td>\n",
       "      <td>0.029775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:27:26,048] Trial 26 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 27 with params: {'learning_rate': 0.00044102599076789074, 'weight_decay': 0.001, 'warmup_steps': 3, 'lambda_param': 0.6000000000000001, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.186300</td>\n",
       "      <td>1.881404</td>\n",
       "      <td>0.420715</td>\n",
       "      <td>0.068956</td>\n",
       "      <td>0.097719</td>\n",
       "      <td>0.075280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.679700</td>\n",
       "      <td>1.452969</td>\n",
       "      <td>0.540788</td>\n",
       "      <td>0.168875</td>\n",
       "      <td>0.173741</td>\n",
       "      <td>0.153621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.297900</td>\n",
       "      <td>1.157043</td>\n",
       "      <td>0.650779</td>\n",
       "      <td>0.238471</td>\n",
       "      <td>0.253763</td>\n",
       "      <td>0.233099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.025700</td>\n",
       "      <td>0.992307</td>\n",
       "      <td>0.685610</td>\n",
       "      <td>0.265253</td>\n",
       "      <td>0.287452</td>\n",
       "      <td>0.262047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.840500</td>\n",
       "      <td>0.895887</td>\n",
       "      <td>0.714024</td>\n",
       "      <td>0.301148</td>\n",
       "      <td>0.322210</td>\n",
       "      <td>0.297596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.706000</td>\n",
       "      <td>0.823649</td>\n",
       "      <td>0.725023</td>\n",
       "      <td>0.362307</td>\n",
       "      <td>0.344923</td>\n",
       "      <td>0.328486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.607300</td>\n",
       "      <td>0.799512</td>\n",
       "      <td>0.730522</td>\n",
       "      <td>0.374015</td>\n",
       "      <td>0.356347</td>\n",
       "      <td>0.341218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.546900</td>\n",
       "      <td>0.767921</td>\n",
       "      <td>0.747938</td>\n",
       "      <td>0.384420</td>\n",
       "      <td>0.391588</td>\n",
       "      <td>0.374352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.494000</td>\n",
       "      <td>0.745995</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.430806</td>\n",
       "      <td>0.409052</td>\n",
       "      <td>0.403767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.444600</td>\n",
       "      <td>0.741683</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.434530</td>\n",
       "      <td>0.411795</td>\n",
       "      <td>0.402091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.417600</td>\n",
       "      <td>0.718107</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.446526</td>\n",
       "      <td>0.425718</td>\n",
       "      <td>0.417634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.386500</td>\n",
       "      <td>0.707041</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.465898</td>\n",
       "      <td>0.429672</td>\n",
       "      <td>0.427737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.369100</td>\n",
       "      <td>0.699490</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.481083</td>\n",
       "      <td>0.438078</td>\n",
       "      <td>0.436469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.356300</td>\n",
       "      <td>0.695713</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.480978</td>\n",
       "      <td>0.449110</td>\n",
       "      <td>0.443032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.353900</td>\n",
       "      <td>0.696734</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.517509</td>\n",
       "      <td>0.460979</td>\n",
       "      <td>0.460613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:28:42,179] Trial 27 finished with value: 0.4606128626709426 and parameters: {'learning_rate': 0.00044102599076789074, 'weight_decay': 0.001, 'warmup_steps': 3, 'lambda_param': 0.6000000000000001, 'temperature': 4.5}. Best is trial 25 with value: 0.46453030960093045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 28 with params: {'learning_rate': 0.00020776571785130973, 'weight_decay': 0.001, 'warmup_steps': 3, 'lambda_param': 0.5, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:24 < 00:49, 7.02 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.293400</td>\n",
       "      <td>2.099753</td>\n",
       "      <td>0.197067</td>\n",
       "      <td>0.038919</td>\n",
       "      <td>0.025561</td>\n",
       "      <td>0.015675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.986500</td>\n",
       "      <td>1.823851</td>\n",
       "      <td>0.432631</td>\n",
       "      <td>0.081443</td>\n",
       "      <td>0.104453</td>\n",
       "      <td>0.078275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.735600</td>\n",
       "      <td>1.587795</td>\n",
       "      <td>0.502291</td>\n",
       "      <td>0.145512</td>\n",
       "      <td>0.146721</td>\n",
       "      <td>0.125266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.513600</td>\n",
       "      <td>1.407041</td>\n",
       "      <td>0.562786</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.184148</td>\n",
       "      <td>0.164613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.349100</td>\n",
       "      <td>1.270774</td>\n",
       "      <td>0.618698</td>\n",
       "      <td>0.222184</td>\n",
       "      <td>0.220895</td>\n",
       "      <td>0.201096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:29:07,818] Trial 28 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 29 with params: {'learning_rate': 0.00038182066544290374, 'weight_decay': 0.002, 'warmup_steps': 2, 'lambda_param': 1.0, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:15, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.201200</td>\n",
       "      <td>1.921113</td>\n",
       "      <td>0.404216</td>\n",
       "      <td>0.074599</td>\n",
       "      <td>0.087662</td>\n",
       "      <td>0.065682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.738800</td>\n",
       "      <td>1.522052</td>\n",
       "      <td>0.523373</td>\n",
       "      <td>0.180120</td>\n",
       "      <td>0.163430</td>\n",
       "      <td>0.146252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.381200</td>\n",
       "      <td>1.235390</td>\n",
       "      <td>0.632447</td>\n",
       "      <td>0.228627</td>\n",
       "      <td>0.231707</td>\n",
       "      <td>0.213016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.117200</td>\n",
       "      <td>1.069633</td>\n",
       "      <td>0.677360</td>\n",
       "      <td>0.264087</td>\n",
       "      <td>0.279986</td>\n",
       "      <td>0.258435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.934800</td>\n",
       "      <td>0.956980</td>\n",
       "      <td>0.704858</td>\n",
       "      <td>0.288086</td>\n",
       "      <td>0.306195</td>\n",
       "      <td>0.282685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.792500</td>\n",
       "      <td>0.868792</td>\n",
       "      <td>0.714940</td>\n",
       "      <td>0.331253</td>\n",
       "      <td>0.323231</td>\n",
       "      <td>0.304013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.686200</td>\n",
       "      <td>0.831799</td>\n",
       "      <td>0.714940</td>\n",
       "      <td>0.335549</td>\n",
       "      <td>0.327907</td>\n",
       "      <td>0.311206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.620100</td>\n",
       "      <td>0.802957</td>\n",
       "      <td>0.738772</td>\n",
       "      <td>0.380541</td>\n",
       "      <td>0.369700</td>\n",
       "      <td>0.349635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.564400</td>\n",
       "      <td>0.774037</td>\n",
       "      <td>0.742438</td>\n",
       "      <td>0.397099</td>\n",
       "      <td>0.383242</td>\n",
       "      <td>0.372097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.511000</td>\n",
       "      <td>0.769407</td>\n",
       "      <td>0.747938</td>\n",
       "      <td>0.434773</td>\n",
       "      <td>0.403699</td>\n",
       "      <td>0.392604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.482300</td>\n",
       "      <td>0.746398</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.440011</td>\n",
       "      <td>0.412113</td>\n",
       "      <td>0.406737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.448300</td>\n",
       "      <td>0.732051</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.435499</td>\n",
       "      <td>0.410500</td>\n",
       "      <td>0.405146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.431200</td>\n",
       "      <td>0.724695</td>\n",
       "      <td>0.757104</td>\n",
       "      <td>0.440274</td>\n",
       "      <td>0.416555</td>\n",
       "      <td>0.410428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.419300</td>\n",
       "      <td>0.718144</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.446624</td>\n",
       "      <td>0.424917</td>\n",
       "      <td>0.416803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.414300</td>\n",
       "      <td>0.719356</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.455304</td>\n",
       "      <td>0.432324</td>\n",
       "      <td>0.423714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:30:25,213] Trial 29 finished with value: 0.42371368321589153 and parameters: {'learning_rate': 0.00038182066544290374, 'weight_decay': 0.002, 'warmup_steps': 2, 'lambda_param': 1.0, 'temperature': 4.5}. Best is trial 25 with value: 0.46453030960093045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 with params: {'learning_rate': 0.00035975819697717514, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 0.9, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.225200</td>\n",
       "      <td>1.955004</td>\n",
       "      <td>0.389551</td>\n",
       "      <td>0.059045</td>\n",
       "      <td>0.083166</td>\n",
       "      <td>0.063044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.774800</td>\n",
       "      <td>1.555810</td>\n",
       "      <td>0.513291</td>\n",
       "      <td>0.139393</td>\n",
       "      <td>0.152102</td>\n",
       "      <td>0.129238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.418800</td>\n",
       "      <td>1.265274</td>\n",
       "      <td>0.615949</td>\n",
       "      <td>0.229215</td>\n",
       "      <td>0.225477</td>\n",
       "      <td>0.207387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.154300</td>\n",
       "      <td>1.095396</td>\n",
       "      <td>0.672777</td>\n",
       "      <td>0.270379</td>\n",
       "      <td>0.276634</td>\n",
       "      <td>0.258244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.972500</td>\n",
       "      <td>0.980502</td>\n",
       "      <td>0.700275</td>\n",
       "      <td>0.285668</td>\n",
       "      <td>0.301995</td>\n",
       "      <td>0.278059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.826400</td>\n",
       "      <td>0.885691</td>\n",
       "      <td>0.718607</td>\n",
       "      <td>0.321769</td>\n",
       "      <td>0.324301</td>\n",
       "      <td>0.304400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.716000</td>\n",
       "      <td>0.840155</td>\n",
       "      <td>0.715857</td>\n",
       "      <td>0.324130</td>\n",
       "      <td>0.321757</td>\n",
       "      <td>0.302107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.647800</td>\n",
       "      <td>0.811585</td>\n",
       "      <td>0.731439</td>\n",
       "      <td>0.381699</td>\n",
       "      <td>0.358099</td>\n",
       "      <td>0.339722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.590300</td>\n",
       "      <td>0.785523</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.403642</td>\n",
       "      <td>0.370082</td>\n",
       "      <td>0.361194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.536100</td>\n",
       "      <td>0.774313</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.403909</td>\n",
       "      <td>0.386471</td>\n",
       "      <td>0.374395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.507500</td>\n",
       "      <td>0.755096</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.424891</td>\n",
       "      <td>0.396442</td>\n",
       "      <td>0.389071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.471400</td>\n",
       "      <td>0.742630</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.425155</td>\n",
       "      <td>0.404806</td>\n",
       "      <td>0.396084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.455800</td>\n",
       "      <td>0.737207</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.449858</td>\n",
       "      <td>0.406538</td>\n",
       "      <td>0.400992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.441500</td>\n",
       "      <td>0.731524</td>\n",
       "      <td>0.755270</td>\n",
       "      <td>0.455413</td>\n",
       "      <td>0.412328</td>\n",
       "      <td>0.405431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.437900</td>\n",
       "      <td>0.733592</td>\n",
       "      <td>0.756187</td>\n",
       "      <td>0.434097</td>\n",
       "      <td>0.411733</td>\n",
       "      <td>0.403430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:31:41,564] Trial 30 finished with value: 0.4034298617313803 and parameters: {'learning_rate': 0.00035975819697717514, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 0.9, 'temperature': 2.0}. Best is trial 25 with value: 0.46453030960093045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 31 with params: {'learning_rate': 0.00047466236594699297, 'weight_decay': 0.003, 'warmup_steps': 3, 'lambda_param': 0.5, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.172500</td>\n",
       "      <td>1.851465</td>\n",
       "      <td>0.428048</td>\n",
       "      <td>0.064181</td>\n",
       "      <td>0.102020</td>\n",
       "      <td>0.075786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.642900</td>\n",
       "      <td>1.415416</td>\n",
       "      <td>0.553621</td>\n",
       "      <td>0.200641</td>\n",
       "      <td>0.189111</td>\n",
       "      <td>0.170654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.251300</td>\n",
       "      <td>1.121557</td>\n",
       "      <td>0.656279</td>\n",
       "      <td>0.238639</td>\n",
       "      <td>0.262938</td>\n",
       "      <td>0.240279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.979700</td>\n",
       "      <td>0.958638</td>\n",
       "      <td>0.692026</td>\n",
       "      <td>0.276896</td>\n",
       "      <td>0.293033</td>\n",
       "      <td>0.271312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.797500</td>\n",
       "      <td>0.872086</td>\n",
       "      <td>0.713107</td>\n",
       "      <td>0.308161</td>\n",
       "      <td>0.323691</td>\n",
       "      <td>0.298488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.671100</td>\n",
       "      <td>0.809066</td>\n",
       "      <td>0.729606</td>\n",
       "      <td>0.383075</td>\n",
       "      <td>0.360800</td>\n",
       "      <td>0.349676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.574400</td>\n",
       "      <td>0.789227</td>\n",
       "      <td>0.732356</td>\n",
       "      <td>0.364978</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.348603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.516200</td>\n",
       "      <td>0.757346</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.425041</td>\n",
       "      <td>0.403851</td>\n",
       "      <td>0.392325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.464800</td>\n",
       "      <td>0.733786</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.456376</td>\n",
       "      <td>0.420232</td>\n",
       "      <td>0.417378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.415600</td>\n",
       "      <td>0.731074</td>\n",
       "      <td>0.755270</td>\n",
       "      <td>0.452860</td>\n",
       "      <td>0.420965</td>\n",
       "      <td>0.415495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.388900</td>\n",
       "      <td>0.707535</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.488356</td>\n",
       "      <td>0.440073</td>\n",
       "      <td>0.439936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.359500</td>\n",
       "      <td>0.697993</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.492972</td>\n",
       "      <td>0.443177</td>\n",
       "      <td>0.444653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.341900</td>\n",
       "      <td>0.690926</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.457873</td>\n",
       "      <td>0.448156</td>\n",
       "      <td>0.441410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.687590</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.487106</td>\n",
       "      <td>0.454822</td>\n",
       "      <td>0.453723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.327800</td>\n",
       "      <td>0.688146</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.470067</td>\n",
       "      <td>0.454296</td>\n",
       "      <td>0.449305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:32:57,420] Trial 31 finished with value: 0.4493050948881866 and parameters: {'learning_rate': 0.00047466236594699297, 'weight_decay': 0.003, 'warmup_steps': 3, 'lambda_param': 0.5, 'temperature': 3.5}. Best is trial 25 with value: 0.46453030960093045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 32 with params: {'learning_rate': 0.000380377126709603, 'weight_decay': 0.0, 'warmup_steps': 3, 'lambda_param': 0.5, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:15, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.209700</td>\n",
       "      <td>1.930400</td>\n",
       "      <td>0.398717</td>\n",
       "      <td>0.075054</td>\n",
       "      <td>0.085919</td>\n",
       "      <td>0.064064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.745100</td>\n",
       "      <td>1.526288</td>\n",
       "      <td>0.523373</td>\n",
       "      <td>0.162155</td>\n",
       "      <td>0.160622</td>\n",
       "      <td>0.140637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.384300</td>\n",
       "      <td>1.235692</td>\n",
       "      <td>0.636114</td>\n",
       "      <td>0.226228</td>\n",
       "      <td>0.238455</td>\n",
       "      <td>0.218505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.118900</td>\n",
       "      <td>1.070223</td>\n",
       "      <td>0.677360</td>\n",
       "      <td>0.262646</td>\n",
       "      <td>0.279606</td>\n",
       "      <td>0.259865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.937000</td>\n",
       "      <td>0.959278</td>\n",
       "      <td>0.705775</td>\n",
       "      <td>0.290430</td>\n",
       "      <td>0.307874</td>\n",
       "      <td>0.284627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.793100</td>\n",
       "      <td>0.869130</td>\n",
       "      <td>0.719523</td>\n",
       "      <td>0.334589</td>\n",
       "      <td>0.327157</td>\n",
       "      <td>0.308267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.686100</td>\n",
       "      <td>0.830187</td>\n",
       "      <td>0.714024</td>\n",
       "      <td>0.329659</td>\n",
       "      <td>0.328275</td>\n",
       "      <td>0.309498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.618900</td>\n",
       "      <td>0.802728</td>\n",
       "      <td>0.739688</td>\n",
       "      <td>0.379554</td>\n",
       "      <td>0.369100</td>\n",
       "      <td>0.350495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.563600</td>\n",
       "      <td>0.777424</td>\n",
       "      <td>0.740605</td>\n",
       "      <td>0.383869</td>\n",
       "      <td>0.380081</td>\n",
       "      <td>0.366879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.511100</td>\n",
       "      <td>0.773821</td>\n",
       "      <td>0.744271</td>\n",
       "      <td>0.420919</td>\n",
       "      <td>0.392436</td>\n",
       "      <td>0.382606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.482500</td>\n",
       "      <td>0.749240</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.420281</td>\n",
       "      <td>0.405097</td>\n",
       "      <td>0.397230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.447700</td>\n",
       "      <td>0.735077</td>\n",
       "      <td>0.756187</td>\n",
       "      <td>0.450160</td>\n",
       "      <td>0.408790</td>\n",
       "      <td>0.405795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.430700</td>\n",
       "      <td>0.728838</td>\n",
       "      <td>0.755270</td>\n",
       "      <td>0.439626</td>\n",
       "      <td>0.413683</td>\n",
       "      <td>0.406680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.418400</td>\n",
       "      <td>0.723270</td>\n",
       "      <td>0.757104</td>\n",
       "      <td>0.441353</td>\n",
       "      <td>0.420192</td>\n",
       "      <td>0.412277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.413600</td>\n",
       "      <td>0.724349</td>\n",
       "      <td>0.755270</td>\n",
       "      <td>0.434169</td>\n",
       "      <td>0.420386</td>\n",
       "      <td>0.410629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:34:14,381] Trial 32 finished with value: 0.41062904162092495 and parameters: {'learning_rate': 0.000380377126709603, 'weight_decay': 0.0, 'warmup_steps': 3, 'lambda_param': 0.5, 'temperature': 4.5}. Best is trial 25 with value: 0.46453030960093045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 33 with params: {'learning_rate': 1.1404826981171539e-05, 'weight_decay': 0.01, 'warmup_steps': 2, 'lambda_param': 0.8, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:48, 7.24 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.457700</td>\n",
       "      <td>2.426316</td>\n",
       "      <td>0.053162</td>\n",
       "      <td>0.008510</td>\n",
       "      <td>0.027481</td>\n",
       "      <td>0.007073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.419300</td>\n",
       "      <td>2.389725</td>\n",
       "      <td>0.170486</td>\n",
       "      <td>0.009995</td>\n",
       "      <td>0.021179</td>\n",
       "      <td>0.010224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.389200</td>\n",
       "      <td>2.359286</td>\n",
       "      <td>0.188818</td>\n",
       "      <td>0.024987</td>\n",
       "      <td>0.024002</td>\n",
       "      <td>0.012070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.363800</td>\n",
       "      <td>2.335363</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>0.012196</td>\n",
       "      <td>0.022466</td>\n",
       "      <td>0.009967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.342000</td>\n",
       "      <td>2.314589</td>\n",
       "      <td>0.184235</td>\n",
       "      <td>0.015019</td>\n",
       "      <td>0.022192</td>\n",
       "      <td>0.009766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:34:39,208] Trial 33 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 34 with params: {'learning_rate': 0.0004874798943543435, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 0.9, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:15, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.176600</td>\n",
       "      <td>1.847266</td>\n",
       "      <td>0.426214</td>\n",
       "      <td>0.063412</td>\n",
       "      <td>0.102190</td>\n",
       "      <td>0.075093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.632300</td>\n",
       "      <td>1.394507</td>\n",
       "      <td>0.561870</td>\n",
       "      <td>0.196017</td>\n",
       "      <td>0.198681</td>\n",
       "      <td>0.176406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.230500</td>\n",
       "      <td>1.103445</td>\n",
       "      <td>0.659945</td>\n",
       "      <td>0.275605</td>\n",
       "      <td>0.269421</td>\n",
       "      <td>0.248072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.960900</td>\n",
       "      <td>0.947070</td>\n",
       "      <td>0.699358</td>\n",
       "      <td>0.285805</td>\n",
       "      <td>0.300731</td>\n",
       "      <td>0.279652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.782400</td>\n",
       "      <td>0.864130</td>\n",
       "      <td>0.720440</td>\n",
       "      <td>0.330085</td>\n",
       "      <td>0.334483</td>\n",
       "      <td>0.310460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.657200</td>\n",
       "      <td>0.799784</td>\n",
       "      <td>0.730522</td>\n",
       "      <td>0.390287</td>\n",
       "      <td>0.361467</td>\n",
       "      <td>0.348976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.562400</td>\n",
       "      <td>0.776782</td>\n",
       "      <td>0.744271</td>\n",
       "      <td>0.397817</td>\n",
       "      <td>0.383109</td>\n",
       "      <td>0.371146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.502400</td>\n",
       "      <td>0.751868</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.421363</td>\n",
       "      <td>0.400340</td>\n",
       "      <td>0.387468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.448500</td>\n",
       "      <td>0.731663</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.453812</td>\n",
       "      <td>0.424699</td>\n",
       "      <td>0.422816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.400700</td>\n",
       "      <td>0.721887</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.488359</td>\n",
       "      <td>0.428984</td>\n",
       "      <td>0.430721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.374300</td>\n",
       "      <td>0.708411</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.485317</td>\n",
       "      <td>0.441840</td>\n",
       "      <td>0.437790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.346500</td>\n",
       "      <td>0.694412</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.536241</td>\n",
       "      <td>0.458885</td>\n",
       "      <td>0.470946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.327200</td>\n",
       "      <td>0.689338</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.496585</td>\n",
       "      <td>0.455861</td>\n",
       "      <td>0.458235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.317000</td>\n",
       "      <td>0.684152</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.520065</td>\n",
       "      <td>0.466153</td>\n",
       "      <td>0.470004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.314700</td>\n",
       "      <td>0.685994</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.518855</td>\n",
       "      <td>0.473139</td>\n",
       "      <td>0.477881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:35:55,965] Trial 34 finished with value: 0.477880764070784 and parameters: {'learning_rate': 0.0004874798943543435, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 0.9, 'temperature': 4.5}. Best is trial 34 with value: 0.477880764070784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 35 with params: {'learning_rate': 0.000434755860227755, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.8, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:21, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.196300</td>\n",
       "      <td>1.891267</td>\n",
       "      <td>0.412466</td>\n",
       "      <td>0.069622</td>\n",
       "      <td>0.092601</td>\n",
       "      <td>0.069958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.687600</td>\n",
       "      <td>1.454554</td>\n",
       "      <td>0.554537</td>\n",
       "      <td>0.181866</td>\n",
       "      <td>0.187158</td>\n",
       "      <td>0.167953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.301700</td>\n",
       "      <td>1.160066</td>\n",
       "      <td>0.651696</td>\n",
       "      <td>0.258254</td>\n",
       "      <td>0.255614</td>\n",
       "      <td>0.236689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.032200</td>\n",
       "      <td>0.996988</td>\n",
       "      <td>0.691109</td>\n",
       "      <td>0.277818</td>\n",
       "      <td>0.297225</td>\n",
       "      <td>0.276462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>0.901095</td>\n",
       "      <td>0.715857</td>\n",
       "      <td>0.347643</td>\n",
       "      <td>0.326900</td>\n",
       "      <td>0.305897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.714900</td>\n",
       "      <td>0.829140</td>\n",
       "      <td>0.720440</td>\n",
       "      <td>0.352830</td>\n",
       "      <td>0.338738</td>\n",
       "      <td>0.321507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.614900</td>\n",
       "      <td>0.801381</td>\n",
       "      <td>0.732356</td>\n",
       "      <td>0.373925</td>\n",
       "      <td>0.363808</td>\n",
       "      <td>0.348885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.554100</td>\n",
       "      <td>0.770184</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.388079</td>\n",
       "      <td>0.391659</td>\n",
       "      <td>0.374346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.498400</td>\n",
       "      <td>0.750180</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.432826</td>\n",
       "      <td>0.407458</td>\n",
       "      <td>0.399245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.448900</td>\n",
       "      <td>0.742569</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.434605</td>\n",
       "      <td>0.410649</td>\n",
       "      <td>0.401333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.420800</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.460964</td>\n",
       "      <td>0.426615</td>\n",
       "      <td>0.421447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.390700</td>\n",
       "      <td>0.709224</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.466351</td>\n",
       "      <td>0.427339</td>\n",
       "      <td>0.426564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.372100</td>\n",
       "      <td>0.702466</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.481742</td>\n",
       "      <td>0.439856</td>\n",
       "      <td>0.437919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>0.697260</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.464108</td>\n",
       "      <td>0.445847</td>\n",
       "      <td>0.438102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.357600</td>\n",
       "      <td>0.698848</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.468973</td>\n",
       "      <td>0.447590</td>\n",
       "      <td>0.440614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:37:18,474] Trial 35 finished with value: 0.4406141811646433 and parameters: {'learning_rate': 0.000434755860227755, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.8, 'temperature': 5.5}. Best is trial 34 with value: 0.477880764070784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 36 with params: {'learning_rate': 0.00011705694027089814, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 0.9, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:50 < 00:25, 6.90 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.354800</td>\n",
       "      <td>2.216873</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.147000</td>\n",
       "      <td>2.033761</td>\n",
       "      <td>0.373052</td>\n",
       "      <td>0.061497</td>\n",
       "      <td>0.077710</td>\n",
       "      <td>0.062359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.987600</td>\n",
       "      <td>1.875219</td>\n",
       "      <td>0.428964</td>\n",
       "      <td>0.068742</td>\n",
       "      <td>0.098215</td>\n",
       "      <td>0.073838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.832300</td>\n",
       "      <td>1.734769</td>\n",
       "      <td>0.472044</td>\n",
       "      <td>0.102375</td>\n",
       "      <td>0.125256</td>\n",
       "      <td>0.101006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>1.615191</td>\n",
       "      <td>0.500458</td>\n",
       "      <td>0.124548</td>\n",
       "      <td>0.142194</td>\n",
       "      <td>0.116159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.589100</td>\n",
       "      <td>1.520944</td>\n",
       "      <td>0.526123</td>\n",
       "      <td>0.191886</td>\n",
       "      <td>0.161682</td>\n",
       "      <td>0.142577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.495900</td>\n",
       "      <td>1.447404</td>\n",
       "      <td>0.554537</td>\n",
       "      <td>0.226821</td>\n",
       "      <td>0.184925</td>\n",
       "      <td>0.171067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.427600</td>\n",
       "      <td>1.386038</td>\n",
       "      <td>0.597617</td>\n",
       "      <td>0.263538</td>\n",
       "      <td>0.216999</td>\n",
       "      <td>0.202780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.361300</td>\n",
       "      <td>1.333885</td>\n",
       "      <td>0.606783</td>\n",
       "      <td>0.244083</td>\n",
       "      <td>0.222574</td>\n",
       "      <td>0.207341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.305700</td>\n",
       "      <td>1.294151</td>\n",
       "      <td>0.628781</td>\n",
       "      <td>0.284160</td>\n",
       "      <td>0.240360</td>\n",
       "      <td>0.230065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:38:10,085] Trial 36 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 37 with params: {'learning_rate': 0.0001809199150247622, 'weight_decay': 0.0, 'warmup_steps': 4, 'lambda_param': 1.0, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:24 < 00:48, 7.15 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.313200</td>\n",
       "      <td>2.131766</td>\n",
       "      <td>0.177819</td>\n",
       "      <td>0.023541</td>\n",
       "      <td>0.020238</td>\n",
       "      <td>0.006488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.031400</td>\n",
       "      <td>1.882933</td>\n",
       "      <td>0.420715</td>\n",
       "      <td>0.067787</td>\n",
       "      <td>0.095397</td>\n",
       "      <td>0.071334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.804500</td>\n",
       "      <td>1.662064</td>\n",
       "      <td>0.483043</td>\n",
       "      <td>0.122002</td>\n",
       "      <td>0.132667</td>\n",
       "      <td>0.107684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.596500</td>\n",
       "      <td>1.488065</td>\n",
       "      <td>0.541705</td>\n",
       "      <td>0.181422</td>\n",
       "      <td>0.169587</td>\n",
       "      <td>0.150840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.441900</td>\n",
       "      <td>1.355097</td>\n",
       "      <td>0.591201</td>\n",
       "      <td>0.249741</td>\n",
       "      <td>0.206600</td>\n",
       "      <td>0.190098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:38:35,261] Trial 37 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 38 with params: {'learning_rate': 2.5689465631735298e-05, 'weight_decay': 0.003, 'warmup_steps': 0, 'lambda_param': 0.0, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:24 < 00:49, 7.11 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.434200</td>\n",
       "      <td>2.378001</td>\n",
       "      <td>0.184235</td>\n",
       "      <td>0.032125</td>\n",
       "      <td>0.022803</td>\n",
       "      <td>0.010698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.361200</td>\n",
       "      <td>2.316641</td>\n",
       "      <td>0.183318</td>\n",
       "      <td>0.015251</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>0.009373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.311700</td>\n",
       "      <td>2.267148</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023551</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.266000</td>\n",
       "      <td>2.224447</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.023554</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.229400</td>\n",
       "      <td>2.184103</td>\n",
       "      <td>0.193401</td>\n",
       "      <td>0.063607</td>\n",
       "      <td>0.024801</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:39:00,647] Trial 38 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 39 with params: {'learning_rate': 0.00038443212074493367, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 0.9, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:18, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.215600</td>\n",
       "      <td>1.933989</td>\n",
       "      <td>0.394134</td>\n",
       "      <td>0.055520</td>\n",
       "      <td>0.084539</td>\n",
       "      <td>0.062450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.744700</td>\n",
       "      <td>1.520418</td>\n",
       "      <td>0.523373</td>\n",
       "      <td>0.149770</td>\n",
       "      <td>0.158584</td>\n",
       "      <td>0.136791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.377600</td>\n",
       "      <td>1.225996</td>\n",
       "      <td>0.638863</td>\n",
       "      <td>0.225606</td>\n",
       "      <td>0.241098</td>\n",
       "      <td>0.219918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.110800</td>\n",
       "      <td>1.060280</td>\n",
       "      <td>0.680110</td>\n",
       "      <td>0.263422</td>\n",
       "      <td>0.280658</td>\n",
       "      <td>0.261020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.927900</td>\n",
       "      <td>0.950645</td>\n",
       "      <td>0.707608</td>\n",
       "      <td>0.297284</td>\n",
       "      <td>0.309774</td>\n",
       "      <td>0.287472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.784800</td>\n",
       "      <td>0.861737</td>\n",
       "      <td>0.725023</td>\n",
       "      <td>0.352051</td>\n",
       "      <td>0.332872</td>\n",
       "      <td>0.314293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.677200</td>\n",
       "      <td>0.821974</td>\n",
       "      <td>0.718607</td>\n",
       "      <td>0.346005</td>\n",
       "      <td>0.332017</td>\n",
       "      <td>0.314312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.611200</td>\n",
       "      <td>0.793476</td>\n",
       "      <td>0.743355</td>\n",
       "      <td>0.386522</td>\n",
       "      <td>0.375867</td>\n",
       "      <td>0.358656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.554800</td>\n",
       "      <td>0.771351</td>\n",
       "      <td>0.742438</td>\n",
       "      <td>0.404894</td>\n",
       "      <td>0.381967</td>\n",
       "      <td>0.370915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.502900</td>\n",
       "      <td>0.761024</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.436480</td>\n",
       "      <td>0.395243</td>\n",
       "      <td>0.385944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.474200</td>\n",
       "      <td>0.741910</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.445877</td>\n",
       "      <td>0.404470</td>\n",
       "      <td>0.400129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.439400</td>\n",
       "      <td>0.729972</td>\n",
       "      <td>0.755270</td>\n",
       "      <td>0.463213</td>\n",
       "      <td>0.411134</td>\n",
       "      <td>0.410361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.423500</td>\n",
       "      <td>0.724443</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.493408</td>\n",
       "      <td>0.420034</td>\n",
       "      <td>0.421670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.410300</td>\n",
       "      <td>0.718507</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.466491</td>\n",
       "      <td>0.423819</td>\n",
       "      <td>0.417594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.406500</td>\n",
       "      <td>0.720353</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.504122</td>\n",
       "      <td>0.435380</td>\n",
       "      <td>0.437972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:40:21,110] Trial 39 finished with value: 0.43797198988477426 and parameters: {'learning_rate': 0.00038443212074493367, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 0.9, 'temperature': 4.5}. Best is trial 34 with value: 0.477880764070784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 40 with params: {'learning_rate': 0.0004814362072710081, 'weight_decay': 0.001, 'warmup_steps': 2, 'lambda_param': 0.5, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:15, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.156300</td>\n",
       "      <td>1.826219</td>\n",
       "      <td>0.431714</td>\n",
       "      <td>0.061918</td>\n",
       "      <td>0.105335</td>\n",
       "      <td>0.075695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.618000</td>\n",
       "      <td>1.391582</td>\n",
       "      <td>0.563703</td>\n",
       "      <td>0.193835</td>\n",
       "      <td>0.195367</td>\n",
       "      <td>0.173983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.231800</td>\n",
       "      <td>1.109537</td>\n",
       "      <td>0.658112</td>\n",
       "      <td>0.277792</td>\n",
       "      <td>0.265717</td>\n",
       "      <td>0.247984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.970700</td>\n",
       "      <td>0.953432</td>\n",
       "      <td>0.705775</td>\n",
       "      <td>0.283389</td>\n",
       "      <td>0.302858</td>\n",
       "      <td>0.280987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.795100</td>\n",
       "      <td>0.869039</td>\n",
       "      <td>0.716774</td>\n",
       "      <td>0.322268</td>\n",
       "      <td>0.331341</td>\n",
       "      <td>0.307084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.669000</td>\n",
       "      <td>0.807116</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.383127</td>\n",
       "      <td>0.372740</td>\n",
       "      <td>0.357781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.573700</td>\n",
       "      <td>0.783947</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.423006</td>\n",
       "      <td>0.386977</td>\n",
       "      <td>0.375737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.514300</td>\n",
       "      <td>0.755840</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.425290</td>\n",
       "      <td>0.407329</td>\n",
       "      <td>0.397693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.459200</td>\n",
       "      <td>0.733873</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.464598</td>\n",
       "      <td>0.430672</td>\n",
       "      <td>0.428134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.410200</td>\n",
       "      <td>0.718908</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.487228</td>\n",
       "      <td>0.441516</td>\n",
       "      <td>0.440801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.382100</td>\n",
       "      <td>0.703629</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.473257</td>\n",
       "      <td>0.445348</td>\n",
       "      <td>0.441868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.354900</td>\n",
       "      <td>0.693684</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.481331</td>\n",
       "      <td>0.446999</td>\n",
       "      <td>0.446172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.336200</td>\n",
       "      <td>0.688136</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.489770</td>\n",
       "      <td>0.450732</td>\n",
       "      <td>0.450900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.684452</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.483847</td>\n",
       "      <td>0.455033</td>\n",
       "      <td>0.452155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.323000</td>\n",
       "      <td>0.686200</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.484095</td>\n",
       "      <td>0.463890</td>\n",
       "      <td>0.457967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:41:37,894] Trial 40 finished with value: 0.45796652775412455 and parameters: {'learning_rate': 0.0004814362072710081, 'weight_decay': 0.001, 'warmup_steps': 2, 'lambda_param': 0.5, 'temperature': 2.5}. Best is trial 34 with value: 0.477880764070784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 41 with params: {'learning_rate': 0.00045519276280906894, 'weight_decay': 0.001, 'warmup_steps': 2, 'lambda_param': 0.4, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:17, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.168200</td>\n",
       "      <td>1.853031</td>\n",
       "      <td>0.427131</td>\n",
       "      <td>0.062891</td>\n",
       "      <td>0.101226</td>\n",
       "      <td>0.074704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.650200</td>\n",
       "      <td>1.424091</td>\n",
       "      <td>0.555454</td>\n",
       "      <td>0.212484</td>\n",
       "      <td>0.190133</td>\n",
       "      <td>0.171544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.269300</td>\n",
       "      <td>1.142262</td>\n",
       "      <td>0.648946</td>\n",
       "      <td>0.256841</td>\n",
       "      <td>0.255435</td>\n",
       "      <td>0.237589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.006700</td>\n",
       "      <td>0.982499</td>\n",
       "      <td>0.696609</td>\n",
       "      <td>0.274735</td>\n",
       "      <td>0.295026</td>\n",
       "      <td>0.272515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.827600</td>\n",
       "      <td>0.888039</td>\n",
       "      <td>0.712191</td>\n",
       "      <td>0.321951</td>\n",
       "      <td>0.324535</td>\n",
       "      <td>0.302549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.697400</td>\n",
       "      <td>0.821811</td>\n",
       "      <td>0.721357</td>\n",
       "      <td>0.355696</td>\n",
       "      <td>0.342966</td>\n",
       "      <td>0.330527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.599600</td>\n",
       "      <td>0.800122</td>\n",
       "      <td>0.733272</td>\n",
       "      <td>0.415135</td>\n",
       "      <td>0.378628</td>\n",
       "      <td>0.365383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.539000</td>\n",
       "      <td>0.767006</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.428561</td>\n",
       "      <td>0.399470</td>\n",
       "      <td>0.389722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.484800</td>\n",
       "      <td>0.749223</td>\n",
       "      <td>0.747938</td>\n",
       "      <td>0.446663</td>\n",
       "      <td>0.413840</td>\n",
       "      <td>0.407098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.434800</td>\n",
       "      <td>0.729932</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.447443</td>\n",
       "      <td>0.422012</td>\n",
       "      <td>0.415961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.406300</td>\n",
       "      <td>0.715047</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.467558</td>\n",
       "      <td>0.435802</td>\n",
       "      <td>0.430721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.377300</td>\n",
       "      <td>0.701339</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.473039</td>\n",
       "      <td>0.435919</td>\n",
       "      <td>0.436636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.360100</td>\n",
       "      <td>0.696506</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.502136</td>\n",
       "      <td>0.450625</td>\n",
       "      <td>0.450560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.347200</td>\n",
       "      <td>0.693180</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.496372</td>\n",
       "      <td>0.450866</td>\n",
       "      <td>0.448538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.345100</td>\n",
       "      <td>0.694114</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.486688</td>\n",
       "      <td>0.456320</td>\n",
       "      <td>0.451046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:42:57,241] Trial 41 finished with value: 0.45104554763748517 and parameters: {'learning_rate': 0.00045519276280906894, 'weight_decay': 0.001, 'warmup_steps': 2, 'lambda_param': 0.4, 'temperature': 2.0}. Best is trial 34 with value: 0.477880764070784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 42 with params: {'learning_rate': 0.00038384402584336157, 'weight_decay': 0.0, 'warmup_steps': 4, 'lambda_param': 0.6000000000000001, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 01:09 < 00:35, 4.98 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.215800</td>\n",
       "      <td>1.934471</td>\n",
       "      <td>0.394134</td>\n",
       "      <td>0.055755</td>\n",
       "      <td>0.084539</td>\n",
       "      <td>0.062515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.745400</td>\n",
       "      <td>1.521201</td>\n",
       "      <td>0.523373</td>\n",
       "      <td>0.149639</td>\n",
       "      <td>0.158584</td>\n",
       "      <td>0.136718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.378600</td>\n",
       "      <td>1.226918</td>\n",
       "      <td>0.638863</td>\n",
       "      <td>0.225606</td>\n",
       "      <td>0.241098</td>\n",
       "      <td>0.219918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.111800</td>\n",
       "      <td>1.061089</td>\n",
       "      <td>0.680110</td>\n",
       "      <td>0.264198</td>\n",
       "      <td>0.280749</td>\n",
       "      <td>0.261352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.928900</td>\n",
       "      <td>0.951298</td>\n",
       "      <td>0.707608</td>\n",
       "      <td>0.297377</td>\n",
       "      <td>0.309774</td>\n",
       "      <td>0.287407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.785700</td>\n",
       "      <td>0.862255</td>\n",
       "      <td>0.725023</td>\n",
       "      <td>0.352150</td>\n",
       "      <td>0.332872</td>\n",
       "      <td>0.314354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.678000</td>\n",
       "      <td>0.822341</td>\n",
       "      <td>0.718607</td>\n",
       "      <td>0.346005</td>\n",
       "      <td>0.332017</td>\n",
       "      <td>0.314312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.612000</td>\n",
       "      <td>0.793836</td>\n",
       "      <td>0.743355</td>\n",
       "      <td>0.386662</td>\n",
       "      <td>0.375867</td>\n",
       "      <td>0.358727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.555500</td>\n",
       "      <td>0.771698</td>\n",
       "      <td>0.742438</td>\n",
       "      <td>0.404894</td>\n",
       "      <td>0.381967</td>\n",
       "      <td>0.370915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.503600</td>\n",
       "      <td>0.761283</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.436331</td>\n",
       "      <td>0.395243</td>\n",
       "      <td>0.385854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:44:08,090] Trial 42 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 43 with params: {'learning_rate': 0.0004145660682858629, 'weight_decay': 0.008, 'warmup_steps': 0, 'lambda_param': 0.30000000000000004, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:15, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.156400</td>\n",
       "      <td>1.857194</td>\n",
       "      <td>0.425298</td>\n",
       "      <td>0.065865</td>\n",
       "      <td>0.101226</td>\n",
       "      <td>0.076108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.669100</td>\n",
       "      <td>1.452550</td>\n",
       "      <td>0.549954</td>\n",
       "      <td>0.171137</td>\n",
       "      <td>0.181700</td>\n",
       "      <td>0.162140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.310100</td>\n",
       "      <td>1.176145</td>\n",
       "      <td>0.640697</td>\n",
       "      <td>0.234039</td>\n",
       "      <td>0.247005</td>\n",
       "      <td>0.228847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.055100</td>\n",
       "      <td>1.024117</td>\n",
       "      <td>0.687443</td>\n",
       "      <td>0.256002</td>\n",
       "      <td>0.288044</td>\n",
       "      <td>0.261855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.881500</td>\n",
       "      <td>0.918540</td>\n",
       "      <td>0.714940</td>\n",
       "      <td>0.325611</td>\n",
       "      <td>0.324487</td>\n",
       "      <td>0.304604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.747800</td>\n",
       "      <td>0.844291</td>\n",
       "      <td>0.728689</td>\n",
       "      <td>0.359775</td>\n",
       "      <td>0.341960</td>\n",
       "      <td>0.322211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.645200</td>\n",
       "      <td>0.809543</td>\n",
       "      <td>0.732356</td>\n",
       "      <td>0.363602</td>\n",
       "      <td>0.360024</td>\n",
       "      <td>0.342268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.580300</td>\n",
       "      <td>0.783450</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.393488</td>\n",
       "      <td>0.386089</td>\n",
       "      <td>0.370478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.526100</td>\n",
       "      <td>0.757816</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.388545</td>\n",
       "      <td>0.390506</td>\n",
       "      <td>0.374964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.475300</td>\n",
       "      <td>0.748762</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.421607</td>\n",
       "      <td>0.406291</td>\n",
       "      <td>0.394754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.447800</td>\n",
       "      <td>0.731994</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.476384</td>\n",
       "      <td>0.428136</td>\n",
       "      <td>0.425372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.416200</td>\n",
       "      <td>0.712670</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.467437</td>\n",
       "      <td>0.430781</td>\n",
       "      <td>0.429424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.398900</td>\n",
       "      <td>0.710073</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.449519</td>\n",
       "      <td>0.432605</td>\n",
       "      <td>0.426374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.386600</td>\n",
       "      <td>0.702861</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.452960</td>\n",
       "      <td>0.441379</td>\n",
       "      <td>0.432164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.384300</td>\n",
       "      <td>0.704242</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.469326</td>\n",
       "      <td>0.447182</td>\n",
       "      <td>0.440119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:45:25,702] Trial 43 finished with value: 0.4401191883308661 and parameters: {'learning_rate': 0.0004145660682858629, 'weight_decay': 0.008, 'warmup_steps': 0, 'lambda_param': 0.30000000000000004, 'temperature': 6.0}. Best is trial 34 with value: 0.477880764070784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 44 with params: {'learning_rate': 0.00017665299926535667, 'weight_decay': 0.009000000000000001, 'warmup_steps': 4, 'lambda_param': 0.9, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:24 < 00:49, 7.10 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.315800</td>\n",
       "      <td>2.136900</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.038600</td>\n",
       "      <td>1.892572</td>\n",
       "      <td>0.416132</td>\n",
       "      <td>0.069527</td>\n",
       "      <td>0.092489</td>\n",
       "      <td>0.068115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.815900</td>\n",
       "      <td>1.674679</td>\n",
       "      <td>0.481210</td>\n",
       "      <td>0.101488</td>\n",
       "      <td>0.130988</td>\n",
       "      <td>0.105118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.610600</td>\n",
       "      <td>1.502152</td>\n",
       "      <td>0.534372</td>\n",
       "      <td>0.183519</td>\n",
       "      <td>0.163361</td>\n",
       "      <td>0.143730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.457800</td>\n",
       "      <td>1.369880</td>\n",
       "      <td>0.585701</td>\n",
       "      <td>0.247331</td>\n",
       "      <td>0.203256</td>\n",
       "      <td>0.187324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:45:51,260] Trial 44 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 45 with params: {'learning_rate': 0.00043371026242218253, 'weight_decay': 0.009000000000000001, 'warmup_steps': 3, 'lambda_param': 0.5, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.189200</td>\n",
       "      <td>1.887658</td>\n",
       "      <td>0.417965</td>\n",
       "      <td>0.071218</td>\n",
       "      <td>0.096213</td>\n",
       "      <td>0.074753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.687500</td>\n",
       "      <td>1.461245</td>\n",
       "      <td>0.539872</td>\n",
       "      <td>0.166438</td>\n",
       "      <td>0.173244</td>\n",
       "      <td>0.153140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.308200</td>\n",
       "      <td>1.165164</td>\n",
       "      <td>0.650779</td>\n",
       "      <td>0.240507</td>\n",
       "      <td>0.253107</td>\n",
       "      <td>0.233707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.036400</td>\n",
       "      <td>0.999663</td>\n",
       "      <td>0.685610</td>\n",
       "      <td>0.265236</td>\n",
       "      <td>0.286646</td>\n",
       "      <td>0.261608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.850700</td>\n",
       "      <td>0.901898</td>\n",
       "      <td>0.716774</td>\n",
       "      <td>0.316176</td>\n",
       "      <td>0.324457</td>\n",
       "      <td>0.300804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.714900</td>\n",
       "      <td>0.827885</td>\n",
       "      <td>0.723190</td>\n",
       "      <td>0.361691</td>\n",
       "      <td>0.342802</td>\n",
       "      <td>0.326555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.615600</td>\n",
       "      <td>0.802517</td>\n",
       "      <td>0.727773</td>\n",
       "      <td>0.362047</td>\n",
       "      <td>0.351748</td>\n",
       "      <td>0.337083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.554700</td>\n",
       "      <td>0.771714</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.391481</td>\n",
       "      <td>0.389921</td>\n",
       "      <td>0.374821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.501100</td>\n",
       "      <td>0.750124</td>\n",
       "      <td>0.757104</td>\n",
       "      <td>0.434577</td>\n",
       "      <td>0.408837</td>\n",
       "      <td>0.403609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.452200</td>\n",
       "      <td>0.746299</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.432251</td>\n",
       "      <td>0.410162</td>\n",
       "      <td>0.400647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.424700</td>\n",
       "      <td>0.722973</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.441791</td>\n",
       "      <td>0.421749</td>\n",
       "      <td>0.413081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.393400</td>\n",
       "      <td>0.711640</td>\n",
       "      <td>0.755270</td>\n",
       "      <td>0.463143</td>\n",
       "      <td>0.427177</td>\n",
       "      <td>0.425312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.376100</td>\n",
       "      <td>0.703442</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.459909</td>\n",
       "      <td>0.433584</td>\n",
       "      <td>0.428905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.363300</td>\n",
       "      <td>0.698863</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.480921</td>\n",
       "      <td>0.447856</td>\n",
       "      <td>0.441251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.360500</td>\n",
       "      <td>0.700112</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.496429</td>\n",
       "      <td>0.456751</td>\n",
       "      <td>0.453154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:47:06,240] Trial 45 finished with value: 0.4531542858652594 and parameters: {'learning_rate': 0.00043371026242218253, 'weight_decay': 0.009000000000000001, 'warmup_steps': 3, 'lambda_param': 0.5, 'temperature': 2.0}. Best is trial 34 with value: 0.477880764070784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 46 with params: {'learning_rate': 0.00039095110215088823, 'weight_decay': 0.001, 'warmup_steps': 1, 'lambda_param': 0.4, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.188700</td>\n",
       "      <td>1.904867</td>\n",
       "      <td>0.409716</td>\n",
       "      <td>0.072649</td>\n",
       "      <td>0.090110</td>\n",
       "      <td>0.067552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.720200</td>\n",
       "      <td>1.501025</td>\n",
       "      <td>0.532539</td>\n",
       "      <td>0.172161</td>\n",
       "      <td>0.165413</td>\n",
       "      <td>0.146941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.361900</td>\n",
       "      <td>1.220115</td>\n",
       "      <td>0.630614</td>\n",
       "      <td>0.228267</td>\n",
       "      <td>0.228617</td>\n",
       "      <td>0.208732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.102100</td>\n",
       "      <td>1.057592</td>\n",
       "      <td>0.682860</td>\n",
       "      <td>0.264542</td>\n",
       "      <td>0.281726</td>\n",
       "      <td>0.260124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.921900</td>\n",
       "      <td>0.946479</td>\n",
       "      <td>0.709441</td>\n",
       "      <td>0.299353</td>\n",
       "      <td>0.311848</td>\n",
       "      <td>0.290430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.782700</td>\n",
       "      <td>0.862032</td>\n",
       "      <td>0.721357</td>\n",
       "      <td>0.307246</td>\n",
       "      <td>0.326766</td>\n",
       "      <td>0.304724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.678400</td>\n",
       "      <td>0.825827</td>\n",
       "      <td>0.719523</td>\n",
       "      <td>0.349117</td>\n",
       "      <td>0.336073</td>\n",
       "      <td>0.322776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.798821</td>\n",
       "      <td>0.743355</td>\n",
       "      <td>0.390592</td>\n",
       "      <td>0.375122</td>\n",
       "      <td>0.357758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.557100</td>\n",
       "      <td>0.773699</td>\n",
       "      <td>0.744271</td>\n",
       "      <td>0.399689</td>\n",
       "      <td>0.387693</td>\n",
       "      <td>0.375926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.504700</td>\n",
       "      <td>0.760993</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.443768</td>\n",
       "      <td>0.407387</td>\n",
       "      <td>0.398308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.476200</td>\n",
       "      <td>0.741174</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.456401</td>\n",
       "      <td>0.416737</td>\n",
       "      <td>0.412696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.442600</td>\n",
       "      <td>0.724606</td>\n",
       "      <td>0.757104</td>\n",
       "      <td>0.466782</td>\n",
       "      <td>0.423206</td>\n",
       "      <td>0.419970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.425800</td>\n",
       "      <td>0.721184</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.452762</td>\n",
       "      <td>0.422868</td>\n",
       "      <td>0.420672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.414000</td>\n",
       "      <td>0.713866</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.455798</td>\n",
       "      <td>0.423606</td>\n",
       "      <td>0.417983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.410300</td>\n",
       "      <td>0.715372</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.475448</td>\n",
       "      <td>0.437295</td>\n",
       "      <td>0.433796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:48:22,499] Trial 46 finished with value: 0.43379607818078897 and parameters: {'learning_rate': 0.00039095110215088823, 'weight_decay': 0.001, 'warmup_steps': 1, 'lambda_param': 0.4, 'temperature': 3.5}. Best is trial 34 with value: 0.477880764070784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 47 with params: {'learning_rate': 1.0393235223774966e-05, 'weight_decay': 0.002, 'warmup_steps': 0, 'lambda_param': 0.5, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:49 < 00:25, 6.99 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.457700</td>\n",
       "      <td>2.428191</td>\n",
       "      <td>0.048579</td>\n",
       "      <td>0.010410</td>\n",
       "      <td>0.027133</td>\n",
       "      <td>0.007270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.422600</td>\n",
       "      <td>2.394848</td>\n",
       "      <td>0.159487</td>\n",
       "      <td>0.008976</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.009358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.394800</td>\n",
       "      <td>2.365916</td>\n",
       "      <td>0.187901</td>\n",
       "      <td>0.017968</td>\n",
       "      <td>0.023728</td>\n",
       "      <td>0.011713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.371000</td>\n",
       "      <td>2.343430</td>\n",
       "      <td>0.186068</td>\n",
       "      <td>0.016623</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.010889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.350200</td>\n",
       "      <td>2.324186</td>\n",
       "      <td>0.186068</td>\n",
       "      <td>0.015369</td>\n",
       "      <td>0.022740</td>\n",
       "      <td>0.010552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.331600</td>\n",
       "      <td>2.307625</td>\n",
       "      <td>0.184235</td>\n",
       "      <td>0.015019</td>\n",
       "      <td>0.022192</td>\n",
       "      <td>0.009766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.318100</td>\n",
       "      <td>2.293196</td>\n",
       "      <td>0.181485</td>\n",
       "      <td>0.017853</td>\n",
       "      <td>0.021370</td>\n",
       "      <td>0.008555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.305300</td>\n",
       "      <td>2.280615</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.294100</td>\n",
       "      <td>2.269839</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.286000</td>\n",
       "      <td>2.261192</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:49:13,217] Trial 47 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 48 with params: {'learning_rate': 0.00029186640119552315, 'weight_decay': 0.001, 'warmup_steps': 2, 'lambda_param': 0.7000000000000001, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:49 < 00:25, 6.96 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.243400</td>\n",
       "      <td>2.009390</td>\n",
       "      <td>0.366636</td>\n",
       "      <td>0.066764</td>\n",
       "      <td>0.075679</td>\n",
       "      <td>0.061855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.855400</td>\n",
       "      <td>1.657168</td>\n",
       "      <td>0.485793</td>\n",
       "      <td>0.143394</td>\n",
       "      <td>0.139134</td>\n",
       "      <td>0.116632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.540400</td>\n",
       "      <td>1.386186</td>\n",
       "      <td>0.562786</td>\n",
       "      <td>0.197118</td>\n",
       "      <td>0.183550</td>\n",
       "      <td>0.163954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.287100</td>\n",
       "      <td>1.198571</td>\n",
       "      <td>0.648946</td>\n",
       "      <td>0.247887</td>\n",
       "      <td>0.255849</td>\n",
       "      <td>0.237963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.104000</td>\n",
       "      <td>1.066760</td>\n",
       "      <td>0.686526</td>\n",
       "      <td>0.266311</td>\n",
       "      <td>0.288280</td>\n",
       "      <td>0.264721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.953300</td>\n",
       "      <td>0.969441</td>\n",
       "      <td>0.700275</td>\n",
       "      <td>0.295525</td>\n",
       "      <td>0.298195</td>\n",
       "      <td>0.277076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.839800</td>\n",
       "      <td>0.910170</td>\n",
       "      <td>0.705775</td>\n",
       "      <td>0.305522</td>\n",
       "      <td>0.302964</td>\n",
       "      <td>0.281198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.766700</td>\n",
       "      <td>0.867523</td>\n",
       "      <td>0.724106</td>\n",
       "      <td>0.335834</td>\n",
       "      <td>0.333000</td>\n",
       "      <td>0.310544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.704300</td>\n",
       "      <td>0.842103</td>\n",
       "      <td>0.725023</td>\n",
       "      <td>0.301848</td>\n",
       "      <td>0.330761</td>\n",
       "      <td>0.307807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.646200</td>\n",
       "      <td>0.825383</td>\n",
       "      <td>0.728689</td>\n",
       "      <td>0.328231</td>\n",
       "      <td>0.345180</td>\n",
       "      <td>0.325246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:50:04,197] Trial 48 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 49 with params: {'learning_rate': 0.00020329934217119537, 'weight_decay': 0.003, 'warmup_steps': 3, 'lambda_param': 0.7000000000000001, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:25 < 00:51, 6.77 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.296000</td>\n",
       "      <td>2.104380</td>\n",
       "      <td>0.188818</td>\n",
       "      <td>0.036927</td>\n",
       "      <td>0.023275</td>\n",
       "      <td>0.011991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.993400</td>\n",
       "      <td>1.833149</td>\n",
       "      <td>0.428964</td>\n",
       "      <td>0.081171</td>\n",
       "      <td>0.101624</td>\n",
       "      <td>0.074767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.746500</td>\n",
       "      <td>1.599430</td>\n",
       "      <td>0.500458</td>\n",
       "      <td>0.145736</td>\n",
       "      <td>0.146052</td>\n",
       "      <td>0.124933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.526700</td>\n",
       "      <td>1.419820</td>\n",
       "      <td>0.559120</td>\n",
       "      <td>0.201405</td>\n",
       "      <td>0.181821</td>\n",
       "      <td>0.161608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.363900</td>\n",
       "      <td>1.284145</td>\n",
       "      <td>0.611366</td>\n",
       "      <td>0.221903</td>\n",
       "      <td>0.216584</td>\n",
       "      <td>0.196499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:50:31,354] Trial 49 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 with params: {'learning_rate': 0.0004984056251371117, 'weight_decay': 0.0, 'warmup_steps': 4, 'lambda_param': 0.8, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.172800</td>\n",
       "      <td>1.839363</td>\n",
       "      <td>0.429881</td>\n",
       "      <td>0.062314</td>\n",
       "      <td>0.103629</td>\n",
       "      <td>0.075018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.622100</td>\n",
       "      <td>1.384496</td>\n",
       "      <td>0.566453</td>\n",
       "      <td>0.196401</td>\n",
       "      <td>0.201108</td>\n",
       "      <td>0.178062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.217600</td>\n",
       "      <td>1.092209</td>\n",
       "      <td>0.665445</td>\n",
       "      <td>0.282302</td>\n",
       "      <td>0.276940</td>\n",
       "      <td>0.256517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.946400</td>\n",
       "      <td>0.936362</td>\n",
       "      <td>0.703025</td>\n",
       "      <td>0.296892</td>\n",
       "      <td>0.303696</td>\n",
       "      <td>0.284288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.858928</td>\n",
       "      <td>0.722273</td>\n",
       "      <td>0.332930</td>\n",
       "      <td>0.337656</td>\n",
       "      <td>0.311366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.800029</td>\n",
       "      <td>0.736939</td>\n",
       "      <td>0.417295</td>\n",
       "      <td>0.374970</td>\n",
       "      <td>0.367644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.554200</td>\n",
       "      <td>0.772977</td>\n",
       "      <td>0.739688</td>\n",
       "      <td>0.386694</td>\n",
       "      <td>0.379197</td>\n",
       "      <td>0.365350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.495600</td>\n",
       "      <td>0.747226</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.427675</td>\n",
       "      <td>0.401563</td>\n",
       "      <td>0.390680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.441400</td>\n",
       "      <td>0.727939</td>\n",
       "      <td>0.755270</td>\n",
       "      <td>0.447733</td>\n",
       "      <td>0.427852</td>\n",
       "      <td>0.424562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.393600</td>\n",
       "      <td>0.719489</td>\n",
       "      <td>0.756187</td>\n",
       "      <td>0.490555</td>\n",
       "      <td>0.428310</td>\n",
       "      <td>0.430775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.366400</td>\n",
       "      <td>0.701986</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.504912</td>\n",
       "      <td>0.451366</td>\n",
       "      <td>0.451644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.338800</td>\n",
       "      <td>0.690793</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.530767</td>\n",
       "      <td>0.453104</td>\n",
       "      <td>0.460320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.321300</td>\n",
       "      <td>0.684220</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.493681</td>\n",
       "      <td>0.458497</td>\n",
       "      <td>0.460805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.310300</td>\n",
       "      <td>0.680352</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.500577</td>\n",
       "      <td>0.463646</td>\n",
       "      <td>0.465734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.307300</td>\n",
       "      <td>0.682366</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.503664</td>\n",
       "      <td>0.470554</td>\n",
       "      <td>0.471691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:51:46,205] Trial 50 finished with value: 0.4716905893774584 and parameters: {'learning_rate': 0.0004984056251371117, 'weight_decay': 0.0, 'warmup_steps': 4, 'lambda_param': 0.8, 'temperature': 4.5}. Best is trial 34 with value: 0.477880764070784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 51 with params: {'learning_rate': 0.00036432523448613356, 'weight_decay': 0.0, 'warmup_steps': 4, 'lambda_param': 0.7000000000000001, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.223400</td>\n",
       "      <td>1.951083</td>\n",
       "      <td>0.389551</td>\n",
       "      <td>0.057345</td>\n",
       "      <td>0.083166</td>\n",
       "      <td>0.062464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.769200</td>\n",
       "      <td>1.549114</td>\n",
       "      <td>0.516040</td>\n",
       "      <td>0.139859</td>\n",
       "      <td>0.153780</td>\n",
       "      <td>0.130468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.411000</td>\n",
       "      <td>1.257814</td>\n",
       "      <td>0.624198</td>\n",
       "      <td>0.228100</td>\n",
       "      <td>0.230673</td>\n",
       "      <td>0.211984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.145900</td>\n",
       "      <td>1.088727</td>\n",
       "      <td>0.673694</td>\n",
       "      <td>0.269110</td>\n",
       "      <td>0.277295</td>\n",
       "      <td>0.258379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.964000</td>\n",
       "      <td>0.974924</td>\n",
       "      <td>0.703025</td>\n",
       "      <td>0.288520</td>\n",
       "      <td>0.304643</td>\n",
       "      <td>0.281088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.818300</td>\n",
       "      <td>0.880777</td>\n",
       "      <td>0.720440</td>\n",
       "      <td>0.323095</td>\n",
       "      <td>0.325401</td>\n",
       "      <td>0.305687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.708300</td>\n",
       "      <td>0.836318</td>\n",
       "      <td>0.714024</td>\n",
       "      <td>0.323290</td>\n",
       "      <td>0.321016</td>\n",
       "      <td>0.301267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.640500</td>\n",
       "      <td>0.807957</td>\n",
       "      <td>0.735105</td>\n",
       "      <td>0.378136</td>\n",
       "      <td>0.361233</td>\n",
       "      <td>0.343180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.583200</td>\n",
       "      <td>0.783036</td>\n",
       "      <td>0.740605</td>\n",
       "      <td>0.406953</td>\n",
       "      <td>0.380244</td>\n",
       "      <td>0.371371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.529500</td>\n",
       "      <td>0.771985</td>\n",
       "      <td>0.744271</td>\n",
       "      <td>0.422603</td>\n",
       "      <td>0.392196</td>\n",
       "      <td>0.383683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.501000</td>\n",
       "      <td>0.754163</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.431774</td>\n",
       "      <td>0.396800</td>\n",
       "      <td>0.389723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.464900</td>\n",
       "      <td>0.739846</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.429806</td>\n",
       "      <td>0.405333</td>\n",
       "      <td>0.397751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>0.734752</td>\n",
       "      <td>0.756187</td>\n",
       "      <td>0.440457</td>\n",
       "      <td>0.407096</td>\n",
       "      <td>0.401368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.435200</td>\n",
       "      <td>0.729340</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.443175</td>\n",
       "      <td>0.411801</td>\n",
       "      <td>0.403962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.431400</td>\n",
       "      <td>0.731236</td>\n",
       "      <td>0.756187</td>\n",
       "      <td>0.453550</td>\n",
       "      <td>0.414352</td>\n",
       "      <td>0.408446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:53:00,986] Trial 51 finished with value: 0.40844618305339947 and parameters: {'learning_rate': 0.00036432523448613356, 'weight_decay': 0.0, 'warmup_steps': 4, 'lambda_param': 0.7000000000000001, 'temperature': 4.5}. Best is trial 34 with value: 0.477880764070784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 52 with params: {'learning_rate': 0.0004624549625399216, 'weight_decay': 0.002, 'warmup_steps': 4, 'lambda_param': 0.8, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:16, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.185700</td>\n",
       "      <td>1.866678</td>\n",
       "      <td>0.421632</td>\n",
       "      <td>0.065934</td>\n",
       "      <td>0.098534</td>\n",
       "      <td>0.074369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.656800</td>\n",
       "      <td>1.419931</td>\n",
       "      <td>0.558203</td>\n",
       "      <td>0.199942</td>\n",
       "      <td>0.190231</td>\n",
       "      <td>0.169767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.262000</td>\n",
       "      <td>1.129563</td>\n",
       "      <td>0.654445</td>\n",
       "      <td>0.255383</td>\n",
       "      <td>0.261069</td>\n",
       "      <td>0.240716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.993600</td>\n",
       "      <td>0.969545</td>\n",
       "      <td>0.687443</td>\n",
       "      <td>0.259138</td>\n",
       "      <td>0.291344</td>\n",
       "      <td>0.267576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.812300</td>\n",
       "      <td>0.880426</td>\n",
       "      <td>0.716774</td>\n",
       "      <td>0.327198</td>\n",
       "      <td>0.328050</td>\n",
       "      <td>0.305906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.814743</td>\n",
       "      <td>0.725023</td>\n",
       "      <td>0.378964</td>\n",
       "      <td>0.353075</td>\n",
       "      <td>0.341774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.586000</td>\n",
       "      <td>0.793365</td>\n",
       "      <td>0.730522</td>\n",
       "      <td>0.402022</td>\n",
       "      <td>0.372611</td>\n",
       "      <td>0.360153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.525900</td>\n",
       "      <td>0.760190</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.402863</td>\n",
       "      <td>0.392513</td>\n",
       "      <td>0.377140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.471600</td>\n",
       "      <td>0.742815</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.460135</td>\n",
       "      <td>0.420536</td>\n",
       "      <td>0.416400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.422800</td>\n",
       "      <td>0.729546</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.472068</td>\n",
       "      <td>0.428736</td>\n",
       "      <td>0.426212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.714633</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.480806</td>\n",
       "      <td>0.437283</td>\n",
       "      <td>0.433545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.366400</td>\n",
       "      <td>0.699553</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.522443</td>\n",
       "      <td>0.445577</td>\n",
       "      <td>0.452020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.346800</td>\n",
       "      <td>0.693131</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.479210</td>\n",
       "      <td>0.454068</td>\n",
       "      <td>0.452945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.335900</td>\n",
       "      <td>0.688410</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.501269</td>\n",
       "      <td>0.456468</td>\n",
       "      <td>0.456209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.333300</td>\n",
       "      <td>0.689937</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.506318</td>\n",
       "      <td>0.458129</td>\n",
       "      <td>0.459479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:54:18,950] Trial 52 finished with value: 0.45947921384572155 and parameters: {'learning_rate': 0.0004624549625399216, 'weight_decay': 0.002, 'warmup_steps': 4, 'lambda_param': 0.8, 'temperature': 4.0}. Best is trial 34 with value: 0.477880764070784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 53 with params: {'learning_rate': 0.0004889391046203257, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 1.0, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:16, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.176100</td>\n",
       "      <td>1.846240</td>\n",
       "      <td>0.426214</td>\n",
       "      <td>0.063409</td>\n",
       "      <td>0.102190</td>\n",
       "      <td>0.075088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.630900</td>\n",
       "      <td>1.393140</td>\n",
       "      <td>0.562786</td>\n",
       "      <td>0.196374</td>\n",
       "      <td>0.199702</td>\n",
       "      <td>0.177350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.228800</td>\n",
       "      <td>1.101910</td>\n",
       "      <td>0.659945</td>\n",
       "      <td>0.275657</td>\n",
       "      <td>0.269421</td>\n",
       "      <td>0.248116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.959000</td>\n",
       "      <td>0.945508</td>\n",
       "      <td>0.699358</td>\n",
       "      <td>0.285805</td>\n",
       "      <td>0.300731</td>\n",
       "      <td>0.279652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.780600</td>\n",
       "      <td>0.862796</td>\n",
       "      <td>0.719523</td>\n",
       "      <td>0.328711</td>\n",
       "      <td>0.334379</td>\n",
       "      <td>0.309952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.656400</td>\n",
       "      <td>0.800811</td>\n",
       "      <td>0.731439</td>\n",
       "      <td>0.386980</td>\n",
       "      <td>0.368738</td>\n",
       "      <td>0.357218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.561000</td>\n",
       "      <td>0.776865</td>\n",
       "      <td>0.739688</td>\n",
       "      <td>0.391131</td>\n",
       "      <td>0.381489</td>\n",
       "      <td>0.370372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.501900</td>\n",
       "      <td>0.750277</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.412805</td>\n",
       "      <td>0.398726</td>\n",
       "      <td>0.388201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.446700</td>\n",
       "      <td>0.732087</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.444092</td>\n",
       "      <td>0.423652</td>\n",
       "      <td>0.420636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.399800</td>\n",
       "      <td>0.722668</td>\n",
       "      <td>0.755270</td>\n",
       "      <td>0.479724</td>\n",
       "      <td>0.426781</td>\n",
       "      <td>0.427231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.373100</td>\n",
       "      <td>0.707941</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.505079</td>\n",
       "      <td>0.445555</td>\n",
       "      <td>0.444597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.345100</td>\n",
       "      <td>0.694120</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.535063</td>\n",
       "      <td>0.458918</td>\n",
       "      <td>0.470397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.326600</td>\n",
       "      <td>0.688717</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.497193</td>\n",
       "      <td>0.454632</td>\n",
       "      <td>0.457524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.315900</td>\n",
       "      <td>0.682907</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.513077</td>\n",
       "      <td>0.466195</td>\n",
       "      <td>0.467402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.313500</td>\n",
       "      <td>0.685101</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.509008</td>\n",
       "      <td>0.471970</td>\n",
       "      <td>0.474457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:55:36,764] Trial 53 finished with value: 0.47445697659191544 and parameters: {'learning_rate': 0.0004889391046203257, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 1.0, 'temperature': 4.0}. Best is trial 34 with value: 0.477880764070784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 54 with params: {'learning_rate': 0.0004535023095910422, 'weight_decay': 0.005, 'warmup_steps': 4, 'lambda_param': 1.0, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.189100</td>\n",
       "      <td>1.874480</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.065794</td>\n",
       "      <td>0.096791</td>\n",
       "      <td>0.073268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.666500</td>\n",
       "      <td>1.430508</td>\n",
       "      <td>0.557287</td>\n",
       "      <td>0.202396</td>\n",
       "      <td>0.190754</td>\n",
       "      <td>0.171360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.274400</td>\n",
       "      <td>1.139259</td>\n",
       "      <td>0.651696</td>\n",
       "      <td>0.255450</td>\n",
       "      <td>0.257846</td>\n",
       "      <td>0.238824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.005800</td>\n",
       "      <td>0.977899</td>\n",
       "      <td>0.688359</td>\n",
       "      <td>0.259811</td>\n",
       "      <td>0.291539</td>\n",
       "      <td>0.267905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.823600</td>\n",
       "      <td>0.886077</td>\n",
       "      <td>0.716774</td>\n",
       "      <td>0.328779</td>\n",
       "      <td>0.329502</td>\n",
       "      <td>0.307922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.693100</td>\n",
       "      <td>0.819380</td>\n",
       "      <td>0.718607</td>\n",
       "      <td>0.369503</td>\n",
       "      <td>0.344388</td>\n",
       "      <td>0.329535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.595400</td>\n",
       "      <td>0.797056</td>\n",
       "      <td>0.730522</td>\n",
       "      <td>0.394328</td>\n",
       "      <td>0.367992</td>\n",
       "      <td>0.353833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.535000</td>\n",
       "      <td>0.762423</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.406169</td>\n",
       "      <td>0.393760</td>\n",
       "      <td>0.378420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.480300</td>\n",
       "      <td>0.747948</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.451526</td>\n",
       "      <td>0.417177</td>\n",
       "      <td>0.411421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.431200</td>\n",
       "      <td>0.734838</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.469727</td>\n",
       "      <td>0.426920</td>\n",
       "      <td>0.425016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.402800</td>\n",
       "      <td>0.719296</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.473636</td>\n",
       "      <td>0.435544</td>\n",
       "      <td>0.433279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.374100</td>\n",
       "      <td>0.704212</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.493223</td>\n",
       "      <td>0.436870</td>\n",
       "      <td>0.438853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.354700</td>\n",
       "      <td>0.697029</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.465376</td>\n",
       "      <td>0.445579</td>\n",
       "      <td>0.441529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.343400</td>\n",
       "      <td>0.691939</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.498546</td>\n",
       "      <td>0.457449</td>\n",
       "      <td>0.455121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.340700</td>\n",
       "      <td>0.693323</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.498922</td>\n",
       "      <td>0.454367</td>\n",
       "      <td>0.451723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:56:53,146] Trial 54 finished with value: 0.45172252995634765 and parameters: {'learning_rate': 0.0004535023095910422, 'weight_decay': 0.005, 'warmup_steps': 4, 'lambda_param': 1.0, 'temperature': 3.5}. Best is trial 34 with value: 0.477880764070784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 55 with params: {'learning_rate': 1.3699906998412503e-05, 'weight_decay': 0.001, 'warmup_steps': 3, 'lambda_param': 0.0, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:50 < 00:25, 6.90 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.454900</td>\n",
       "      <td>2.419359</td>\n",
       "      <td>0.083410</td>\n",
       "      <td>0.008102</td>\n",
       "      <td>0.030199</td>\n",
       "      <td>0.007795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.409600</td>\n",
       "      <td>2.376210</td>\n",
       "      <td>0.182401</td>\n",
       "      <td>0.009993</td>\n",
       "      <td>0.022335</td>\n",
       "      <td>0.009984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.375200</td>\n",
       "      <td>2.343427</td>\n",
       "      <td>0.184235</td>\n",
       "      <td>0.011439</td>\n",
       "      <td>0.022362</td>\n",
       "      <td>0.009865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.347000</td>\n",
       "      <td>2.316581</td>\n",
       "      <td>0.184235</td>\n",
       "      <td>0.015023</td>\n",
       "      <td>0.022192</td>\n",
       "      <td>0.009771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.322700</td>\n",
       "      <td>2.292089</td>\n",
       "      <td>0.181485</td>\n",
       "      <td>0.020231</td>\n",
       "      <td>0.021370</td>\n",
       "      <td>0.008582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.299300</td>\n",
       "      <td>2.271177</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.018561</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.281700</td>\n",
       "      <td>2.252937</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023554</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.266200</td>\n",
       "      <td>2.237278</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023554</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.252300</td>\n",
       "      <td>2.223956</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023554</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.242700</td>\n",
       "      <td>2.213177</td>\n",
       "      <td>0.182401</td>\n",
       "      <td>0.043564</td>\n",
       "      <td>0.021585</td>\n",
       "      <td>0.009040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:57:44,726] Trial 55 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 56 with params: {'learning_rate': 0.00041958991272579696, 'weight_decay': 0.0, 'warmup_steps': 3, 'lambda_param': 0.8, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:48 < 00:24, 7.19 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.194800</td>\n",
       "      <td>1.899458</td>\n",
       "      <td>0.411549</td>\n",
       "      <td>0.071307</td>\n",
       "      <td>0.093269</td>\n",
       "      <td>0.072151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.702800</td>\n",
       "      <td>1.478029</td>\n",
       "      <td>0.536205</td>\n",
       "      <td>0.163876</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0.150020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.328400</td>\n",
       "      <td>1.182062</td>\n",
       "      <td>0.647113</td>\n",
       "      <td>0.238582</td>\n",
       "      <td>0.250765</td>\n",
       "      <td>0.231377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.057700</td>\n",
       "      <td>1.016247</td>\n",
       "      <td>0.685610</td>\n",
       "      <td>0.267946</td>\n",
       "      <td>0.287099</td>\n",
       "      <td>0.263879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.872100</td>\n",
       "      <td>0.914882</td>\n",
       "      <td>0.716774</td>\n",
       "      <td>0.317071</td>\n",
       "      <td>0.321308</td>\n",
       "      <td>0.299572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.733700</td>\n",
       "      <td>0.837084</td>\n",
       "      <td>0.724106</td>\n",
       "      <td>0.340943</td>\n",
       "      <td>0.336075</td>\n",
       "      <td>0.315853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.632500</td>\n",
       "      <td>0.808259</td>\n",
       "      <td>0.724106</td>\n",
       "      <td>0.364455</td>\n",
       "      <td>0.342961</td>\n",
       "      <td>0.327566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.570600</td>\n",
       "      <td>0.778526</td>\n",
       "      <td>0.747938</td>\n",
       "      <td>0.397399</td>\n",
       "      <td>0.386035</td>\n",
       "      <td>0.370750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.516300</td>\n",
       "      <td>0.754206</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.438733</td>\n",
       "      <td>0.401241</td>\n",
       "      <td>0.395789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.467000</td>\n",
       "      <td>0.755742</td>\n",
       "      <td>0.747938</td>\n",
       "      <td>0.443193</td>\n",
       "      <td>0.398353</td>\n",
       "      <td>0.390230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:58:34,278] Trial 56 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 57 with params: {'learning_rate': 0.00015629272253669425, 'weight_decay': 0.009000000000000001, 'warmup_steps': 0, 'lambda_param': 0.30000000000000004, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:49 < 00:24, 7.07 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.306400</td>\n",
       "      <td>2.144367</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.059300</td>\n",
       "      <td>1.928741</td>\n",
       "      <td>0.409716</td>\n",
       "      <td>0.051704</td>\n",
       "      <td>0.088292</td>\n",
       "      <td>0.063031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.863100</td>\n",
       "      <td>1.731618</td>\n",
       "      <td>0.459212</td>\n",
       "      <td>0.101842</td>\n",
       "      <td>0.118315</td>\n",
       "      <td>0.091729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.675400</td>\n",
       "      <td>1.570262</td>\n",
       "      <td>0.516957</td>\n",
       "      <td>0.205508</td>\n",
       "      <td>0.156537</td>\n",
       "      <td>0.138031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.534200</td>\n",
       "      <td>1.443634</td>\n",
       "      <td>0.563703</td>\n",
       "      <td>0.228332</td>\n",
       "      <td>0.190213</td>\n",
       "      <td>0.172615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.400600</td>\n",
       "      <td>1.345307</td>\n",
       "      <td>0.593951</td>\n",
       "      <td>0.239781</td>\n",
       "      <td>0.211756</td>\n",
       "      <td>0.196676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.296900</td>\n",
       "      <td>1.265622</td>\n",
       "      <td>0.636114</td>\n",
       "      <td>0.268989</td>\n",
       "      <td>0.241517</td>\n",
       "      <td>0.229652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.221300</td>\n",
       "      <td>1.204177</td>\n",
       "      <td>0.660862</td>\n",
       "      <td>0.261835</td>\n",
       "      <td>0.265686</td>\n",
       "      <td>0.247986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.150300</td>\n",
       "      <td>1.153292</td>\n",
       "      <td>0.670027</td>\n",
       "      <td>0.264481</td>\n",
       "      <td>0.275871</td>\n",
       "      <td>0.254782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.089900</td>\n",
       "      <td>1.114517</td>\n",
       "      <td>0.681943</td>\n",
       "      <td>0.264543</td>\n",
       "      <td>0.283347</td>\n",
       "      <td>0.260827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:59:24,663] Trial 57 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 58 with params: {'learning_rate': 0.00047869201160203576, 'weight_decay': 0.001, 'warmup_steps': 2, 'lambda_param': 0.6000000000000001, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:20, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.157400</td>\n",
       "      <td>1.828676</td>\n",
       "      <td>0.428964</td>\n",
       "      <td>0.061616</td>\n",
       "      <td>0.103400</td>\n",
       "      <td>0.074759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.621000</td>\n",
       "      <td>1.394686</td>\n",
       "      <td>0.560953</td>\n",
       "      <td>0.193006</td>\n",
       "      <td>0.193865</td>\n",
       "      <td>0.171784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.235500</td>\n",
       "      <td>1.112935</td>\n",
       "      <td>0.658112</td>\n",
       "      <td>0.277792</td>\n",
       "      <td>0.265717</td>\n",
       "      <td>0.247984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.974500</td>\n",
       "      <td>0.956164</td>\n",
       "      <td>0.703941</td>\n",
       "      <td>0.282585</td>\n",
       "      <td>0.300645</td>\n",
       "      <td>0.278906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.798600</td>\n",
       "      <td>0.870970</td>\n",
       "      <td>0.717690</td>\n",
       "      <td>0.322816</td>\n",
       "      <td>0.331579</td>\n",
       "      <td>0.307659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.671900</td>\n",
       "      <td>0.808860</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.383088</td>\n",
       "      <td>0.371770</td>\n",
       "      <td>0.357542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.576300</td>\n",
       "      <td>0.784995</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.423006</td>\n",
       "      <td>0.386977</td>\n",
       "      <td>0.375737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.516900</td>\n",
       "      <td>0.759720</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.426792</td>\n",
       "      <td>0.407037</td>\n",
       "      <td>0.397615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.461700</td>\n",
       "      <td>0.735847</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.464716</td>\n",
       "      <td>0.426107</td>\n",
       "      <td>0.421846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.412300</td>\n",
       "      <td>0.720817</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.487034</td>\n",
       "      <td>0.440451</td>\n",
       "      <td>0.440003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.384400</td>\n",
       "      <td>0.705768</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.476331</td>\n",
       "      <td>0.444956</td>\n",
       "      <td>0.440849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.357000</td>\n",
       "      <td>0.695100</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.477053</td>\n",
       "      <td>0.444499</td>\n",
       "      <td>0.443823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.338600</td>\n",
       "      <td>0.689761</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.491105</td>\n",
       "      <td>0.451005</td>\n",
       "      <td>0.451246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.327100</td>\n",
       "      <td>0.685818</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.485320</td>\n",
       "      <td>0.452318</td>\n",
       "      <td>0.450035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.325300</td>\n",
       "      <td>0.687712</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.484678</td>\n",
       "      <td>0.463675</td>\n",
       "      <td>0.457820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:00:46,276] Trial 58 finished with value: 0.45782043827717417 and parameters: {'learning_rate': 0.00047869201160203576, 'weight_decay': 0.001, 'warmup_steps': 2, 'lambda_param': 0.6000000000000001, 'temperature': 4.5}. Best is trial 34 with value: 0.477880764070784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 59 with params: {'learning_rate': 0.00046329107000868657, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 1.0, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:16, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.185400</td>\n",
       "      <td>1.866012</td>\n",
       "      <td>0.421632</td>\n",
       "      <td>0.065934</td>\n",
       "      <td>0.098534</td>\n",
       "      <td>0.074369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.655900</td>\n",
       "      <td>1.419062</td>\n",
       "      <td>0.558203</td>\n",
       "      <td>0.200100</td>\n",
       "      <td>0.190231</td>\n",
       "      <td>0.169880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.260900</td>\n",
       "      <td>1.128710</td>\n",
       "      <td>0.654445</td>\n",
       "      <td>0.255383</td>\n",
       "      <td>0.261069</td>\n",
       "      <td>0.240716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.992400</td>\n",
       "      <td>0.968815</td>\n",
       "      <td>0.687443</td>\n",
       "      <td>0.259138</td>\n",
       "      <td>0.291344</td>\n",
       "      <td>0.267576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.811200</td>\n",
       "      <td>0.879793</td>\n",
       "      <td>0.717690</td>\n",
       "      <td>0.327652</td>\n",
       "      <td>0.328959</td>\n",
       "      <td>0.306518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.681900</td>\n",
       "      <td>0.814236</td>\n",
       "      <td>0.724106</td>\n",
       "      <td>0.378030</td>\n",
       "      <td>0.352122</td>\n",
       "      <td>0.341188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.585100</td>\n",
       "      <td>0.792758</td>\n",
       "      <td>0.731439</td>\n",
       "      <td>0.400816</td>\n",
       "      <td>0.375111</td>\n",
       "      <td>0.363932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.760029</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.402863</td>\n",
       "      <td>0.392513</td>\n",
       "      <td>0.377140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.470900</td>\n",
       "      <td>0.742267</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.460884</td>\n",
       "      <td>0.420536</td>\n",
       "      <td>0.416904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.422100</td>\n",
       "      <td>0.728953</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.473854</td>\n",
       "      <td>0.429788</td>\n",
       "      <td>0.427727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>0.714109</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.483704</td>\n",
       "      <td>0.439783</td>\n",
       "      <td>0.436630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.365700</td>\n",
       "      <td>0.699202</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.522443</td>\n",
       "      <td>0.445577</td>\n",
       "      <td>0.452020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.346200</td>\n",
       "      <td>0.692851</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.479210</td>\n",
       "      <td>0.454068</td>\n",
       "      <td>0.452945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.335200</td>\n",
       "      <td>0.688088</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.501269</td>\n",
       "      <td>0.456468</td>\n",
       "      <td>0.456209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.332600</td>\n",
       "      <td>0.689565</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.506318</td>\n",
       "      <td>0.458129</td>\n",
       "      <td>0.459479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:02:04,084] Trial 59 finished with value: 0.45947921384572155 and parameters: {'learning_rate': 0.00046329107000868657, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 1.0, 'temperature': 3.5}. Best is trial 34 with value: 0.477880764070784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 60 with params: {'learning_rate': 4.608864757704483e-05, 'weight_decay': 0.005, 'warmup_steps': 4, 'lambda_param': 0.5, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:50 < 00:25, 6.87 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.416500</td>\n",
       "      <td>2.336309</td>\n",
       "      <td>0.181485</td>\n",
       "      <td>0.013574</td>\n",
       "      <td>0.021370</td>\n",
       "      <td>0.008474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.306700</td>\n",
       "      <td>2.244493</td>\n",
       "      <td>0.178735</td>\n",
       "      <td>0.023545</td>\n",
       "      <td>0.020548</td>\n",
       "      <td>0.007089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.228400</td>\n",
       "      <td>2.164548</td>\n",
       "      <td>0.201650</td>\n",
       "      <td>0.059635</td>\n",
       "      <td>0.026992</td>\n",
       "      <td>0.017953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.155100</td>\n",
       "      <td>2.093710</td>\n",
       "      <td>0.344638</td>\n",
       "      <td>0.069284</td>\n",
       "      <td>0.068776</td>\n",
       "      <td>0.060514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.096300</td>\n",
       "      <td>2.032597</td>\n",
       "      <td>0.391384</td>\n",
       "      <td>0.077739</td>\n",
       "      <td>0.082847</td>\n",
       "      <td>0.064592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.034100</td>\n",
       "      <td>1.979052</td>\n",
       "      <td>0.407883</td>\n",
       "      <td>0.074458</td>\n",
       "      <td>0.087656</td>\n",
       "      <td>0.065314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.983100</td>\n",
       "      <td>1.932265</td>\n",
       "      <td>0.415215</td>\n",
       "      <td>0.092397</td>\n",
       "      <td>0.092040</td>\n",
       "      <td>0.070769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.942400</td>\n",
       "      <td>1.891068</td>\n",
       "      <td>0.437214</td>\n",
       "      <td>0.088528</td>\n",
       "      <td>0.102957</td>\n",
       "      <td>0.080986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.903700</td>\n",
       "      <td>1.856319</td>\n",
       "      <td>0.444546</td>\n",
       "      <td>0.105743</td>\n",
       "      <td>0.106968</td>\n",
       "      <td>0.085396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.874700</td>\n",
       "      <td>1.828419</td>\n",
       "      <td>0.460128</td>\n",
       "      <td>0.104562</td>\n",
       "      <td>0.116793</td>\n",
       "      <td>0.093935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:02:55,683] Trial 60 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 61 with params: {'learning_rate': 0.0002928184488683756, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.7000000000000001, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:48, 7.23 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.253800</td>\n",
       "      <td>2.015555</td>\n",
       "      <td>0.360220</td>\n",
       "      <td>0.067849</td>\n",
       "      <td>0.073305</td>\n",
       "      <td>0.060406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.862300</td>\n",
       "      <td>1.660786</td>\n",
       "      <td>0.479377</td>\n",
       "      <td>0.142534</td>\n",
       "      <td>0.135522</td>\n",
       "      <td>0.111132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.544200</td>\n",
       "      <td>1.387946</td>\n",
       "      <td>0.562786</td>\n",
       "      <td>0.199337</td>\n",
       "      <td>0.184194</td>\n",
       "      <td>0.163674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.289600</td>\n",
       "      <td>1.201240</td>\n",
       "      <td>0.649863</td>\n",
       "      <td>0.248002</td>\n",
       "      <td>0.253515</td>\n",
       "      <td>0.236808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.107800</td>\n",
       "      <td>1.069700</td>\n",
       "      <td>0.686526</td>\n",
       "      <td>0.269934</td>\n",
       "      <td>0.284420</td>\n",
       "      <td>0.262661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:03:20,686] Trial 61 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 62 with params: {'learning_rate': 0.000495313190572418, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 0.0, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:20, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.173800</td>\n",
       "      <td>1.841542</td>\n",
       "      <td>0.428048</td>\n",
       "      <td>0.062617</td>\n",
       "      <td>0.103199</td>\n",
       "      <td>0.074993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.624900</td>\n",
       "      <td>1.387151</td>\n",
       "      <td>0.564620</td>\n",
       "      <td>0.197668</td>\n",
       "      <td>0.200405</td>\n",
       "      <td>0.177760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.221200</td>\n",
       "      <td>1.095313</td>\n",
       "      <td>0.662695</td>\n",
       "      <td>0.276004</td>\n",
       "      <td>0.271825</td>\n",
       "      <td>0.251533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.950500</td>\n",
       "      <td>0.939162</td>\n",
       "      <td>0.702108</td>\n",
       "      <td>0.296810</td>\n",
       "      <td>0.303333</td>\n",
       "      <td>0.283886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.773200</td>\n",
       "      <td>0.858735</td>\n",
       "      <td>0.721357</td>\n",
       "      <td>0.331038</td>\n",
       "      <td>0.336372</td>\n",
       "      <td>0.310340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.651200</td>\n",
       "      <td>0.797212</td>\n",
       "      <td>0.733272</td>\n",
       "      <td>0.415557</td>\n",
       "      <td>0.370896</td>\n",
       "      <td>0.363321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.556000</td>\n",
       "      <td>0.773935</td>\n",
       "      <td>0.739688</td>\n",
       "      <td>0.389874</td>\n",
       "      <td>0.381839</td>\n",
       "      <td>0.369196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.497100</td>\n",
       "      <td>0.748183</td>\n",
       "      <td>0.747938</td>\n",
       "      <td>0.415935</td>\n",
       "      <td>0.401381</td>\n",
       "      <td>0.387318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.442600</td>\n",
       "      <td>0.729410</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.447677</td>\n",
       "      <td>0.427008</td>\n",
       "      <td>0.424337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.394900</td>\n",
       "      <td>0.718143</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.492199</td>\n",
       "      <td>0.431915</td>\n",
       "      <td>0.435638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.367800</td>\n",
       "      <td>0.703419</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.503663</td>\n",
       "      <td>0.447984</td>\n",
       "      <td>0.446622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.340300</td>\n",
       "      <td>0.690953</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.540082</td>\n",
       "      <td>0.455859</td>\n",
       "      <td>0.464698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.322400</td>\n",
       "      <td>0.684540</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.499244</td>\n",
       "      <td>0.457183</td>\n",
       "      <td>0.459691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.311500</td>\n",
       "      <td>0.680380</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.520551</td>\n",
       "      <td>0.466958</td>\n",
       "      <td>0.470978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.308400</td>\n",
       "      <td>0.682296</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.507326</td>\n",
       "      <td>0.475022</td>\n",
       "      <td>0.477193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:04:43,008] Trial 62 finished with value: 0.4771931368124554 and parameters: {'learning_rate': 0.000495313190572418, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 0.0, 'temperature': 2.0}. Best is trial 34 with value: 0.477880764070784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 63 with params: {'learning_rate': 0.00037289600544837765, 'weight_decay': 0.001, 'warmup_steps': 3, 'lambda_param': 0.0, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:25 < 00:50, 6.90 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.212800</td>\n",
       "      <td>1.936925</td>\n",
       "      <td>0.395967</td>\n",
       "      <td>0.055209</td>\n",
       "      <td>0.084820</td>\n",
       "      <td>0.062720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.753600</td>\n",
       "      <td>1.535629</td>\n",
       "      <td>0.520623</td>\n",
       "      <td>0.159906</td>\n",
       "      <td>0.158420</td>\n",
       "      <td>0.138484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.395200</td>\n",
       "      <td>1.246141</td>\n",
       "      <td>0.633364</td>\n",
       "      <td>0.225789</td>\n",
       "      <td>0.236000</td>\n",
       "      <td>0.216449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.130800</td>\n",
       "      <td>1.080297</td>\n",
       "      <td>0.674610</td>\n",
       "      <td>0.262514</td>\n",
       "      <td>0.278185</td>\n",
       "      <td>0.258827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.949800</td>\n",
       "      <td>0.968144</td>\n",
       "      <td>0.704858</td>\n",
       "      <td>0.290935</td>\n",
       "      <td>0.307347</td>\n",
       "      <td>0.284737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:05:09,026] Trial 63 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 64 with params: {'learning_rate': 0.00044567610748604626, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 0.0, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:16, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.192100</td>\n",
       "      <td>1.881538</td>\n",
       "      <td>0.417965</td>\n",
       "      <td>0.070360</td>\n",
       "      <td>0.095930</td>\n",
       "      <td>0.073594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.675400</td>\n",
       "      <td>1.440488</td>\n",
       "      <td>0.554537</td>\n",
       "      <td>0.182794</td>\n",
       "      <td>0.187512</td>\n",
       "      <td>0.167707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.285800</td>\n",
       "      <td>1.147863</td>\n",
       "      <td>0.650779</td>\n",
       "      <td>0.257555</td>\n",
       "      <td>0.255509</td>\n",
       "      <td>0.236825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.016800</td>\n",
       "      <td>0.985435</td>\n",
       "      <td>0.693859</td>\n",
       "      <td>0.277814</td>\n",
       "      <td>0.300276</td>\n",
       "      <td>0.278662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.833700</td>\n",
       "      <td>0.891928</td>\n",
       "      <td>0.716774</td>\n",
       "      <td>0.339012</td>\n",
       "      <td>0.328528</td>\n",
       "      <td>0.307191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.702300</td>\n",
       "      <td>0.823433</td>\n",
       "      <td>0.717690</td>\n",
       "      <td>0.366700</td>\n",
       "      <td>0.342839</td>\n",
       "      <td>0.327409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.603300</td>\n",
       "      <td>0.797655</td>\n",
       "      <td>0.730522</td>\n",
       "      <td>0.375277</td>\n",
       "      <td>0.363688</td>\n",
       "      <td>0.346867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.542600</td>\n",
       "      <td>0.765106</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.409220</td>\n",
       "      <td>0.395320</td>\n",
       "      <td>0.380092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.487100</td>\n",
       "      <td>0.747848</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.435263</td>\n",
       "      <td>0.410975</td>\n",
       "      <td>0.401788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.438000</td>\n",
       "      <td>0.738207</td>\n",
       "      <td>0.757104</td>\n",
       "      <td>0.434425</td>\n",
       "      <td>0.414993</td>\n",
       "      <td>0.406565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.410100</td>\n",
       "      <td>0.720286</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.451479</td>\n",
       "      <td>0.428195</td>\n",
       "      <td>0.423260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.380600</td>\n",
       "      <td>0.706111</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.489326</td>\n",
       "      <td>0.431128</td>\n",
       "      <td>0.434339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.361600</td>\n",
       "      <td>0.698880</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.467445</td>\n",
       "      <td>0.443624</td>\n",
       "      <td>0.440316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.349900</td>\n",
       "      <td>0.693701</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.491814</td>\n",
       "      <td>0.455190</td>\n",
       "      <td>0.451379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.347400</td>\n",
       "      <td>0.695260</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.489182</td>\n",
       "      <td>0.451802</td>\n",
       "      <td>0.447439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:06:26,714] Trial 64 finished with value: 0.44743856039786045 and parameters: {'learning_rate': 0.00044567610748604626, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 0.0, 'temperature': 2.0}. Best is trial 34 with value: 0.477880764070784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 65 with params: {'learning_rate': 0.0003309726189437743, 'weight_decay': 0.002, 'warmup_steps': 4, 'lambda_param': 0.30000000000000004, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:24 < 00:49, 7.11 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.236900</td>\n",
       "      <td>1.979940</td>\n",
       "      <td>0.376719</td>\n",
       "      <td>0.063924</td>\n",
       "      <td>0.078707</td>\n",
       "      <td>0.062624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.811000</td>\n",
       "      <td>1.599152</td>\n",
       "      <td>0.499542</td>\n",
       "      <td>0.130577</td>\n",
       "      <td>0.145234</td>\n",
       "      <td>0.121818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.470100</td>\n",
       "      <td>1.315083</td>\n",
       "      <td>0.593034</td>\n",
       "      <td>0.227175</td>\n",
       "      <td>0.206956</td>\n",
       "      <td>0.189263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.209000</td>\n",
       "      <td>1.137363</td>\n",
       "      <td>0.660862</td>\n",
       "      <td>0.263272</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.250495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.026500</td>\n",
       "      <td>1.014579</td>\n",
       "      <td>0.694775</td>\n",
       "      <td>0.289128</td>\n",
       "      <td>0.293555</td>\n",
       "      <td>0.270516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:06:51,958] Trial 65 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 66 with params: {'learning_rate': 0.0001855853030494943, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 0.1, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:48 < 00:24, 7.12 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.310500</td>\n",
       "      <td>2.126421</td>\n",
       "      <td>0.178735</td>\n",
       "      <td>0.023545</td>\n",
       "      <td>0.020476</td>\n",
       "      <td>0.006952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.023800</td>\n",
       "      <td>1.872576</td>\n",
       "      <td>0.424381</td>\n",
       "      <td>0.065837</td>\n",
       "      <td>0.097547</td>\n",
       "      <td>0.072981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.792400</td>\n",
       "      <td>1.648564</td>\n",
       "      <td>0.489459</td>\n",
       "      <td>0.141929</td>\n",
       "      <td>0.140238</td>\n",
       "      <td>0.118145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.581500</td>\n",
       "      <td>1.473127</td>\n",
       "      <td>0.545371</td>\n",
       "      <td>0.160608</td>\n",
       "      <td>0.173147</td>\n",
       "      <td>0.153395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.425000</td>\n",
       "      <td>1.339413</td>\n",
       "      <td>0.594867</td>\n",
       "      <td>0.249737</td>\n",
       "      <td>0.208595</td>\n",
       "      <td>0.192411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.280100</td>\n",
       "      <td>1.235450</td>\n",
       "      <td>0.648029</td>\n",
       "      <td>0.268400</td>\n",
       "      <td>0.253910</td>\n",
       "      <td>0.241298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.169800</td>\n",
       "      <td>1.154757</td>\n",
       "      <td>0.664528</td>\n",
       "      <td>0.269045</td>\n",
       "      <td>0.269236</td>\n",
       "      <td>0.252107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.091100</td>\n",
       "      <td>1.095045</td>\n",
       "      <td>0.681027</td>\n",
       "      <td>0.257689</td>\n",
       "      <td>0.283466</td>\n",
       "      <td>0.260400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.017300</td>\n",
       "      <td>1.047684</td>\n",
       "      <td>0.692026</td>\n",
       "      <td>0.292792</td>\n",
       "      <td>0.293659</td>\n",
       "      <td>0.270204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.955400</td>\n",
       "      <td>1.011853</td>\n",
       "      <td>0.700275</td>\n",
       "      <td>0.294650</td>\n",
       "      <td>0.298997</td>\n",
       "      <td>0.277404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:07:41,798] Trial 66 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 67 with params: {'learning_rate': 1.5641639605857323e-05, 'weight_decay': 0.005, 'warmup_steps': 2, 'lambda_param': 0.6000000000000001, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:24 < 00:49, 7.09 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.451400</td>\n",
       "      <td>2.412460</td>\n",
       "      <td>0.109074</td>\n",
       "      <td>0.009675</td>\n",
       "      <td>0.033271</td>\n",
       "      <td>0.008640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.400900</td>\n",
       "      <td>2.365041</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>0.014581</td>\n",
       "      <td>0.022906</td>\n",
       "      <td>0.010746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.363900</td>\n",
       "      <td>2.330106</td>\n",
       "      <td>0.181485</td>\n",
       "      <td>0.011921</td>\n",
       "      <td>0.021370</td>\n",
       "      <td>0.008436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.333100</td>\n",
       "      <td>2.301184</td>\n",
       "      <td>0.184235</td>\n",
       "      <td>0.015895</td>\n",
       "      <td>0.022192</td>\n",
       "      <td>0.009804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.306700</td>\n",
       "      <td>2.273307</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.019564</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:08:07,221] Trial 67 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 68 with params: {'learning_rate': 0.0003288544461073333, 'weight_decay': 0.0, 'warmup_steps': 4, 'lambda_param': 0.0, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:24 < 00:49, 7.10 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.237800</td>\n",
       "      <td>1.981822</td>\n",
       "      <td>0.375802</td>\n",
       "      <td>0.064074</td>\n",
       "      <td>0.078343</td>\n",
       "      <td>0.062505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.813800</td>\n",
       "      <td>1.602539</td>\n",
       "      <td>0.494959</td>\n",
       "      <td>0.126084</td>\n",
       "      <td>0.141965</td>\n",
       "      <td>0.117553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.474100</td>\n",
       "      <td>1.319078</td>\n",
       "      <td>0.589368</td>\n",
       "      <td>0.227303</td>\n",
       "      <td>0.204876</td>\n",
       "      <td>0.186935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.213300</td>\n",
       "      <td>1.140606</td>\n",
       "      <td>0.659945</td>\n",
       "      <td>0.262655</td>\n",
       "      <td>0.265788</td>\n",
       "      <td>0.249915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.030600</td>\n",
       "      <td>1.017271</td>\n",
       "      <td>0.694775</td>\n",
       "      <td>0.289130</td>\n",
       "      <td>0.293555</td>\n",
       "      <td>0.270626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:08:32,579] Trial 68 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 69 with params: {'learning_rate': 1.460315612078236e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 3, 'lambda_param': 0.8, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:50 < 00:25, 6.90 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.453600</td>\n",
       "      <td>2.416477</td>\n",
       "      <td>0.096242</td>\n",
       "      <td>0.007906</td>\n",
       "      <td>0.031649</td>\n",
       "      <td>0.008065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.405800</td>\n",
       "      <td>2.371090</td>\n",
       "      <td>0.183318</td>\n",
       "      <td>0.013743</td>\n",
       "      <td>0.022699</td>\n",
       "      <td>0.010622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.370000</td>\n",
       "      <td>2.337292</td>\n",
       "      <td>0.183318</td>\n",
       "      <td>0.011839</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>0.009219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.340600</td>\n",
       "      <td>2.309474</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>0.015594</td>\n",
       "      <td>0.022466</td>\n",
       "      <td>0.010184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.315300</td>\n",
       "      <td>2.283392</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.019564</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.290700</td>\n",
       "      <td>2.261451</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.272000</td>\n",
       "      <td>2.242266</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023554</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.255900</td>\n",
       "      <td>2.225931</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023554</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.241400</td>\n",
       "      <td>2.212002</td>\n",
       "      <td>0.183318</td>\n",
       "      <td>0.043567</td>\n",
       "      <td>0.021859</td>\n",
       "      <td>0.009518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.231300</td>\n",
       "      <td>2.200544</td>\n",
       "      <td>0.186068</td>\n",
       "      <td>0.043581</td>\n",
       "      <td>0.022681</td>\n",
       "      <td>0.010890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:09:24,045] Trial 69 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 70 with params: {'learning_rate': 0.00032990252154684437, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 1.0, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:15, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.237300</td>\n",
       "      <td>1.980906</td>\n",
       "      <td>0.376719</td>\n",
       "      <td>0.063971</td>\n",
       "      <td>0.078707</td>\n",
       "      <td>0.062669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.812400</td>\n",
       "      <td>1.600922</td>\n",
       "      <td>0.496792</td>\n",
       "      <td>0.128641</td>\n",
       "      <td>0.143372</td>\n",
       "      <td>0.119495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.472100</td>\n",
       "      <td>1.317108</td>\n",
       "      <td>0.592117</td>\n",
       "      <td>0.228008</td>\n",
       "      <td>0.206430</td>\n",
       "      <td>0.188454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.211200</td>\n",
       "      <td>1.139023</td>\n",
       "      <td>0.660862</td>\n",
       "      <td>0.262885</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.250367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.028600</td>\n",
       "      <td>1.015960</td>\n",
       "      <td>0.694775</td>\n",
       "      <td>0.289128</td>\n",
       "      <td>0.293555</td>\n",
       "      <td>0.270516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.880500</td>\n",
       "      <td>0.920769</td>\n",
       "      <td>0.714940</td>\n",
       "      <td>0.300442</td>\n",
       "      <td>0.314686</td>\n",
       "      <td>0.293866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.768300</td>\n",
       "      <td>0.867769</td>\n",
       "      <td>0.710357</td>\n",
       "      <td>0.300823</td>\n",
       "      <td>0.313893</td>\n",
       "      <td>0.293022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.697800</td>\n",
       "      <td>0.834058</td>\n",
       "      <td>0.728689</td>\n",
       "      <td>0.335504</td>\n",
       "      <td>0.345569</td>\n",
       "      <td>0.323006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.638600</td>\n",
       "      <td>0.809185</td>\n",
       "      <td>0.729606</td>\n",
       "      <td>0.362323</td>\n",
       "      <td>0.352161</td>\n",
       "      <td>0.338269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.582100</td>\n",
       "      <td>0.797420</td>\n",
       "      <td>0.742438</td>\n",
       "      <td>0.376910</td>\n",
       "      <td>0.374023</td>\n",
       "      <td>0.357869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.553100</td>\n",
       "      <td>0.776873</td>\n",
       "      <td>0.744271</td>\n",
       "      <td>0.429415</td>\n",
       "      <td>0.387550</td>\n",
       "      <td>0.379749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.515600</td>\n",
       "      <td>0.759705</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.416819</td>\n",
       "      <td>0.391300</td>\n",
       "      <td>0.382369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.502000</td>\n",
       "      <td>0.753971</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.433917</td>\n",
       "      <td>0.393835</td>\n",
       "      <td>0.386481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.485600</td>\n",
       "      <td>0.747564</td>\n",
       "      <td>0.757104</td>\n",
       "      <td>0.449234</td>\n",
       "      <td>0.410828</td>\n",
       "      <td>0.403898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.481500</td>\n",
       "      <td>0.749212</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.444410</td>\n",
       "      <td>0.410503</td>\n",
       "      <td>0.401641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:10:41,789] Trial 70 finished with value: 0.401640914843656 and parameters: {'learning_rate': 0.00032990252154684437, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 1.0, 'temperature': 5.5}. Best is trial 34 with value: 0.477880764070784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 71 with params: {'learning_rate': 0.0004445390873396189, 'weight_decay': 0.002, 'warmup_steps': 3, 'lambda_param': 0.9, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.184800</td>\n",
       "      <td>1.878325</td>\n",
       "      <td>0.421632</td>\n",
       "      <td>0.068412</td>\n",
       "      <td>0.097934</td>\n",
       "      <td>0.075186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.676000</td>\n",
       "      <td>1.449114</td>\n",
       "      <td>0.540788</td>\n",
       "      <td>0.169242</td>\n",
       "      <td>0.173741</td>\n",
       "      <td>0.153708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.293100</td>\n",
       "      <td>1.153247</td>\n",
       "      <td>0.651696</td>\n",
       "      <td>0.240204</td>\n",
       "      <td>0.254677</td>\n",
       "      <td>0.233986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.020700</td>\n",
       "      <td>0.988816</td>\n",
       "      <td>0.685610</td>\n",
       "      <td>0.271600</td>\n",
       "      <td>0.287452</td>\n",
       "      <td>0.262075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.835700</td>\n",
       "      <td>0.893034</td>\n",
       "      <td>0.715857</td>\n",
       "      <td>0.301620</td>\n",
       "      <td>0.323060</td>\n",
       "      <td>0.298388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.702000</td>\n",
       "      <td>0.821889</td>\n",
       "      <td>0.725940</td>\n",
       "      <td>0.362620</td>\n",
       "      <td>0.346400</td>\n",
       "      <td>0.329386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.603600</td>\n",
       "      <td>0.798627</td>\n",
       "      <td>0.730522</td>\n",
       "      <td>0.373524</td>\n",
       "      <td>0.356347</td>\n",
       "      <td>0.340908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.543600</td>\n",
       "      <td>0.766506</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.405474</td>\n",
       "      <td>0.398709</td>\n",
       "      <td>0.385160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.490800</td>\n",
       "      <td>0.741712</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.451205</td>\n",
       "      <td>0.412948</td>\n",
       "      <td>0.410603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.441500</td>\n",
       "      <td>0.740133</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.431201</td>\n",
       "      <td>0.413497</td>\n",
       "      <td>0.402247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.414600</td>\n",
       "      <td>0.714225</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.445836</td>\n",
       "      <td>0.424267</td>\n",
       "      <td>0.416522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.383600</td>\n",
       "      <td>0.705035</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.465908</td>\n",
       "      <td>0.429569</td>\n",
       "      <td>0.427697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.698350</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.471175</td>\n",
       "      <td>0.437637</td>\n",
       "      <td>0.435116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.353400</td>\n",
       "      <td>0.694225</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.478731</td>\n",
       "      <td>0.448421</td>\n",
       "      <td>0.441722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.351200</td>\n",
       "      <td>0.695165</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.517430</td>\n",
       "      <td>0.464418</td>\n",
       "      <td>0.465265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:11:56,782] Trial 71 finished with value: 0.46526531790863423 and parameters: {'learning_rate': 0.0004445390873396189, 'weight_decay': 0.002, 'warmup_steps': 3, 'lambda_param': 0.9, 'temperature': 4.5}. Best is trial 34 with value: 0.477880764070784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 72 with params: {'learning_rate': 0.0004701555596851597, 'weight_decay': 0.003, 'warmup_steps': 3, 'lambda_param': 0.9, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.174300</td>\n",
       "      <td>1.855500</td>\n",
       "      <td>0.426214</td>\n",
       "      <td>0.063963</td>\n",
       "      <td>0.100730</td>\n",
       "      <td>0.075063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.647500</td>\n",
       "      <td>1.420306</td>\n",
       "      <td>0.553621</td>\n",
       "      <td>0.199222</td>\n",
       "      <td>0.186531</td>\n",
       "      <td>0.167298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.257300</td>\n",
       "      <td>1.126071</td>\n",
       "      <td>0.656279</td>\n",
       "      <td>0.239405</td>\n",
       "      <td>0.262665</td>\n",
       "      <td>0.240340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.985300</td>\n",
       "      <td>0.962771</td>\n",
       "      <td>0.690192</td>\n",
       "      <td>0.273184</td>\n",
       "      <td>0.290840</td>\n",
       "      <td>0.266281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.802400</td>\n",
       "      <td>0.875066</td>\n",
       "      <td>0.714024</td>\n",
       "      <td>0.299098</td>\n",
       "      <td>0.323795</td>\n",
       "      <td>0.297910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.675200</td>\n",
       "      <td>0.810467</td>\n",
       "      <td>0.727773</td>\n",
       "      <td>0.381789</td>\n",
       "      <td>0.357154</td>\n",
       "      <td>0.344809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.578600</td>\n",
       "      <td>0.791395</td>\n",
       "      <td>0.730522</td>\n",
       "      <td>0.365527</td>\n",
       "      <td>0.364540</td>\n",
       "      <td>0.347844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.520300</td>\n",
       "      <td>0.758823</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.414266</td>\n",
       "      <td>0.400541</td>\n",
       "      <td>0.389263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.468900</td>\n",
       "      <td>0.738474</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.445483</td>\n",
       "      <td>0.416157</td>\n",
       "      <td>0.411219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.419100</td>\n",
       "      <td>0.729992</td>\n",
       "      <td>0.755270</td>\n",
       "      <td>0.440866</td>\n",
       "      <td>0.417890</td>\n",
       "      <td>0.410113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.392700</td>\n",
       "      <td>0.708942</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.468955</td>\n",
       "      <td>0.433829</td>\n",
       "      <td>0.430400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.363200</td>\n",
       "      <td>0.698384</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.486657</td>\n",
       "      <td>0.436162</td>\n",
       "      <td>0.437682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.692040</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.457933</td>\n",
       "      <td>0.448156</td>\n",
       "      <td>0.441482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.333500</td>\n",
       "      <td>0.688506</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.470839</td>\n",
       "      <td>0.451605</td>\n",
       "      <td>0.446570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.331500</td>\n",
       "      <td>0.689181</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.475666</td>\n",
       "      <td>0.456127</td>\n",
       "      <td>0.450600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:13:13,087] Trial 72 finished with value: 0.4505997422515422 and parameters: {'learning_rate': 0.0004701555596851597, 'weight_decay': 0.003, 'warmup_steps': 3, 'lambda_param': 0.9, 'temperature': 4.0}. Best is trial 34 with value: 0.477880764070784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 73 with params: {'learning_rate': 0.0004852295070146293, 'weight_decay': 0.0, 'warmup_steps': 4, 'lambda_param': 1.0, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:16, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.177500</td>\n",
       "      <td>1.848979</td>\n",
       "      <td>0.426214</td>\n",
       "      <td>0.063700</td>\n",
       "      <td>0.102190</td>\n",
       "      <td>0.075204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.634500</td>\n",
       "      <td>1.396772</td>\n",
       "      <td>0.562786</td>\n",
       "      <td>0.196219</td>\n",
       "      <td>0.199327</td>\n",
       "      <td>0.176839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.233300</td>\n",
       "      <td>1.105771</td>\n",
       "      <td>0.659945</td>\n",
       "      <td>0.275916</td>\n",
       "      <td>0.269421</td>\n",
       "      <td>0.248171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.963900</td>\n",
       "      <td>0.949042</td>\n",
       "      <td>0.698442</td>\n",
       "      <td>0.282625</td>\n",
       "      <td>0.300276</td>\n",
       "      <td>0.278741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.785000</td>\n",
       "      <td>0.865706</td>\n",
       "      <td>0.719523</td>\n",
       "      <td>0.328371</td>\n",
       "      <td>0.332944</td>\n",
       "      <td>0.308984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.659100</td>\n",
       "      <td>0.802592</td>\n",
       "      <td>0.728689</td>\n",
       "      <td>0.389988</td>\n",
       "      <td>0.360991</td>\n",
       "      <td>0.348580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.563900</td>\n",
       "      <td>0.777704</td>\n",
       "      <td>0.741522</td>\n",
       "      <td>0.397945</td>\n",
       "      <td>0.382143</td>\n",
       "      <td>0.370428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.504200</td>\n",
       "      <td>0.750910</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.422264</td>\n",
       "      <td>0.400601</td>\n",
       "      <td>0.388918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.450300</td>\n",
       "      <td>0.733683</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.440943</td>\n",
       "      <td>0.419698</td>\n",
       "      <td>0.416172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.402800</td>\n",
       "      <td>0.722948</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.474623</td>\n",
       "      <td>0.429946</td>\n",
       "      <td>0.430395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.376400</td>\n",
       "      <td>0.709459</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.484999</td>\n",
       "      <td>0.441588</td>\n",
       "      <td>0.437353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.348200</td>\n",
       "      <td>0.696308</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.538905</td>\n",
       "      <td>0.455098</td>\n",
       "      <td>0.465801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.329200</td>\n",
       "      <td>0.689981</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.496780</td>\n",
       "      <td>0.455407</td>\n",
       "      <td>0.458141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.319000</td>\n",
       "      <td>0.684790</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.520467</td>\n",
       "      <td>0.464385</td>\n",
       "      <td>0.467782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.317200</td>\n",
       "      <td>0.686658</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.515497</td>\n",
       "      <td>0.464747</td>\n",
       "      <td>0.465795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:14:31,287] Trial 73 finished with value: 0.4657949340930646 and parameters: {'learning_rate': 0.0004852295070146293, 'weight_decay': 0.0, 'warmup_steps': 4, 'lambda_param': 1.0, 'temperature': 5.5}. Best is trial 34 with value: 0.477880764070784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 74 with params: {'learning_rate': 0.0002575917610207219, 'weight_decay': 0.0, 'warmup_steps': 4, 'lambda_param': 1.0, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:47 < 00:23, 7.31 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.271600</td>\n",
       "      <td>2.053063</td>\n",
       "      <td>0.300642</td>\n",
       "      <td>0.072294</td>\n",
       "      <td>0.055984</td>\n",
       "      <td>0.045537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.913000</td>\n",
       "      <td>1.723951</td>\n",
       "      <td>0.463795</td>\n",
       "      <td>0.125216</td>\n",
       "      <td>0.127881</td>\n",
       "      <td>0.102174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.618700</td>\n",
       "      <td>1.463332</td>\n",
       "      <td>0.533456</td>\n",
       "      <td>0.180760</td>\n",
       "      <td>0.161648</td>\n",
       "      <td>0.142447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.374700</td>\n",
       "      <td>1.275077</td>\n",
       "      <td>0.621448</td>\n",
       "      <td>0.250028</td>\n",
       "      <td>0.228518</td>\n",
       "      <td>0.210659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.195800</td>\n",
       "      <td>1.136341</td>\n",
       "      <td>0.670944</td>\n",
       "      <td>0.260826</td>\n",
       "      <td>0.270102</td>\n",
       "      <td>0.250972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.042800</td>\n",
       "      <td>1.036266</td>\n",
       "      <td>0.693859</td>\n",
       "      <td>0.294675</td>\n",
       "      <td>0.291937</td>\n",
       "      <td>0.271529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.926400</td>\n",
       "      <td>0.966612</td>\n",
       "      <td>0.701192</td>\n",
       "      <td>0.276396</td>\n",
       "      <td>0.295605</td>\n",
       "      <td>0.273066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.850200</td>\n",
       "      <td>0.916080</td>\n",
       "      <td>0.717690</td>\n",
       "      <td>0.319812</td>\n",
       "      <td>0.320001</td>\n",
       "      <td>0.299636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.783500</td>\n",
       "      <td>0.887306</td>\n",
       "      <td>0.722273</td>\n",
       "      <td>0.309405</td>\n",
       "      <td>0.324285</td>\n",
       "      <td>0.302633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.723900</td>\n",
       "      <td>0.862409</td>\n",
       "      <td>0.723190</td>\n",
       "      <td>0.314520</td>\n",
       "      <td>0.330037</td>\n",
       "      <td>0.309015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:15:19,851] Trial 74 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 75 with params: {'learning_rate': 0.00044096491957423665, 'weight_decay': 0.0, 'warmup_steps': 4, 'lambda_param': 0.8, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.193900</td>\n",
       "      <td>1.885785</td>\n",
       "      <td>0.417049</td>\n",
       "      <td>0.070369</td>\n",
       "      <td>0.095285</td>\n",
       "      <td>0.073019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.680900</td>\n",
       "      <td>1.446623</td>\n",
       "      <td>0.555454</td>\n",
       "      <td>0.183432</td>\n",
       "      <td>0.188039</td>\n",
       "      <td>0.168338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.292700</td>\n",
       "      <td>1.153184</td>\n",
       "      <td>0.650779</td>\n",
       "      <td>0.257233</td>\n",
       "      <td>0.255126</td>\n",
       "      <td>0.236317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.023500</td>\n",
       "      <td>0.990414</td>\n",
       "      <td>0.693859</td>\n",
       "      <td>0.278319</td>\n",
       "      <td>0.300242</td>\n",
       "      <td>0.278692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.839900</td>\n",
       "      <td>0.895744</td>\n",
       "      <td>0.716774</td>\n",
       "      <td>0.338765</td>\n",
       "      <td>0.327387</td>\n",
       "      <td>0.306424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.707900</td>\n",
       "      <td>0.825803</td>\n",
       "      <td>0.720440</td>\n",
       "      <td>0.371420</td>\n",
       "      <td>0.344881</td>\n",
       "      <td>0.328923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.608300</td>\n",
       "      <td>0.798863</td>\n",
       "      <td>0.733272</td>\n",
       "      <td>0.372401</td>\n",
       "      <td>0.364816</td>\n",
       "      <td>0.348202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.547400</td>\n",
       "      <td>0.767046</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.410789</td>\n",
       "      <td>0.396272</td>\n",
       "      <td>0.381070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.492000</td>\n",
       "      <td>0.749765</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.432624</td>\n",
       "      <td>0.409791</td>\n",
       "      <td>0.400189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.442600</td>\n",
       "      <td>0.739527</td>\n",
       "      <td>0.755270</td>\n",
       "      <td>0.438691</td>\n",
       "      <td>0.412802</td>\n",
       "      <td>0.404782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.414600</td>\n",
       "      <td>0.722380</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.450974</td>\n",
       "      <td>0.428195</td>\n",
       "      <td>0.422941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>0.707854</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.489278</td>\n",
       "      <td>0.433834</td>\n",
       "      <td>0.435958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.366100</td>\n",
       "      <td>0.701007</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.476782</td>\n",
       "      <td>0.443647</td>\n",
       "      <td>0.440405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.354200</td>\n",
       "      <td>0.695372</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.493859</td>\n",
       "      <td>0.458115</td>\n",
       "      <td>0.453965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.351500</td>\n",
       "      <td>0.696795</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.487575</td>\n",
       "      <td>0.452289</td>\n",
       "      <td>0.446981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:16:35,841] Trial 75 finished with value: 0.4469811002520372 and parameters: {'learning_rate': 0.00044096491957423665, 'weight_decay': 0.0, 'warmup_steps': 4, 'lambda_param': 0.8, 'temperature': 5.0}. Best is trial 34 with value: 0.477880764070784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 76 with params: {'learning_rate': 0.00037072626819241775, 'weight_decay': 0.002, 'warmup_steps': 4, 'lambda_param': 1.0, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.220900</td>\n",
       "      <td>1.945600</td>\n",
       "      <td>0.390467</td>\n",
       "      <td>0.057022</td>\n",
       "      <td>0.083530</td>\n",
       "      <td>0.062380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.761300</td>\n",
       "      <td>1.539838</td>\n",
       "      <td>0.518790</td>\n",
       "      <td>0.142585</td>\n",
       "      <td>0.155675</td>\n",
       "      <td>0.132827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.400200</td>\n",
       "      <td>1.247558</td>\n",
       "      <td>0.629698</td>\n",
       "      <td>0.226317</td>\n",
       "      <td>0.233903</td>\n",
       "      <td>0.214977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.134500</td>\n",
       "      <td>1.079582</td>\n",
       "      <td>0.674610</td>\n",
       "      <td>0.268614</td>\n",
       "      <td>0.277658</td>\n",
       "      <td>0.258238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.952300</td>\n",
       "      <td>0.967116</td>\n",
       "      <td>0.705775</td>\n",
       "      <td>0.289766</td>\n",
       "      <td>0.305676</td>\n",
       "      <td>0.282191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.807300</td>\n",
       "      <td>0.874300</td>\n",
       "      <td>0.720440</td>\n",
       "      <td>0.349812</td>\n",
       "      <td>0.327888</td>\n",
       "      <td>0.309857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.697900</td>\n",
       "      <td>0.831281</td>\n",
       "      <td>0.714940</td>\n",
       "      <td>0.343042</td>\n",
       "      <td>0.327319</td>\n",
       "      <td>0.310476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.630800</td>\n",
       "      <td>0.803076</td>\n",
       "      <td>0.739688</td>\n",
       "      <td>0.387486</td>\n",
       "      <td>0.367619</td>\n",
       "      <td>0.350473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.573700</td>\n",
       "      <td>0.779466</td>\n",
       "      <td>0.740605</td>\n",
       "      <td>0.404847</td>\n",
       "      <td>0.380244</td>\n",
       "      <td>0.370108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.520600</td>\n",
       "      <td>0.769038</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.440791</td>\n",
       "      <td>0.394696</td>\n",
       "      <td>0.387005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.492100</td>\n",
       "      <td>0.749685</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.428983</td>\n",
       "      <td>0.396800</td>\n",
       "      <td>0.388306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.456200</td>\n",
       "      <td>0.737136</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.450878</td>\n",
       "      <td>0.405237</td>\n",
       "      <td>0.400570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.440500</td>\n",
       "      <td>0.731474</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.468211</td>\n",
       "      <td>0.412226</td>\n",
       "      <td>0.408963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.426900</td>\n",
       "      <td>0.725987</td>\n",
       "      <td>0.756187</td>\n",
       "      <td>0.465039</td>\n",
       "      <td>0.416326</td>\n",
       "      <td>0.410877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.423000</td>\n",
       "      <td>0.727896</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.454839</td>\n",
       "      <td>0.416988</td>\n",
       "      <td>0.410572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:17:51,485] Trial 76 finished with value: 0.4105720197763161 and parameters: {'learning_rate': 0.00037072626819241775, 'weight_decay': 0.002, 'warmup_steps': 4, 'lambda_param': 1.0, 'temperature': 4.5}. Best is trial 34 with value: 0.477880764070784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 77 with params: {'learning_rate': 0.00030927025673911044, 'weight_decay': 0.001, 'warmup_steps': 3, 'lambda_param': 1.0, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:24 < 00:48, 7.16 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.240600</td>\n",
       "      <td>1.994966</td>\n",
       "      <td>0.376719</td>\n",
       "      <td>0.066179</td>\n",
       "      <td>0.078447</td>\n",
       "      <td>0.063737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.835700</td>\n",
       "      <td>1.630534</td>\n",
       "      <td>0.484876</td>\n",
       "      <td>0.133129</td>\n",
       "      <td>0.135314</td>\n",
       "      <td>0.109298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.508500</td>\n",
       "      <td>1.353894</td>\n",
       "      <td>0.572869</td>\n",
       "      <td>0.224220</td>\n",
       "      <td>0.192125</td>\n",
       "      <td>0.175041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.251600</td>\n",
       "      <td>1.171306</td>\n",
       "      <td>0.660862</td>\n",
       "      <td>0.263684</td>\n",
       "      <td>0.265932</td>\n",
       "      <td>0.249950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.069700</td>\n",
       "      <td>1.043697</td>\n",
       "      <td>0.695692</td>\n",
       "      <td>0.268822</td>\n",
       "      <td>0.291886</td>\n",
       "      <td>0.267089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:18:16,570] Trial 77 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 78 with params: {'learning_rate': 0.0003782288255961332, 'weight_decay': 0.003, 'warmup_steps': 1, 'lambda_param': 0.7000000000000001, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:47, 7.32 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.194200</td>\n",
       "      <td>1.916187</td>\n",
       "      <td>0.404216</td>\n",
       "      <td>0.053030</td>\n",
       "      <td>0.086950</td>\n",
       "      <td>0.062947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.735300</td>\n",
       "      <td>1.518004</td>\n",
       "      <td>0.525206</td>\n",
       "      <td>0.157194</td>\n",
       "      <td>0.159814</td>\n",
       "      <td>0.139467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.381600</td>\n",
       "      <td>1.237794</td>\n",
       "      <td>0.618698</td>\n",
       "      <td>0.224819</td>\n",
       "      <td>0.221268</td>\n",
       "      <td>0.200766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.122500</td>\n",
       "      <td>1.073492</td>\n",
       "      <td>0.679193</td>\n",
       "      <td>0.257322</td>\n",
       "      <td>0.280804</td>\n",
       "      <td>0.258920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.943300</td>\n",
       "      <td>0.960569</td>\n",
       "      <td>0.707608</td>\n",
       "      <td>0.292768</td>\n",
       "      <td>0.305806</td>\n",
       "      <td>0.282588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:18:41,325] Trial 78 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 79 with params: {'learning_rate': 1.1513610346634454e-05, 'weight_decay': 0.002, 'warmup_steps': 4, 'lambda_param': 0.5, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:48 < 00:24, 7.20 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.458600</td>\n",
       "      <td>2.426998</td>\n",
       "      <td>0.049496</td>\n",
       "      <td>0.008331</td>\n",
       "      <td>0.027066</td>\n",
       "      <td>0.006800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.419800</td>\n",
       "      <td>2.389886</td>\n",
       "      <td>0.170486</td>\n",
       "      <td>0.010151</td>\n",
       "      <td>0.021179</td>\n",
       "      <td>0.010271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.389100</td>\n",
       "      <td>2.359105</td>\n",
       "      <td>0.188818</td>\n",
       "      <td>0.025331</td>\n",
       "      <td>0.024002</td>\n",
       "      <td>0.012140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.363500</td>\n",
       "      <td>2.334886</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>0.012621</td>\n",
       "      <td>0.022466</td>\n",
       "      <td>0.010003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.341400</td>\n",
       "      <td>2.313814</td>\n",
       "      <td>0.184235</td>\n",
       "      <td>0.015019</td>\n",
       "      <td>0.022192</td>\n",
       "      <td>0.009766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.321000</td>\n",
       "      <td>2.295636</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.016898</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.306000</td>\n",
       "      <td>2.279735</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.292100</td>\n",
       "      <td>2.265926</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.279800</td>\n",
       "      <td>2.254118</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023554</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.271200</td>\n",
       "      <td>2.244710</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023554</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:19:30,703] Trial 79 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 80 with params: {'learning_rate': 0.0004196887749054982, 'weight_decay': 0.002, 'warmup_steps': 3, 'lambda_param': 1.0, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:49 < 00:24, 7.03 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.194700</td>\n",
       "      <td>1.899409</td>\n",
       "      <td>0.412466</td>\n",
       "      <td>0.071398</td>\n",
       "      <td>0.093484</td>\n",
       "      <td>0.072336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.702700</td>\n",
       "      <td>1.477894</td>\n",
       "      <td>0.536205</td>\n",
       "      <td>0.163876</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0.150020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.328300</td>\n",
       "      <td>1.181965</td>\n",
       "      <td>0.647113</td>\n",
       "      <td>0.238582</td>\n",
       "      <td>0.250765</td>\n",
       "      <td>0.231377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.057600</td>\n",
       "      <td>1.016126</td>\n",
       "      <td>0.684693</td>\n",
       "      <td>0.267660</td>\n",
       "      <td>0.286995</td>\n",
       "      <td>0.263666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.914851</td>\n",
       "      <td>0.716774</td>\n",
       "      <td>0.317071</td>\n",
       "      <td>0.321308</td>\n",
       "      <td>0.299572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.733500</td>\n",
       "      <td>0.837032</td>\n",
       "      <td>0.723190</td>\n",
       "      <td>0.340777</td>\n",
       "      <td>0.335972</td>\n",
       "      <td>0.315703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.632400</td>\n",
       "      <td>0.808215</td>\n",
       "      <td>0.724106</td>\n",
       "      <td>0.364455</td>\n",
       "      <td>0.342961</td>\n",
       "      <td>0.327566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.570500</td>\n",
       "      <td>0.778492</td>\n",
       "      <td>0.747938</td>\n",
       "      <td>0.397399</td>\n",
       "      <td>0.386035</td>\n",
       "      <td>0.370750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.516300</td>\n",
       "      <td>0.754201</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.438733</td>\n",
       "      <td>0.401241</td>\n",
       "      <td>0.395789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.467000</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>0.747938</td>\n",
       "      <td>0.443145</td>\n",
       "      <td>0.398353</td>\n",
       "      <td>0.390346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:20:21,188] Trial 80 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 81 with params: {'learning_rate': 0.0003051276334935715, 'weight_decay': 0.002, 'warmup_steps': 3, 'lambda_param': 0.5, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:49 < 00:24, 7.04 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.242500</td>\n",
       "      <td>1.998784</td>\n",
       "      <td>0.374885</td>\n",
       "      <td>0.066410</td>\n",
       "      <td>0.077868</td>\n",
       "      <td>0.063481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.841500</td>\n",
       "      <td>1.637530</td>\n",
       "      <td>0.483043</td>\n",
       "      <td>0.122271</td>\n",
       "      <td>0.134300</td>\n",
       "      <td>0.107730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.516900</td>\n",
       "      <td>1.362218</td>\n",
       "      <td>0.571036</td>\n",
       "      <td>0.220756</td>\n",
       "      <td>0.191111</td>\n",
       "      <td>0.173552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.260800</td>\n",
       "      <td>1.178632</td>\n",
       "      <td>0.658112</td>\n",
       "      <td>0.260440</td>\n",
       "      <td>0.260892</td>\n",
       "      <td>0.244031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.078900</td>\n",
       "      <td>1.050051</td>\n",
       "      <td>0.695692</td>\n",
       "      <td>0.269107</td>\n",
       "      <td>0.291502</td>\n",
       "      <td>0.267137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.929400</td>\n",
       "      <td>0.955273</td>\n",
       "      <td>0.706691</td>\n",
       "      <td>0.299427</td>\n",
       "      <td>0.304913</td>\n",
       "      <td>0.285382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.817100</td>\n",
       "      <td>0.896798</td>\n",
       "      <td>0.708524</td>\n",
       "      <td>0.300792</td>\n",
       "      <td>0.306792</td>\n",
       "      <td>0.283562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.744600</td>\n",
       "      <td>0.857282</td>\n",
       "      <td>0.727773</td>\n",
       "      <td>0.330706</td>\n",
       "      <td>0.335845</td>\n",
       "      <td>0.313065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.683700</td>\n",
       "      <td>0.832626</td>\n",
       "      <td>0.724106</td>\n",
       "      <td>0.331982</td>\n",
       "      <td>0.336671</td>\n",
       "      <td>0.318016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.625900</td>\n",
       "      <td>0.813794</td>\n",
       "      <td>0.742438</td>\n",
       "      <td>0.374016</td>\n",
       "      <td>0.364691</td>\n",
       "      <td>0.350127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:21:11,636] Trial 81 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 82 with params: {'learning_rate': 4.2241048909514606e-05, 'weight_decay': 0.005, 'warmup_steps': 1, 'lambda_param': 0.8, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:24 < 00:49, 7.04 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.415600</td>\n",
       "      <td>2.339908</td>\n",
       "      <td>0.182401</td>\n",
       "      <td>0.012815</td>\n",
       "      <td>0.021644</td>\n",
       "      <td>0.008869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.313300</td>\n",
       "      <td>2.254847</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023548</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.241000</td>\n",
       "      <td>2.180511</td>\n",
       "      <td>0.187901</td>\n",
       "      <td>0.063577</td>\n",
       "      <td>0.023157</td>\n",
       "      <td>0.011815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.173200</td>\n",
       "      <td>2.115137</td>\n",
       "      <td>0.318973</td>\n",
       "      <td>0.072585</td>\n",
       "      <td>0.061195</td>\n",
       "      <td>0.055572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.118900</td>\n",
       "      <td>2.058060</td>\n",
       "      <td>0.384051</td>\n",
       "      <td>0.080719</td>\n",
       "      <td>0.080760</td>\n",
       "      <td>0.065231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:21:37,367] Trial 82 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 83 with params: {'learning_rate': 0.0004960970701067248, 'weight_decay': 0.002, 'warmup_steps': 4, 'lambda_param': 0.2, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.173500</td>\n",
       "      <td>1.840984</td>\n",
       "      <td>0.428964</td>\n",
       "      <td>0.062722</td>\n",
       "      <td>0.103414</td>\n",
       "      <td>0.075170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.624200</td>\n",
       "      <td>1.386573</td>\n",
       "      <td>0.564620</td>\n",
       "      <td>0.195721</td>\n",
       "      <td>0.199984</td>\n",
       "      <td>0.176852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.220300</td>\n",
       "      <td>1.094507</td>\n",
       "      <td>0.664528</td>\n",
       "      <td>0.276888</td>\n",
       "      <td>0.274851</td>\n",
       "      <td>0.253609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.949400</td>\n",
       "      <td>0.938261</td>\n",
       "      <td>0.702108</td>\n",
       "      <td>0.296793</td>\n",
       "      <td>0.303333</td>\n",
       "      <td>0.283900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.772400</td>\n",
       "      <td>0.860091</td>\n",
       "      <td>0.717690</td>\n",
       "      <td>0.321888</td>\n",
       "      <td>0.335645</td>\n",
       "      <td>0.309870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.651800</td>\n",
       "      <td>0.800607</td>\n",
       "      <td>0.735105</td>\n",
       "      <td>0.409807</td>\n",
       "      <td>0.377628</td>\n",
       "      <td>0.370524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.556100</td>\n",
       "      <td>0.778029</td>\n",
       "      <td>0.741522</td>\n",
       "      <td>0.383329</td>\n",
       "      <td>0.380153</td>\n",
       "      <td>0.366897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.498900</td>\n",
       "      <td>0.749924</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.420372</td>\n",
       "      <td>0.399479</td>\n",
       "      <td>0.386978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.442600</td>\n",
       "      <td>0.731435</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.452688</td>\n",
       "      <td>0.423436</td>\n",
       "      <td>0.420559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0.723483</td>\n",
       "      <td>0.756187</td>\n",
       "      <td>0.481753</td>\n",
       "      <td>0.427137</td>\n",
       "      <td>0.429609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.368400</td>\n",
       "      <td>0.707528</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.504475</td>\n",
       "      <td>0.448575</td>\n",
       "      <td>0.447308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.340100</td>\n",
       "      <td>0.695891</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.529050</td>\n",
       "      <td>0.454154</td>\n",
       "      <td>0.461068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.322700</td>\n",
       "      <td>0.691020</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.496993</td>\n",
       "      <td>0.456762</td>\n",
       "      <td>0.458637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.311300</td>\n",
       "      <td>0.684282</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.518233</td>\n",
       "      <td>0.466753</td>\n",
       "      <td>0.470788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.308400</td>\n",
       "      <td>0.686501</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.499934</td>\n",
       "      <td>0.466753</td>\n",
       "      <td>0.467340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:22:52,820] Trial 83 finished with value: 0.4673402544142266 and parameters: {'learning_rate': 0.0004960970701067248, 'weight_decay': 0.002, 'warmup_steps': 4, 'lambda_param': 0.2, 'temperature': 2.0}. Best is trial 34 with value: 0.477880764070784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 84 with params: {'learning_rate': 0.00034728821117664427, 'weight_decay': 0.004, 'warmup_steps': 3, 'lambda_param': 0.2, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:47, 7.42 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.224000</td>\n",
       "      <td>1.960494</td>\n",
       "      <td>0.390467</td>\n",
       "      <td>0.058968</td>\n",
       "      <td>0.083270</td>\n",
       "      <td>0.063423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.785200</td>\n",
       "      <td>1.570951</td>\n",
       "      <td>0.509624</td>\n",
       "      <td>0.140158</td>\n",
       "      <td>0.150052</td>\n",
       "      <td>0.127636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.437000</td>\n",
       "      <td>1.284328</td>\n",
       "      <td>0.608616</td>\n",
       "      <td>0.228643</td>\n",
       "      <td>0.220382</td>\n",
       "      <td>0.202753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.174600</td>\n",
       "      <td>1.112667</td>\n",
       "      <td>0.673694</td>\n",
       "      <td>0.261324</td>\n",
       "      <td>0.277108</td>\n",
       "      <td>0.257432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.993800</td>\n",
       "      <td>0.995077</td>\n",
       "      <td>0.699358</td>\n",
       "      <td>0.289998</td>\n",
       "      <td>0.300404</td>\n",
       "      <td>0.277785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:23:17,087] Trial 84 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 85 with params: {'learning_rate': 4.4166255288717016e-05, 'weight_decay': 0.0, 'warmup_steps': 1, 'lambda_param': 1.0, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:49 < 00:24, 7.10 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.413400</td>\n",
       "      <td>2.335785</td>\n",
       "      <td>0.181485</td>\n",
       "      <td>0.012668</td>\n",
       "      <td>0.021370</td>\n",
       "      <td>0.008450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.308100</td>\n",
       "      <td>2.247884</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023548</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.233300</td>\n",
       "      <td>2.171139</td>\n",
       "      <td>0.195234</td>\n",
       "      <td>0.063604</td>\n",
       "      <td>0.025218</td>\n",
       "      <td>0.015205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.163000</td>\n",
       "      <td>2.103335</td>\n",
       "      <td>0.336389</td>\n",
       "      <td>0.070635</td>\n",
       "      <td>0.066405</td>\n",
       "      <td>0.059460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.106800</td>\n",
       "      <td>2.044625</td>\n",
       "      <td>0.388634</td>\n",
       "      <td>0.079318</td>\n",
       "      <td>0.081905</td>\n",
       "      <td>0.064904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.047200</td>\n",
       "      <td>1.993693</td>\n",
       "      <td>0.405133</td>\n",
       "      <td>0.055414</td>\n",
       "      <td>0.086622</td>\n",
       "      <td>0.064742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.998500</td>\n",
       "      <td>1.948846</td>\n",
       "      <td>0.411549</td>\n",
       "      <td>0.092703</td>\n",
       "      <td>0.089932</td>\n",
       "      <td>0.067989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.959500</td>\n",
       "      <td>1.909391</td>\n",
       "      <td>0.431714</td>\n",
       "      <td>0.090792</td>\n",
       "      <td>0.099468</td>\n",
       "      <td>0.077654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.922500</td>\n",
       "      <td>1.875778</td>\n",
       "      <td>0.439047</td>\n",
       "      <td>0.087236</td>\n",
       "      <td>0.103874</td>\n",
       "      <td>0.080872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.894600</td>\n",
       "      <td>1.848783</td>\n",
       "      <td>0.451879</td>\n",
       "      <td>0.105642</td>\n",
       "      <td>0.111302</td>\n",
       "      <td>0.088372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:24:07,170] Trial 85 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 86 with params: {'learning_rate': 0.00048481023093695626, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.4, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.177600</td>\n",
       "      <td>1.849294</td>\n",
       "      <td>0.425298</td>\n",
       "      <td>0.063474</td>\n",
       "      <td>0.101545</td>\n",
       "      <td>0.074792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.634800</td>\n",
       "      <td>1.397211</td>\n",
       "      <td>0.563703</td>\n",
       "      <td>0.196798</td>\n",
       "      <td>0.199565</td>\n",
       "      <td>0.177244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.233800</td>\n",
       "      <td>1.106173</td>\n",
       "      <td>0.659945</td>\n",
       "      <td>0.275916</td>\n",
       "      <td>0.269421</td>\n",
       "      <td>0.248171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.964400</td>\n",
       "      <td>0.949381</td>\n",
       "      <td>0.698442</td>\n",
       "      <td>0.282625</td>\n",
       "      <td>0.300276</td>\n",
       "      <td>0.278741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.785500</td>\n",
       "      <td>0.866060</td>\n",
       "      <td>0.719523</td>\n",
       "      <td>0.329761</td>\n",
       "      <td>0.332944</td>\n",
       "      <td>0.309400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.659600</td>\n",
       "      <td>0.802889</td>\n",
       "      <td>0.728689</td>\n",
       "      <td>0.389988</td>\n",
       "      <td>0.360991</td>\n",
       "      <td>0.348580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.564300</td>\n",
       "      <td>0.777709</td>\n",
       "      <td>0.740605</td>\n",
       "      <td>0.395826</td>\n",
       "      <td>0.381689</td>\n",
       "      <td>0.369773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.504600</td>\n",
       "      <td>0.752066</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.420728</td>\n",
       "      <td>0.399388</td>\n",
       "      <td>0.387400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.451000</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.446445</td>\n",
       "      <td>0.424620</td>\n",
       "      <td>0.422308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.402600</td>\n",
       "      <td>0.723492</td>\n",
       "      <td>0.757104</td>\n",
       "      <td>0.472288</td>\n",
       "      <td>0.427002</td>\n",
       "      <td>0.428631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.376600</td>\n",
       "      <td>0.709674</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.486112</td>\n",
       "      <td>0.441698</td>\n",
       "      <td>0.438202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.348300</td>\n",
       "      <td>0.695380</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.541213</td>\n",
       "      <td>0.455553</td>\n",
       "      <td>0.467011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.329300</td>\n",
       "      <td>0.689723</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.499468</td>\n",
       "      <td>0.453185</td>\n",
       "      <td>0.456035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.319100</td>\n",
       "      <td>0.684669</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.523115</td>\n",
       "      <td>0.466607</td>\n",
       "      <td>0.471390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.317000</td>\n",
       "      <td>0.686605</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.519370</td>\n",
       "      <td>0.472684</td>\n",
       "      <td>0.477888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:25:21,399] Trial 86 finished with value: 0.4778879458794155 and parameters: {'learning_rate': 0.00048481023093695626, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.4, 'temperature': 2.5}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 87 with params: {'learning_rate': 0.0004385356626520977, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.30000000000000004, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.194800</td>\n",
       "      <td>1.887827</td>\n",
       "      <td>0.416132</td>\n",
       "      <td>0.070496</td>\n",
       "      <td>0.095182</td>\n",
       "      <td>0.073014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.683400</td>\n",
       "      <td>1.449679</td>\n",
       "      <td>0.555454</td>\n",
       "      <td>0.184139</td>\n",
       "      <td>0.187613</td>\n",
       "      <td>0.168167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.296200</td>\n",
       "      <td>1.155716</td>\n",
       "      <td>0.651696</td>\n",
       "      <td>0.256404</td>\n",
       "      <td>0.255614</td>\n",
       "      <td>0.236659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.026800</td>\n",
       "      <td>0.992863</td>\n",
       "      <td>0.692942</td>\n",
       "      <td>0.277711</td>\n",
       "      <td>0.299290</td>\n",
       "      <td>0.278013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>0.897802</td>\n",
       "      <td>0.716774</td>\n",
       "      <td>0.338766</td>\n",
       "      <td>0.327387</td>\n",
       "      <td>0.306585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>0.827064</td>\n",
       "      <td>0.721357</td>\n",
       "      <td>0.372158</td>\n",
       "      <td>0.344190</td>\n",
       "      <td>0.328964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.610900</td>\n",
       "      <td>0.799885</td>\n",
       "      <td>0.732356</td>\n",
       "      <td>0.371815</td>\n",
       "      <td>0.364713</td>\n",
       "      <td>0.347756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.768319</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.408693</td>\n",
       "      <td>0.395611</td>\n",
       "      <td>0.379655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.494500</td>\n",
       "      <td>0.750025</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.432778</td>\n",
       "      <td>0.408861</td>\n",
       "      <td>0.399425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.445100</td>\n",
       "      <td>0.740674</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.438637</td>\n",
       "      <td>0.412348</td>\n",
       "      <td>0.404563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.417000</td>\n",
       "      <td>0.723015</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.459458</td>\n",
       "      <td>0.426376</td>\n",
       "      <td>0.421423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.387300</td>\n",
       "      <td>0.708530</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.488250</td>\n",
       "      <td>0.432767</td>\n",
       "      <td>0.434991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.368400</td>\n",
       "      <td>0.701660</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.477157</td>\n",
       "      <td>0.444589</td>\n",
       "      <td>0.441024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.356500</td>\n",
       "      <td>0.696190</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.492505</td>\n",
       "      <td>0.453300</td>\n",
       "      <td>0.448041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.353900</td>\n",
       "      <td>0.697603</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.489238</td>\n",
       "      <td>0.451237</td>\n",
       "      <td>0.447314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:26:35,920] Trial 87 finished with value: 0.44731370533334447 and parameters: {'learning_rate': 0.0004385356626520977, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.30000000000000004, 'temperature': 2.5}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 88 with params: {'learning_rate': 0.000223991456731085, 'weight_decay': 0.005, 'warmup_steps': 4, 'lambda_param': 0.30000000000000004, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:48 < 00:24, 7.11 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.289600</td>\n",
       "      <td>2.087601</td>\n",
       "      <td>0.219065</td>\n",
       "      <td>0.058389</td>\n",
       "      <td>0.031755</td>\n",
       "      <td>0.024005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.965600</td>\n",
       "      <td>1.793663</td>\n",
       "      <td>0.447296</td>\n",
       "      <td>0.102300</td>\n",
       "      <td>0.113531</td>\n",
       "      <td>0.086959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.699100</td>\n",
       "      <td>1.548022</td>\n",
       "      <td>0.514207</td>\n",
       "      <td>0.165438</td>\n",
       "      <td>0.153166</td>\n",
       "      <td>0.133618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.468500</td>\n",
       "      <td>1.362709</td>\n",
       "      <td>0.572869</td>\n",
       "      <td>0.201090</td>\n",
       "      <td>0.190952</td>\n",
       "      <td>0.170549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.297700</td>\n",
       "      <td>1.224020</td>\n",
       "      <td>0.651696</td>\n",
       "      <td>0.269407</td>\n",
       "      <td>0.253246</td>\n",
       "      <td>0.240595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.144800</td>\n",
       "      <td>1.118508</td>\n",
       "      <td>0.676444</td>\n",
       "      <td>0.266764</td>\n",
       "      <td>0.273572</td>\n",
       "      <td>0.256279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.029900</td>\n",
       "      <td>1.042669</td>\n",
       "      <td>0.692942</td>\n",
       "      <td>0.278009</td>\n",
       "      <td>0.289621</td>\n",
       "      <td>0.270020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.951500</td>\n",
       "      <td>0.987197</td>\n",
       "      <td>0.703941</td>\n",
       "      <td>0.292117</td>\n",
       "      <td>0.302474</td>\n",
       "      <td>0.277975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.881100</td>\n",
       "      <td>0.950016</td>\n",
       "      <td>0.710357</td>\n",
       "      <td>0.304869</td>\n",
       "      <td>0.311043</td>\n",
       "      <td>0.289813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.819500</td>\n",
       "      <td>0.918177</td>\n",
       "      <td>0.718607</td>\n",
       "      <td>0.333005</td>\n",
       "      <td>0.323146</td>\n",
       "      <td>0.303606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:27:25,868] Trial 88 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 89 with params: {'learning_rate': 6.961472074236449e-05, 'weight_decay': 0.003, 'warmup_steps': 0, 'lambda_param': 0.0, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:24 < 00:49, 7.11 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.381000</td>\n",
       "      <td>2.283038</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.240400</td>\n",
       "      <td>2.160906</td>\n",
       "      <td>0.188818</td>\n",
       "      <td>0.043581</td>\n",
       "      <td>0.023490</td>\n",
       "      <td>0.012242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.136000</td>\n",
       "      <td>2.053872</td>\n",
       "      <td>0.374885</td>\n",
       "      <td>0.061083</td>\n",
       "      <td>0.077776</td>\n",
       "      <td>0.062172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.034900</td>\n",
       "      <td>1.959246</td>\n",
       "      <td>0.407883</td>\n",
       "      <td>0.071903</td>\n",
       "      <td>0.087633</td>\n",
       "      <td>0.064025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.953200</td>\n",
       "      <td>1.874346</td>\n",
       "      <td>0.437214</td>\n",
       "      <td>0.086495</td>\n",
       "      <td>0.102797</td>\n",
       "      <td>0.079488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:27:51,221] Trial 89 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 90 with params: {'learning_rate': 0.00039680681549353884, 'weight_decay': 0.004, 'warmup_steps': 4, 'lambda_param': 0.6000000000000001, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:50 < 00:25, 6.87 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.210800</td>\n",
       "      <td>1.923640</td>\n",
       "      <td>0.397800</td>\n",
       "      <td>0.074818</td>\n",
       "      <td>0.085978</td>\n",
       "      <td>0.063623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.730200</td>\n",
       "      <td>1.503700</td>\n",
       "      <td>0.529789</td>\n",
       "      <td>0.170163</td>\n",
       "      <td>0.165481</td>\n",
       "      <td>0.146195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.357900</td>\n",
       "      <td>1.207496</td>\n",
       "      <td>0.641613</td>\n",
       "      <td>0.225670</td>\n",
       "      <td>0.242872</td>\n",
       "      <td>0.220785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.090200</td>\n",
       "      <td>1.043855</td>\n",
       "      <td>0.683776</td>\n",
       "      <td>0.271126</td>\n",
       "      <td>0.284644</td>\n",
       "      <td>0.264734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.906800</td>\n",
       "      <td>0.937101</td>\n",
       "      <td>0.709441</td>\n",
       "      <td>0.299702</td>\n",
       "      <td>0.311690</td>\n",
       "      <td>0.289932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.765600</td>\n",
       "      <td>0.852051</td>\n",
       "      <td>0.724106</td>\n",
       "      <td>0.357349</td>\n",
       "      <td>0.333478</td>\n",
       "      <td>0.316559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.660100</td>\n",
       "      <td>0.815486</td>\n",
       "      <td>0.724106</td>\n",
       "      <td>0.354198</td>\n",
       "      <td>0.342654</td>\n",
       "      <td>0.326723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.595100</td>\n",
       "      <td>0.786997</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.392697</td>\n",
       "      <td>0.379415</td>\n",
       "      <td>0.362842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.539300</td>\n",
       "      <td>0.764590</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.408099</td>\n",
       "      <td>0.385756</td>\n",
       "      <td>0.375030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.488300</td>\n",
       "      <td>0.758157</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.439012</td>\n",
       "      <td>0.399474</td>\n",
       "      <td>0.391057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:28:42,924] Trial 90 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 91 with params: {'learning_rate': 0.000398295002879009, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 0.30000000000000004, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.210200</td>\n",
       "      <td>1.922396</td>\n",
       "      <td>0.397800</td>\n",
       "      <td>0.074657</td>\n",
       "      <td>0.085978</td>\n",
       "      <td>0.063526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.728400</td>\n",
       "      <td>1.501789</td>\n",
       "      <td>0.530706</td>\n",
       "      <td>0.170780</td>\n",
       "      <td>0.165969</td>\n",
       "      <td>0.146916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.355600</td>\n",
       "      <td>1.205507</td>\n",
       "      <td>0.642530</td>\n",
       "      <td>0.225841</td>\n",
       "      <td>0.243825</td>\n",
       "      <td>0.221167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.087900</td>\n",
       "      <td>1.042136</td>\n",
       "      <td>0.684693</td>\n",
       "      <td>0.271094</td>\n",
       "      <td>0.287144</td>\n",
       "      <td>0.265899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.904500</td>\n",
       "      <td>0.935750</td>\n",
       "      <td>0.710357</td>\n",
       "      <td>0.300675</td>\n",
       "      <td>0.313119</td>\n",
       "      <td>0.291717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.763600</td>\n",
       "      <td>0.851222</td>\n",
       "      <td>0.724106</td>\n",
       "      <td>0.357173</td>\n",
       "      <td>0.333478</td>\n",
       "      <td>0.316455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.658300</td>\n",
       "      <td>0.814926</td>\n",
       "      <td>0.724106</td>\n",
       "      <td>0.354198</td>\n",
       "      <td>0.342654</td>\n",
       "      <td>0.326723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.593400</td>\n",
       "      <td>0.786460</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.393426</td>\n",
       "      <td>0.380749</td>\n",
       "      <td>0.363561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.537600</td>\n",
       "      <td>0.763947</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.408099</td>\n",
       "      <td>0.385756</td>\n",
       "      <td>0.375030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.486700</td>\n",
       "      <td>0.757869</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.458595</td>\n",
       "      <td>0.401843</td>\n",
       "      <td>0.395699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.458200</td>\n",
       "      <td>0.736283</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.458897</td>\n",
       "      <td>0.410607</td>\n",
       "      <td>0.408039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.424300</td>\n",
       "      <td>0.724456</td>\n",
       "      <td>0.756187</td>\n",
       "      <td>0.462667</td>\n",
       "      <td>0.412991</td>\n",
       "      <td>0.411043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.408500</td>\n",
       "      <td>0.719538</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.476239</td>\n",
       "      <td>0.424915</td>\n",
       "      <td>0.424186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.395600</td>\n",
       "      <td>0.713897</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.482592</td>\n",
       "      <td>0.436335</td>\n",
       "      <td>0.434069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.391800</td>\n",
       "      <td>0.715526</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.495366</td>\n",
       "      <td>0.439308</td>\n",
       "      <td>0.440901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:29:58,417] Trial 91 finished with value: 0.4409012067685775 and parameters: {'learning_rate': 0.000398295002879009, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 0.30000000000000004, 'temperature': 2.5}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 92 with params: {'learning_rate': 0.0003725588397131786, 'weight_decay': 0.007, 'warmup_steps': 2, 'lambda_param': 0.9, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:51 < 00:25, 6.81 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.205600</td>\n",
       "      <td>1.930469</td>\n",
       "      <td>0.398717</td>\n",
       "      <td>0.074848</td>\n",
       "      <td>0.085919</td>\n",
       "      <td>0.063965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.750700</td>\n",
       "      <td>1.535696</td>\n",
       "      <td>0.523373</td>\n",
       "      <td>0.182488</td>\n",
       "      <td>0.163069</td>\n",
       "      <td>0.145734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.396700</td>\n",
       "      <td>1.249168</td>\n",
       "      <td>0.624198</td>\n",
       "      <td>0.225629</td>\n",
       "      <td>0.228509</td>\n",
       "      <td>0.210051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.132400</td>\n",
       "      <td>1.081626</td>\n",
       "      <td>0.676444</td>\n",
       "      <td>0.265003</td>\n",
       "      <td>0.279401</td>\n",
       "      <td>0.258036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.949900</td>\n",
       "      <td>0.967071</td>\n",
       "      <td>0.705775</td>\n",
       "      <td>0.295893</td>\n",
       "      <td>0.308767</td>\n",
       "      <td>0.285933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.805800</td>\n",
       "      <td>0.875793</td>\n",
       "      <td>0.714940</td>\n",
       "      <td>0.311923</td>\n",
       "      <td>0.319612</td>\n",
       "      <td>0.299071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.698300</td>\n",
       "      <td>0.836887</td>\n",
       "      <td>0.707608</td>\n",
       "      <td>0.300796</td>\n",
       "      <td>0.317430</td>\n",
       "      <td>0.295689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.631600</td>\n",
       "      <td>0.808080</td>\n",
       "      <td>0.736939</td>\n",
       "      <td>0.381389</td>\n",
       "      <td>0.367729</td>\n",
       "      <td>0.349559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.575300</td>\n",
       "      <td>0.786281</td>\n",
       "      <td>0.738772</td>\n",
       "      <td>0.387298</td>\n",
       "      <td>0.376220</td>\n",
       "      <td>0.364253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.522400</td>\n",
       "      <td>0.774482</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.411036</td>\n",
       "      <td>0.399183</td>\n",
       "      <td>0.387511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:30:50,527] Trial 92 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 93 with params: {'learning_rate': 0.00035688475656907954, 'weight_decay': 0.002, 'warmup_steps': 3, 'lambda_param': 0.4, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.219800</td>\n",
       "      <td>1.951599</td>\n",
       "      <td>0.391384</td>\n",
       "      <td>0.057058</td>\n",
       "      <td>0.083596</td>\n",
       "      <td>0.062824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.773000</td>\n",
       "      <td>1.557159</td>\n",
       "      <td>0.514207</td>\n",
       "      <td>0.138875</td>\n",
       "      <td>0.151987</td>\n",
       "      <td>0.129199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.420500</td>\n",
       "      <td>1.269331</td>\n",
       "      <td>0.616865</td>\n",
       "      <td>0.226082</td>\n",
       "      <td>0.226033</td>\n",
       "      <td>0.208242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.157400</td>\n",
       "      <td>1.100183</td>\n",
       "      <td>0.675527</td>\n",
       "      <td>0.263952</td>\n",
       "      <td>0.278231</td>\n",
       "      <td>0.259029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.976900</td>\n",
       "      <td>0.985297</td>\n",
       "      <td>0.701192</td>\n",
       "      <td>0.291251</td>\n",
       "      <td>0.303499</td>\n",
       "      <td>0.281610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.830700</td>\n",
       "      <td>0.890371</td>\n",
       "      <td>0.714940</td>\n",
       "      <td>0.296841</td>\n",
       "      <td>0.318107</td>\n",
       "      <td>0.297302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.721400</td>\n",
       "      <td>0.844776</td>\n",
       "      <td>0.711274</td>\n",
       "      <td>0.323801</td>\n",
       "      <td>0.319277</td>\n",
       "      <td>0.299929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.652300</td>\n",
       "      <td>0.815745</td>\n",
       "      <td>0.732356</td>\n",
       "      <td>0.349640</td>\n",
       "      <td>0.353648</td>\n",
       "      <td>0.332363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.788543</td>\n",
       "      <td>0.734189</td>\n",
       "      <td>0.361013</td>\n",
       "      <td>0.363286</td>\n",
       "      <td>0.348401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.540600</td>\n",
       "      <td>0.780087</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.395684</td>\n",
       "      <td>0.382409</td>\n",
       "      <td>0.367305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.512400</td>\n",
       "      <td>0.758571</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.422502</td>\n",
       "      <td>0.401196</td>\n",
       "      <td>0.393015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.476100</td>\n",
       "      <td>0.744383</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.407615</td>\n",
       "      <td>0.398547</td>\n",
       "      <td>0.390059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.739191</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.427727</td>\n",
       "      <td>0.401879</td>\n",
       "      <td>0.393741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.446300</td>\n",
       "      <td>0.733511</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.436961</td>\n",
       "      <td>0.421117</td>\n",
       "      <td>0.411087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.442200</td>\n",
       "      <td>0.734916</td>\n",
       "      <td>0.755270</td>\n",
       "      <td>0.430119</td>\n",
       "      <td>0.418462</td>\n",
       "      <td>0.407797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:32:06,065] Trial 93 finished with value: 0.40779667087983495 and parameters: {'learning_rate': 0.00035688475656907954, 'weight_decay': 0.002, 'warmup_steps': 3, 'lambda_param': 0.4, 'temperature': 4.0}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 94 with params: {'learning_rate': 0.00036943749446526915, 'weight_decay': 0.002, 'warmup_steps': 3, 'lambda_param': 0.4, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:24 < 00:50, 6.93 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.214300</td>\n",
       "      <td>1.940046</td>\n",
       "      <td>0.394134</td>\n",
       "      <td>0.055306</td>\n",
       "      <td>0.084390</td>\n",
       "      <td>0.062492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.757600</td>\n",
       "      <td>1.540025</td>\n",
       "      <td>0.517874</td>\n",
       "      <td>0.143199</td>\n",
       "      <td>0.154906</td>\n",
       "      <td>0.132861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.400300</td>\n",
       "      <td>1.251015</td>\n",
       "      <td>0.630614</td>\n",
       "      <td>0.225066</td>\n",
       "      <td>0.233778</td>\n",
       "      <td>0.214418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.136300</td>\n",
       "      <td>1.084738</td>\n",
       "      <td>0.672777</td>\n",
       "      <td>0.262129</td>\n",
       "      <td>0.277606</td>\n",
       "      <td>0.258263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.955600</td>\n",
       "      <td>0.972099</td>\n",
       "      <td>0.701192</td>\n",
       "      <td>0.290197</td>\n",
       "      <td>0.303749</td>\n",
       "      <td>0.280814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:32:32,013] Trial 94 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 95 with params: {'learning_rate': 5.047617393737974e-05, 'weight_decay': 0.0, 'warmup_steps': 0, 'lambda_param': 0.4, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:52 < 00:26, 6.65 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.402200</td>\n",
       "      <td>2.319473</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.018551</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.288500</td>\n",
       "      <td>2.222953</td>\n",
       "      <td>0.178735</td>\n",
       "      <td>0.023545</td>\n",
       "      <td>0.020548</td>\n",
       "      <td>0.007089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.206600</td>\n",
       "      <td>2.139323</td>\n",
       "      <td>0.244730</td>\n",
       "      <td>0.072895</td>\n",
       "      <td>0.039080</td>\n",
       "      <td>0.033813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.128700</td>\n",
       "      <td>2.064645</td>\n",
       "      <td>0.378552</td>\n",
       "      <td>0.081240</td>\n",
       "      <td>0.079252</td>\n",
       "      <td>0.064616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.066600</td>\n",
       "      <td>2.000153</td>\n",
       "      <td>0.404216</td>\n",
       "      <td>0.055335</td>\n",
       "      <td>0.086259</td>\n",
       "      <td>0.064519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.999700</td>\n",
       "      <td>1.942670</td>\n",
       "      <td>0.412466</td>\n",
       "      <td>0.092625</td>\n",
       "      <td>0.090295</td>\n",
       "      <td>0.067965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.945700</td>\n",
       "      <td>1.893328</td>\n",
       "      <td>0.430797</td>\n",
       "      <td>0.087415</td>\n",
       "      <td>0.099525</td>\n",
       "      <td>0.077493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.902800</td>\n",
       "      <td>1.850276</td>\n",
       "      <td>0.446379</td>\n",
       "      <td>0.105678</td>\n",
       "      <td>0.107853</td>\n",
       "      <td>0.085434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.861700</td>\n",
       "      <td>1.813975</td>\n",
       "      <td>0.456462</td>\n",
       "      <td>0.102520</td>\n",
       "      <td>0.115083</td>\n",
       "      <td>0.092808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.831100</td>\n",
       "      <td>1.784945</td>\n",
       "      <td>0.472961</td>\n",
       "      <td>0.102637</td>\n",
       "      <td>0.123830</td>\n",
       "      <td>0.099567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:33:25,356] Trial 95 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 96 with params: {'learning_rate': 2.6821272497630925e-05, 'weight_decay': 0.01, 'warmup_steps': 0, 'lambda_param': 0.1, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:24 < 00:48, 7.17 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.432500</td>\n",
       "      <td>2.374880</td>\n",
       "      <td>0.186068</td>\n",
       "      <td>0.032682</td>\n",
       "      <td>0.023180</td>\n",
       "      <td>0.011072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.357400</td>\n",
       "      <td>2.311867</td>\n",
       "      <td>0.182401</td>\n",
       "      <td>0.014490</td>\n",
       "      <td>0.021644</td>\n",
       "      <td>0.008931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.306300</td>\n",
       "      <td>2.260536</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023548</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.259000</td>\n",
       "      <td>2.216236</td>\n",
       "      <td>0.182401</td>\n",
       "      <td>0.023561</td>\n",
       "      <td>0.021644</td>\n",
       "      <td>0.009083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.221300</td>\n",
       "      <td>2.174765</td>\n",
       "      <td>0.204400</td>\n",
       "      <td>0.063648</td>\n",
       "      <td>0.027958</td>\n",
       "      <td>0.018728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:33:50,491] Trial 96 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 97 with params: {'learning_rate': 0.00015758755429273638, 'weight_decay': 0.004, 'warmup_steps': 4, 'lambda_param': 1.0, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:48 < 00:24, 7.16 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.327800</td>\n",
       "      <td>2.161618</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.072400</td>\n",
       "      <td>1.937683</td>\n",
       "      <td>0.410632</td>\n",
       "      <td>0.092579</td>\n",
       "      <td>0.089481</td>\n",
       "      <td>0.066296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.868700</td>\n",
       "      <td>1.734291</td>\n",
       "      <td>0.467461</td>\n",
       "      <td>0.101816</td>\n",
       "      <td>0.123947</td>\n",
       "      <td>0.098488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.677100</td>\n",
       "      <td>1.570236</td>\n",
       "      <td>0.517874</td>\n",
       "      <td>0.162790</td>\n",
       "      <td>0.153707</td>\n",
       "      <td>0.130471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.532500</td>\n",
       "      <td>1.441092</td>\n",
       "      <td>0.560953</td>\n",
       "      <td>0.227559</td>\n",
       "      <td>0.188788</td>\n",
       "      <td>0.171225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.395900</td>\n",
       "      <td>1.339232</td>\n",
       "      <td>0.594867</td>\n",
       "      <td>0.241494</td>\n",
       "      <td>0.214289</td>\n",
       "      <td>0.199538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.289800</td>\n",
       "      <td>1.257853</td>\n",
       "      <td>0.638863</td>\n",
       "      <td>0.270952</td>\n",
       "      <td>0.245168</td>\n",
       "      <td>0.234834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.212900</td>\n",
       "      <td>1.195491</td>\n",
       "      <td>0.660862</td>\n",
       "      <td>0.262978</td>\n",
       "      <td>0.269676</td>\n",
       "      <td>0.251040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.139400</td>\n",
       "      <td>1.143780</td>\n",
       "      <td>0.673694</td>\n",
       "      <td>0.265778</td>\n",
       "      <td>0.275391</td>\n",
       "      <td>0.255968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.079200</td>\n",
       "      <td>1.105531</td>\n",
       "      <td>0.682860</td>\n",
       "      <td>0.266075</td>\n",
       "      <td>0.285302</td>\n",
       "      <td>0.262383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:34:40,053] Trial 97 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 98 with params: {'learning_rate': 2.025662008519137e-05, 'weight_decay': 0.008, 'warmup_steps': 4, 'lambda_param': 0.30000000000000004, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:49 < 00:24, 7.02 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.446700</td>\n",
       "      <td>2.399420</td>\n",
       "      <td>0.153071</td>\n",
       "      <td>0.009399</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.008930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.384100</td>\n",
       "      <td>2.343836</td>\n",
       "      <td>0.182401</td>\n",
       "      <td>0.010670</td>\n",
       "      <td>0.021644</td>\n",
       "      <td>0.008784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.341000</td>\n",
       "      <td>2.302176</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.303000</td>\n",
       "      <td>2.267023</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.019561</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.271300</td>\n",
       "      <td>2.231851</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023554</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.239700</td>\n",
       "      <td>2.204185</td>\n",
       "      <td>0.181485</td>\n",
       "      <td>0.043564</td>\n",
       "      <td>0.021311</td>\n",
       "      <td>0.008554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.214900</td>\n",
       "      <td>2.179431</td>\n",
       "      <td>0.196150</td>\n",
       "      <td>0.063614</td>\n",
       "      <td>0.025492</td>\n",
       "      <td>0.015601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.194100</td>\n",
       "      <td>2.157942</td>\n",
       "      <td>0.226398</td>\n",
       "      <td>0.079049</td>\n",
       "      <td>0.033977</td>\n",
       "      <td>0.028055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.175700</td>\n",
       "      <td>2.139898</td>\n",
       "      <td>0.265811</td>\n",
       "      <td>0.073041</td>\n",
       "      <td>0.045215</td>\n",
       "      <td>0.041056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.161500</td>\n",
       "      <td>2.124325</td>\n",
       "      <td>0.303391</td>\n",
       "      <td>0.073874</td>\n",
       "      <td>0.056196</td>\n",
       "      <td>0.051836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:35:30,598] Trial 98 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 99 with params: {'learning_rate': 4.35374541141818e-05, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.0, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:48, 7.27 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.419200</td>\n",
       "      <td>2.341503</td>\n",
       "      <td>0.182401</td>\n",
       "      <td>0.013581</td>\n",
       "      <td>0.021644</td>\n",
       "      <td>0.008897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.313400</td>\n",
       "      <td>2.253500</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023548</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.238500</td>\n",
       "      <td>2.176896</td>\n",
       "      <td>0.189734</td>\n",
       "      <td>0.063584</td>\n",
       "      <td>0.023705</td>\n",
       "      <td>0.012673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.168500</td>\n",
       "      <td>2.109167</td>\n",
       "      <td>0.329056</td>\n",
       "      <td>0.071906</td>\n",
       "      <td>0.064365</td>\n",
       "      <td>0.057686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.112200</td>\n",
       "      <td>2.050308</td>\n",
       "      <td>0.387718</td>\n",
       "      <td>0.079798</td>\n",
       "      <td>0.081690</td>\n",
       "      <td>0.065028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:35:55,642] Trial 99 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 with params: {'learning_rate': 4.174411847798711e-05, 'weight_decay': 0.008, 'warmup_steps': 4, 'lambda_param': 1.0, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:48 < 00:24, 7.13 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.421100</td>\n",
       "      <td>2.345301</td>\n",
       "      <td>0.183318</td>\n",
       "      <td>0.012344</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>0.009239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.318200</td>\n",
       "      <td>2.259895</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023548</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.245600</td>\n",
       "      <td>2.185724</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>0.043567</td>\n",
       "      <td>0.022430</td>\n",
       "      <td>0.010476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.178000</td>\n",
       "      <td>2.120303</td>\n",
       "      <td>0.306141</td>\n",
       "      <td>0.072309</td>\n",
       "      <td>0.057587</td>\n",
       "      <td>0.052029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.123600</td>\n",
       "      <td>2.062937</td>\n",
       "      <td>0.382218</td>\n",
       "      <td>0.081679</td>\n",
       "      <td>0.080159</td>\n",
       "      <td>0.065361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.066500</td>\n",
       "      <td>2.014195</td>\n",
       "      <td>0.394134</td>\n",
       "      <td>0.076270</td>\n",
       "      <td>0.083813</td>\n",
       "      <td>0.064221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.019500</td>\n",
       "      <td>1.970546</td>\n",
       "      <td>0.407883</td>\n",
       "      <td>0.073666</td>\n",
       "      <td>0.087656</td>\n",
       "      <td>0.064875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.981900</td>\n",
       "      <td>1.932516</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.092361</td>\n",
       "      <td>0.093920</td>\n",
       "      <td>0.072601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.946300</td>\n",
       "      <td>1.899841</td>\n",
       "      <td>0.431714</td>\n",
       "      <td>0.087609</td>\n",
       "      <td>0.100193</td>\n",
       "      <td>0.078021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.919300</td>\n",
       "      <td>1.873568</td>\n",
       "      <td>0.442713</td>\n",
       "      <td>0.086189</td>\n",
       "      <td>0.106086</td>\n",
       "      <td>0.083148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:36:45,591] Trial 100 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 101 with params: {'learning_rate': 0.0004636837052468016, 'weight_decay': 0.0, 'warmup_steps': 3, 'lambda_param': 0.7000000000000001, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.176900</td>\n",
       "      <td>1.861312</td>\n",
       "      <td>0.425298</td>\n",
       "      <td>0.064297</td>\n",
       "      <td>0.100084</td>\n",
       "      <td>0.074891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.655000</td>\n",
       "      <td>1.428223</td>\n",
       "      <td>0.553621</td>\n",
       "      <td>0.198545</td>\n",
       "      <td>0.185964</td>\n",
       "      <td>0.166688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.266500</td>\n",
       "      <td>1.132888</td>\n",
       "      <td>0.655362</td>\n",
       "      <td>0.239403</td>\n",
       "      <td>0.258618</td>\n",
       "      <td>0.236147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.994000</td>\n",
       "      <td>0.969335</td>\n",
       "      <td>0.686526</td>\n",
       "      <td>0.271558</td>\n",
       "      <td>0.289828</td>\n",
       "      <td>0.264434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.810200</td>\n",
       "      <td>0.878822</td>\n",
       "      <td>0.713107</td>\n",
       "      <td>0.298225</td>\n",
       "      <td>0.319884</td>\n",
       "      <td>0.294464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.681200</td>\n",
       "      <td>0.812722</td>\n",
       "      <td>0.725023</td>\n",
       "      <td>0.366093</td>\n",
       "      <td>0.345978</td>\n",
       "      <td>0.329193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>0.794231</td>\n",
       "      <td>0.730522</td>\n",
       "      <td>0.367487</td>\n",
       "      <td>0.364651</td>\n",
       "      <td>0.347979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.526000</td>\n",
       "      <td>0.760569</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.415393</td>\n",
       "      <td>0.399895</td>\n",
       "      <td>0.389026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.474400</td>\n",
       "      <td>0.743110</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.445925</td>\n",
       "      <td>0.409183</td>\n",
       "      <td>0.404429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.731924</td>\n",
       "      <td>0.755270</td>\n",
       "      <td>0.459258</td>\n",
       "      <td>0.424398</td>\n",
       "      <td>0.418881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.398500</td>\n",
       "      <td>0.711251</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.468592</td>\n",
       "      <td>0.433014</td>\n",
       "      <td>0.429573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.368400</td>\n",
       "      <td>0.700589</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.489132</td>\n",
       "      <td>0.436824</td>\n",
       "      <td>0.439101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.350600</td>\n",
       "      <td>0.693783</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.463532</td>\n",
       "      <td>0.446624</td>\n",
       "      <td>0.442330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.338600</td>\n",
       "      <td>0.690495</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.461691</td>\n",
       "      <td>0.449356</td>\n",
       "      <td>0.443324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.336500</td>\n",
       "      <td>0.691069</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.483857</td>\n",
       "      <td>0.452127</td>\n",
       "      <td>0.449344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:38:01,259] Trial 101 finished with value: 0.4493441148240114 and parameters: {'learning_rate': 0.0004636837052468016, 'weight_decay': 0.0, 'warmup_steps': 3, 'lambda_param': 0.7000000000000001, 'temperature': 3.5}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 102 with params: {'learning_rate': 0.0004891719445432319, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.0, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:17, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.176000</td>\n",
       "      <td>1.846061</td>\n",
       "      <td>0.426214</td>\n",
       "      <td>0.062980</td>\n",
       "      <td>0.102190</td>\n",
       "      <td>0.074838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.630700</td>\n",
       "      <td>1.392909</td>\n",
       "      <td>0.563703</td>\n",
       "      <td>0.196423</td>\n",
       "      <td>0.199806</td>\n",
       "      <td>0.177427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.228500</td>\n",
       "      <td>1.101701</td>\n",
       "      <td>0.659945</td>\n",
       "      <td>0.275657</td>\n",
       "      <td>0.269421</td>\n",
       "      <td>0.248116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.958700</td>\n",
       "      <td>0.945359</td>\n",
       "      <td>0.699358</td>\n",
       "      <td>0.285805</td>\n",
       "      <td>0.300731</td>\n",
       "      <td>0.279652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.780400</td>\n",
       "      <td>0.862477</td>\n",
       "      <td>0.719523</td>\n",
       "      <td>0.329727</td>\n",
       "      <td>0.334379</td>\n",
       "      <td>0.310198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.656100</td>\n",
       "      <td>0.802678</td>\n",
       "      <td>0.730522</td>\n",
       "      <td>0.385881</td>\n",
       "      <td>0.362831</td>\n",
       "      <td>0.349378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.562200</td>\n",
       "      <td>0.776587</td>\n",
       "      <td>0.741522</td>\n",
       "      <td>0.391466</td>\n",
       "      <td>0.386836</td>\n",
       "      <td>0.373492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.503200</td>\n",
       "      <td>0.753054</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.413992</td>\n",
       "      <td>0.397338</td>\n",
       "      <td>0.386882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.448400</td>\n",
       "      <td>0.732541</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.446409</td>\n",
       "      <td>0.425570</td>\n",
       "      <td>0.422650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.401100</td>\n",
       "      <td>0.722022</td>\n",
       "      <td>0.755270</td>\n",
       "      <td>0.481838</td>\n",
       "      <td>0.427259</td>\n",
       "      <td>0.427822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.373400</td>\n",
       "      <td>0.707858</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.504497</td>\n",
       "      <td>0.447872</td>\n",
       "      <td>0.447044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.345600</td>\n",
       "      <td>0.694201</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.540626</td>\n",
       "      <td>0.455948</td>\n",
       "      <td>0.466577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.326600</td>\n",
       "      <td>0.688835</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.497387</td>\n",
       "      <td>0.452968</td>\n",
       "      <td>0.454594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.316500</td>\n",
       "      <td>0.682245</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.525098</td>\n",
       "      <td>0.466402</td>\n",
       "      <td>0.469848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.313800</td>\n",
       "      <td>0.684559</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.516087</td>\n",
       "      <td>0.468874</td>\n",
       "      <td>0.471896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:39:20,144] Trial 102 finished with value: 0.47189610388824405 and parameters: {'learning_rate': 0.0004891719445432319, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.0, 'temperature': 2.5}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 103 with params: {'learning_rate': 0.00045918198842206346, 'weight_decay': 0.004, 'warmup_steps': 4, 'lambda_param': 0.0, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.187000</td>\n",
       "      <td>1.869466</td>\n",
       "      <td>0.421632</td>\n",
       "      <td>0.066060</td>\n",
       "      <td>0.097674</td>\n",
       "      <td>0.073796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.660300</td>\n",
       "      <td>1.423766</td>\n",
       "      <td>0.557287</td>\n",
       "      <td>0.200138</td>\n",
       "      <td>0.190016</td>\n",
       "      <td>0.169848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.266500</td>\n",
       "      <td>1.133207</td>\n",
       "      <td>0.653529</td>\n",
       "      <td>0.255737</td>\n",
       "      <td>0.259162</td>\n",
       "      <td>0.239526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.998000</td>\n",
       "      <td>0.972528</td>\n",
       "      <td>0.686526</td>\n",
       "      <td>0.258841</td>\n",
       "      <td>0.290981</td>\n",
       "      <td>0.267200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.816400</td>\n",
       "      <td>0.882550</td>\n",
       "      <td>0.717690</td>\n",
       "      <td>0.328274</td>\n",
       "      <td>0.329717</td>\n",
       "      <td>0.307661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.686600</td>\n",
       "      <td>0.816362</td>\n",
       "      <td>0.725023</td>\n",
       "      <td>0.378964</td>\n",
       "      <td>0.353075</td>\n",
       "      <td>0.341774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.589400</td>\n",
       "      <td>0.794930</td>\n",
       "      <td>0.730522</td>\n",
       "      <td>0.395903</td>\n",
       "      <td>0.373006</td>\n",
       "      <td>0.359503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.529200</td>\n",
       "      <td>0.761111</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.404522</td>\n",
       "      <td>0.391166</td>\n",
       "      <td>0.376253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.474800</td>\n",
       "      <td>0.744801</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.459219</td>\n",
       "      <td>0.420010</td>\n",
       "      <td>0.415638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.425800</td>\n",
       "      <td>0.731864</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.470506</td>\n",
       "      <td>0.428372</td>\n",
       "      <td>0.425726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.397400</td>\n",
       "      <td>0.716409</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.480369</td>\n",
       "      <td>0.436756</td>\n",
       "      <td>0.433028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.369100</td>\n",
       "      <td>0.701073</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.519911</td>\n",
       "      <td>0.445577</td>\n",
       "      <td>0.451537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.349600</td>\n",
       "      <td>0.694390</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.479948</td>\n",
       "      <td>0.454809</td>\n",
       "      <td>0.453733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.338600</td>\n",
       "      <td>0.689759</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.501273</td>\n",
       "      <td>0.456468</td>\n",
       "      <td>0.456227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.335900</td>\n",
       "      <td>0.691259</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.505333</td>\n",
       "      <td>0.458129</td>\n",
       "      <td>0.458838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:40:36,100] Trial 103 finished with value: 0.4588381698404095 and parameters: {'learning_rate': 0.00045918198842206346, 'weight_decay': 0.004, 'warmup_steps': 4, 'lambda_param': 0.0, 'temperature': 2.5}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 104 with params: {'learning_rate': 0.000474007732838863, 'weight_decay': 0.0, 'warmup_steps': 3, 'lambda_param': 1.0, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.172700</td>\n",
       "      <td>1.852070</td>\n",
       "      <td>0.427131</td>\n",
       "      <td>0.063929</td>\n",
       "      <td>0.101375</td>\n",
       "      <td>0.075348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.643600</td>\n",
       "      <td>1.416094</td>\n",
       "      <td>0.554537</td>\n",
       "      <td>0.200855</td>\n",
       "      <td>0.189214</td>\n",
       "      <td>0.170852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.252100</td>\n",
       "      <td>1.122142</td>\n",
       "      <td>0.655362</td>\n",
       "      <td>0.238048</td>\n",
       "      <td>0.262450</td>\n",
       "      <td>0.240010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.980400</td>\n",
       "      <td>0.959264</td>\n",
       "      <td>0.692026</td>\n",
       "      <td>0.276243</td>\n",
       "      <td>0.293033</td>\n",
       "      <td>0.270772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.798100</td>\n",
       "      <td>0.872584</td>\n",
       "      <td>0.714024</td>\n",
       "      <td>0.308421</td>\n",
       "      <td>0.323795</td>\n",
       "      <td>0.298661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.671700</td>\n",
       "      <td>0.809296</td>\n",
       "      <td>0.729606</td>\n",
       "      <td>0.383738</td>\n",
       "      <td>0.360800</td>\n",
       "      <td>0.349922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.789666</td>\n",
       "      <td>0.732356</td>\n",
       "      <td>0.364915</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.348563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.516800</td>\n",
       "      <td>0.757638</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.414590</td>\n",
       "      <td>0.402184</td>\n",
       "      <td>0.390823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.465300</td>\n",
       "      <td>0.738737</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.442978</td>\n",
       "      <td>0.415142</td>\n",
       "      <td>0.409295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.416100</td>\n",
       "      <td>0.727947</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.448756</td>\n",
       "      <td>0.419912</td>\n",
       "      <td>0.413075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.389600</td>\n",
       "      <td>0.708576</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.487435</td>\n",
       "      <td>0.440798</td>\n",
       "      <td>0.439452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.360500</td>\n",
       "      <td>0.697602</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.489420</td>\n",
       "      <td>0.440044</td>\n",
       "      <td>0.441130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.342500</td>\n",
       "      <td>0.691018</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.454104</td>\n",
       "      <td>0.448156</td>\n",
       "      <td>0.440818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.330700</td>\n",
       "      <td>0.687759</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.487394</td>\n",
       "      <td>0.455771</td>\n",
       "      <td>0.454624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.328500</td>\n",
       "      <td>0.688355</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.472365</td>\n",
       "      <td>0.452342</td>\n",
       "      <td>0.445650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:41:51,980] Trial 104 finished with value: 0.44564968938491534 and parameters: {'learning_rate': 0.000474007732838863, 'weight_decay': 0.0, 'warmup_steps': 3, 'lambda_param': 1.0, 'temperature': 4.5}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 105 with params: {'learning_rate': 0.0004972156650098043, 'weight_decay': 0.002, 'warmup_steps': 4, 'lambda_param': 0.7000000000000001, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:10, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.173200</td>\n",
       "      <td>1.840220</td>\n",
       "      <td>0.428964</td>\n",
       "      <td>0.062722</td>\n",
       "      <td>0.103414</td>\n",
       "      <td>0.075170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.623200</td>\n",
       "      <td>1.385588</td>\n",
       "      <td>0.565536</td>\n",
       "      <td>0.196303</td>\n",
       "      <td>0.200893</td>\n",
       "      <td>0.177913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.219000</td>\n",
       "      <td>1.093360</td>\n",
       "      <td>0.665445</td>\n",
       "      <td>0.282302</td>\n",
       "      <td>0.276940</td>\n",
       "      <td>0.256517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.947900</td>\n",
       "      <td>0.937315</td>\n",
       "      <td>0.703025</td>\n",
       "      <td>0.296390</td>\n",
       "      <td>0.303696</td>\n",
       "      <td>0.283896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.771200</td>\n",
       "      <td>0.858503</td>\n",
       "      <td>0.719523</td>\n",
       "      <td>0.331833</td>\n",
       "      <td>0.334936</td>\n",
       "      <td>0.309599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.650800</td>\n",
       "      <td>0.801015</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.415680</td>\n",
       "      <td>0.373541</td>\n",
       "      <td>0.366011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.554900</td>\n",
       "      <td>0.771182</td>\n",
       "      <td>0.740605</td>\n",
       "      <td>0.386716</td>\n",
       "      <td>0.379435</td>\n",
       "      <td>0.365466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.495900</td>\n",
       "      <td>0.746913</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.427671</td>\n",
       "      <td>0.403068</td>\n",
       "      <td>0.391105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.442100</td>\n",
       "      <td>0.726724</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.443934</td>\n",
       "      <td>0.426338</td>\n",
       "      <td>0.422320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.393500</td>\n",
       "      <td>0.718626</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.467217</td>\n",
       "      <td>0.424547</td>\n",
       "      <td>0.424555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.366500</td>\n",
       "      <td>0.702744</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.507948</td>\n",
       "      <td>0.455342</td>\n",
       "      <td>0.455076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.339000</td>\n",
       "      <td>0.691959</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.530822</td>\n",
       "      <td>0.453457</td>\n",
       "      <td>0.460267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.321700</td>\n",
       "      <td>0.686437</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.494115</td>\n",
       "      <td>0.458951</td>\n",
       "      <td>0.461375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.310700</td>\n",
       "      <td>0.681069</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.527624</td>\n",
       "      <td>0.466958</td>\n",
       "      <td>0.471998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.307900</td>\n",
       "      <td>0.683270</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.502958</td>\n",
       "      <td>0.471008</td>\n",
       "      <td>0.471870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:43:04,468] Trial 105 finished with value: 0.47187001129115386 and parameters: {'learning_rate': 0.0004972156650098043, 'weight_decay': 0.002, 'warmup_steps': 4, 'lambda_param': 0.7000000000000001, 'temperature': 4.5}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 106 with params: {'learning_rate': 0.00038830645075827786, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 1.0, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.214100</td>\n",
       "      <td>1.930704</td>\n",
       "      <td>0.395967</td>\n",
       "      <td>0.055119</td>\n",
       "      <td>0.085117</td>\n",
       "      <td>0.062490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.740100</td>\n",
       "      <td>1.515051</td>\n",
       "      <td>0.525206</td>\n",
       "      <td>0.166279</td>\n",
       "      <td>0.161683</td>\n",
       "      <td>0.141621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.371400</td>\n",
       "      <td>1.220024</td>\n",
       "      <td>0.640697</td>\n",
       "      <td>0.225812</td>\n",
       "      <td>0.241801</td>\n",
       "      <td>0.220423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.104200</td>\n",
       "      <td>1.054837</td>\n",
       "      <td>0.682860</td>\n",
       "      <td>0.272792</td>\n",
       "      <td>0.284117</td>\n",
       "      <td>0.264796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.921100</td>\n",
       "      <td>0.946075</td>\n",
       "      <td>0.708524</td>\n",
       "      <td>0.297146</td>\n",
       "      <td>0.311202</td>\n",
       "      <td>0.289217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.778500</td>\n",
       "      <td>0.858459</td>\n",
       "      <td>0.725023</td>\n",
       "      <td>0.352217</td>\n",
       "      <td>0.332872</td>\n",
       "      <td>0.314407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.671500</td>\n",
       "      <td>0.819747</td>\n",
       "      <td>0.718607</td>\n",
       "      <td>0.341844</td>\n",
       "      <td>0.333597</td>\n",
       "      <td>0.317207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.605900</td>\n",
       "      <td>0.791206</td>\n",
       "      <td>0.743355</td>\n",
       "      <td>0.386024</td>\n",
       "      <td>0.375867</td>\n",
       "      <td>0.358379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.549800</td>\n",
       "      <td>0.768629</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.401256</td>\n",
       "      <td>0.386027</td>\n",
       "      <td>0.372968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.498100</td>\n",
       "      <td>0.760638</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.436870</td>\n",
       "      <td>0.395346</td>\n",
       "      <td>0.386243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.469500</td>\n",
       "      <td>0.740070</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.441053</td>\n",
       "      <td>0.404997</td>\n",
       "      <td>0.399098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.434900</td>\n",
       "      <td>0.728361</td>\n",
       "      <td>0.757104</td>\n",
       "      <td>0.460561</td>\n",
       "      <td>0.412941</td>\n",
       "      <td>0.410833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.419200</td>\n",
       "      <td>0.722897</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.492882</td>\n",
       "      <td>0.420975</td>\n",
       "      <td>0.421728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.406100</td>\n",
       "      <td>0.717014</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.477098</td>\n",
       "      <td>0.430438</td>\n",
       "      <td>0.427325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.402200</td>\n",
       "      <td>0.718877</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.499437</td>\n",
       "      <td>0.434854</td>\n",
       "      <td>0.435705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:44:19,300] Trial 106 finished with value: 0.435704867137416 and parameters: {'learning_rate': 0.00038830645075827786, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 1.0, 'temperature': 6.5}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 107 with params: {'learning_rate': 0.0003596738637418528, 'weight_decay': 0.002, 'warmup_steps': 4, 'lambda_param': 0.0, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:46, 7.46 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.225300</td>\n",
       "      <td>1.955141</td>\n",
       "      <td>0.389551</td>\n",
       "      <td>0.059026</td>\n",
       "      <td>0.083166</td>\n",
       "      <td>0.063025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.775000</td>\n",
       "      <td>1.555923</td>\n",
       "      <td>0.513291</td>\n",
       "      <td>0.139393</td>\n",
       "      <td>0.152102</td>\n",
       "      <td>0.129238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.419000</td>\n",
       "      <td>1.265341</td>\n",
       "      <td>0.615949</td>\n",
       "      <td>0.229215</td>\n",
       "      <td>0.225477</td>\n",
       "      <td>0.207387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.154400</td>\n",
       "      <td>1.095427</td>\n",
       "      <td>0.673694</td>\n",
       "      <td>0.270519</td>\n",
       "      <td>0.276872</td>\n",
       "      <td>0.258395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.972600</td>\n",
       "      <td>0.980529</td>\n",
       "      <td>0.700275</td>\n",
       "      <td>0.285668</td>\n",
       "      <td>0.301995</td>\n",
       "      <td>0.278059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:44:43,445] Trial 107 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 108 with params: {'learning_rate': 0.00028166078804503996, 'weight_decay': 0.005, 'warmup_steps': 4, 'lambda_param': 0.6000000000000001, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:47, 7.35 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.259200</td>\n",
       "      <td>2.027096</td>\n",
       "      <td>0.339138</td>\n",
       "      <td>0.068508</td>\n",
       "      <td>0.067258</td>\n",
       "      <td>0.054969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.877200</td>\n",
       "      <td>1.679015</td>\n",
       "      <td>0.477544</td>\n",
       "      <td>0.144346</td>\n",
       "      <td>0.134398</td>\n",
       "      <td>0.109746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.566000</td>\n",
       "      <td>1.409601</td>\n",
       "      <td>0.556370</td>\n",
       "      <td>0.199233</td>\n",
       "      <td>0.180638</td>\n",
       "      <td>0.160157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.314100</td>\n",
       "      <td>1.222022</td>\n",
       "      <td>0.638863</td>\n",
       "      <td>0.248299</td>\n",
       "      <td>0.244106</td>\n",
       "      <td>0.227777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.133000</td>\n",
       "      <td>1.087815</td>\n",
       "      <td>0.682860</td>\n",
       "      <td>0.268938</td>\n",
       "      <td>0.282357</td>\n",
       "      <td>0.261071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:45:08,028] Trial 108 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 109 with params: {'learning_rate': 0.0004544605928817944, 'weight_decay': 0.0, 'warmup_steps': 4, 'lambda_param': 1.0, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.188700</td>\n",
       "      <td>1.873598</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.065794</td>\n",
       "      <td>0.096791</td>\n",
       "      <td>0.073268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.665400</td>\n",
       "      <td>1.429323</td>\n",
       "      <td>0.556370</td>\n",
       "      <td>0.200387</td>\n",
       "      <td>0.189801</td>\n",
       "      <td>0.169785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.273000</td>\n",
       "      <td>1.138252</td>\n",
       "      <td>0.651696</td>\n",
       "      <td>0.255450</td>\n",
       "      <td>0.257846</td>\n",
       "      <td>0.238824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.004500</td>\n",
       "      <td>0.976990</td>\n",
       "      <td>0.688359</td>\n",
       "      <td>0.259811</td>\n",
       "      <td>0.291539</td>\n",
       "      <td>0.267905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.822400</td>\n",
       "      <td>0.885466</td>\n",
       "      <td>0.716774</td>\n",
       "      <td>0.328714</td>\n",
       "      <td>0.329502</td>\n",
       "      <td>0.307906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.692000</td>\n",
       "      <td>0.818932</td>\n",
       "      <td>0.720440</td>\n",
       "      <td>0.370516</td>\n",
       "      <td>0.346270</td>\n",
       "      <td>0.330961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.594400</td>\n",
       "      <td>0.796663</td>\n",
       "      <td>0.730522</td>\n",
       "      <td>0.394328</td>\n",
       "      <td>0.367992</td>\n",
       "      <td>0.353833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.534100</td>\n",
       "      <td>0.762329</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.406071</td>\n",
       "      <td>0.393397</td>\n",
       "      <td>0.378197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.479300</td>\n",
       "      <td>0.747453</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.451840</td>\n",
       "      <td>0.417177</td>\n",
       "      <td>0.411766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.430200</td>\n",
       "      <td>0.734211</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.470422</td>\n",
       "      <td>0.428587</td>\n",
       "      <td>0.426068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.401900</td>\n",
       "      <td>0.718740</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.473205</td>\n",
       "      <td>0.435090</td>\n",
       "      <td>0.432828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.373200</td>\n",
       "      <td>0.703493</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.493456</td>\n",
       "      <td>0.436632</td>\n",
       "      <td>0.439021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.353800</td>\n",
       "      <td>0.696316</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.465575</td>\n",
       "      <td>0.446066</td>\n",
       "      <td>0.441865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.342500</td>\n",
       "      <td>0.691512</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.498546</td>\n",
       "      <td>0.457449</td>\n",
       "      <td>0.455121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.339900</td>\n",
       "      <td>0.692980</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.499473</td>\n",
       "      <td>0.458367</td>\n",
       "      <td>0.456958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:46:22,832] Trial 109 finished with value: 0.45695793507780297 and parameters: {'learning_rate': 0.0004544605928817944, 'weight_decay': 0.0, 'warmup_steps': 4, 'lambda_param': 1.0, 'temperature': 4.5}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 110 with params: {'learning_rate': 0.0002916371527822545, 'weight_decay': 0.002, 'warmup_steps': 4, 'lambda_param': 0.4, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:48 < 00:24, 7.13 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.254400</td>\n",
       "      <td>2.016776</td>\n",
       "      <td>0.357470</td>\n",
       "      <td>0.068399</td>\n",
       "      <td>0.072578</td>\n",
       "      <td>0.059968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.863800</td>\n",
       "      <td>1.662706</td>\n",
       "      <td>0.479377</td>\n",
       "      <td>0.142534</td>\n",
       "      <td>0.135522</td>\n",
       "      <td>0.111132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.546500</td>\n",
       "      <td>1.390233</td>\n",
       "      <td>0.560953</td>\n",
       "      <td>0.199187</td>\n",
       "      <td>0.183285</td>\n",
       "      <td>0.163084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.292200</td>\n",
       "      <td>1.203424</td>\n",
       "      <td>0.648946</td>\n",
       "      <td>0.247526</td>\n",
       "      <td>0.252562</td>\n",
       "      <td>0.236067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.110400</td>\n",
       "      <td>1.071599</td>\n",
       "      <td>0.685610</td>\n",
       "      <td>0.270157</td>\n",
       "      <td>0.284056</td>\n",
       "      <td>0.262505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.975249</td>\n",
       "      <td>0.705775</td>\n",
       "      <td>0.298827</td>\n",
       "      <td>0.302227</td>\n",
       "      <td>0.282840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.844800</td>\n",
       "      <td>0.912551</td>\n",
       "      <td>0.702108</td>\n",
       "      <td>0.273085</td>\n",
       "      <td>0.299974</td>\n",
       "      <td>0.276288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.771100</td>\n",
       "      <td>0.870289</td>\n",
       "      <td>0.724106</td>\n",
       "      <td>0.336362</td>\n",
       "      <td>0.332909</td>\n",
       "      <td>0.310726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.708600</td>\n",
       "      <td>0.846379</td>\n",
       "      <td>0.723190</td>\n",
       "      <td>0.327517</td>\n",
       "      <td>0.330490</td>\n",
       "      <td>0.309348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.650300</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.731439</td>\n",
       "      <td>0.366309</td>\n",
       "      <td>0.354272</td>\n",
       "      <td>0.339652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:47:12,553] Trial 110 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 111 with params: {'learning_rate': 0.000495988193335961, 'weight_decay': 0.003, 'warmup_steps': 3, 'lambda_param': 0.5, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.164100</td>\n",
       "      <td>1.834023</td>\n",
       "      <td>0.430797</td>\n",
       "      <td>0.062853</td>\n",
       "      <td>0.104237</td>\n",
       "      <td>0.075805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.621000</td>\n",
       "      <td>1.391271</td>\n",
       "      <td>0.562786</td>\n",
       "      <td>0.195956</td>\n",
       "      <td>0.199441</td>\n",
       "      <td>0.176049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.224200</td>\n",
       "      <td>1.103717</td>\n",
       "      <td>0.662695</td>\n",
       "      <td>0.286790</td>\n",
       "      <td>0.271543</td>\n",
       "      <td>0.253132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.957000</td>\n",
       "      <td>0.946586</td>\n",
       "      <td>0.693859</td>\n",
       "      <td>0.275898</td>\n",
       "      <td>0.295542</td>\n",
       "      <td>0.273990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.777700</td>\n",
       "      <td>0.862403</td>\n",
       "      <td>0.717690</td>\n",
       "      <td>0.333260</td>\n",
       "      <td>0.331743</td>\n",
       "      <td>0.307372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.653700</td>\n",
       "      <td>0.802816</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.407481</td>\n",
       "      <td>0.380737</td>\n",
       "      <td>0.371206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.557500</td>\n",
       "      <td>0.780549</td>\n",
       "      <td>0.736939</td>\n",
       "      <td>0.366099</td>\n",
       "      <td>0.369918</td>\n",
       "      <td>0.353791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.498500</td>\n",
       "      <td>0.749905</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.428647</td>\n",
       "      <td>0.415308</td>\n",
       "      <td>0.402998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.446300</td>\n",
       "      <td>0.724587</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.455051</td>\n",
       "      <td>0.422005</td>\n",
       "      <td>0.418859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.399100</td>\n",
       "      <td>0.717981</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.453646</td>\n",
       "      <td>0.427168</td>\n",
       "      <td>0.421781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.370900</td>\n",
       "      <td>0.700884</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.483890</td>\n",
       "      <td>0.445028</td>\n",
       "      <td>0.443597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.343900</td>\n",
       "      <td>0.689291</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.482177</td>\n",
       "      <td>0.441307</td>\n",
       "      <td>0.441095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.326900</td>\n",
       "      <td>0.683859</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.476124</td>\n",
       "      <td>0.454789</td>\n",
       "      <td>0.452759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.314700</td>\n",
       "      <td>0.680496</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.467339</td>\n",
       "      <td>0.447910</td>\n",
       "      <td>0.445074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.312200</td>\n",
       "      <td>0.681567</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.478163</td>\n",
       "      <td>0.458698</td>\n",
       "      <td>0.454319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:48:29,153] Trial 111 finished with value: 0.45431889686694843 and parameters: {'learning_rate': 0.000495988193335961, 'weight_decay': 0.003, 'warmup_steps': 3, 'lambda_param': 0.5, 'temperature': 5.5}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 112 with params: {'learning_rate': 0.00043024518854995066, 'weight_decay': 0.002, 'warmup_steps': 4, 'lambda_param': 0.7000000000000001, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.198000</td>\n",
       "      <td>1.895304</td>\n",
       "      <td>0.410632</td>\n",
       "      <td>0.072801</td>\n",
       "      <td>0.091311</td>\n",
       "      <td>0.068880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.692500</td>\n",
       "      <td>1.460381</td>\n",
       "      <td>0.553621</td>\n",
       "      <td>0.180466</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>0.166757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.308300</td>\n",
       "      <td>1.165365</td>\n",
       "      <td>0.651696</td>\n",
       "      <td>0.258170</td>\n",
       "      <td>0.256160</td>\n",
       "      <td>0.236707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.038700</td>\n",
       "      <td>1.002445</td>\n",
       "      <td>0.689276</td>\n",
       "      <td>0.276260</td>\n",
       "      <td>0.296407</td>\n",
       "      <td>0.275115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.854400</td>\n",
       "      <td>0.905106</td>\n",
       "      <td>0.714940</td>\n",
       "      <td>0.347781</td>\n",
       "      <td>0.325221</td>\n",
       "      <td>0.304760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.720200</td>\n",
       "      <td>0.832273</td>\n",
       "      <td>0.721357</td>\n",
       "      <td>0.361922</td>\n",
       "      <td>0.337558</td>\n",
       "      <td>0.320444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.620100</td>\n",
       "      <td>0.803621</td>\n",
       "      <td>0.732356</td>\n",
       "      <td>0.375632</td>\n",
       "      <td>0.362929</td>\n",
       "      <td>0.349362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.559000</td>\n",
       "      <td>0.772601</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.388055</td>\n",
       "      <td>0.392830</td>\n",
       "      <td>0.375224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.503000</td>\n",
       "      <td>0.752688</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.431149</td>\n",
       "      <td>0.399151</td>\n",
       "      <td>0.391878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.453500</td>\n",
       "      <td>0.744209</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.434002</td>\n",
       "      <td>0.406410</td>\n",
       "      <td>0.397535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.425300</td>\n",
       "      <td>0.724774</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.440114</td>\n",
       "      <td>0.419923</td>\n",
       "      <td>0.410981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.394600</td>\n",
       "      <td>0.710567</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.463436</td>\n",
       "      <td>0.421896</td>\n",
       "      <td>0.420158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.376400</td>\n",
       "      <td>0.704098</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.458746</td>\n",
       "      <td>0.434095</td>\n",
       "      <td>0.428831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.364500</td>\n",
       "      <td>0.699022</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.448255</td>\n",
       "      <td>0.441807</td>\n",
       "      <td>0.431574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.361700</td>\n",
       "      <td>0.700611</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.472579</td>\n",
       "      <td>0.446876</td>\n",
       "      <td>0.440922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:49:42,912] Trial 112 finished with value: 0.44092158388558816 and parameters: {'learning_rate': 0.00043024518854995066, 'weight_decay': 0.002, 'warmup_steps': 4, 'lambda_param': 0.7000000000000001, 'temperature': 4.5}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 113 with params: {'learning_rate': 0.00010121831356866389, 'weight_decay': 0.009000000000000001, 'warmup_steps': 3, 'lambda_param': 0.2, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:47, 7.42 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.363800</td>\n",
       "      <td>2.238740</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.177100</td>\n",
       "      <td>2.073528</td>\n",
       "      <td>0.335472</td>\n",
       "      <td>0.069809</td>\n",
       "      <td>0.066359</td>\n",
       "      <td>0.057643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.034900</td>\n",
       "      <td>1.933203</td>\n",
       "      <td>0.411549</td>\n",
       "      <td>0.071735</td>\n",
       "      <td>0.089138</td>\n",
       "      <td>0.064313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.896900</td>\n",
       "      <td>1.804580</td>\n",
       "      <td>0.448213</td>\n",
       "      <td>0.097323</td>\n",
       "      <td>0.109279</td>\n",
       "      <td>0.085441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.786100</td>\n",
       "      <td>1.694167</td>\n",
       "      <td>0.483043</td>\n",
       "      <td>0.103508</td>\n",
       "      <td>0.132189</td>\n",
       "      <td>0.107020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:50:07,139] Trial 113 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 114 with params: {'learning_rate': 0.00048028646482360107, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.9, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:11, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.179300</td>\n",
       "      <td>1.852665</td>\n",
       "      <td>0.426214</td>\n",
       "      <td>0.064685</td>\n",
       "      <td>0.101760</td>\n",
       "      <td>0.075521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.639200</td>\n",
       "      <td>1.401603</td>\n",
       "      <td>0.563703</td>\n",
       "      <td>0.197235</td>\n",
       "      <td>0.199588</td>\n",
       "      <td>0.177467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.239400</td>\n",
       "      <td>1.110956</td>\n",
       "      <td>0.658112</td>\n",
       "      <td>0.257581</td>\n",
       "      <td>0.267504</td>\n",
       "      <td>0.245381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.970400</td>\n",
       "      <td>0.953588</td>\n",
       "      <td>0.696609</td>\n",
       "      <td>0.278375</td>\n",
       "      <td>0.297109</td>\n",
       "      <td>0.274889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.790900</td>\n",
       "      <td>0.869171</td>\n",
       "      <td>0.716774</td>\n",
       "      <td>0.326043</td>\n",
       "      <td>0.330335</td>\n",
       "      <td>0.307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.805541</td>\n",
       "      <td>0.725940</td>\n",
       "      <td>0.387242</td>\n",
       "      <td>0.356860</td>\n",
       "      <td>0.344961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.568600</td>\n",
       "      <td>0.785307</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.397495</td>\n",
       "      <td>0.381668</td>\n",
       "      <td>0.370297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.509900</td>\n",
       "      <td>0.753015</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.419037</td>\n",
       "      <td>0.400277</td>\n",
       "      <td>0.388391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.456200</td>\n",
       "      <td>0.736353</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.441093</td>\n",
       "      <td>0.422283</td>\n",
       "      <td>0.418307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.407900</td>\n",
       "      <td>0.723446</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.477107</td>\n",
       "      <td>0.427671</td>\n",
       "      <td>0.428606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.708876</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.484622</td>\n",
       "      <td>0.445061</td>\n",
       "      <td>0.441628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.352600</td>\n",
       "      <td>0.695245</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.536380</td>\n",
       "      <td>0.452428</td>\n",
       "      <td>0.461348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.333200</td>\n",
       "      <td>0.688973</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.477978</td>\n",
       "      <td>0.452233</td>\n",
       "      <td>0.451997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.322600</td>\n",
       "      <td>0.683931</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.520249</td>\n",
       "      <td>0.462481</td>\n",
       "      <td>0.464627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.320700</td>\n",
       "      <td>0.685730</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.521757</td>\n",
       "      <td>0.464261</td>\n",
       "      <td>0.467908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:51:20,619] Trial 114 finished with value: 0.46790808088535774 and parameters: {'learning_rate': 0.00048028646482360107, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.9, 'temperature': 4.5}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 115 with params: {'learning_rate': 0.0003361903816895983, 'weight_decay': 0.004, 'warmup_steps': 4, 'lambda_param': 0.8, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:46, 7.46 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.234700</td>\n",
       "      <td>1.975406</td>\n",
       "      <td>0.378552</td>\n",
       "      <td>0.062630</td>\n",
       "      <td>0.079286</td>\n",
       "      <td>0.062384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.804300</td>\n",
       "      <td>1.590955</td>\n",
       "      <td>0.502291</td>\n",
       "      <td>0.130722</td>\n",
       "      <td>0.146358</td>\n",
       "      <td>0.122827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.460300</td>\n",
       "      <td>1.305451</td>\n",
       "      <td>0.596700</td>\n",
       "      <td>0.225858</td>\n",
       "      <td>0.210621</td>\n",
       "      <td>0.193758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.198600</td>\n",
       "      <td>1.129425</td>\n",
       "      <td>0.666361</td>\n",
       "      <td>0.256895</td>\n",
       "      <td>0.268797</td>\n",
       "      <td>0.251517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.016300</td>\n",
       "      <td>1.008003</td>\n",
       "      <td>0.693859</td>\n",
       "      <td>0.288590</td>\n",
       "      <td>0.294041</td>\n",
       "      <td>0.270746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:51:44,683] Trial 115 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 116 with params: {'learning_rate': 0.00046004707891416665, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 0.9, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:11, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.186600</td>\n",
       "      <td>1.868715</td>\n",
       "      <td>0.421632</td>\n",
       "      <td>0.066060</td>\n",
       "      <td>0.097674</td>\n",
       "      <td>0.073796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.659300</td>\n",
       "      <td>1.422690</td>\n",
       "      <td>0.558203</td>\n",
       "      <td>0.200036</td>\n",
       "      <td>0.190231</td>\n",
       "      <td>0.169812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.265300</td>\n",
       "      <td>1.132292</td>\n",
       "      <td>0.655362</td>\n",
       "      <td>0.256618</td>\n",
       "      <td>0.261024</td>\n",
       "      <td>0.240773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.996900</td>\n",
       "      <td>0.971867</td>\n",
       "      <td>0.687443</td>\n",
       "      <td>0.258980</td>\n",
       "      <td>0.291344</td>\n",
       "      <td>0.267462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.815300</td>\n",
       "      <td>0.882098</td>\n",
       "      <td>0.717690</td>\n",
       "      <td>0.328229</td>\n",
       "      <td>0.329717</td>\n",
       "      <td>0.307566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.685600</td>\n",
       "      <td>0.816001</td>\n",
       "      <td>0.725023</td>\n",
       "      <td>0.378964</td>\n",
       "      <td>0.353075</td>\n",
       "      <td>0.341774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.588500</td>\n",
       "      <td>0.794700</td>\n",
       "      <td>0.731439</td>\n",
       "      <td>0.396535</td>\n",
       "      <td>0.373461</td>\n",
       "      <td>0.360071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.528400</td>\n",
       "      <td>0.760839</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.404522</td>\n",
       "      <td>0.391166</td>\n",
       "      <td>0.376253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.473900</td>\n",
       "      <td>0.744277</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.459863</td>\n",
       "      <td>0.420536</td>\n",
       "      <td>0.416227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.731291</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.472068</td>\n",
       "      <td>0.428736</td>\n",
       "      <td>0.426212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.396600</td>\n",
       "      <td>0.716068</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.480369</td>\n",
       "      <td>0.436756</td>\n",
       "      <td>0.433028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.368400</td>\n",
       "      <td>0.700721</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.519911</td>\n",
       "      <td>0.445577</td>\n",
       "      <td>0.451537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.348900</td>\n",
       "      <td>0.694084</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.479948</td>\n",
       "      <td>0.454809</td>\n",
       "      <td>0.453733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.337900</td>\n",
       "      <td>0.689443</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.501557</td>\n",
       "      <td>0.456468</td>\n",
       "      <td>0.456384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.335300</td>\n",
       "      <td>0.690943</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.506114</td>\n",
       "      <td>0.458129</td>\n",
       "      <td>0.459361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:52:57,572] Trial 116 finished with value: 0.4593608610890367 and parameters: {'learning_rate': 0.00046004707891416665, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 0.9, 'temperature': 5.5}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 117 with params: {'learning_rate': 0.0004828435266487486, 'weight_decay': 0.002, 'warmup_steps': 4, 'lambda_param': 0.1, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.178300</td>\n",
       "      <td>1.850747</td>\n",
       "      <td>0.425298</td>\n",
       "      <td>0.063480</td>\n",
       "      <td>0.101545</td>\n",
       "      <td>0.074804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.636700</td>\n",
       "      <td>1.399063</td>\n",
       "      <td>0.563703</td>\n",
       "      <td>0.196703</td>\n",
       "      <td>0.199565</td>\n",
       "      <td>0.177199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.236200</td>\n",
       "      <td>1.108194</td>\n",
       "      <td>0.658112</td>\n",
       "      <td>0.255633</td>\n",
       "      <td>0.267504</td>\n",
       "      <td>0.245076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.967000</td>\n",
       "      <td>0.951128</td>\n",
       "      <td>0.697525</td>\n",
       "      <td>0.282299</td>\n",
       "      <td>0.299750</td>\n",
       "      <td>0.278319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.787900</td>\n",
       "      <td>0.867286</td>\n",
       "      <td>0.719523</td>\n",
       "      <td>0.330212</td>\n",
       "      <td>0.332944</td>\n",
       "      <td>0.309170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.661400</td>\n",
       "      <td>0.804026</td>\n",
       "      <td>0.725940</td>\n",
       "      <td>0.388140</td>\n",
       "      <td>0.358086</td>\n",
       "      <td>0.346198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.566400</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.741522</td>\n",
       "      <td>0.397287</td>\n",
       "      <td>0.382215</td>\n",
       "      <td>0.370838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.506900</td>\n",
       "      <td>0.754680</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.420640</td>\n",
       "      <td>0.399676</td>\n",
       "      <td>0.387837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.453700</td>\n",
       "      <td>0.733125</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.441479</td>\n",
       "      <td>0.422431</td>\n",
       "      <td>0.418587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.404500</td>\n",
       "      <td>0.722375</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.480707</td>\n",
       "      <td>0.427677</td>\n",
       "      <td>0.429611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.377600</td>\n",
       "      <td>0.709043</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.483907</td>\n",
       "      <td>0.440990</td>\n",
       "      <td>0.436424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.349700</td>\n",
       "      <td>0.694525</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.542669</td>\n",
       "      <td>0.455852</td>\n",
       "      <td>0.467481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.330800</td>\n",
       "      <td>0.688960</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.498917</td>\n",
       "      <td>0.454375</td>\n",
       "      <td>0.456468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.320500</td>\n",
       "      <td>0.683487</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.526527</td>\n",
       "      <td>0.463536</td>\n",
       "      <td>0.467826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.318400</td>\n",
       "      <td>0.685653</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.517890</td>\n",
       "      <td>0.468874</td>\n",
       "      <td>0.473476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:54:11,509] Trial 117 finished with value: 0.4734758165909028 and parameters: {'learning_rate': 0.0004828435266487486, 'weight_decay': 0.002, 'warmup_steps': 4, 'lambda_param': 0.1, 'temperature': 2.0}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 118 with params: {'learning_rate': 0.0004538493543253887, 'weight_decay': 0.005, 'warmup_steps': 4, 'lambda_param': 0.30000000000000004, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.189000</td>\n",
       "      <td>1.874167</td>\n",
       "      <td>0.419798</td>\n",
       "      <td>0.065794</td>\n",
       "      <td>0.096791</td>\n",
       "      <td>0.073268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.666100</td>\n",
       "      <td>1.430116</td>\n",
       "      <td>0.556370</td>\n",
       "      <td>0.200864</td>\n",
       "      <td>0.189801</td>\n",
       "      <td>0.170049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.273900</td>\n",
       "      <td>1.138897</td>\n",
       "      <td>0.651696</td>\n",
       "      <td>0.255450</td>\n",
       "      <td>0.257846</td>\n",
       "      <td>0.238824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.005400</td>\n",
       "      <td>0.977608</td>\n",
       "      <td>0.689276</td>\n",
       "      <td>0.260498</td>\n",
       "      <td>0.292491</td>\n",
       "      <td>0.268610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.823200</td>\n",
       "      <td>0.885930</td>\n",
       "      <td>0.716774</td>\n",
       "      <td>0.328762</td>\n",
       "      <td>0.329502</td>\n",
       "      <td>0.307929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.692800</td>\n",
       "      <td>0.819225</td>\n",
       "      <td>0.720440</td>\n",
       "      <td>0.370516</td>\n",
       "      <td>0.346270</td>\n",
       "      <td>0.330961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.796876</td>\n",
       "      <td>0.730522</td>\n",
       "      <td>0.394328</td>\n",
       "      <td>0.367992</td>\n",
       "      <td>0.353833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.534700</td>\n",
       "      <td>0.762450</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.406351</td>\n",
       "      <td>0.393760</td>\n",
       "      <td>0.378520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.479900</td>\n",
       "      <td>0.747705</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.451526</td>\n",
       "      <td>0.417177</td>\n",
       "      <td>0.411421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.430800</td>\n",
       "      <td>0.734573</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.469727</td>\n",
       "      <td>0.426920</td>\n",
       "      <td>0.425016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.402400</td>\n",
       "      <td>0.719050</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.473636</td>\n",
       "      <td>0.435544</td>\n",
       "      <td>0.433279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.373700</td>\n",
       "      <td>0.703938</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.493456</td>\n",
       "      <td>0.436632</td>\n",
       "      <td>0.439021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.354400</td>\n",
       "      <td>0.696680</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.465376</td>\n",
       "      <td>0.445579</td>\n",
       "      <td>0.441529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.343000</td>\n",
       "      <td>0.691705</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.498546</td>\n",
       "      <td>0.457449</td>\n",
       "      <td>0.455121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.340400</td>\n",
       "      <td>0.693122</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.498922</td>\n",
       "      <td>0.454367</td>\n",
       "      <td>0.451723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:55:27,088] Trial 118 finished with value: 0.45172252995634765 and parameters: {'learning_rate': 0.0004538493543253887, 'weight_decay': 0.005, 'warmup_steps': 4, 'lambda_param': 0.30000000000000004, 'temperature': 3.0}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 119 with params: {'learning_rate': 1.0704036787379217e-05, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.4, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:48 < 00:24, 7.14 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.459800</td>\n",
       "      <td>2.429662</td>\n",
       "      <td>0.043080</td>\n",
       "      <td>0.009653</td>\n",
       "      <td>0.026341</td>\n",
       "      <td>0.006402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.423400</td>\n",
       "      <td>2.395048</td>\n",
       "      <td>0.159487</td>\n",
       "      <td>0.008370</td>\n",
       "      <td>0.019244</td>\n",
       "      <td>0.008997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.394500</td>\n",
       "      <td>2.365108</td>\n",
       "      <td>0.187901</td>\n",
       "      <td>0.020452</td>\n",
       "      <td>0.023728</td>\n",
       "      <td>0.011758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.369800</td>\n",
       "      <td>2.341886</td>\n",
       "      <td>0.184235</td>\n",
       "      <td>0.015572</td>\n",
       "      <td>0.022452</td>\n",
       "      <td>0.010131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.348500</td>\n",
       "      <td>2.322017</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>0.014851</td>\n",
       "      <td>0.022466</td>\n",
       "      <td>0.010148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.329300</td>\n",
       "      <td>2.304889</td>\n",
       "      <td>0.182401</td>\n",
       "      <td>0.014490</td>\n",
       "      <td>0.021644</td>\n",
       "      <td>0.008931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.315200</td>\n",
       "      <td>2.289916</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.302100</td>\n",
       "      <td>2.276883</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.290400</td>\n",
       "      <td>2.265748</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.282100</td>\n",
       "      <td>2.256823</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023554</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:56:16,730] Trial 119 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 120 with params: {'learning_rate': 2.70102317495885e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 2, 'lambda_param': 0.2, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:47, 7.43 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.435900</td>\n",
       "      <td>2.377661</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>0.032541</td>\n",
       "      <td>0.022906</td>\n",
       "      <td>0.010803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.359500</td>\n",
       "      <td>2.313644</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.307600</td>\n",
       "      <td>2.261610</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023548</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.259700</td>\n",
       "      <td>2.216617</td>\n",
       "      <td>0.181485</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.021370</td>\n",
       "      <td>0.008605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.221400</td>\n",
       "      <td>2.174619</td>\n",
       "      <td>0.201650</td>\n",
       "      <td>0.063638</td>\n",
       "      <td>0.027136</td>\n",
       "      <td>0.017753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:56:41,034] Trial 120 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 121 with params: {'learning_rate': 1.5745418122329243e-05, 'weight_decay': 0.003, 'warmup_steps': 3, 'lambda_param': 1.0, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:48 < 00:24, 7.18 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.452000</td>\n",
       "      <td>2.412838</td>\n",
       "      <td>0.109074</td>\n",
       "      <td>0.009732</td>\n",
       "      <td>0.033271</td>\n",
       "      <td>0.008700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.401000</td>\n",
       "      <td>2.364999</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>0.014581</td>\n",
       "      <td>0.022906</td>\n",
       "      <td>0.010746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.363700</td>\n",
       "      <td>2.329768</td>\n",
       "      <td>0.181485</td>\n",
       "      <td>0.011921</td>\n",
       "      <td>0.021370</td>\n",
       "      <td>0.008436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.332700</td>\n",
       "      <td>2.300641</td>\n",
       "      <td>0.184235</td>\n",
       "      <td>0.015895</td>\n",
       "      <td>0.022192</td>\n",
       "      <td>0.009804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.306100</td>\n",
       "      <td>2.272509</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.019564</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.008101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.280000</td>\n",
       "      <td>2.249357</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.260100</td>\n",
       "      <td>2.229105</td>\n",
       "      <td>0.179652</td>\n",
       "      <td>0.023554</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.007615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.243000</td>\n",
       "      <td>2.211770</td>\n",
       "      <td>0.180568</td>\n",
       "      <td>0.043558</td>\n",
       "      <td>0.021037</td>\n",
       "      <td>0.008045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.227800</td>\n",
       "      <td>2.197138</td>\n",
       "      <td>0.186984</td>\n",
       "      <td>0.043584</td>\n",
       "      <td>0.022955</td>\n",
       "      <td>0.011324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.216900</td>\n",
       "      <td>2.184819</td>\n",
       "      <td>0.195234</td>\n",
       "      <td>0.063611</td>\n",
       "      <td>0.025290</td>\n",
       "      <td>0.015081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:57:30,477] Trial 121 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 122 with params: {'learning_rate': 0.000418584161567306, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.1, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:48 < 00:24, 7.10 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.202500</td>\n",
       "      <td>1.905607</td>\n",
       "      <td>0.403300</td>\n",
       "      <td>0.073531</td>\n",
       "      <td>0.088277</td>\n",
       "      <td>0.065749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.705700</td>\n",
       "      <td>1.476166</td>\n",
       "      <td>0.540788</td>\n",
       "      <td>0.174127</td>\n",
       "      <td>0.172028</td>\n",
       "      <td>0.153064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.325300</td>\n",
       "      <td>1.179695</td>\n",
       "      <td>0.651696</td>\n",
       "      <td>0.257309</td>\n",
       "      <td>0.253579</td>\n",
       "      <td>0.234173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.056100</td>\n",
       "      <td>1.017848</td>\n",
       "      <td>0.685610</td>\n",
       "      <td>0.259739</td>\n",
       "      <td>0.287532</td>\n",
       "      <td>0.264159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.872200</td>\n",
       "      <td>0.916413</td>\n",
       "      <td>0.713107</td>\n",
       "      <td>0.311512</td>\n",
       "      <td>0.319719</td>\n",
       "      <td>0.299166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.735500</td>\n",
       "      <td>0.839979</td>\n",
       "      <td>0.723190</td>\n",
       "      <td>0.363084</td>\n",
       "      <td>0.338025</td>\n",
       "      <td>0.320886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.633900</td>\n",
       "      <td>0.808804</td>\n",
       "      <td>0.727773</td>\n",
       "      <td>0.378891</td>\n",
       "      <td>0.350098</td>\n",
       "      <td>0.339506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.571100</td>\n",
       "      <td>0.778918</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.387307</td>\n",
       "      <td>0.392804</td>\n",
       "      <td>0.375039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.515200</td>\n",
       "      <td>0.758153</td>\n",
       "      <td>0.747938</td>\n",
       "      <td>0.407970</td>\n",
       "      <td>0.389683</td>\n",
       "      <td>0.378848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.465400</td>\n",
       "      <td>0.749421</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.438800</td>\n",
       "      <td>0.406638</td>\n",
       "      <td>0.399811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:58:20,483] Trial 122 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 123 with params: {'learning_rate': 0.0004842140345505916, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.9, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:18, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.177900</td>\n",
       "      <td>1.849738</td>\n",
       "      <td>0.425298</td>\n",
       "      <td>0.063474</td>\n",
       "      <td>0.101545</td>\n",
       "      <td>0.074792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.635400</td>\n",
       "      <td>1.397776</td>\n",
       "      <td>0.563703</td>\n",
       "      <td>0.196703</td>\n",
       "      <td>0.199565</td>\n",
       "      <td>0.177199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.234500</td>\n",
       "      <td>1.106752</td>\n",
       "      <td>0.659028</td>\n",
       "      <td>0.255866</td>\n",
       "      <td>0.267992</td>\n",
       "      <td>0.245459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.965200</td>\n",
       "      <td>0.949871</td>\n",
       "      <td>0.698442</td>\n",
       "      <td>0.282674</td>\n",
       "      <td>0.300276</td>\n",
       "      <td>0.278727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.786200</td>\n",
       "      <td>0.866455</td>\n",
       "      <td>0.719523</td>\n",
       "      <td>0.330212</td>\n",
       "      <td>0.332944</td>\n",
       "      <td>0.309170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.660100</td>\n",
       "      <td>0.803141</td>\n",
       "      <td>0.726856</td>\n",
       "      <td>0.389018</td>\n",
       "      <td>0.359419</td>\n",
       "      <td>0.347325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.564400</td>\n",
       "      <td>0.783099</td>\n",
       "      <td>0.739688</td>\n",
       "      <td>0.397866</td>\n",
       "      <td>0.381701</td>\n",
       "      <td>0.371000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.505600</td>\n",
       "      <td>0.751764</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.418280</td>\n",
       "      <td>0.400492</td>\n",
       "      <td>0.387741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.451900</td>\n",
       "      <td>0.734034</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.445303</td>\n",
       "      <td>0.424516</td>\n",
       "      <td>0.421469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.723372</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.471597</td>\n",
       "      <td>0.428053</td>\n",
       "      <td>0.429272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.376700</td>\n",
       "      <td>0.707728</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.486610</td>\n",
       "      <td>0.442640</td>\n",
       "      <td>0.438915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.349200</td>\n",
       "      <td>0.694625</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.534166</td>\n",
       "      <td>0.451209</td>\n",
       "      <td>0.459677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.330200</td>\n",
       "      <td>0.688520</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.475801</td>\n",
       "      <td>0.452233</td>\n",
       "      <td>0.451095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.319500</td>\n",
       "      <td>0.683354</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.521688</td>\n",
       "      <td>0.462481</td>\n",
       "      <td>0.465188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.317600</td>\n",
       "      <td>0.685368</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.518054</td>\n",
       "      <td>0.467118</td>\n",
       "      <td>0.470783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:59:41,057] Trial 123 finished with value: 0.47078326689420136 and parameters: {'learning_rate': 0.0004842140345505916, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.9, 'temperature': 4.0}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 124 with params: {'learning_rate': 0.0003444978864092439, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 1.0, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:31 < 01:04, 5.43 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.231300</td>\n",
       "      <td>1.968190</td>\n",
       "      <td>0.385885</td>\n",
       "      <td>0.061795</td>\n",
       "      <td>0.082009</td>\n",
       "      <td>0.063576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.793800</td>\n",
       "      <td>1.578331</td>\n",
       "      <td>0.506874</td>\n",
       "      <td>0.137458</td>\n",
       "      <td>0.148889</td>\n",
       "      <td>0.125299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.445300</td>\n",
       "      <td>1.290738</td>\n",
       "      <td>0.604950</td>\n",
       "      <td>0.226067</td>\n",
       "      <td>0.215515</td>\n",
       "      <td>0.197757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.182600</td>\n",
       "      <td>1.117226</td>\n",
       "      <td>0.669111</td>\n",
       "      <td>0.261782</td>\n",
       "      <td>0.272704</td>\n",
       "      <td>0.254868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.000700</td>\n",
       "      <td>0.998098</td>\n",
       "      <td>0.695692</td>\n",
       "      <td>0.286423</td>\n",
       "      <td>0.296231</td>\n",
       "      <td>0.272082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:00:13,893] Trial 124 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 125 with params: {'learning_rate': 0.0003258457570114764, 'weight_decay': 0.004, 'warmup_steps': 4, 'lambda_param': 0.8, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:52 < 00:26, 6.68 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.239000</td>\n",
       "      <td>1.984457</td>\n",
       "      <td>0.374885</td>\n",
       "      <td>0.064579</td>\n",
       "      <td>0.077868</td>\n",
       "      <td>0.062361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.817700</td>\n",
       "      <td>1.607312</td>\n",
       "      <td>0.494042</td>\n",
       "      <td>0.126231</td>\n",
       "      <td>0.141511</td>\n",
       "      <td>0.117093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.479800</td>\n",
       "      <td>1.324634</td>\n",
       "      <td>0.587534</td>\n",
       "      <td>0.227670</td>\n",
       "      <td>0.203934</td>\n",
       "      <td>0.186522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.219400</td>\n",
       "      <td>1.145192</td>\n",
       "      <td>0.659945</td>\n",
       "      <td>0.262460</td>\n",
       "      <td>0.265365</td>\n",
       "      <td>0.249604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.036600</td>\n",
       "      <td>1.021062</td>\n",
       "      <td>0.694775</td>\n",
       "      <td>0.289350</td>\n",
       "      <td>0.293555</td>\n",
       "      <td>0.270900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.888200</td>\n",
       "      <td>0.925907</td>\n",
       "      <td>0.713107</td>\n",
       "      <td>0.299927</td>\n",
       "      <td>0.312893</td>\n",
       "      <td>0.291713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.775700</td>\n",
       "      <td>0.871934</td>\n",
       "      <td>0.710357</td>\n",
       "      <td>0.300823</td>\n",
       "      <td>0.313893</td>\n",
       "      <td>0.293022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.704900</td>\n",
       "      <td>0.837338</td>\n",
       "      <td>0.728689</td>\n",
       "      <td>0.347080</td>\n",
       "      <td>0.345569</td>\n",
       "      <td>0.323645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.645500</td>\n",
       "      <td>0.812694</td>\n",
       "      <td>0.729606</td>\n",
       "      <td>0.365562</td>\n",
       "      <td>0.354423</td>\n",
       "      <td>0.340743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.588700</td>\n",
       "      <td>0.799826</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.378237</td>\n",
       "      <td>0.375056</td>\n",
       "      <td>0.359219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:01:07,015] Trial 125 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 126 with params: {'learning_rate': 0.00040332152063429446, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.0, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:48 < 00:24, 7.21 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.208300</td>\n",
       "      <td>1.918232</td>\n",
       "      <td>0.400550</td>\n",
       "      <td>0.074532</td>\n",
       "      <td>0.087053</td>\n",
       "      <td>0.064880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.722700</td>\n",
       "      <td>1.495339</td>\n",
       "      <td>0.532539</td>\n",
       "      <td>0.170517</td>\n",
       "      <td>0.166710</td>\n",
       "      <td>0.147771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.348000</td>\n",
       "      <td>1.198751</td>\n",
       "      <td>0.645280</td>\n",
       "      <td>0.266429</td>\n",
       "      <td>0.248117</td>\n",
       "      <td>0.228814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>1.036193</td>\n",
       "      <td>0.681943</td>\n",
       "      <td>0.258771</td>\n",
       "      <td>0.285575</td>\n",
       "      <td>0.262273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.896500</td>\n",
       "      <td>0.930834</td>\n",
       "      <td>0.711274</td>\n",
       "      <td>0.301516</td>\n",
       "      <td>0.313573</td>\n",
       "      <td>0.292473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.756500</td>\n",
       "      <td>0.848140</td>\n",
       "      <td>0.727773</td>\n",
       "      <td>0.359272</td>\n",
       "      <td>0.335866</td>\n",
       "      <td>0.318660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.652100</td>\n",
       "      <td>0.812990</td>\n",
       "      <td>0.725023</td>\n",
       "      <td>0.363018</td>\n",
       "      <td>0.345513</td>\n",
       "      <td>0.332344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.587600</td>\n",
       "      <td>0.784478</td>\n",
       "      <td>0.747938</td>\n",
       "      <td>0.392885</td>\n",
       "      <td>0.381224</td>\n",
       "      <td>0.363668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.531800</td>\n",
       "      <td>0.763706</td>\n",
       "      <td>0.747938</td>\n",
       "      <td>0.405793</td>\n",
       "      <td>0.389666</td>\n",
       "      <td>0.377624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.481200</td>\n",
       "      <td>0.755469</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.457829</td>\n",
       "      <td>0.402543</td>\n",
       "      <td>0.396076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:01:56,244] Trial 126 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 127 with params: {'learning_rate': 0.0004757376866892141, 'weight_decay': 0.002, 'warmup_steps': 4, 'lambda_param': 0.9, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:19, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.180900</td>\n",
       "      <td>1.856098</td>\n",
       "      <td>0.424381</td>\n",
       "      <td>0.064607</td>\n",
       "      <td>0.100470</td>\n",
       "      <td>0.074850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.643500</td>\n",
       "      <td>1.406111</td>\n",
       "      <td>0.561870</td>\n",
       "      <td>0.196800</td>\n",
       "      <td>0.196633</td>\n",
       "      <td>0.175416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.245000</td>\n",
       "      <td>1.115526</td>\n",
       "      <td>0.658112</td>\n",
       "      <td>0.257153</td>\n",
       "      <td>0.267504</td>\n",
       "      <td>0.245197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.976200</td>\n",
       "      <td>0.957451</td>\n",
       "      <td>0.696609</td>\n",
       "      <td>0.278284</td>\n",
       "      <td>0.297655</td>\n",
       "      <td>0.275045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.796100</td>\n",
       "      <td>0.871823</td>\n",
       "      <td>0.716774</td>\n",
       "      <td>0.324411</td>\n",
       "      <td>0.330335</td>\n",
       "      <td>0.306757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.668300</td>\n",
       "      <td>0.807910</td>\n",
       "      <td>0.727773</td>\n",
       "      <td>0.380089</td>\n",
       "      <td>0.357313</td>\n",
       "      <td>0.345095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.572700</td>\n",
       "      <td>0.785188</td>\n",
       "      <td>0.736939</td>\n",
       "      <td>0.394580</td>\n",
       "      <td>0.379581</td>\n",
       "      <td>0.367213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.513400</td>\n",
       "      <td>0.759338</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.422484</td>\n",
       "      <td>0.399313</td>\n",
       "      <td>0.387624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.459800</td>\n",
       "      <td>0.736806</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.441206</td>\n",
       "      <td>0.419357</td>\n",
       "      <td>0.414326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.411000</td>\n",
       "      <td>0.723010</td>\n",
       "      <td>0.755270</td>\n",
       "      <td>0.477052</td>\n",
       "      <td>0.426170</td>\n",
       "      <td>0.427166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.383000</td>\n",
       "      <td>0.709358</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.482860</td>\n",
       "      <td>0.440535</td>\n",
       "      <td>0.435678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.355200</td>\n",
       "      <td>0.695598</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.528981</td>\n",
       "      <td>0.445775</td>\n",
       "      <td>0.454717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>0.689780</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.477915</td>\n",
       "      <td>0.451707</td>\n",
       "      <td>0.451695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.325500</td>\n",
       "      <td>0.684779</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.525207</td>\n",
       "      <td>0.462306</td>\n",
       "      <td>0.464290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.323700</td>\n",
       "      <td>0.686723</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.524578</td>\n",
       "      <td>0.465730</td>\n",
       "      <td>0.470238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:03:16,944] Trial 127 finished with value: 0.47023782805672404 and parameters: {'learning_rate': 0.0004757376866892141, 'weight_decay': 0.002, 'warmup_steps': 4, 'lambda_param': 0.9, 'temperature': 4.5}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 128 with params: {'learning_rate': 0.00040001163209461567, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.9, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.209600</td>\n",
       "      <td>1.920930</td>\n",
       "      <td>0.400550</td>\n",
       "      <td>0.074670</td>\n",
       "      <td>0.087053</td>\n",
       "      <td>0.064972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.726400</td>\n",
       "      <td>1.499497</td>\n",
       "      <td>0.530706</td>\n",
       "      <td>0.169612</td>\n",
       "      <td>0.165969</td>\n",
       "      <td>0.146871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.353000</td>\n",
       "      <td>1.203082</td>\n",
       "      <td>0.643446</td>\n",
       "      <td>0.246017</td>\n",
       "      <td>0.246325</td>\n",
       "      <td>0.225758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.085000</td>\n",
       "      <td>1.039918</td>\n",
       "      <td>0.682860</td>\n",
       "      <td>0.260677</td>\n",
       "      <td>0.285441</td>\n",
       "      <td>0.263147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.901700</td>\n",
       "      <td>0.933989</td>\n",
       "      <td>0.710357</td>\n",
       "      <td>0.300679</td>\n",
       "      <td>0.313119</td>\n",
       "      <td>0.291789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.761100</td>\n",
       "      <td>0.850001</td>\n",
       "      <td>0.725023</td>\n",
       "      <td>0.357537</td>\n",
       "      <td>0.334005</td>\n",
       "      <td>0.316888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.656100</td>\n",
       "      <td>0.814133</td>\n",
       "      <td>0.723190</td>\n",
       "      <td>0.357899</td>\n",
       "      <td>0.343409</td>\n",
       "      <td>0.328337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.591300</td>\n",
       "      <td>0.785754</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.393159</td>\n",
       "      <td>0.380645</td>\n",
       "      <td>0.363364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.535500</td>\n",
       "      <td>0.763915</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.409947</td>\n",
       "      <td>0.386809</td>\n",
       "      <td>0.376662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.484800</td>\n",
       "      <td>0.757353</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.457396</td>\n",
       "      <td>0.401843</td>\n",
       "      <td>0.395471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.456300</td>\n",
       "      <td>0.735494</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.458709</td>\n",
       "      <td>0.410504</td>\n",
       "      <td>0.407885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.422600</td>\n",
       "      <td>0.723660</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.463144</td>\n",
       "      <td>0.413684</td>\n",
       "      <td>0.411795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.406600</td>\n",
       "      <td>0.718679</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.476857</td>\n",
       "      <td>0.426434</td>\n",
       "      <td>0.426098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.393900</td>\n",
       "      <td>0.713155</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.482082</td>\n",
       "      <td>0.436357</td>\n",
       "      <td>0.433789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.390100</td>\n",
       "      <td>0.714822</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.497377</td>\n",
       "      <td>0.446501</td>\n",
       "      <td>0.448181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:04:32,318] Trial 128 finished with value: 0.4481808081500425 and parameters: {'learning_rate': 0.00040001163209461567, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.9, 'temperature': 3.5}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 129 with params: {'learning_rate': 0.0004968336400777481, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.30000000000000004, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.173300</td>\n",
       "      <td>1.840518</td>\n",
       "      <td>0.428964</td>\n",
       "      <td>0.062722</td>\n",
       "      <td>0.103414</td>\n",
       "      <td>0.075170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.623600</td>\n",
       "      <td>1.385929</td>\n",
       "      <td>0.564620</td>\n",
       "      <td>0.195633</td>\n",
       "      <td>0.199984</td>\n",
       "      <td>0.176809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.219500</td>\n",
       "      <td>1.093803</td>\n",
       "      <td>0.665445</td>\n",
       "      <td>0.282065</td>\n",
       "      <td>0.276518</td>\n",
       "      <td>0.256219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.948500</td>\n",
       "      <td>0.937681</td>\n",
       "      <td>0.702108</td>\n",
       "      <td>0.296723</td>\n",
       "      <td>0.303333</td>\n",
       "      <td>0.283826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.771700</td>\n",
       "      <td>0.858738</td>\n",
       "      <td>0.720440</td>\n",
       "      <td>0.322614</td>\n",
       "      <td>0.335040</td>\n",
       "      <td>0.310034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.651300</td>\n",
       "      <td>0.800977</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.415880</td>\n",
       "      <td>0.373541</td>\n",
       "      <td>0.366093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.555500</td>\n",
       "      <td>0.772267</td>\n",
       "      <td>0.741522</td>\n",
       "      <td>0.387173</td>\n",
       "      <td>0.380863</td>\n",
       "      <td>0.367530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.496500</td>\n",
       "      <td>0.747359</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.426863</td>\n",
       "      <td>0.403118</td>\n",
       "      <td>0.391107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.442700</td>\n",
       "      <td>0.727230</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.444287</td>\n",
       "      <td>0.425843</td>\n",
       "      <td>0.421699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.719177</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.469881</td>\n",
       "      <td>0.426126</td>\n",
       "      <td>0.426968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.367300</td>\n",
       "      <td>0.703604</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>0.454296</td>\n",
       "      <td>0.454090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.339600</td>\n",
       "      <td>0.691703</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.536689</td>\n",
       "      <td>0.452743</td>\n",
       "      <td>0.460354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.322100</td>\n",
       "      <td>0.685634</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.498577</td>\n",
       "      <td>0.459406</td>\n",
       "      <td>0.462482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.311200</td>\n",
       "      <td>0.680642</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.527383</td>\n",
       "      <td>0.466958</td>\n",
       "      <td>0.471862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.308300</td>\n",
       "      <td>0.682786</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.502589</td>\n",
       "      <td>0.470482</td>\n",
       "      <td>0.471320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:05:48,144] Trial 129 finished with value: 0.4713200881499334 and parameters: {'learning_rate': 0.0004968336400777481, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.30000000000000004, 'temperature': 2.0}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 130 with params: {'learning_rate': 0.0004961264572494048, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 0.1, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:15, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.173500</td>\n",
       "      <td>1.840952</td>\n",
       "      <td>0.428964</td>\n",
       "      <td>0.062722</td>\n",
       "      <td>0.103414</td>\n",
       "      <td>0.075170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.624200</td>\n",
       "      <td>1.386488</td>\n",
       "      <td>0.564620</td>\n",
       "      <td>0.194155</td>\n",
       "      <td>0.199984</td>\n",
       "      <td>0.176636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.220300</td>\n",
       "      <td>1.094471</td>\n",
       "      <td>0.664528</td>\n",
       "      <td>0.276888</td>\n",
       "      <td>0.274851</td>\n",
       "      <td>0.253609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.949500</td>\n",
       "      <td>0.938390</td>\n",
       "      <td>0.703025</td>\n",
       "      <td>0.297744</td>\n",
       "      <td>0.303787</td>\n",
       "      <td>0.284664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.772300</td>\n",
       "      <td>0.858599</td>\n",
       "      <td>0.718607</td>\n",
       "      <td>0.332603</td>\n",
       "      <td>0.335883</td>\n",
       "      <td>0.310268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.649900</td>\n",
       "      <td>0.798703</td>\n",
       "      <td>0.736939</td>\n",
       "      <td>0.416839</td>\n",
       "      <td>0.373694</td>\n",
       "      <td>0.366858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.555600</td>\n",
       "      <td>0.773601</td>\n",
       "      <td>0.741522</td>\n",
       "      <td>0.389706</td>\n",
       "      <td>0.386837</td>\n",
       "      <td>0.371735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.497200</td>\n",
       "      <td>0.748331</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.431829</td>\n",
       "      <td>0.405170</td>\n",
       "      <td>0.393725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.442500</td>\n",
       "      <td>0.731629</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.447899</td>\n",
       "      <td>0.430514</td>\n",
       "      <td>0.426107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.719961</td>\n",
       "      <td>0.757104</td>\n",
       "      <td>0.488754</td>\n",
       "      <td>0.429283</td>\n",
       "      <td>0.432529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.367600</td>\n",
       "      <td>0.704690</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.505635</td>\n",
       "      <td>0.449500</td>\n",
       "      <td>0.448143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.339700</td>\n",
       "      <td>0.692891</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.539287</td>\n",
       "      <td>0.453093</td>\n",
       "      <td>0.460331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.321800</td>\n",
       "      <td>0.687210</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.497189</td>\n",
       "      <td>0.461729</td>\n",
       "      <td>0.462518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.311100</td>\n",
       "      <td>0.681610</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.520482</td>\n",
       "      <td>0.467413</td>\n",
       "      <td>0.471887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.308500</td>\n",
       "      <td>0.684035</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.515098</td>\n",
       "      <td>0.468615</td>\n",
       "      <td>0.469335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:07:05,699] Trial 130 finished with value: 0.46933531708628534 and parameters: {'learning_rate': 0.0004961264572494048, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 0.1, 'temperature': 2.5}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 131 with params: {'learning_rate': 0.0004746453105341743, 'weight_decay': 0.002, 'warmup_steps': 4, 'lambda_param': 0.1, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:15, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.181300</td>\n",
       "      <td>1.856909</td>\n",
       "      <td>0.424381</td>\n",
       "      <td>0.064611</td>\n",
       "      <td>0.100470</td>\n",
       "      <td>0.074857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.644500</td>\n",
       "      <td>1.407100</td>\n",
       "      <td>0.560953</td>\n",
       "      <td>0.195674</td>\n",
       "      <td>0.195681</td>\n",
       "      <td>0.174341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.246300</td>\n",
       "      <td>1.116611</td>\n",
       "      <td>0.658112</td>\n",
       "      <td>0.257483</td>\n",
       "      <td>0.267504</td>\n",
       "      <td>0.245376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.977600</td>\n",
       "      <td>0.958442</td>\n",
       "      <td>0.696609</td>\n",
       "      <td>0.278748</td>\n",
       "      <td>0.297655</td>\n",
       "      <td>0.275239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.797400</td>\n",
       "      <td>0.872522</td>\n",
       "      <td>0.717690</td>\n",
       "      <td>0.325102</td>\n",
       "      <td>0.330823</td>\n",
       "      <td>0.307466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.669400</td>\n",
       "      <td>0.808473</td>\n",
       "      <td>0.727773</td>\n",
       "      <td>0.380679</td>\n",
       "      <td>0.357313</td>\n",
       "      <td>0.345377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.573700</td>\n",
       "      <td>0.785764</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.402136</td>\n",
       "      <td>0.378153</td>\n",
       "      <td>0.366201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.514400</td>\n",
       "      <td>0.759930</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.421728</td>\n",
       "      <td>0.399210</td>\n",
       "      <td>0.387108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.460700</td>\n",
       "      <td>0.737343</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.441206</td>\n",
       "      <td>0.419357</td>\n",
       "      <td>0.414326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.412000</td>\n",
       "      <td>0.723079</td>\n",
       "      <td>0.756187</td>\n",
       "      <td>0.477672</td>\n",
       "      <td>0.426657</td>\n",
       "      <td>0.427703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.383900</td>\n",
       "      <td>0.709537</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.482635</td>\n",
       "      <td>0.439457</td>\n",
       "      <td>0.435152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.356100</td>\n",
       "      <td>0.695827</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.523290</td>\n",
       "      <td>0.446489</td>\n",
       "      <td>0.452999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.336900</td>\n",
       "      <td>0.689940</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.478686</td>\n",
       "      <td>0.452660</td>\n",
       "      <td>0.452526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.326300</td>\n",
       "      <td>0.684943</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.524546</td>\n",
       "      <td>0.462306</td>\n",
       "      <td>0.463958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.324500</td>\n",
       "      <td>0.686857</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.525857</td>\n",
       "      <td>0.466256</td>\n",
       "      <td>0.470821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:08:23,233] Trial 131 finished with value: 0.47082080220104283 and parameters: {'learning_rate': 0.0004746453105341743, 'weight_decay': 0.002, 'warmup_steps': 4, 'lambda_param': 0.1, 'temperature': 3.0}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 132 with params: {'learning_rate': 0.0004546368061268981, 'weight_decay': 0.001, 'warmup_steps': 3, 'lambda_param': 0.1, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.180700</td>\n",
       "      <td>1.869444</td>\n",
       "      <td>0.423465</td>\n",
       "      <td>0.066127</td>\n",
       "      <td>0.098794</td>\n",
       "      <td>0.074932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.665200</td>\n",
       "      <td>1.438285</td>\n",
       "      <td>0.549038</td>\n",
       "      <td>0.196912</td>\n",
       "      <td>0.182228</td>\n",
       "      <td>0.163778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.279200</td>\n",
       "      <td>1.142356</td>\n",
       "      <td>0.652612</td>\n",
       "      <td>0.240361</td>\n",
       "      <td>0.256435</td>\n",
       "      <td>0.234318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.006600</td>\n",
       "      <td>0.978768</td>\n",
       "      <td>0.686526</td>\n",
       "      <td>0.271471</td>\n",
       "      <td>0.288104</td>\n",
       "      <td>0.262709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.822100</td>\n",
       "      <td>0.885067</td>\n",
       "      <td>0.714024</td>\n",
       "      <td>0.299063</td>\n",
       "      <td>0.320099</td>\n",
       "      <td>0.295102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.690600</td>\n",
       "      <td>0.816624</td>\n",
       "      <td>0.725023</td>\n",
       "      <td>0.367708</td>\n",
       "      <td>0.345978</td>\n",
       "      <td>0.329912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.593700</td>\n",
       "      <td>0.797244</td>\n",
       "      <td>0.728689</td>\n",
       "      <td>0.363053</td>\n",
       "      <td>0.361625</td>\n",
       "      <td>0.344725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.534600</td>\n",
       "      <td>0.763333</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.412512</td>\n",
       "      <td>0.399687</td>\n",
       "      <td>0.388253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.482400</td>\n",
       "      <td>0.745066</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.428331</td>\n",
       "      <td>0.407578</td>\n",
       "      <td>0.401389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.432600</td>\n",
       "      <td>0.734264</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.438311</td>\n",
       "      <td>0.417913</td>\n",
       "      <td>0.408510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.406300</td>\n",
       "      <td>0.713224</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.445398</td>\n",
       "      <td>0.426265</td>\n",
       "      <td>0.418756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.375500</td>\n",
       "      <td>0.702348</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.471008</td>\n",
       "      <td>0.430847</td>\n",
       "      <td>0.430061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.357900</td>\n",
       "      <td>0.695524</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.472963</td>\n",
       "      <td>0.443010</td>\n",
       "      <td>0.441040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.345700</td>\n",
       "      <td>0.692475</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.465268</td>\n",
       "      <td>0.449256</td>\n",
       "      <td>0.442708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.343400</td>\n",
       "      <td>0.693177</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.506101</td>\n",
       "      <td>0.464793</td>\n",
       "      <td>0.464530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:09:37,376] Trial 132 finished with value: 0.46453030960093045 and parameters: {'learning_rate': 0.0004546368061268981, 'weight_decay': 0.001, 'warmup_steps': 3, 'lambda_param': 0.1, 'temperature': 3.5}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 133 with params: {'learning_rate': 0.0004343254498789213, 'weight_decay': 0.0, 'warmup_steps': 4, 'lambda_param': 0.1, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.196500</td>\n",
       "      <td>1.891641</td>\n",
       "      <td>0.412466</td>\n",
       "      <td>0.069774</td>\n",
       "      <td>0.092601</td>\n",
       "      <td>0.070009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.688100</td>\n",
       "      <td>1.455093</td>\n",
       "      <td>0.554537</td>\n",
       "      <td>0.181866</td>\n",
       "      <td>0.187158</td>\n",
       "      <td>0.167953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.302300</td>\n",
       "      <td>1.160605</td>\n",
       "      <td>0.650779</td>\n",
       "      <td>0.257907</td>\n",
       "      <td>0.255250</td>\n",
       "      <td>0.236132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.032800</td>\n",
       "      <td>0.997520</td>\n",
       "      <td>0.691109</td>\n",
       "      <td>0.277818</td>\n",
       "      <td>0.297225</td>\n",
       "      <td>0.276462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.848600</td>\n",
       "      <td>0.901430</td>\n",
       "      <td>0.715857</td>\n",
       "      <td>0.347643</td>\n",
       "      <td>0.326900</td>\n",
       "      <td>0.305897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.715400</td>\n",
       "      <td>0.829492</td>\n",
       "      <td>0.720440</td>\n",
       "      <td>0.352830</td>\n",
       "      <td>0.338738</td>\n",
       "      <td>0.321507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.615500</td>\n",
       "      <td>0.801721</td>\n",
       "      <td>0.732356</td>\n",
       "      <td>0.375084</td>\n",
       "      <td>0.363808</td>\n",
       "      <td>0.349407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.554600</td>\n",
       "      <td>0.770419</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.388079</td>\n",
       "      <td>0.391659</td>\n",
       "      <td>0.374346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.498900</td>\n",
       "      <td>0.750473</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.435231</td>\n",
       "      <td>0.407458</td>\n",
       "      <td>0.400070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.449300</td>\n",
       "      <td>0.742710</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.436646</td>\n",
       "      <td>0.411012</td>\n",
       "      <td>0.401837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.421300</td>\n",
       "      <td>0.723554</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.461782</td>\n",
       "      <td>0.426127</td>\n",
       "      <td>0.421432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.391000</td>\n",
       "      <td>0.709295</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.466351</td>\n",
       "      <td>0.427339</td>\n",
       "      <td>0.426564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>0.702580</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.480202</td>\n",
       "      <td>0.438914</td>\n",
       "      <td>0.436673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.360600</td>\n",
       "      <td>0.697419</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.464108</td>\n",
       "      <td>0.445847</td>\n",
       "      <td>0.438102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.358000</td>\n",
       "      <td>0.698974</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.469044</td>\n",
       "      <td>0.447590</td>\n",
       "      <td>0.440496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:10:52,114] Trial 133 finished with value: 0.44049558966674146 and parameters: {'learning_rate': 0.0004343254498789213, 'weight_decay': 0.0, 'warmup_steps': 4, 'lambda_param': 0.1, 'temperature': 3.0}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 134 with params: {'learning_rate': 9.499899727306372e-05, 'weight_decay': 0.005, 'warmup_steps': 1, 'lambda_param': 0.2, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:24 < 00:48, 7.19 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.362700</td>\n",
       "      <td>2.243520</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.186000</td>\n",
       "      <td>2.087139</td>\n",
       "      <td>0.316224</td>\n",
       "      <td>0.071651</td>\n",
       "      <td>0.060585</td>\n",
       "      <td>0.054272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.051600</td>\n",
       "      <td>1.954155</td>\n",
       "      <td>0.408799</td>\n",
       "      <td>0.052207</td>\n",
       "      <td>0.087914</td>\n",
       "      <td>0.063164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.921500</td>\n",
       "      <td>1.832315</td>\n",
       "      <td>0.442713</td>\n",
       "      <td>0.101040</td>\n",
       "      <td>0.105226</td>\n",
       "      <td>0.081954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.816500</td>\n",
       "      <td>1.726509</td>\n",
       "      <td>0.477544</td>\n",
       "      <td>0.103762</td>\n",
       "      <td>0.128544</td>\n",
       "      <td>0.104752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:11:17,062] Trial 134 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 135 with params: {'learning_rate': 0.0004991786459085929, 'weight_decay': 0.003, 'warmup_steps': 3, 'lambda_param': 0.2, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:11, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.162800</td>\n",
       "      <td>1.831679</td>\n",
       "      <td>0.431714</td>\n",
       "      <td>0.062517</td>\n",
       "      <td>0.104882</td>\n",
       "      <td>0.075818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.617900</td>\n",
       "      <td>1.388214</td>\n",
       "      <td>0.562786</td>\n",
       "      <td>0.195956</td>\n",
       "      <td>0.199441</td>\n",
       "      <td>0.176049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.220700</td>\n",
       "      <td>1.101162</td>\n",
       "      <td>0.661778</td>\n",
       "      <td>0.284292</td>\n",
       "      <td>0.271952</td>\n",
       "      <td>0.252769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.954000</td>\n",
       "      <td>0.945199</td>\n",
       "      <td>0.692942</td>\n",
       "      <td>0.275408</td>\n",
       "      <td>0.295327</td>\n",
       "      <td>0.273672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.774900</td>\n",
       "      <td>0.861178</td>\n",
       "      <td>0.717690</td>\n",
       "      <td>0.335458</td>\n",
       "      <td>0.332717</td>\n",
       "      <td>0.308968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.651300</td>\n",
       "      <td>0.801770</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.407699</td>\n",
       "      <td>0.380737</td>\n",
       "      <td>0.371327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>0.778686</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.366250</td>\n",
       "      <td>0.371413</td>\n",
       "      <td>0.354868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.495700</td>\n",
       "      <td>0.748487</td>\n",
       "      <td>0.757104</td>\n",
       "      <td>0.427486</td>\n",
       "      <td>0.413393</td>\n",
       "      <td>0.400291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.442600</td>\n",
       "      <td>0.726614</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.455833</td>\n",
       "      <td>0.424649</td>\n",
       "      <td>0.420483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.396500</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.490804</td>\n",
       "      <td>0.435406</td>\n",
       "      <td>0.434724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.368500</td>\n",
       "      <td>0.700319</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.483211</td>\n",
       "      <td>0.444910</td>\n",
       "      <td>0.441038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.341500</td>\n",
       "      <td>0.687782</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.488823</td>\n",
       "      <td>0.442169</td>\n",
       "      <td>0.443691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.324400</td>\n",
       "      <td>0.682106</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.476255</td>\n",
       "      <td>0.454727</td>\n",
       "      <td>0.453036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.312200</td>\n",
       "      <td>0.679469</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.471250</td>\n",
       "      <td>0.449353</td>\n",
       "      <td>0.447060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.309700</td>\n",
       "      <td>0.680687</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.476818</td>\n",
       "      <td>0.460138</td>\n",
       "      <td>0.455231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:12:30,082] Trial 135 finished with value: 0.45523056288389796 and parameters: {'learning_rate': 0.0004991786459085929, 'weight_decay': 0.003, 'warmup_steps': 3, 'lambda_param': 0.2, 'temperature': 2.5}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 136 with params: {'learning_rate': 0.00041484507008942537, 'weight_decay': 0.004, 'warmup_steps': 4, 'lambda_param': 0.7000000000000001, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:49 < 00:24, 7.10 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.203900</td>\n",
       "      <td>1.908746</td>\n",
       "      <td>0.402383</td>\n",
       "      <td>0.073984</td>\n",
       "      <td>0.087913</td>\n",
       "      <td>0.065781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>1.481056</td>\n",
       "      <td>0.537122</td>\n",
       "      <td>0.172061</td>\n",
       "      <td>0.169364</td>\n",
       "      <td>0.150432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.330900</td>\n",
       "      <td>1.184385</td>\n",
       "      <td>0.652612</td>\n",
       "      <td>0.259296</td>\n",
       "      <td>0.253439</td>\n",
       "      <td>0.234285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.062000</td>\n",
       "      <td>1.022715</td>\n",
       "      <td>0.684693</td>\n",
       "      <td>0.260153</td>\n",
       "      <td>0.287168</td>\n",
       "      <td>0.263956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.878200</td>\n",
       "      <td>0.919853</td>\n",
       "      <td>0.714024</td>\n",
       "      <td>0.315172</td>\n",
       "      <td>0.319957</td>\n",
       "      <td>0.300355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.740700</td>\n",
       "      <td>0.842053</td>\n",
       "      <td>0.722273</td>\n",
       "      <td>0.353090</td>\n",
       "      <td>0.332690</td>\n",
       "      <td>0.314123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.638500</td>\n",
       "      <td>0.809991</td>\n",
       "      <td>0.725940</td>\n",
       "      <td>0.374533</td>\n",
       "      <td>0.347431</td>\n",
       "      <td>0.335881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.575200</td>\n",
       "      <td>0.780747</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.388541</td>\n",
       "      <td>0.388795</td>\n",
       "      <td>0.371673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.519300</td>\n",
       "      <td>0.759493</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.405263</td>\n",
       "      <td>0.389436</td>\n",
       "      <td>0.377315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.469000</td>\n",
       "      <td>0.751190</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.447987</td>\n",
       "      <td>0.401304</td>\n",
       "      <td>0.394225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:13:20,077] Trial 136 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 137 with params: {'learning_rate': 0.0004727216067798781, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.9, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.182000</td>\n",
       "      <td>1.858387</td>\n",
       "      <td>0.424381</td>\n",
       "      <td>0.064738</td>\n",
       "      <td>0.100470</td>\n",
       "      <td>0.074935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.646400</td>\n",
       "      <td>1.409054</td>\n",
       "      <td>0.560037</td>\n",
       "      <td>0.197280</td>\n",
       "      <td>0.193181</td>\n",
       "      <td>0.172396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.248700</td>\n",
       "      <td>1.118658</td>\n",
       "      <td>0.657195</td>\n",
       "      <td>0.256069</td>\n",
       "      <td>0.266595</td>\n",
       "      <td>0.244521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.980100</td>\n",
       "      <td>0.960335</td>\n",
       "      <td>0.692942</td>\n",
       "      <td>0.266915</td>\n",
       "      <td>0.294499</td>\n",
       "      <td>0.270918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.799700</td>\n",
       "      <td>0.873928</td>\n",
       "      <td>0.715857</td>\n",
       "      <td>0.324431</td>\n",
       "      <td>0.330097</td>\n",
       "      <td>0.306612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.671400</td>\n",
       "      <td>0.809518</td>\n",
       "      <td>0.726856</td>\n",
       "      <td>0.380124</td>\n",
       "      <td>0.355979</td>\n",
       "      <td>0.344106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.575700</td>\n",
       "      <td>0.786982</td>\n",
       "      <td>0.735105</td>\n",
       "      <td>0.401675</td>\n",
       "      <td>0.376614</td>\n",
       "      <td>0.365113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.516300</td>\n",
       "      <td>0.760925</td>\n",
       "      <td>0.744271</td>\n",
       "      <td>0.420899</td>\n",
       "      <td>0.398755</td>\n",
       "      <td>0.386610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.462400</td>\n",
       "      <td>0.738710</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.441772</td>\n",
       "      <td>0.419357</td>\n",
       "      <td>0.414563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.413700</td>\n",
       "      <td>0.723940</td>\n",
       "      <td>0.757104</td>\n",
       "      <td>0.477557</td>\n",
       "      <td>0.427145</td>\n",
       "      <td>0.427883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.385500</td>\n",
       "      <td>0.710276</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.484282</td>\n",
       "      <td>0.439984</td>\n",
       "      <td>0.436280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.357800</td>\n",
       "      <td>0.696532</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.445775</td>\n",
       "      <td>0.452360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.338400</td>\n",
       "      <td>0.690591</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.479130</td>\n",
       "      <td>0.452660</td>\n",
       "      <td>0.452270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.327800</td>\n",
       "      <td>0.685732</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.522699</td>\n",
       "      <td>0.457306</td>\n",
       "      <td>0.460293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.325800</td>\n",
       "      <td>0.687563</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.525951</td>\n",
       "      <td>0.467208</td>\n",
       "      <td>0.471367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:14:33,799] Trial 137 finished with value: 0.47136743691502486 and parameters: {'learning_rate': 0.0004727216067798781, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.9, 'temperature': 4.0}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 138 with params: {'learning_rate': 0.0004965729592855284, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 0.2, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.173400</td>\n",
       "      <td>1.840650</td>\n",
       "      <td>0.428964</td>\n",
       "      <td>0.062722</td>\n",
       "      <td>0.103414</td>\n",
       "      <td>0.075170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.623800</td>\n",
       "      <td>1.386068</td>\n",
       "      <td>0.564620</td>\n",
       "      <td>0.195633</td>\n",
       "      <td>0.199984</td>\n",
       "      <td>0.176809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.219700</td>\n",
       "      <td>1.094040</td>\n",
       "      <td>0.665445</td>\n",
       "      <td>0.282065</td>\n",
       "      <td>0.276518</td>\n",
       "      <td>0.256219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.948800</td>\n",
       "      <td>0.938014</td>\n",
       "      <td>0.702108</td>\n",
       "      <td>0.296793</td>\n",
       "      <td>0.303333</td>\n",
       "      <td>0.283900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.771900</td>\n",
       "      <td>0.859703</td>\n",
       "      <td>0.718607</td>\n",
       "      <td>0.322112</td>\n",
       "      <td>0.335749</td>\n",
       "      <td>0.310131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.800055</td>\n",
       "      <td>0.736939</td>\n",
       "      <td>0.414774</td>\n",
       "      <td>0.373468</td>\n",
       "      <td>0.365710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.555400</td>\n",
       "      <td>0.775427</td>\n",
       "      <td>0.740605</td>\n",
       "      <td>0.387788</td>\n",
       "      <td>0.381963</td>\n",
       "      <td>0.369045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.497400</td>\n",
       "      <td>0.749827</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.424616</td>\n",
       "      <td>0.401173</td>\n",
       "      <td>0.389054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.442500</td>\n",
       "      <td>0.730373</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.455701</td>\n",
       "      <td>0.425194</td>\n",
       "      <td>0.422105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.394700</td>\n",
       "      <td>0.717418</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.483532</td>\n",
       "      <td>0.430109</td>\n",
       "      <td>0.431996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.367300</td>\n",
       "      <td>0.703531</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.505411</td>\n",
       "      <td>0.449011</td>\n",
       "      <td>0.447568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.339900</td>\n",
       "      <td>0.692829</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.531725</td>\n",
       "      <td>0.452175</td>\n",
       "      <td>0.458710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.321800</td>\n",
       "      <td>0.687634</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.497832</td>\n",
       "      <td>0.458951</td>\n",
       "      <td>0.461683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.311200</td>\n",
       "      <td>0.682574</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.518852</td>\n",
       "      <td>0.466504</td>\n",
       "      <td>0.470856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.308300</td>\n",
       "      <td>0.685291</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.512182</td>\n",
       "      <td>0.468686</td>\n",
       "      <td>0.468675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:15:49,055] Trial 138 finished with value: 0.46867521275733326 and parameters: {'learning_rate': 0.0004965729592855284, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 0.2, 'temperature': 3.0}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 139 with params: {'learning_rate': 0.00043865666805057785, 'weight_decay': 0.005, 'warmup_steps': 4, 'lambda_param': 1.0, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:49 < 00:24, 7.08 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.194800</td>\n",
       "      <td>1.887768</td>\n",
       "      <td>0.416132</td>\n",
       "      <td>0.070496</td>\n",
       "      <td>0.095182</td>\n",
       "      <td>0.073014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.683400</td>\n",
       "      <td>1.449556</td>\n",
       "      <td>0.555454</td>\n",
       "      <td>0.184139</td>\n",
       "      <td>0.187613</td>\n",
       "      <td>0.168167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.296000</td>\n",
       "      <td>1.155631</td>\n",
       "      <td>0.651696</td>\n",
       "      <td>0.257457</td>\n",
       "      <td>0.255614</td>\n",
       "      <td>0.236702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.026700</td>\n",
       "      <td>0.992806</td>\n",
       "      <td>0.693859</td>\n",
       "      <td>0.278319</td>\n",
       "      <td>0.300242</td>\n",
       "      <td>0.278692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.842900</td>\n",
       "      <td>0.897704</td>\n",
       "      <td>0.716774</td>\n",
       "      <td>0.338521</td>\n",
       "      <td>0.327387</td>\n",
       "      <td>0.306282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.710500</td>\n",
       "      <td>0.827054</td>\n",
       "      <td>0.721357</td>\n",
       "      <td>0.372158</td>\n",
       "      <td>0.344190</td>\n",
       "      <td>0.328964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.610800</td>\n",
       "      <td>0.799805</td>\n",
       "      <td>0.732356</td>\n",
       "      <td>0.371815</td>\n",
       "      <td>0.364713</td>\n",
       "      <td>0.347756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.768211</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.408693</td>\n",
       "      <td>0.395611</td>\n",
       "      <td>0.379655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.494500</td>\n",
       "      <td>0.750256</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.430504</td>\n",
       "      <td>0.408861</td>\n",
       "      <td>0.399134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.445000</td>\n",
       "      <td>0.740452</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.438244</td>\n",
       "      <td>0.411860</td>\n",
       "      <td>0.404109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:16:39,058] Trial 139 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 140 with params: {'learning_rate': 0.0003224275665351777, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 0.8, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:49 < 00:24, 7.10 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.240500</td>\n",
       "      <td>1.987523</td>\n",
       "      <td>0.373969</td>\n",
       "      <td>0.064933</td>\n",
       "      <td>0.077505</td>\n",
       "      <td>0.062292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.822300</td>\n",
       "      <td>1.612869</td>\n",
       "      <td>0.492209</td>\n",
       "      <td>0.122387</td>\n",
       "      <td>0.139789</td>\n",
       "      <td>0.114878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.486400</td>\n",
       "      <td>1.331138</td>\n",
       "      <td>0.584785</td>\n",
       "      <td>0.226077</td>\n",
       "      <td>0.200490</td>\n",
       "      <td>0.182777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.226400</td>\n",
       "      <td>1.150571</td>\n",
       "      <td>0.661778</td>\n",
       "      <td>0.264255</td>\n",
       "      <td>0.265841</td>\n",
       "      <td>0.250296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.043500</td>\n",
       "      <td>1.025578</td>\n",
       "      <td>0.694775</td>\n",
       "      <td>0.289472</td>\n",
       "      <td>0.293555</td>\n",
       "      <td>0.270825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.894900</td>\n",
       "      <td>0.930437</td>\n",
       "      <td>0.710357</td>\n",
       "      <td>0.298029</td>\n",
       "      <td>0.308329</td>\n",
       "      <td>0.289271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.782100</td>\n",
       "      <td>0.875536</td>\n",
       "      <td>0.707608</td>\n",
       "      <td>0.298467</td>\n",
       "      <td>0.310462</td>\n",
       "      <td>0.288531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.711100</td>\n",
       "      <td>0.840071</td>\n",
       "      <td>0.728689</td>\n",
       "      <td>0.346588</td>\n",
       "      <td>0.343415</td>\n",
       "      <td>0.322254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.651400</td>\n",
       "      <td>0.815769</td>\n",
       "      <td>0.730522</td>\n",
       "      <td>0.365922</td>\n",
       "      <td>0.354877</td>\n",
       "      <td>0.341150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.594400</td>\n",
       "      <td>0.801714</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.377709</td>\n",
       "      <td>0.370511</td>\n",
       "      <td>0.354618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:17:29,006] Trial 140 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 141 with params: {'learning_rate': 0.0004185746031446022, 'weight_decay': 0.002, 'warmup_steps': 4, 'lambda_param': 0.2, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:48 < 00:24, 7.25 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.202500</td>\n",
       "      <td>1.905607</td>\n",
       "      <td>0.403300</td>\n",
       "      <td>0.073531</td>\n",
       "      <td>0.088277</td>\n",
       "      <td>0.065749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.705800</td>\n",
       "      <td>1.476161</td>\n",
       "      <td>0.540788</td>\n",
       "      <td>0.174127</td>\n",
       "      <td>0.172028</td>\n",
       "      <td>0.153064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.325300</td>\n",
       "      <td>1.179683</td>\n",
       "      <td>0.649863</td>\n",
       "      <td>0.256913</td>\n",
       "      <td>0.252689</td>\n",
       "      <td>0.233266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.056000</td>\n",
       "      <td>1.017750</td>\n",
       "      <td>0.684693</td>\n",
       "      <td>0.259493</td>\n",
       "      <td>0.287168</td>\n",
       "      <td>0.263807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.872100</td>\n",
       "      <td>0.916379</td>\n",
       "      <td>0.713107</td>\n",
       "      <td>0.313993</td>\n",
       "      <td>0.319719</td>\n",
       "      <td>0.299414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.735400</td>\n",
       "      <td>0.839981</td>\n",
       "      <td>0.723190</td>\n",
       "      <td>0.363084</td>\n",
       "      <td>0.338025</td>\n",
       "      <td>0.320886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.633900</td>\n",
       "      <td>0.808757</td>\n",
       "      <td>0.727773</td>\n",
       "      <td>0.378959</td>\n",
       "      <td>0.350098</td>\n",
       "      <td>0.339617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.571100</td>\n",
       "      <td>0.778867</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.387307</td>\n",
       "      <td>0.392804</td>\n",
       "      <td>0.375039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>0.758153</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.407715</td>\n",
       "      <td>0.389580</td>\n",
       "      <td>0.378649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.465300</td>\n",
       "      <td>0.749439</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.438800</td>\n",
       "      <td>0.406638</td>\n",
       "      <td>0.399811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:18:18,510] Trial 141 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 142 with params: {'learning_rate': 0.0003206381591668457, 'weight_decay': 0.002, 'warmup_steps': 4, 'lambda_param': 0.2, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:47 < 00:23, 7.33 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.241200</td>\n",
       "      <td>1.989120</td>\n",
       "      <td>0.373969</td>\n",
       "      <td>0.064958</td>\n",
       "      <td>0.077505</td>\n",
       "      <td>0.062316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.824700</td>\n",
       "      <td>1.615804</td>\n",
       "      <td>0.492209</td>\n",
       "      <td>0.122713</td>\n",
       "      <td>0.139550</td>\n",
       "      <td>0.114587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.489900</td>\n",
       "      <td>1.334566</td>\n",
       "      <td>0.582951</td>\n",
       "      <td>0.225471</td>\n",
       "      <td>0.198769</td>\n",
       "      <td>0.181674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.230100</td>\n",
       "      <td>1.153415</td>\n",
       "      <td>0.661778</td>\n",
       "      <td>0.264012</td>\n",
       "      <td>0.265841</td>\n",
       "      <td>0.250229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.047200</td>\n",
       "      <td>1.028021</td>\n",
       "      <td>0.693859</td>\n",
       "      <td>0.285962</td>\n",
       "      <td>0.292127</td>\n",
       "      <td>0.268461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.898400</td>\n",
       "      <td>0.932894</td>\n",
       "      <td>0.708524</td>\n",
       "      <td>0.294360</td>\n",
       "      <td>0.305948</td>\n",
       "      <td>0.286344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.785600</td>\n",
       "      <td>0.877531</td>\n",
       "      <td>0.707608</td>\n",
       "      <td>0.299167</td>\n",
       "      <td>0.310462</td>\n",
       "      <td>0.288123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.714400</td>\n",
       "      <td>0.841693</td>\n",
       "      <td>0.727773</td>\n",
       "      <td>0.345554</td>\n",
       "      <td>0.341748</td>\n",
       "      <td>0.320846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.654700</td>\n",
       "      <td>0.817483</td>\n",
       "      <td>0.727773</td>\n",
       "      <td>0.346661</td>\n",
       "      <td>0.347877</td>\n",
       "      <td>0.332055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.597500</td>\n",
       "      <td>0.802790</td>\n",
       "      <td>0.744271</td>\n",
       "      <td>0.377834</td>\n",
       "      <td>0.370147</td>\n",
       "      <td>0.354643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:19:06,979] Trial 142 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 143 with params: {'learning_rate': 0.0004859810790115975, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 0.0, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.177200</td>\n",
       "      <td>1.848341</td>\n",
       "      <td>0.426214</td>\n",
       "      <td>0.063555</td>\n",
       "      <td>0.102190</td>\n",
       "      <td>0.075151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.633700</td>\n",
       "      <td>1.395974</td>\n",
       "      <td>0.562786</td>\n",
       "      <td>0.196219</td>\n",
       "      <td>0.199327</td>\n",
       "      <td>0.176839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.232400</td>\n",
       "      <td>1.104994</td>\n",
       "      <td>0.659945</td>\n",
       "      <td>0.275916</td>\n",
       "      <td>0.269421</td>\n",
       "      <td>0.248171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.962900</td>\n",
       "      <td>0.948524</td>\n",
       "      <td>0.698442</td>\n",
       "      <td>0.282625</td>\n",
       "      <td>0.300276</td>\n",
       "      <td>0.278741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.784200</td>\n",
       "      <td>0.865405</td>\n",
       "      <td>0.719523</td>\n",
       "      <td>0.329515</td>\n",
       "      <td>0.332944</td>\n",
       "      <td>0.309225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.658500</td>\n",
       "      <td>0.802221</td>\n",
       "      <td>0.728689</td>\n",
       "      <td>0.389988</td>\n",
       "      <td>0.360991</td>\n",
       "      <td>0.348580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.563200</td>\n",
       "      <td>0.777701</td>\n",
       "      <td>0.742438</td>\n",
       "      <td>0.398131</td>\n",
       "      <td>0.382381</td>\n",
       "      <td>0.370660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.503500</td>\n",
       "      <td>0.750263</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.422264</td>\n",
       "      <td>0.400601</td>\n",
       "      <td>0.388918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.449600</td>\n",
       "      <td>0.733824</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.444247</td>\n",
       "      <td>0.423521</td>\n",
       "      <td>0.420034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.402400</td>\n",
       "      <td>0.722781</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.472231</td>\n",
       "      <td>0.428995</td>\n",
       "      <td>0.429493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.375900</td>\n",
       "      <td>0.709504</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.484749</td>\n",
       "      <td>0.441224</td>\n",
       "      <td>0.437045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.347800</td>\n",
       "      <td>0.696444</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.538451</td>\n",
       "      <td>0.454995</td>\n",
       "      <td>0.465506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.328800</td>\n",
       "      <td>0.690086</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.496549</td>\n",
       "      <td>0.455303</td>\n",
       "      <td>0.457972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.318500</td>\n",
       "      <td>0.684702</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.526491</td>\n",
       "      <td>0.463930</td>\n",
       "      <td>0.467960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.316700</td>\n",
       "      <td>0.686509</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.515016</td>\n",
       "      <td>0.469827</td>\n",
       "      <td>0.472336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:20:21,794] Trial 143 finished with value: 0.47233594283367625 and parameters: {'learning_rate': 0.0004859810790115975, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 0.0, 'temperature': 2.0}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 144 with params: {'learning_rate': 0.0004372517403740796, 'weight_decay': 0.0, 'warmup_steps': 4, 'lambda_param': 0.0, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:13, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.195300</td>\n",
       "      <td>1.888990</td>\n",
       "      <td>0.414299</td>\n",
       "      <td>0.070184</td>\n",
       "      <td>0.093891</td>\n",
       "      <td>0.071592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.684800</td>\n",
       "      <td>1.451297</td>\n",
       "      <td>0.554537</td>\n",
       "      <td>0.184196</td>\n",
       "      <td>0.187158</td>\n",
       "      <td>0.167930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.298000</td>\n",
       "      <td>1.157188</td>\n",
       "      <td>0.651696</td>\n",
       "      <td>0.256883</td>\n",
       "      <td>0.255614</td>\n",
       "      <td>0.236429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.028600</td>\n",
       "      <td>0.994267</td>\n",
       "      <td>0.692942</td>\n",
       "      <td>0.278341</td>\n",
       "      <td>0.299290</td>\n",
       "      <td>0.278242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.844600</td>\n",
       "      <td>0.898899</td>\n",
       "      <td>0.716774</td>\n",
       "      <td>0.338846</td>\n",
       "      <td>0.327387</td>\n",
       "      <td>0.306617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>0.827756</td>\n",
       "      <td>0.720440</td>\n",
       "      <td>0.352083</td>\n",
       "      <td>0.338738</td>\n",
       "      <td>0.321122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.612200</td>\n",
       "      <td>0.800445</td>\n",
       "      <td>0.732356</td>\n",
       "      <td>0.372481</td>\n",
       "      <td>0.364713</td>\n",
       "      <td>0.348254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.551500</td>\n",
       "      <td>0.768985</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.388723</td>\n",
       "      <td>0.393111</td>\n",
       "      <td>0.375018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.495800</td>\n",
       "      <td>0.749757</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.432355</td>\n",
       "      <td>0.408407</td>\n",
       "      <td>0.399013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.446400</td>\n",
       "      <td>0.741470</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.437942</td>\n",
       "      <td>0.411860</td>\n",
       "      <td>0.404140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.418400</td>\n",
       "      <td>0.723117</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.460156</td>\n",
       "      <td>0.427069</td>\n",
       "      <td>0.422132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.388400</td>\n",
       "      <td>0.708759</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.466351</td>\n",
       "      <td>0.427339</td>\n",
       "      <td>0.426564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.369700</td>\n",
       "      <td>0.701827</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.475592</td>\n",
       "      <td>0.440589</td>\n",
       "      <td>0.435889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.357800</td>\n",
       "      <td>0.696529</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.491220</td>\n",
       "      <td>0.451988</td>\n",
       "      <td>0.446499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.355200</td>\n",
       "      <td>0.697968</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.490137</td>\n",
       "      <td>0.452408</td>\n",
       "      <td>0.448365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:21:36,972] Trial 144 finished with value: 0.4483650033004464 and parameters: {'learning_rate': 0.0004372517403740796, 'weight_decay': 0.0, 'warmup_steps': 4, 'lambda_param': 0.0, 'temperature': 2.5}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 145 with params: {'learning_rate': 0.00030443484511967825, 'weight_decay': 0.001, 'warmup_steps': 3, 'lambda_param': 0.0, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:32 < 01:06, 5.27 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.242800</td>\n",
       "      <td>1.999401</td>\n",
       "      <td>0.374885</td>\n",
       "      <td>0.066875</td>\n",
       "      <td>0.077868</td>\n",
       "      <td>0.063553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.842400</td>\n",
       "      <td>1.638687</td>\n",
       "      <td>0.482126</td>\n",
       "      <td>0.122614</td>\n",
       "      <td>0.133845</td>\n",
       "      <td>0.107124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.518300</td>\n",
       "      <td>1.363561</td>\n",
       "      <td>0.570119</td>\n",
       "      <td>0.221558</td>\n",
       "      <td>0.190342</td>\n",
       "      <td>0.173282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.262300</td>\n",
       "      <td>1.179880</td>\n",
       "      <td>0.658112</td>\n",
       "      <td>0.260440</td>\n",
       "      <td>0.260892</td>\n",
       "      <td>0.244031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.080500</td>\n",
       "      <td>1.051170</td>\n",
       "      <td>0.695692</td>\n",
       "      <td>0.269107</td>\n",
       "      <td>0.291502</td>\n",
       "      <td>0.267137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:22:11,100] Trial 145 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 146 with params: {'learning_rate': 0.0003630312598777649, 'weight_decay': 0.002, 'warmup_steps': 4, 'lambda_param': 0.0, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.223900</td>\n",
       "      <td>1.952198</td>\n",
       "      <td>0.389551</td>\n",
       "      <td>0.057999</td>\n",
       "      <td>0.083166</td>\n",
       "      <td>0.062655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.770800</td>\n",
       "      <td>1.550999</td>\n",
       "      <td>0.516040</td>\n",
       "      <td>0.139859</td>\n",
       "      <td>0.153780</td>\n",
       "      <td>0.130468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.413200</td>\n",
       "      <td>1.259954</td>\n",
       "      <td>0.620532</td>\n",
       "      <td>0.227850</td>\n",
       "      <td>0.228142</td>\n",
       "      <td>0.209919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.148300</td>\n",
       "      <td>1.090630</td>\n",
       "      <td>0.673694</td>\n",
       "      <td>0.269564</td>\n",
       "      <td>0.277295</td>\n",
       "      <td>0.258314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.966400</td>\n",
       "      <td>0.976538</td>\n",
       "      <td>0.701192</td>\n",
       "      <td>0.286717</td>\n",
       "      <td>0.302450</td>\n",
       "      <td>0.278762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.820600</td>\n",
       "      <td>0.882180</td>\n",
       "      <td>0.720440</td>\n",
       "      <td>0.323095</td>\n",
       "      <td>0.325401</td>\n",
       "      <td>0.305687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.710500</td>\n",
       "      <td>0.837435</td>\n",
       "      <td>0.714024</td>\n",
       "      <td>0.323290</td>\n",
       "      <td>0.321016</td>\n",
       "      <td>0.301267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.642600</td>\n",
       "      <td>0.808979</td>\n",
       "      <td>0.733272</td>\n",
       "      <td>0.383057</td>\n",
       "      <td>0.358566</td>\n",
       "      <td>0.340721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.585200</td>\n",
       "      <td>0.783793</td>\n",
       "      <td>0.740605</td>\n",
       "      <td>0.407416</td>\n",
       "      <td>0.380244</td>\n",
       "      <td>0.371417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.531400</td>\n",
       "      <td>0.772536</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.424453</td>\n",
       "      <td>0.392684</td>\n",
       "      <td>0.384465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.502800</td>\n",
       "      <td>0.754654</td>\n",
       "      <td>0.747938</td>\n",
       "      <td>0.434457</td>\n",
       "      <td>0.397015</td>\n",
       "      <td>0.390539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.466700</td>\n",
       "      <td>0.740499</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.429792</td>\n",
       "      <td>0.405333</td>\n",
       "      <td>0.397744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.450800</td>\n",
       "      <td>0.735373</td>\n",
       "      <td>0.756187</td>\n",
       "      <td>0.440358</td>\n",
       "      <td>0.407096</td>\n",
       "      <td>0.401304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.436900</td>\n",
       "      <td>0.729958</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.443175</td>\n",
       "      <td>0.411801</td>\n",
       "      <td>0.403962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.433100</td>\n",
       "      <td>0.731840</td>\n",
       "      <td>0.757104</td>\n",
       "      <td>0.454184</td>\n",
       "      <td>0.414878</td>\n",
       "      <td>0.408959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:23:26,876] Trial 146 finished with value: 0.4089588189122477 and parameters: {'learning_rate': 0.0003630312598777649, 'weight_decay': 0.002, 'warmup_steps': 4, 'lambda_param': 0.0, 'temperature': 2.5}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 147 with params: {'learning_rate': 0.00036786391393189155, 'weight_decay': 0.001, 'warmup_steps': 4, 'lambda_param': 0.2, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/525 00:23 < 00:48, 7.23 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.222000</td>\n",
       "      <td>1.948025</td>\n",
       "      <td>0.390467</td>\n",
       "      <td>0.057212</td>\n",
       "      <td>0.083530</td>\n",
       "      <td>0.062505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.764800</td>\n",
       "      <td>1.543994</td>\n",
       "      <td>0.516957</td>\n",
       "      <td>0.140300</td>\n",
       "      <td>0.154235</td>\n",
       "      <td>0.131061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.405100</td>\n",
       "      <td>1.252230</td>\n",
       "      <td>0.625115</td>\n",
       "      <td>0.228007</td>\n",
       "      <td>0.231271</td>\n",
       "      <td>0.212476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.139700</td>\n",
       "      <td>1.083851</td>\n",
       "      <td>0.673694</td>\n",
       "      <td>0.269345</td>\n",
       "      <td>0.277295</td>\n",
       "      <td>0.258313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.957600</td>\n",
       "      <td>0.970639</td>\n",
       "      <td>0.704858</td>\n",
       "      <td>0.289275</td>\n",
       "      <td>0.305312</td>\n",
       "      <td>0.281953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:23:51,770] Trial 147 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 148 with params: {'learning_rate': 0.00048236333478817866, 'weight_decay': 0.002, 'warmup_steps': 4, 'lambda_param': 0.0, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:14, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.178500</td>\n",
       "      <td>1.851163</td>\n",
       "      <td>0.425298</td>\n",
       "      <td>0.063747</td>\n",
       "      <td>0.101545</td>\n",
       "      <td>0.074923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.637200</td>\n",
       "      <td>1.399599</td>\n",
       "      <td>0.563703</td>\n",
       "      <td>0.196703</td>\n",
       "      <td>0.199565</td>\n",
       "      <td>0.177199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.236800</td>\n",
       "      <td>1.108765</td>\n",
       "      <td>0.658112</td>\n",
       "      <td>0.257146</td>\n",
       "      <td>0.267504</td>\n",
       "      <td>0.245183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.967600</td>\n",
       "      <td>0.951466</td>\n",
       "      <td>0.698442</td>\n",
       "      <td>0.283157</td>\n",
       "      <td>0.300205</td>\n",
       "      <td>0.279052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.788400</td>\n",
       "      <td>0.867552</td>\n",
       "      <td>0.719523</td>\n",
       "      <td>0.330370</td>\n",
       "      <td>0.332944</td>\n",
       "      <td>0.309245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.661800</td>\n",
       "      <td>0.804185</td>\n",
       "      <td>0.726856</td>\n",
       "      <td>0.388767</td>\n",
       "      <td>0.359039</td>\n",
       "      <td>0.346918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.566900</td>\n",
       "      <td>0.779895</td>\n",
       "      <td>0.740605</td>\n",
       "      <td>0.396561</td>\n",
       "      <td>0.381689</td>\n",
       "      <td>0.370182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.507400</td>\n",
       "      <td>0.754791</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.420640</td>\n",
       "      <td>0.399676</td>\n",
       "      <td>0.387837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.454200</td>\n",
       "      <td>0.733645</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.441479</td>\n",
       "      <td>0.422431</td>\n",
       "      <td>0.418587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.722666</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.480707</td>\n",
       "      <td>0.427677</td>\n",
       "      <td>0.429611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.378100</td>\n",
       "      <td>0.709163</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.483907</td>\n",
       "      <td>0.440990</td>\n",
       "      <td>0.436424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.350100</td>\n",
       "      <td>0.694748</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.542669</td>\n",
       "      <td>0.455852</td>\n",
       "      <td>0.467481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.331200</td>\n",
       "      <td>0.689166</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.498441</td>\n",
       "      <td>0.454375</td>\n",
       "      <td>0.456191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.320900</td>\n",
       "      <td>0.683865</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.528288</td>\n",
       "      <td>0.461314</td>\n",
       "      <td>0.465083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.318800</td>\n",
       "      <td>0.686017</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.517808</td>\n",
       "      <td>0.466652</td>\n",
       "      <td>0.470704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:25:08,004] Trial 148 finished with value: 0.47070410106521526 and parameters: {'learning_rate': 0.00048236333478817866, 'weight_decay': 0.002, 'warmup_steps': 4, 'lambda_param': 0.0, 'temperature': 2.5}. Best is trial 86 with value: 0.4778879458794155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 149 with params: {'learning_rate': 0.0003091947441664066, 'weight_decay': 0.004, 'warmup_steps': 3, 'lambda_param': 0.0, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/525 00:50 < 00:25, 6.86 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.240600</td>\n",
       "      <td>1.995046</td>\n",
       "      <td>0.376719</td>\n",
       "      <td>0.066179</td>\n",
       "      <td>0.078447</td>\n",
       "      <td>0.063737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.835800</td>\n",
       "      <td>1.630691</td>\n",
       "      <td>0.484876</td>\n",
       "      <td>0.133129</td>\n",
       "      <td>0.135314</td>\n",
       "      <td>0.109298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.508600</td>\n",
       "      <td>1.354026</td>\n",
       "      <td>0.571952</td>\n",
       "      <td>0.224180</td>\n",
       "      <td>0.191599</td>\n",
       "      <td>0.174036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.251700</td>\n",
       "      <td>1.171419</td>\n",
       "      <td>0.660862</td>\n",
       "      <td>0.263684</td>\n",
       "      <td>0.265932</td>\n",
       "      <td>0.249950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.069800</td>\n",
       "      <td>1.043775</td>\n",
       "      <td>0.695692</td>\n",
       "      <td>0.268822</td>\n",
       "      <td>0.291886</td>\n",
       "      <td>0.267089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.920400</td>\n",
       "      <td>0.949116</td>\n",
       "      <td>0.708524</td>\n",
       "      <td>0.299800</td>\n",
       "      <td>0.306229</td>\n",
       "      <td>0.286202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.808500</td>\n",
       "      <td>0.891648</td>\n",
       "      <td>0.708524</td>\n",
       "      <td>0.298573</td>\n",
       "      <td>0.307103</td>\n",
       "      <td>0.284081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.736200</td>\n",
       "      <td>0.853041</td>\n",
       "      <td>0.725940</td>\n",
       "      <td>0.327903</td>\n",
       "      <td>0.335378</td>\n",
       "      <td>0.311706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.675700</td>\n",
       "      <td>0.828287</td>\n",
       "      <td>0.724106</td>\n",
       "      <td>0.330660</td>\n",
       "      <td>0.338123</td>\n",
       "      <td>0.319351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.618100</td>\n",
       "      <td>0.809933</td>\n",
       "      <td>0.742438</td>\n",
       "      <td>0.373351</td>\n",
       "      <td>0.364691</td>\n",
       "      <td>0.349815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:25:59,883] Trial 149 pruned. \n"
     ]
    }
   ],
   "source": [
    "best_trial_distill = trainer.hyperparameter_search(\n",
    "    direction=\"maximize\",\n",
    "    backend=\"optuna\",\n",
    "    hp_space=hp_space,\n",
    "    compute_objective=lambda metrics: metrics[\"eval_f1\"],\n",
    "    pruner=pruner,\n",
    "    sampler=sampler,\n",
    "    study_name=\"Distilation\",\n",
    "    n_trials=150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25c277ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BestRun(run_id='86', objective=0.4778879458794155, hyperparameters={'learning_rate': 0.00048481023093695626, 'weight_decay': 0.003, 'warmup_steps': 4, 'lambda_param': 0.4, 'temperature': 2.5}, run_summary=None)\n"
     ]
    }
   ],
   "source": [
    "print(best_trial_distill)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506ffd55",
   "metadata": {},
   "source": [
    "Přepočet kroků s ohledem na změnu velikosti datasetu. Ke zmenšení počtu epoch nedochází, augmentovaný dataset je stále relativně malý. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc14977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = len(train_aug)\n",
    "min_r = math.ceil(data_length/batch_size)*5\n",
    "max_r = math.ceil(data_length/batch_size)*num_epochs\n",
    "warm_up = math.ceil(data_length/batch_size/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b28705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604fa872",
   "metadata": {},
   "source": [
    "## Prohledávání s normálním tréninkem nad augmentovaným datasetem\n",
    "Konfigurace jednotlivých tréninků."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f24245a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bert-base-aug_fine_hp-search\", logging_dir=f\"~/logs/{DATASET}/bert-base-aug_fine_hp-search\", epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7473b6e0",
   "metadata": {},
   "source": [
    "Definice hledaných hyperparametrů a jejich rozmezí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ebd4d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_space(trial):\n",
    "    params =  {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 5e-4, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0, 1e-2, step=1e-3),\n",
    "        \"warmup_steps\" : trial.suggest_int(\"warmup_steps\", 0, warm_up),\n",
    "    }\n",
    "    print(f\"Trial {trial.number} with params: {params}\")\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb898a9",
   "metadata": {},
   "source": [
    "Konfigurace Optuny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dc12e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pruner = optuna.pruners.HyperbandPruner(min_resource=min_r, max_resource=max_r, reduction_factor=2, bootstrap_count=2)\n",
    "sampler = optuna.samplers.TPESampler(seed=42, multivariate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d45670",
   "metadata": {},
   "source": [
    "Konfigurace trenéra pro jednotlivé tréninky. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4414ae99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    args=training_args,\n",
    "    train_dataset=train_aug,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    model_init = lambda: get_Bert()\n",
    ")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99192030",
   "metadata": {},
   "source": [
    "Nastavení prohledávání."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bcbdaec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:26:00,559] A new study created in memory with name: Test-base-aug\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 with params: {'learning_rate': 4.3284502212938785e-05, 'weight_decay': 0.01, 'warmup_steps': 39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:28 < 02:56, 29.71 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.932700</td>\n",
       "      <td>2.235381</td>\n",
       "      <td>0.577452</td>\n",
       "      <td>0.251613</td>\n",
       "      <td>0.206702</td>\n",
       "      <td>0.192989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.724400</td>\n",
       "      <td>1.548038</td>\n",
       "      <td>0.703025</td>\n",
       "      <td>0.320607</td>\n",
       "      <td>0.331331</td>\n",
       "      <td>0.310229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.151000</td>\n",
       "      <td>1.272127</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.382888</td>\n",
       "      <td>0.401835</td>\n",
       "      <td>0.379462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.842700</td>\n",
       "      <td>1.145172</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.441398</td>\n",
       "      <td>0.439341</td>\n",
       "      <td>0.423260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.655500</td>\n",
       "      <td>1.084483</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.471065</td>\n",
       "      <td>0.463492</td>\n",
       "      <td>0.449217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:27:30,154] Trial 0 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 with params: {'learning_rate': 0.00010401663679887307, 'weight_decay': 0.001, 'warmup_steps': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:56 < 01:28, 29.66 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.175400</td>\n",
       "      <td>1.397009</td>\n",
       "      <td>0.733272</td>\n",
       "      <td>0.357032</td>\n",
       "      <td>0.374699</td>\n",
       "      <td>0.351703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.816400</td>\n",
       "      <td>1.074034</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.451657</td>\n",
       "      <td>0.458918</td>\n",
       "      <td>0.445542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.432700</td>\n",
       "      <td>0.997396</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.494056</td>\n",
       "      <td>0.497951</td>\n",
       "      <td>0.481924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.256300</td>\n",
       "      <td>1.012277</td>\n",
       "      <td>0.779102</td>\n",
       "      <td>0.618539</td>\n",
       "      <td>0.556540</td>\n",
       "      <td>0.568428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.163100</td>\n",
       "      <td>1.018821</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.677925</td>\n",
       "      <td>0.614088</td>\n",
       "      <td>0.627822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.111600</td>\n",
       "      <td>1.052724</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.688095</td>\n",
       "      <td>0.609935</td>\n",
       "      <td>0.630828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>1.079528</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.705145</td>\n",
       "      <td>0.644480</td>\n",
       "      <td>0.656518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.061200</td>\n",
       "      <td>1.104620</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.783738</td>\n",
       "      <td>0.686365</td>\n",
       "      <td>0.706878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>1.139490</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.771125</td>\n",
       "      <td>0.677404</td>\n",
       "      <td>0.700903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>1.186543</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.773754</td>\n",
       "      <td>0.697850</td>\n",
       "      <td>0.712939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:30:28,101] Trial 1 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 with params: {'learning_rate': 1.2551115172973821e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:26 < 02:52, 30.42 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.517000</td>\n",
       "      <td>3.196738</td>\n",
       "      <td>0.351054</td>\n",
       "      <td>0.055195</td>\n",
       "      <td>0.074407</td>\n",
       "      <td>0.051748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.938300</td>\n",
       "      <td>2.738555</td>\n",
       "      <td>0.478460</td>\n",
       "      <td>0.105283</td>\n",
       "      <td>0.133664</td>\n",
       "      <td>0.111068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.523100</td>\n",
       "      <td>2.398709</td>\n",
       "      <td>0.527039</td>\n",
       "      <td>0.172007</td>\n",
       "      <td>0.163069</td>\n",
       "      <td>0.142250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.207500</td>\n",
       "      <td>2.148483</td>\n",
       "      <td>0.585701</td>\n",
       "      <td>0.250816</td>\n",
       "      <td>0.215852</td>\n",
       "      <td>0.199271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.958300</td>\n",
       "      <td>1.956343</td>\n",
       "      <td>0.614115</td>\n",
       "      <td>0.260171</td>\n",
       "      <td>0.240123</td>\n",
       "      <td>0.222300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:31:55,308] Trial 2 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 with params: {'learning_rate': 0.00015958573588141273, 'weight_decay': 0.0, 'warmup_steps': 52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:53 < 01:26, 30.20 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.895100</td>\n",
       "      <td>1.174138</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.441487</td>\n",
       "      <td>0.434300</td>\n",
       "      <td>0.418386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.530700</td>\n",
       "      <td>0.996867</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.514725</td>\n",
       "      <td>0.508635</td>\n",
       "      <td>0.502272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.231200</td>\n",
       "      <td>0.980664</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.651960</td>\n",
       "      <td>0.609097</td>\n",
       "      <td>0.616692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.118800</td>\n",
       "      <td>1.040272</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.716676</td>\n",
       "      <td>0.629055</td>\n",
       "      <td>0.654560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.071600</td>\n",
       "      <td>1.081217</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.773172</td>\n",
       "      <td>0.698715</td>\n",
       "      <td>0.719975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>1.130470</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.785667</td>\n",
       "      <td>0.657598</td>\n",
       "      <td>0.693858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.033400</td>\n",
       "      <td>1.187070</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.805077</td>\n",
       "      <td>0.701408</td>\n",
       "      <td>0.727515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.026300</td>\n",
       "      <td>1.197125</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.795629</td>\n",
       "      <td>0.739477</td>\n",
       "      <td>0.749265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>1.254264</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.789459</td>\n",
       "      <td>0.710928</td>\n",
       "      <td>0.732169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>1.302470</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.815834</td>\n",
       "      <td>0.709758</td>\n",
       "      <td>0.734385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:34:50,033] Trial 3 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 with params: {'learning_rate': 0.00025959425503112657, 'weight_decay': 0.002, 'warmup_steps': 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:55 < 01:27, 29.97 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.416200</td>\n",
       "      <td>1.032974</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.449340</td>\n",
       "      <td>0.471039</td>\n",
       "      <td>0.449134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.274800</td>\n",
       "      <td>1.018367</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.671033</td>\n",
       "      <td>0.608093</td>\n",
       "      <td>0.620665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.101800</td>\n",
       "      <td>1.094981</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.766668</td>\n",
       "      <td>0.698511</td>\n",
       "      <td>0.714644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>1.129571</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.811794</td>\n",
       "      <td>0.685051</td>\n",
       "      <td>0.724949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>1.220691</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.776820</td>\n",
       "      <td>0.717004</td>\n",
       "      <td>0.728165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>1.198218</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.801529</td>\n",
       "      <td>0.695447</td>\n",
       "      <td>0.726203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>1.314942</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.787690</td>\n",
       "      <td>0.693135</td>\n",
       "      <td>0.718063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>1.313053</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.787902</td>\n",
       "      <td>0.701706</td>\n",
       "      <td>0.722950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>1.375067</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.795940</td>\n",
       "      <td>0.706360</td>\n",
       "      <td>0.730281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>1.390883</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.793276</td>\n",
       "      <td>0.723698</td>\n",
       "      <td>0.737487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:37:46,131] Trial 4 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 with params: {'learning_rate': 2.049268011541735e-05, 'weight_decay': 0.003, 'warmup_steps': 28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:52 < 01:26, 30.38 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.334600</td>\n",
       "      <td>2.885929</td>\n",
       "      <td>0.445463</td>\n",
       "      <td>0.109365</td>\n",
       "      <td>0.112952</td>\n",
       "      <td>0.096663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.523400</td>\n",
       "      <td>2.282967</td>\n",
       "      <td>0.561870</td>\n",
       "      <td>0.206598</td>\n",
       "      <td>0.190136</td>\n",
       "      <td>0.173908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.994800</td>\n",
       "      <td>1.900837</td>\n",
       "      <td>0.630614</td>\n",
       "      <td>0.294492</td>\n",
       "      <td>0.257746</td>\n",
       "      <td>0.240120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.637900</td>\n",
       "      <td>1.649444</td>\n",
       "      <td>0.685610</td>\n",
       "      <td>0.335732</td>\n",
       "      <td>0.307292</td>\n",
       "      <td>0.292571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.381700</td>\n",
       "      <td>1.479711</td>\n",
       "      <td>0.708524</td>\n",
       "      <td>0.338391</td>\n",
       "      <td>0.337635</td>\n",
       "      <td>0.316831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.200600</td>\n",
       "      <td>1.364818</td>\n",
       "      <td>0.726856</td>\n",
       "      <td>0.379894</td>\n",
       "      <td>0.371914</td>\n",
       "      <td>0.353988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.060500</td>\n",
       "      <td>1.284745</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.430392</td>\n",
       "      <td>0.417392</td>\n",
       "      <td>0.404883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.961500</td>\n",
       "      <td>1.231742</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.426907</td>\n",
       "      <td>0.430992</td>\n",
       "      <td>0.411552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.883100</td>\n",
       "      <td>1.193065</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.423434</td>\n",
       "      <td>0.426507</td>\n",
       "      <td>0.406944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.818500</td>\n",
       "      <td>1.165618</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.438519</td>\n",
       "      <td>0.444075</td>\n",
       "      <td>0.426882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:40:39,879] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 with params: {'learning_rate': 5.4182823195332406e-05, 'weight_decay': 0.003, 'warmup_steps': 33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:54 < 01:27, 30.16 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.764400</td>\n",
       "      <td>2.009660</td>\n",
       "      <td>0.609533</td>\n",
       "      <td>0.268080</td>\n",
       "      <td>0.244097</td>\n",
       "      <td>0.226531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.467700</td>\n",
       "      <td>1.374825</td>\n",
       "      <td>0.731439</td>\n",
       "      <td>0.377656</td>\n",
       "      <td>0.377592</td>\n",
       "      <td>0.358852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>1.164127</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.449244</td>\n",
       "      <td>0.439250</td>\n",
       "      <td>0.423922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.658800</td>\n",
       "      <td>1.073958</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.448756</td>\n",
       "      <td>0.462178</td>\n",
       "      <td>0.445439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.495600</td>\n",
       "      <td>1.036264</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.511268</td>\n",
       "      <td>0.492931</td>\n",
       "      <td>0.486726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.388500</td>\n",
       "      <td>1.013636</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.516378</td>\n",
       "      <td>0.502978</td>\n",
       "      <td>0.497515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.305200</td>\n",
       "      <td>1.008563</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.534964</td>\n",
       "      <td>0.510533</td>\n",
       "      <td>0.506712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.252600</td>\n",
       "      <td>0.998516</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>0.595344</td>\n",
       "      <td>0.542472</td>\n",
       "      <td>0.548879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.214000</td>\n",
       "      <td>1.010424</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.599075</td>\n",
       "      <td>0.550816</td>\n",
       "      <td>0.559993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>1.023824</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.644041</td>\n",
       "      <td>0.580671</td>\n",
       "      <td>0.595894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:43:34,918] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 with params: {'learning_rate': 1.7258215396625005e-05, 'weight_decay': 0.003, 'warmup_steps': 19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:55 < 01:27, 29.90 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.399000</td>\n",
       "      <td>3.000930</td>\n",
       "      <td>0.420715</td>\n",
       "      <td>0.096502</td>\n",
       "      <td>0.099510</td>\n",
       "      <td>0.084453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.678400</td>\n",
       "      <td>2.446831</td>\n",
       "      <td>0.526123</td>\n",
       "      <td>0.183561</td>\n",
       "      <td>0.161139</td>\n",
       "      <td>0.141123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.185700</td>\n",
       "      <td>2.075567</td>\n",
       "      <td>0.596700</td>\n",
       "      <td>0.281815</td>\n",
       "      <td>0.228563</td>\n",
       "      <td>0.212293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.838300</td>\n",
       "      <td>1.817021</td>\n",
       "      <td>0.653529</td>\n",
       "      <td>0.314028</td>\n",
       "      <td>0.271264</td>\n",
       "      <td>0.255615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.579500</td>\n",
       "      <td>1.631970</td>\n",
       "      <td>0.690192</td>\n",
       "      <td>0.332171</td>\n",
       "      <td>0.312699</td>\n",
       "      <td>0.296952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.391800</td>\n",
       "      <td>1.499478</td>\n",
       "      <td>0.709441</td>\n",
       "      <td>0.360701</td>\n",
       "      <td>0.347438</td>\n",
       "      <td>0.331062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.244100</td>\n",
       "      <td>1.403939</td>\n",
       "      <td>0.719523</td>\n",
       "      <td>0.389168</td>\n",
       "      <td>0.362614</td>\n",
       "      <td>0.348632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.136800</td>\n",
       "      <td>1.338363</td>\n",
       "      <td>0.734189</td>\n",
       "      <td>0.426167</td>\n",
       "      <td>0.397922</td>\n",
       "      <td>0.384227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.051800</td>\n",
       "      <td>1.287230</td>\n",
       "      <td>0.742438</td>\n",
       "      <td>0.423397</td>\n",
       "      <td>0.410106</td>\n",
       "      <td>0.398179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.982300</td>\n",
       "      <td>1.252371</td>\n",
       "      <td>0.743355</td>\n",
       "      <td>0.420824</td>\n",
       "      <td>0.417765</td>\n",
       "      <td>0.402239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:46:31,584] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 with params: {'learning_rate': 5.954553793888986e-05, 'weight_decay': 0.008, 'warmup_steps': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:59 < 01:29, 29.19 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.653300</td>\n",
       "      <td>1.894241</td>\n",
       "      <td>0.625115</td>\n",
       "      <td>0.289193</td>\n",
       "      <td>0.256988</td>\n",
       "      <td>0.242139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.348800</td>\n",
       "      <td>1.305623</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.404773</td>\n",
       "      <td>0.401660</td>\n",
       "      <td>0.383059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.839500</td>\n",
       "      <td>1.125017</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.456775</td>\n",
       "      <td>0.450526</td>\n",
       "      <td>0.435955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.586100</td>\n",
       "      <td>1.050710</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.480157</td>\n",
       "      <td>0.474433</td>\n",
       "      <td>0.464943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.431800</td>\n",
       "      <td>1.016618</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.497649</td>\n",
       "      <td>0.492911</td>\n",
       "      <td>0.484976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.330200</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.554039</td>\n",
       "      <td>0.518719</td>\n",
       "      <td>0.516950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.255200</td>\n",
       "      <td>1.005029</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.593239</td>\n",
       "      <td>0.536098</td>\n",
       "      <td>0.540026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.208700</td>\n",
       "      <td>0.998983</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.641463</td>\n",
       "      <td>0.570038</td>\n",
       "      <td>0.585656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.175900</td>\n",
       "      <td>1.017802</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.645807</td>\n",
       "      <td>0.590989</td>\n",
       "      <td>0.602962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.149700</td>\n",
       "      <td>1.036667</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.670982</td>\n",
       "      <td>0.602204</td>\n",
       "      <td>0.619668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:49:32,557] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 with params: {'learning_rate': 7.475992999956501e-05, 'weight_decay': 0.006, 'warmup_steps': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:56 < 01:28, 29.76 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.454400</td>\n",
       "      <td>1.672142</td>\n",
       "      <td>0.688359</td>\n",
       "      <td>0.326686</td>\n",
       "      <td>0.310781</td>\n",
       "      <td>0.297020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.115900</td>\n",
       "      <td>1.182524</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.441132</td>\n",
       "      <td>0.421358</td>\n",
       "      <td>0.409552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.657200</td>\n",
       "      <td>1.062601</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.467027</td>\n",
       "      <td>0.472590</td>\n",
       "      <td>0.457610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.437000</td>\n",
       "      <td>1.010823</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.504221</td>\n",
       "      <td>0.499310</td>\n",
       "      <td>0.491929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.301100</td>\n",
       "      <td>0.994802</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>0.560047</td>\n",
       "      <td>0.521980</td>\n",
       "      <td>0.522992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.218800</td>\n",
       "      <td>1.005510</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.619803</td>\n",
       "      <td>0.573622</td>\n",
       "      <td>0.583387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>1.026962</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.672568</td>\n",
       "      <td>0.604641</td>\n",
       "      <td>0.621858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.129800</td>\n",
       "      <td>1.029195</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.666401</td>\n",
       "      <td>0.610701</td>\n",
       "      <td>0.624257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.107100</td>\n",
       "      <td>1.051578</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.679173</td>\n",
       "      <td>0.609678</td>\n",
       "      <td>0.625774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>1.085384</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.725531</td>\n",
       "      <td>0.643370</td>\n",
       "      <td>0.662894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:52:29,935] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 with params: {'learning_rate': 0.0004587604755149822, 'weight_decay': 0.002, 'warmup_steps': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:29, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.016800</td>\n",
       "      <td>1.012189</td>\n",
       "      <td>0.778185</td>\n",
       "      <td>0.554060</td>\n",
       "      <td>0.560090</td>\n",
       "      <td>0.548193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.134800</td>\n",
       "      <td>1.117707</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.728469</td>\n",
       "      <td>0.691829</td>\n",
       "      <td>0.695316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.053600</td>\n",
       "      <td>1.251234</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.762463</td>\n",
       "      <td>0.712827</td>\n",
       "      <td>0.724393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>1.334953</td>\n",
       "      <td>0.778185</td>\n",
       "      <td>0.800739</td>\n",
       "      <td>0.703991</td>\n",
       "      <td>0.732888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>1.347624</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.802625</td>\n",
       "      <td>0.728297</td>\n",
       "      <td>0.744976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.015500</td>\n",
       "      <td>1.385880</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.783455</td>\n",
       "      <td>0.703191</td>\n",
       "      <td>0.725167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>1.390878</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.799999</td>\n",
       "      <td>0.718383</td>\n",
       "      <td>0.740194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>1.504664</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.721691</td>\n",
       "      <td>0.734309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.527934</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.771435</td>\n",
       "      <td>0.721912</td>\n",
       "      <td>0.731802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.567686</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.781343</td>\n",
       "      <td>0.730292</td>\n",
       "      <td>0.740534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>1.594932</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.771091</td>\n",
       "      <td>0.709230</td>\n",
       "      <td>0.726029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.598223</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.776373</td>\n",
       "      <td>0.721351</td>\n",
       "      <td>0.736861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.613526</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.776368</td>\n",
       "      <td>0.718487</td>\n",
       "      <td>0.731377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.604868</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.776891</td>\n",
       "      <td>0.721991</td>\n",
       "      <td>0.733733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.637143</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.779121</td>\n",
       "      <td>0.714086</td>\n",
       "      <td>0.729888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 13:57:00,578] Trial 10 finished with value: 0.7298882081886409 and parameters: {'learning_rate': 0.0004587604755149822, 'weight_decay': 0.002, 'warmup_steps': 1}. Best is trial 10 with value: 0.7298882081886409.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 with params: {'learning_rate': 0.0004362378788055201, 'weight_decay': 0.003, 'warmup_steps': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:23, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.037200</td>\n",
       "      <td>0.991951</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.577837</td>\n",
       "      <td>0.567303</td>\n",
       "      <td>0.557790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.141700</td>\n",
       "      <td>1.144146</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.711295</td>\n",
       "      <td>0.675612</td>\n",
       "      <td>0.673705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>1.223456</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.773586</td>\n",
       "      <td>0.733392</td>\n",
       "      <td>0.738922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>1.279960</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.821620</td>\n",
       "      <td>0.709299</td>\n",
       "      <td>0.742697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>1.307653</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.800675</td>\n",
       "      <td>0.699426</td>\n",
       "      <td>0.731295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>1.405703</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.811528</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.735039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>1.470590</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.783611</td>\n",
       "      <td>0.708122</td>\n",
       "      <td>0.730875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>1.440552</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.789359</td>\n",
       "      <td>0.730667</td>\n",
       "      <td>0.744259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.524564</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.781213</td>\n",
       "      <td>0.712014</td>\n",
       "      <td>0.731655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.537916</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.772991</td>\n",
       "      <td>0.708670</td>\n",
       "      <td>0.727177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.596474</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.797889</td>\n",
       "      <td>0.703781</td>\n",
       "      <td>0.731467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.617318</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.782760</td>\n",
       "      <td>0.719323</td>\n",
       "      <td>0.735864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.619573</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.768156</td>\n",
       "      <td>0.700830</td>\n",
       "      <td>0.721388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.624195</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.794827</td>\n",
       "      <td>0.722606</td>\n",
       "      <td>0.742593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.633065</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.800014</td>\n",
       "      <td>0.723358</td>\n",
       "      <td>0.745340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 14:01:25,681] Trial 11 finished with value: 0.7453400168527454 and parameters: {'learning_rate': 0.0004362378788055201, 'weight_decay': 0.003, 'warmup_steps': 0}. Best is trial 11 with value: 0.7453400168527454.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 with params: {'learning_rate': 0.00040699996899648717, 'weight_decay': 0.005, 'warmup_steps': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:56 < 01:28, 29.82 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.106700</td>\n",
       "      <td>0.977303</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.579324</td>\n",
       "      <td>0.558282</td>\n",
       "      <td>0.554546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.154700</td>\n",
       "      <td>1.084340</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.716696</td>\n",
       "      <td>0.675535</td>\n",
       "      <td>0.677483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.057400</td>\n",
       "      <td>1.192208</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.771712</td>\n",
       "      <td>0.713076</td>\n",
       "      <td>0.724011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>1.303247</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.820392</td>\n",
       "      <td>0.718114</td>\n",
       "      <td>0.748969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>1.357278</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.777776</td>\n",
       "      <td>0.712343</td>\n",
       "      <td>0.728852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>1.442685</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.789747</td>\n",
       "      <td>0.692040</td>\n",
       "      <td>0.718071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>1.472583</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.772709</td>\n",
       "      <td>0.708872</td>\n",
       "      <td>0.720210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.467125</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>0.768372</td>\n",
       "      <td>0.706474</td>\n",
       "      <td>0.720730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>1.498188</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.802560</td>\n",
       "      <td>0.703776</td>\n",
       "      <td>0.733142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>1.572629</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.790753</td>\n",
       "      <td>0.706266</td>\n",
       "      <td>0.729579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 14:04:22,683] Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13 with params: {'learning_rate': 0.00047120889231092516, 'weight_decay': 0.0, 'warmup_steps': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:23, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.027100</td>\n",
       "      <td>0.981177</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.601391</td>\n",
       "      <td>0.574920</td>\n",
       "      <td>0.577561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.133100</td>\n",
       "      <td>1.150900</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.730753</td>\n",
       "      <td>0.687366</td>\n",
       "      <td>0.693307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.054100</td>\n",
       "      <td>1.271895</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.793765</td>\n",
       "      <td>0.734468</td>\n",
       "      <td>0.747231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>1.274890</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.734646</td>\n",
       "      <td>0.693225</td>\n",
       "      <td>0.696667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>1.347593</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.796573</td>\n",
       "      <td>0.716213</td>\n",
       "      <td>0.736628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>1.390026</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.812316</td>\n",
       "      <td>0.699344</td>\n",
       "      <td>0.734196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>1.498425</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.791656</td>\n",
       "      <td>0.697788</td>\n",
       "      <td>0.725346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>1.477690</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.759835</td>\n",
       "      <td>0.699077</td>\n",
       "      <td>0.711866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>1.474432</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.775771</td>\n",
       "      <td>0.712722</td>\n",
       "      <td>0.728005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.478139</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.788474</td>\n",
       "      <td>0.715714</td>\n",
       "      <td>0.729547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.545253</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.786821</td>\n",
       "      <td>0.691422</td>\n",
       "      <td>0.720534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.533646</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.770123</td>\n",
       "      <td>0.700607</td>\n",
       "      <td>0.721628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.576486</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.783141</td>\n",
       "      <td>0.693251</td>\n",
       "      <td>0.720653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.586449</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.785378</td>\n",
       "      <td>0.698800</td>\n",
       "      <td>0.724746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.587653</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.786849</td>\n",
       "      <td>0.691033</td>\n",
       "      <td>0.719688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 14:08:47,341] Trial 13 finished with value: 0.7196875427337419 and parameters: {'learning_rate': 0.00047120889231092516, 'weight_decay': 0.0, 'warmup_steps': 7}. Best is trial 11 with value: 0.7453400168527454.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 with params: {'learning_rate': 0.0003750707646511455, 'weight_decay': 0.008, 'warmup_steps': 26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:57 < 01:28, 29.51 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.204000</td>\n",
       "      <td>0.992989</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>0.519150</td>\n",
       "      <td>0.509568</td>\n",
       "      <td>0.498536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.169800</td>\n",
       "      <td>1.096906</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.752682</td>\n",
       "      <td>0.647747</td>\n",
       "      <td>0.677164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.062300</td>\n",
       "      <td>1.195739</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.774813</td>\n",
       "      <td>0.720966</td>\n",
       "      <td>0.732592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.032200</td>\n",
       "      <td>1.317065</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.799491</td>\n",
       "      <td>0.701431</td>\n",
       "      <td>0.722698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>1.291203</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.777650</td>\n",
       "      <td>0.708457</td>\n",
       "      <td>0.722845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>1.386321</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.795969</td>\n",
       "      <td>0.716973</td>\n",
       "      <td>0.740547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>1.447145</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.781812</td>\n",
       "      <td>0.694067</td>\n",
       "      <td>0.715738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.499647</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.755069</td>\n",
       "      <td>0.706517</td>\n",
       "      <td>0.715227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>1.526763</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>0.769885</td>\n",
       "      <td>0.700089</td>\n",
       "      <td>0.719205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.553535</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.779508</td>\n",
       "      <td>0.702941</td>\n",
       "      <td>0.724902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 14:11:46,080] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 with params: {'learning_rate': 0.0002578039701724928, 'weight_decay': 0.004, 'warmup_steps': 28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:20, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.464900</td>\n",
       "      <td>1.027478</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.462171</td>\n",
       "      <td>0.472596</td>\n",
       "      <td>0.453131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.280200</td>\n",
       "      <td>1.016750</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.688893</td>\n",
       "      <td>0.623360</td>\n",
       "      <td>0.638521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.103200</td>\n",
       "      <td>1.083300</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.729723</td>\n",
       "      <td>0.651756</td>\n",
       "      <td>0.672770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.051200</td>\n",
       "      <td>1.148334</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.827016</td>\n",
       "      <td>0.706162</td>\n",
       "      <td>0.743620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.032200</td>\n",
       "      <td>1.191835</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.795326</td>\n",
       "      <td>0.724726</td>\n",
       "      <td>0.744479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>1.267987</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.801355</td>\n",
       "      <td>0.687125</td>\n",
       "      <td>0.721982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>1.352166</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.777953</td>\n",
       "      <td>0.695850</td>\n",
       "      <td>0.717998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>1.347995</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.783425</td>\n",
       "      <td>0.703404</td>\n",
       "      <td>0.724698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>1.399341</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.777546</td>\n",
       "      <td>0.722801</td>\n",
       "      <td>0.735665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>1.448406</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.818903</td>\n",
       "      <td>0.715035</td>\n",
       "      <td>0.744147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>1.472524</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.803883</td>\n",
       "      <td>0.715525</td>\n",
       "      <td>0.739355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>1.450933</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.810391</td>\n",
       "      <td>0.735369</td>\n",
       "      <td>0.754444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.481700</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.786355</td>\n",
       "      <td>0.714733</td>\n",
       "      <td>0.731933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.469403</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.794944</td>\n",
       "      <td>0.715690</td>\n",
       "      <td>0.735211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.473934</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.798395</td>\n",
       "      <td>0.717208</td>\n",
       "      <td>0.737335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 14:16:08,410] Trial 15 finished with value: 0.7373352475492936 and parameters: {'learning_rate': 0.0002578039701724928, 'weight_decay': 0.004, 'warmup_steps': 28}. Best is trial 11 with value: 0.7453400168527454.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16 with params: {'learning_rate': 0.0001903565661716161, 'weight_decay': 0.003, 'warmup_steps': 28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:28, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.699300</td>\n",
       "      <td>1.096948</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.436669</td>\n",
       "      <td>0.447257</td>\n",
       "      <td>0.426031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.419300</td>\n",
       "      <td>0.977895</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.624977</td>\n",
       "      <td>0.575207</td>\n",
       "      <td>0.581526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.168500</td>\n",
       "      <td>1.021845</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.734966</td>\n",
       "      <td>0.645806</td>\n",
       "      <td>0.669967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.084400</td>\n",
       "      <td>1.083307</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.712973</td>\n",
       "      <td>0.634078</td>\n",
       "      <td>0.656684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.050800</td>\n",
       "      <td>1.125195</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.805940</td>\n",
       "      <td>0.721449</td>\n",
       "      <td>0.746445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.035300</td>\n",
       "      <td>1.200926</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.802613</td>\n",
       "      <td>0.671810</td>\n",
       "      <td>0.707829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>1.246181</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.811980</td>\n",
       "      <td>0.704629</td>\n",
       "      <td>0.733016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>1.248230</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.808546</td>\n",
       "      <td>0.734469</td>\n",
       "      <td>0.748826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>1.273036</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.796114</td>\n",
       "      <td>0.711343</td>\n",
       "      <td>0.731013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>1.321468</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.811564</td>\n",
       "      <td>0.718583</td>\n",
       "      <td>0.740024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>1.372010</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.801922</td>\n",
       "      <td>0.710620</td>\n",
       "      <td>0.729032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>1.365018</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.783118</td>\n",
       "      <td>0.728565</td>\n",
       "      <td>0.738734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>1.390809</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.788259</td>\n",
       "      <td>0.715724</td>\n",
       "      <td>0.733711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.393982</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.816577</td>\n",
       "      <td>0.727477</td>\n",
       "      <td>0.750780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.398472</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.817112</td>\n",
       "      <td>0.727441</td>\n",
       "      <td>0.749735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 14:20:37,957] Trial 16 finished with value: 0.7497354203350519 and parameters: {'learning_rate': 0.0001903565661716161, 'weight_decay': 0.003, 'warmup_steps': 28}. Best is trial 16 with value: 0.7497354203350519.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17 with params: {'learning_rate': 0.0003148149268759786, 'weight_decay': 0.0, 'warmup_steps': 27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:26, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.320400</td>\n",
       "      <td>1.005342</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.481170</td>\n",
       "      <td>0.491518</td>\n",
       "      <td>0.474755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.213500</td>\n",
       "      <td>1.065212</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.720246</td>\n",
       "      <td>0.637771</td>\n",
       "      <td>0.658142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.077800</td>\n",
       "      <td>1.147612</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.786263</td>\n",
       "      <td>0.730591</td>\n",
       "      <td>0.742506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.038700</td>\n",
       "      <td>1.205114</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.828258</td>\n",
       "      <td>0.717883</td>\n",
       "      <td>0.750372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>1.240852</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.809370</td>\n",
       "      <td>0.722871</td>\n",
       "      <td>0.746003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>1.321498</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.820985</td>\n",
       "      <td>0.710781</td>\n",
       "      <td>0.742137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>1.367792</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.795039</td>\n",
       "      <td>0.696083</td>\n",
       "      <td>0.722005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>1.438610</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.799594</td>\n",
       "      <td>0.733150</td>\n",
       "      <td>0.748024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.473730</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.801149</td>\n",
       "      <td>0.722395</td>\n",
       "      <td>0.743197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>1.463719</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.802937</td>\n",
       "      <td>0.726457</td>\n",
       "      <td>0.744217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.503010</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.814428</td>\n",
       "      <td>0.734416</td>\n",
       "      <td>0.754788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.494773</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.808701</td>\n",
       "      <td>0.737044</td>\n",
       "      <td>0.756678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.527774</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.806929</td>\n",
       "      <td>0.734418</td>\n",
       "      <td>0.753450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.509560</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.820591</td>\n",
       "      <td>0.739115</td>\n",
       "      <td>0.761859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.506841</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.811485</td>\n",
       "      <td>0.737068</td>\n",
       "      <td>0.758005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 14:25:05,680] Trial 17 finished with value: 0.7580050071093316 and parameters: {'learning_rate': 0.0003148149268759786, 'weight_decay': 0.0, 'warmup_steps': 27}. Best is trial 17 with value: 0.7580050071093316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18 with params: {'learning_rate': 0.00021317012046880978, 'weight_decay': 0.0, 'warmup_steps': 30}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:30, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.613900</td>\n",
       "      <td>1.062475</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.451242</td>\n",
       "      <td>0.453385</td>\n",
       "      <td>0.433896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.363200</td>\n",
       "      <td>0.975847</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.624841</td>\n",
       "      <td>0.583806</td>\n",
       "      <td>0.589896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.138800</td>\n",
       "      <td>1.046318</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.723678</td>\n",
       "      <td>0.645774</td>\n",
       "      <td>0.662452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>1.094177</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.788287</td>\n",
       "      <td>0.677043</td>\n",
       "      <td>0.713105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.042800</td>\n",
       "      <td>1.165750</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.788735</td>\n",
       "      <td>0.714877</td>\n",
       "      <td>0.734674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>1.210843</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.790247</td>\n",
       "      <td>0.685893</td>\n",
       "      <td>0.715190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.020600</td>\n",
       "      <td>1.269847</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.808013</td>\n",
       "      <td>0.697374</td>\n",
       "      <td>0.725944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>1.279790</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.802325</td>\n",
       "      <td>0.727926</td>\n",
       "      <td>0.743951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>1.312556</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.800806</td>\n",
       "      <td>0.725343</td>\n",
       "      <td>0.741858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>1.361781</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.801182</td>\n",
       "      <td>0.717915</td>\n",
       "      <td>0.738121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>1.414606</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.804737</td>\n",
       "      <td>0.720329</td>\n",
       "      <td>0.741995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>1.368684</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.795382</td>\n",
       "      <td>0.717670</td>\n",
       "      <td>0.735158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.408254</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.794852</td>\n",
       "      <td>0.719016</td>\n",
       "      <td>0.738129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>1.420295</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.812981</td>\n",
       "      <td>0.726505</td>\n",
       "      <td>0.748920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.428702</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.819657</td>\n",
       "      <td>0.725824</td>\n",
       "      <td>0.751583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 14:29:37,179] Trial 18 finished with value: 0.7515829644349895 and parameters: {'learning_rate': 0.00021317012046880978, 'weight_decay': 0.0, 'warmup_steps': 30}. Best is trial 17 with value: 0.7580050071093316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 19 with params: {'learning_rate': 0.0003820528120429927, 'weight_decay': 0.0, 'warmup_steps': 29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:26 < 02:53, 30.26 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.199900</td>\n",
       "      <td>0.991758</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.536317</td>\n",
       "      <td>0.517879</td>\n",
       "      <td>0.509648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.166900</td>\n",
       "      <td>1.102166</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.716461</td>\n",
       "      <td>0.644369</td>\n",
       "      <td>0.663451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.061800</td>\n",
       "      <td>1.200520</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.768549</td>\n",
       "      <td>0.722436</td>\n",
       "      <td>0.730020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>1.274727</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.809326</td>\n",
       "      <td>0.690350</td>\n",
       "      <td>0.719521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>1.338713</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.768698</td>\n",
       "      <td>0.709008</td>\n",
       "      <td>0.721768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 14:31:04,828] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 with params: {'learning_rate': 0.000361812949512664, 'weight_decay': 0.004, 'warmup_steps': 43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:24, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.267800</td>\n",
       "      <td>1.000523</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.526352</td>\n",
       "      <td>0.511373</td>\n",
       "      <td>0.502507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.182600</td>\n",
       "      <td>1.065666</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.741510</td>\n",
       "      <td>0.655441</td>\n",
       "      <td>0.677514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.066900</td>\n",
       "      <td>1.131336</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.801231</td>\n",
       "      <td>0.726302</td>\n",
       "      <td>0.739596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>1.239411</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.823397</td>\n",
       "      <td>0.704186</td>\n",
       "      <td>0.739662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>1.304322</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.804602</td>\n",
       "      <td>0.723181</td>\n",
       "      <td>0.738929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>1.296278</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.826712</td>\n",
       "      <td>0.708686</td>\n",
       "      <td>0.742163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>1.434993</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.792951</td>\n",
       "      <td>0.698793</td>\n",
       "      <td>0.714824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>1.424732</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.790857</td>\n",
       "      <td>0.723844</td>\n",
       "      <td>0.732272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>1.503668</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.808244</td>\n",
       "      <td>0.732270</td>\n",
       "      <td>0.748684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.526368</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.802857</td>\n",
       "      <td>0.721084</td>\n",
       "      <td>0.738989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.516793</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.806970</td>\n",
       "      <td>0.710800</td>\n",
       "      <td>0.737351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.508502</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.823680</td>\n",
       "      <td>0.702014</td>\n",
       "      <td>0.737743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.527109</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.790686</td>\n",
       "      <td>0.717911</td>\n",
       "      <td>0.730236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.535189</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.796524</td>\n",
       "      <td>0.715685</td>\n",
       "      <td>0.730033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.544935</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.799588</td>\n",
       "      <td>0.726616</td>\n",
       "      <td>0.737089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 14:35:31,225] Trial 20 finished with value: 0.7370887780689291 and parameters: {'learning_rate': 0.000361812949512664, 'weight_decay': 0.004, 'warmup_steps': 43}. Best is trial 17 with value: 0.7580050071093316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 21 with params: {'learning_rate': 0.00011026679403682653, 'weight_decay': 0.001, 'warmup_steps': 31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:26 < 02:53, 30.18 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.167900</td>\n",
       "      <td>1.365226</td>\n",
       "      <td>0.739688</td>\n",
       "      <td>0.393730</td>\n",
       "      <td>0.385999</td>\n",
       "      <td>0.364381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.778500</td>\n",
       "      <td>1.069919</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.483172</td>\n",
       "      <td>0.468636</td>\n",
       "      <td>0.461949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.405500</td>\n",
       "      <td>0.998044</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.511290</td>\n",
       "      <td>0.510098</td>\n",
       "      <td>0.499486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.235300</td>\n",
       "      <td>1.016451</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>0.646376</td>\n",
       "      <td>0.567255</td>\n",
       "      <td>0.585562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.147500</td>\n",
       "      <td>1.025737</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.680811</td>\n",
       "      <td>0.614708</td>\n",
       "      <td>0.630010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 14:36:59,100] Trial 21 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 22 with params: {'learning_rate': 0.00021395919910874566, 'weight_decay': 0.0, 'warmup_steps': 22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:22, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.592300</td>\n",
       "      <td>1.064490</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.428614</td>\n",
       "      <td>0.460625</td>\n",
       "      <td>0.435892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.359200</td>\n",
       "      <td>0.992285</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.616803</td>\n",
       "      <td>0.578763</td>\n",
       "      <td>0.581397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.137000</td>\n",
       "      <td>1.068351</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.715481</td>\n",
       "      <td>0.644659</td>\n",
       "      <td>0.662727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.068700</td>\n",
       "      <td>1.116451</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.786813</td>\n",
       "      <td>0.670329</td>\n",
       "      <td>0.708278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.042500</td>\n",
       "      <td>1.141690</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.790859</td>\n",
       "      <td>0.715172</td>\n",
       "      <td>0.738254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>1.203510</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.790571</td>\n",
       "      <td>0.690604</td>\n",
       "      <td>0.720980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.020600</td>\n",
       "      <td>1.280643</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.790239</td>\n",
       "      <td>0.685968</td>\n",
       "      <td>0.715120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>1.283796</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.781728</td>\n",
       "      <td>0.713356</td>\n",
       "      <td>0.729808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>1.307708</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.786277</td>\n",
       "      <td>0.714999</td>\n",
       "      <td>0.733000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>1.361951</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.813911</td>\n",
       "      <td>0.731742</td>\n",
       "      <td>0.752438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.401739</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.808067</td>\n",
       "      <td>0.707047</td>\n",
       "      <td>0.734964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>1.399965</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.796820</td>\n",
       "      <td>0.737976</td>\n",
       "      <td>0.750028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>1.414328</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.783167</td>\n",
       "      <td>0.732781</td>\n",
       "      <td>0.745040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.416775</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.809366</td>\n",
       "      <td>0.736494</td>\n",
       "      <td>0.754705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.423944</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.817065</td>\n",
       "      <td>0.735859</td>\n",
       "      <td>0.756950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 14:41:23,189] Trial 22 finished with value: 0.7569498805852943 and parameters: {'learning_rate': 0.00021395919910874566, 'weight_decay': 0.0, 'warmup_steps': 22}. Best is trial 17 with value: 0.7580050071093316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 23 with params: {'learning_rate': 0.00013556631398918, 'weight_decay': 0.0, 'warmup_steps': 25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:27 < 02:54, 30.09 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.976100</td>\n",
       "      <td>1.242712</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.405633</td>\n",
       "      <td>0.409496</td>\n",
       "      <td>0.388975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.622100</td>\n",
       "      <td>1.025029</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.487094</td>\n",
       "      <td>0.487781</td>\n",
       "      <td>0.478090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.291800</td>\n",
       "      <td>0.996974</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.603113</td>\n",
       "      <td>0.565990</td>\n",
       "      <td>0.570564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.158100</td>\n",
       "      <td>1.043222</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.679024</td>\n",
       "      <td>0.600858</td>\n",
       "      <td>0.624626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.096100</td>\n",
       "      <td>1.059476</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.688594</td>\n",
       "      <td>0.617765</td>\n",
       "      <td>0.635399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 14:42:51,342] Trial 23 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 24 with params: {'learning_rate': 0.00045779559037543175, 'weight_decay': 0.001, 'warmup_steps': 40}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:31, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.122100</td>\n",
       "      <td>1.001019</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.563925</td>\n",
       "      <td>0.559342</td>\n",
       "      <td>0.550362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.135200</td>\n",
       "      <td>1.130160</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.721901</td>\n",
       "      <td>0.664846</td>\n",
       "      <td>0.675905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>1.221628</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.763983</td>\n",
       "      <td>0.709411</td>\n",
       "      <td>0.716075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.029300</td>\n",
       "      <td>1.302753</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.777357</td>\n",
       "      <td>0.725442</td>\n",
       "      <td>0.734343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>1.339757</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.780491</td>\n",
       "      <td>0.699378</td>\n",
       "      <td>0.723717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>1.342650</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.816784</td>\n",
       "      <td>0.716026</td>\n",
       "      <td>0.743868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>1.461431</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.789704</td>\n",
       "      <td>0.695651</td>\n",
       "      <td>0.721186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>1.518393</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.784181</td>\n",
       "      <td>0.702108</td>\n",
       "      <td>0.722768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>1.635905</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.769093</td>\n",
       "      <td>0.696124</td>\n",
       "      <td>0.713827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.563534</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.803220</td>\n",
       "      <td>0.713689</td>\n",
       "      <td>0.734797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.571104</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.774607</td>\n",
       "      <td>0.690406</td>\n",
       "      <td>0.715551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.593830</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.767784</td>\n",
       "      <td>0.719944</td>\n",
       "      <td>0.725273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.635738</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.781045</td>\n",
       "      <td>0.721171</td>\n",
       "      <td>0.731574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.624408</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.772645</td>\n",
       "      <td>0.718812</td>\n",
       "      <td>0.729709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.620835</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.776863</td>\n",
       "      <td>0.711566</td>\n",
       "      <td>0.726862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 14:47:24,220] Trial 24 finished with value: 0.7268618251744781 and parameters: {'learning_rate': 0.00045779559037543175, 'weight_decay': 0.001, 'warmup_steps': 40}. Best is trial 17 with value: 0.7580050071093316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 with params: {'learning_rate': 0.00029316020225973684, 'weight_decay': 0.0, 'warmup_steps': 22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:23, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.357200</td>\n",
       "      <td>1.013097</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.473900</td>\n",
       "      <td>0.481209</td>\n",
       "      <td>0.464683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.232800</td>\n",
       "      <td>1.049055</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.741880</td>\n",
       "      <td>0.642819</td>\n",
       "      <td>0.669344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.084100</td>\n",
       "      <td>1.099239</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.758618</td>\n",
       "      <td>0.713146</td>\n",
       "      <td>0.723086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.042400</td>\n",
       "      <td>1.162179</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.800125</td>\n",
       "      <td>0.706135</td>\n",
       "      <td>0.733969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.027200</td>\n",
       "      <td>1.247058</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.776338</td>\n",
       "      <td>0.729331</td>\n",
       "      <td>0.739473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>1.292130</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.821590</td>\n",
       "      <td>0.706830</td>\n",
       "      <td>0.741728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>1.371214</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.783454</td>\n",
       "      <td>0.695446</td>\n",
       "      <td>0.714175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>1.377844</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.777486</td>\n",
       "      <td>0.711204</td>\n",
       "      <td>0.724464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>1.411340</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.777550</td>\n",
       "      <td>0.706367</td>\n",
       "      <td>0.723955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>1.441520</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.793771</td>\n",
       "      <td>0.714029</td>\n",
       "      <td>0.732433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.467098</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.779940</td>\n",
       "      <td>0.708573</td>\n",
       "      <td>0.725907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.455581</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.791881</td>\n",
       "      <td>0.723479</td>\n",
       "      <td>0.739586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.463380</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.771639</td>\n",
       "      <td>0.712793</td>\n",
       "      <td>0.726311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.469162</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.795047</td>\n",
       "      <td>0.727523</td>\n",
       "      <td>0.743983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.482176</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.798023</td>\n",
       "      <td>0.725099</td>\n",
       "      <td>0.743267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 14:51:49,077] Trial 25 finished with value: 0.7432670059707221 and parameters: {'learning_rate': 0.00029316020225973684, 'weight_decay': 0.0, 'warmup_steps': 22}. Best is trial 17 with value: 0.7580050071093316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 with params: {'learning_rate': 0.00021183183333503693, 'weight_decay': 0.001, 'warmup_steps': 33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:23, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.625700</td>\n",
       "      <td>1.064072</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.432558</td>\n",
       "      <td>0.451489</td>\n",
       "      <td>0.430218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.367100</td>\n",
       "      <td>0.975822</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.622050</td>\n",
       "      <td>0.580157</td>\n",
       "      <td>0.585901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.140500</td>\n",
       "      <td>1.042242</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.730978</td>\n",
       "      <td>0.649264</td>\n",
       "      <td>0.668624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>1.098554</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.801375</td>\n",
       "      <td>0.688687</td>\n",
       "      <td>0.724733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.042800</td>\n",
       "      <td>1.166963</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.778802</td>\n",
       "      <td>0.712948</td>\n",
       "      <td>0.731318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>1.236592</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.816931</td>\n",
       "      <td>0.690061</td>\n",
       "      <td>0.725432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>1.288869</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.807211</td>\n",
       "      <td>0.694807</td>\n",
       "      <td>0.724703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>1.297768</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.797699</td>\n",
       "      <td>0.724346</td>\n",
       "      <td>0.738049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>1.313787</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.781176</td>\n",
       "      <td>0.711893</td>\n",
       "      <td>0.728151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>1.358748</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.805283</td>\n",
       "      <td>0.719624</td>\n",
       "      <td>0.739739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>1.405206</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.808719</td>\n",
       "      <td>0.704818</td>\n",
       "      <td>0.730657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.378363</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.795100</td>\n",
       "      <td>0.736185</td>\n",
       "      <td>0.747669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>1.412373</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.789336</td>\n",
       "      <td>0.722584</td>\n",
       "      <td>0.739369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>1.416538</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.807322</td>\n",
       "      <td>0.725575</td>\n",
       "      <td>0.747122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.420121</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.813321</td>\n",
       "      <td>0.725458</td>\n",
       "      <td>0.749289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 14:56:13,754] Trial 26 finished with value: 0.7492893231772806 and parameters: {'learning_rate': 0.00021183183333503693, 'weight_decay': 0.001, 'warmup_steps': 33}. Best is trial 17 with value: 0.7580050071093316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 27 with params: {'learning_rate': 3.392171417341792e-05, 'weight_decay': 0.001, 'warmup_steps': 52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:26 < 02:54, 30.16 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.100700</td>\n",
       "      <td>2.474713</td>\n",
       "      <td>0.516040</td>\n",
       "      <td>0.164406</td>\n",
       "      <td>0.154103</td>\n",
       "      <td>0.133092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.004000</td>\n",
       "      <td>1.777640</td>\n",
       "      <td>0.676444</td>\n",
       "      <td>0.312077</td>\n",
       "      <td>0.299828</td>\n",
       "      <td>0.283410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.416000</td>\n",
       "      <td>1.434303</td>\n",
       "      <td>0.715857</td>\n",
       "      <td>0.369344</td>\n",
       "      <td>0.352275</td>\n",
       "      <td>0.334557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.075000</td>\n",
       "      <td>1.261288</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.376980</td>\n",
       "      <td>0.407094</td>\n",
       "      <td>0.381066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.859200</td>\n",
       "      <td>1.166448</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.420335</td>\n",
       "      <td>0.437960</td>\n",
       "      <td>0.418647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 14:57:41,941] Trial 27 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 28 with params: {'learning_rate': 0.0004660178751295263, 'weight_decay': 0.001, 'warmup_steps': 23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:34, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.074100</td>\n",
       "      <td>1.018013</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.569529</td>\n",
       "      <td>0.559863</td>\n",
       "      <td>0.551210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.134800</td>\n",
       "      <td>1.096953</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.770966</td>\n",
       "      <td>0.688494</td>\n",
       "      <td>0.706298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>1.253013</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.752990</td>\n",
       "      <td>0.723614</td>\n",
       "      <td>0.724736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>1.316740</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.826807</td>\n",
       "      <td>0.709310</td>\n",
       "      <td>0.743332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>1.364364</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.789409</td>\n",
       "      <td>0.711109</td>\n",
       "      <td>0.732129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>1.408139</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.815480</td>\n",
       "      <td>0.705371</td>\n",
       "      <td>0.735882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.594470</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.779085</td>\n",
       "      <td>0.690162</td>\n",
       "      <td>0.715239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>1.581487</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.768445</td>\n",
       "      <td>0.702788</td>\n",
       "      <td>0.717602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1.582771</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.795781</td>\n",
       "      <td>0.713435</td>\n",
       "      <td>0.737677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.620097</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.780053</td>\n",
       "      <td>0.727249</td>\n",
       "      <td>0.740082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.593267</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.782485</td>\n",
       "      <td>0.700613</td>\n",
       "      <td>0.722140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.665148</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.779757</td>\n",
       "      <td>0.715438</td>\n",
       "      <td>0.732418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.711017</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.770143</td>\n",
       "      <td>0.689704</td>\n",
       "      <td>0.711845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.654948</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.770661</td>\n",
       "      <td>0.716351</td>\n",
       "      <td>0.728528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>1.667147</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.776011</td>\n",
       "      <td>0.717561</td>\n",
       "      <td>0.732914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:02:17,632] Trial 28 finished with value: 0.7329138871656129 and parameters: {'learning_rate': 0.0004660178751295263, 'weight_decay': 0.001, 'warmup_steps': 23}. Best is trial 17 with value: 0.7580050071093316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 29 with params: {'learning_rate': 2.0641950878300647e-05, 'weight_decay': 0.003, 'warmup_steps': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:57 < 01:28, 29.56 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.308000</td>\n",
       "      <td>2.865723</td>\n",
       "      <td>0.447296</td>\n",
       "      <td>0.108563</td>\n",
       "      <td>0.113069</td>\n",
       "      <td>0.095446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.504500</td>\n",
       "      <td>2.267059</td>\n",
       "      <td>0.572869</td>\n",
       "      <td>0.216079</td>\n",
       "      <td>0.200183</td>\n",
       "      <td>0.185259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.979200</td>\n",
       "      <td>1.886768</td>\n",
       "      <td>0.630614</td>\n",
       "      <td>0.299019</td>\n",
       "      <td>0.259754</td>\n",
       "      <td>0.242226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.624000</td>\n",
       "      <td>1.636927</td>\n",
       "      <td>0.687443</td>\n",
       "      <td>0.333688</td>\n",
       "      <td>0.310050</td>\n",
       "      <td>0.293281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.368600</td>\n",
       "      <td>1.468848</td>\n",
       "      <td>0.707608</td>\n",
       "      <td>0.337620</td>\n",
       "      <td>0.335254</td>\n",
       "      <td>0.315498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.188500</td>\n",
       "      <td>1.355462</td>\n",
       "      <td>0.730522</td>\n",
       "      <td>0.385137</td>\n",
       "      <td>0.379966</td>\n",
       "      <td>0.362650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.049200</td>\n",
       "      <td>1.276898</td>\n",
       "      <td>0.744271</td>\n",
       "      <td>0.388397</td>\n",
       "      <td>0.402319</td>\n",
       "      <td>0.381387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.951100</td>\n",
       "      <td>1.224587</td>\n",
       "      <td>0.747938</td>\n",
       "      <td>0.386726</td>\n",
       "      <td>0.411815</td>\n",
       "      <td>0.385115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.873400</td>\n",
       "      <td>1.186583</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.410494</td>\n",
       "      <td>0.426566</td>\n",
       "      <td>0.406537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.809300</td>\n",
       "      <td>1.159403</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.419172</td>\n",
       "      <td>0.431577</td>\n",
       "      <td>0.411451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:05:16,091] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 with params: {'learning_rate': 6.987985617740108e-05, 'weight_decay': 0.0, 'warmup_steps': 17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:55 < 01:27, 29.93 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.535400</td>\n",
       "      <td>1.742593</td>\n",
       "      <td>0.675527</td>\n",
       "      <td>0.315473</td>\n",
       "      <td>0.295664</td>\n",
       "      <td>0.281621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.185800</td>\n",
       "      <td>1.214891</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.407289</td>\n",
       "      <td>0.413791</td>\n",
       "      <td>0.394192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.709100</td>\n",
       "      <td>1.077266</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.448725</td>\n",
       "      <td>0.468826</td>\n",
       "      <td>0.444165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.479900</td>\n",
       "      <td>1.022524</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.471236</td>\n",
       "      <td>0.476512</td>\n",
       "      <td>0.467897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.338100</td>\n",
       "      <td>0.994959</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.556209</td>\n",
       "      <td>0.512408</td>\n",
       "      <td>0.511101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.249400</td>\n",
       "      <td>0.997320</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>0.616999</td>\n",
       "      <td>0.563026</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.187400</td>\n",
       "      <td>1.015383</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.648794</td>\n",
       "      <td>0.583776</td>\n",
       "      <td>0.600168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.150700</td>\n",
       "      <td>1.015381</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.665089</td>\n",
       "      <td>0.604939</td>\n",
       "      <td>0.619498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.039915</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.666166</td>\n",
       "      <td>0.600638</td>\n",
       "      <td>0.614792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.104500</td>\n",
       "      <td>1.064718</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.703862</td>\n",
       "      <td>0.621312</td>\n",
       "      <td>0.641820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:08:12,632] Trial 30 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 31 with params: {'learning_rate': 0.00014924666987052023, 'weight_decay': 0.003, 'warmup_steps': 21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:26 < 02:53, 30.19 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.886000</td>\n",
       "      <td>1.191772</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.424148</td>\n",
       "      <td>0.427409</td>\n",
       "      <td>0.408330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.557600</td>\n",
       "      <td>1.000096</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.512692</td>\n",
       "      <td>0.508387</td>\n",
       "      <td>0.499622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.249700</td>\n",
       "      <td>0.987286</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.651371</td>\n",
       "      <td>0.597153</td>\n",
       "      <td>0.607417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.131200</td>\n",
       "      <td>1.050511</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.707745</td>\n",
       "      <td>0.625997</td>\n",
       "      <td>0.651737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.079400</td>\n",
       "      <td>1.071304</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.711789</td>\n",
       "      <td>0.649744</td>\n",
       "      <td>0.664648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:09:40,602] Trial 31 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 32 with params: {'learning_rate': 6.345426898630038e-05, 'weight_decay': 0.007, 'warmup_steps': 36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 03:06 < 01:33, 28.09 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.647200</td>\n",
       "      <td>1.855612</td>\n",
       "      <td>0.633364</td>\n",
       "      <td>0.290985</td>\n",
       "      <td>0.262393</td>\n",
       "      <td>0.246879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.298000</td>\n",
       "      <td>1.275791</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.406549</td>\n",
       "      <td>0.405670</td>\n",
       "      <td>0.382910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.793100</td>\n",
       "      <td>1.108657</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.459571</td>\n",
       "      <td>0.462479</td>\n",
       "      <td>0.443625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.547200</td>\n",
       "      <td>1.042066</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.480383</td>\n",
       "      <td>0.479177</td>\n",
       "      <td>0.471436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.397200</td>\n",
       "      <td>1.010589</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.495499</td>\n",
       "      <td>0.497778</td>\n",
       "      <td>0.486828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.299400</td>\n",
       "      <td>0.999449</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.572397</td>\n",
       "      <td>0.531203</td>\n",
       "      <td>0.535702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.228700</td>\n",
       "      <td>1.011061</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.616364</td>\n",
       "      <td>0.559521</td>\n",
       "      <td>0.568063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.185500</td>\n",
       "      <td>1.006341</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.650559</td>\n",
       "      <td>0.586293</td>\n",
       "      <td>0.602378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.155300</td>\n",
       "      <td>1.028409</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.644232</td>\n",
       "      <td>0.592316</td>\n",
       "      <td>0.603085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.131000</td>\n",
       "      <td>1.049430</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.692261</td>\n",
       "      <td>0.612784</td>\n",
       "      <td>0.631086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:12:48,442] Trial 32 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 33 with params: {'learning_rate': 0.00017430004274843807, 'weight_decay': 0.0, 'warmup_steps': 26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:28, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.766700</td>\n",
       "      <td>1.126739</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.413167</td>\n",
       "      <td>0.442648</td>\n",
       "      <td>0.417568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.466900</td>\n",
       "      <td>0.985336</td>\n",
       "      <td>0.778185</td>\n",
       "      <td>0.595319</td>\n",
       "      <td>0.541703</td>\n",
       "      <td>0.545147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.195200</td>\n",
       "      <td>1.008497</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.709793</td>\n",
       "      <td>0.636971</td>\n",
       "      <td>0.654383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.099200</td>\n",
       "      <td>1.069866</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.717072</td>\n",
       "      <td>0.630960</td>\n",
       "      <td>0.656054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>1.104326</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.796636</td>\n",
       "      <td>0.717823</td>\n",
       "      <td>0.742210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.040500</td>\n",
       "      <td>1.187187</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.779801</td>\n",
       "      <td>0.663537</td>\n",
       "      <td>0.697101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>1.239047</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.800949</td>\n",
       "      <td>0.692596</td>\n",
       "      <td>0.722262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>1.219584</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.812345</td>\n",
       "      <td>0.726780</td>\n",
       "      <td>0.746152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>1.263839</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.800712</td>\n",
       "      <td>0.705104</td>\n",
       "      <td>0.732188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>1.306304</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.816305</td>\n",
       "      <td>0.712985</td>\n",
       "      <td>0.737721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>1.324374</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.801405</td>\n",
       "      <td>0.722166</td>\n",
       "      <td>0.738892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>1.340308</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.781565</td>\n",
       "      <td>0.722317</td>\n",
       "      <td>0.733892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>1.372928</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.799775</td>\n",
       "      <td>0.726732</td>\n",
       "      <td>0.744969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>1.370220</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.818704</td>\n",
       "      <td>0.728825</td>\n",
       "      <td>0.751654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.376486</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.824133</td>\n",
       "      <td>0.728673</td>\n",
       "      <td>0.752858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:17:18,646] Trial 33 finished with value: 0.7528584883043424 and parameters: {'learning_rate': 0.00017430004274843807, 'weight_decay': 0.0, 'warmup_steps': 26}. Best is trial 17 with value: 0.7580050071093316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 34 with params: {'learning_rate': 0.00015787988695294925, 'weight_decay': 0.0, 'warmup_steps': 23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:25, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.842800</td>\n",
       "      <td>1.165748</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.426338</td>\n",
       "      <td>0.438101</td>\n",
       "      <td>0.420167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.524000</td>\n",
       "      <td>0.993953</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.510956</td>\n",
       "      <td>0.508922</td>\n",
       "      <td>0.499078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.228500</td>\n",
       "      <td>0.991997</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.644318</td>\n",
       "      <td>0.596789</td>\n",
       "      <td>0.603871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.118700</td>\n",
       "      <td>1.058587</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.705606</td>\n",
       "      <td>0.625937</td>\n",
       "      <td>0.650848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.071700</td>\n",
       "      <td>1.089444</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.758730</td>\n",
       "      <td>0.688762</td>\n",
       "      <td>0.709230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.048700</td>\n",
       "      <td>1.157826</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.770450</td>\n",
       "      <td>0.660472</td>\n",
       "      <td>0.692302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>1.207285</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.807708</td>\n",
       "      <td>0.694496</td>\n",
       "      <td>0.723009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.026800</td>\n",
       "      <td>1.188141</td>\n",
       "      <td>0.806599</td>\n",
       "      <td>0.799156</td>\n",
       "      <td>0.737388</td>\n",
       "      <td>0.749069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>1.240221</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.787788</td>\n",
       "      <td>0.683068</td>\n",
       "      <td>0.711845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>1.277690</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.806872</td>\n",
       "      <td>0.710345</td>\n",
       "      <td>0.731232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.292240</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.796759</td>\n",
       "      <td>0.704112</td>\n",
       "      <td>0.724770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>1.309081</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.782655</td>\n",
       "      <td>0.724393</td>\n",
       "      <td>0.732946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>1.336277</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.792892</td>\n",
       "      <td>0.725846</td>\n",
       "      <td>0.740825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.335539</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.809082</td>\n",
       "      <td>0.726395</td>\n",
       "      <td>0.745230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>1.344453</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.809586</td>\n",
       "      <td>0.723930</td>\n",
       "      <td>0.743169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:21:45,802] Trial 34 finished with value: 0.7431685718388262 and parameters: {'learning_rate': 0.00015787988695294925, 'weight_decay': 0.0, 'warmup_steps': 23}. Best is trial 17 with value: 0.7580050071093316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 35 with params: {'learning_rate': 0.00022960780811284495, 'weight_decay': 0.0, 'warmup_steps': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:29, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.561100</td>\n",
       "      <td>1.047609</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.436304</td>\n",
       "      <td>0.459997</td>\n",
       "      <td>0.436472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.330900</td>\n",
       "      <td>0.988089</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.648417</td>\n",
       "      <td>0.595499</td>\n",
       "      <td>0.605383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.123600</td>\n",
       "      <td>1.064147</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.737404</td>\n",
       "      <td>0.662007</td>\n",
       "      <td>0.681910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.061100</td>\n",
       "      <td>1.123247</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.786428</td>\n",
       "      <td>0.675511</td>\n",
       "      <td>0.710648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.038100</td>\n",
       "      <td>1.152096</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.797520</td>\n",
       "      <td>0.720778</td>\n",
       "      <td>0.743422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>1.211240</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.795212</td>\n",
       "      <td>0.690237</td>\n",
       "      <td>0.720518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.018700</td>\n",
       "      <td>1.256299</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.800260</td>\n",
       "      <td>0.705905</td>\n",
       "      <td>0.730310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>1.305656</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.786047</td>\n",
       "      <td>0.715616</td>\n",
       "      <td>0.729304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>1.288958</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.790716</td>\n",
       "      <td>0.719884</td>\n",
       "      <td>0.736235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>1.374259</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.808462</td>\n",
       "      <td>0.722988</td>\n",
       "      <td>0.744764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.408726</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.808878</td>\n",
       "      <td>0.710887</td>\n",
       "      <td>0.736251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.389976</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.739972</td>\n",
       "      <td>0.755470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>1.410489</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.795310</td>\n",
       "      <td>0.724299</td>\n",
       "      <td>0.740528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.408307</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.807768</td>\n",
       "      <td>0.729362</td>\n",
       "      <td>0.748742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>1.415474</td>\n",
       "      <td>0.805683</td>\n",
       "      <td>0.819324</td>\n",
       "      <td>0.739355</td>\n",
       "      <td>0.759444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:26:16,590] Trial 35 finished with value: 0.7594440660912989 and parameters: {'learning_rate': 0.00022960780811284495, 'weight_decay': 0.0, 'warmup_steps': 32}. Best is trial 35 with value: 0.7594440660912989.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 36 with params: {'learning_rate': 1.0625556226593494e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:56 < 01:28, 29.72 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.556400</td>\n",
       "      <td>3.277113</td>\n",
       "      <td>0.344638</td>\n",
       "      <td>0.041242</td>\n",
       "      <td>0.071194</td>\n",
       "      <td>0.049556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.048800</td>\n",
       "      <td>2.866364</td>\n",
       "      <td>0.450046</td>\n",
       "      <td>0.107878</td>\n",
       "      <td>0.117442</td>\n",
       "      <td>0.101260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.676300</td>\n",
       "      <td>2.555880</td>\n",
       "      <td>0.496792</td>\n",
       "      <td>0.128688</td>\n",
       "      <td>0.142019</td>\n",
       "      <td>0.117496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.385800</td>\n",
       "      <td>2.315833</td>\n",
       "      <td>0.545371</td>\n",
       "      <td>0.215387</td>\n",
       "      <td>0.177761</td>\n",
       "      <td>0.160297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.150000</td>\n",
       "      <td>2.130701</td>\n",
       "      <td>0.590284</td>\n",
       "      <td>0.252087</td>\n",
       "      <td>0.219675</td>\n",
       "      <td>0.202746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.967700</td>\n",
       "      <td>1.984557</td>\n",
       "      <td>0.608616</td>\n",
       "      <td>0.277066</td>\n",
       "      <td>0.236241</td>\n",
       "      <td>0.221381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.817800</td>\n",
       "      <td>1.867865</td>\n",
       "      <td>0.630614</td>\n",
       "      <td>0.269416</td>\n",
       "      <td>0.252817</td>\n",
       "      <td>0.236675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.702200</td>\n",
       "      <td>1.776535</td>\n",
       "      <td>0.662695</td>\n",
       "      <td>0.296337</td>\n",
       "      <td>0.278332</td>\n",
       "      <td>0.261177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.607500</td>\n",
       "      <td>1.702992</td>\n",
       "      <td>0.677360</td>\n",
       "      <td>0.349868</td>\n",
       "      <td>0.297492</td>\n",
       "      <td>0.281517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.530400</td>\n",
       "      <td>1.646366</td>\n",
       "      <td>0.683776</td>\n",
       "      <td>0.342437</td>\n",
       "      <td>0.303762</td>\n",
       "      <td>0.287951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:29:14,102] Trial 36 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 37 with params: {'learning_rate': 0.00015825915775592185, 'weight_decay': 0.0, 'warmup_steps': 11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:27 < 02:54, 30.00 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.813200</td>\n",
       "      <td>1.166780</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.420051</td>\n",
       "      <td>0.438593</td>\n",
       "      <td>0.416749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.518600</td>\n",
       "      <td>0.991947</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.533309</td>\n",
       "      <td>0.515211</td>\n",
       "      <td>0.510130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.226100</td>\n",
       "      <td>0.995811</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.645175</td>\n",
       "      <td>0.602662</td>\n",
       "      <td>0.608594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.118100</td>\n",
       "      <td>1.054857</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.697514</td>\n",
       "      <td>0.621272</td>\n",
       "      <td>0.644300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>1.093040</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.767121</td>\n",
       "      <td>0.690611</td>\n",
       "      <td>0.710609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:30:42,600] Trial 37 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 38 with params: {'learning_rate': 0.0003170124206449671, 'weight_decay': 0.0, 'warmup_steps': 34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:52 < 01:26, 30.35 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.332600</td>\n",
       "      <td>1.011052</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.477851</td>\n",
       "      <td>0.483923</td>\n",
       "      <td>0.469884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.213500</td>\n",
       "      <td>1.061812</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.740442</td>\n",
       "      <td>0.642259</td>\n",
       "      <td>0.667430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>1.169240</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.746540</td>\n",
       "      <td>0.708760</td>\n",
       "      <td>0.710595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>1.213153</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.810219</td>\n",
       "      <td>0.696029</td>\n",
       "      <td>0.720801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>1.275878</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.803856</td>\n",
       "      <td>0.715780</td>\n",
       "      <td>0.739202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>1.327408</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.800474</td>\n",
       "      <td>0.716923</td>\n",
       "      <td>0.742138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>1.430923</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.784838</td>\n",
       "      <td>0.705203</td>\n",
       "      <td>0.723722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>1.459790</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.789648</td>\n",
       "      <td>0.730571</td>\n",
       "      <td>0.742841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>1.491943</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.804922</td>\n",
       "      <td>0.712877</td>\n",
       "      <td>0.737068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1.509696</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.760814</td>\n",
       "      <td>0.719105</td>\n",
       "      <td>0.721953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:33:36,526] Trial 38 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 39 with params: {'learning_rate': 0.00013253735630179916, 'weight_decay': 0.009000000000000001, 'warmup_steps': 53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:23, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.055700</td>\n",
       "      <td>1.264311</td>\n",
       "      <td>0.741522</td>\n",
       "      <td>0.371309</td>\n",
       "      <td>0.392818</td>\n",
       "      <td>0.367256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.650800</td>\n",
       "      <td>1.037162</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.486087</td>\n",
       "      <td>0.489683</td>\n",
       "      <td>0.481139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.312100</td>\n",
       "      <td>0.984352</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.629428</td>\n",
       "      <td>0.576830</td>\n",
       "      <td>0.586500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.168700</td>\n",
       "      <td>1.017910</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.670489</td>\n",
       "      <td>0.604070</td>\n",
       "      <td>0.621558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.102200</td>\n",
       "      <td>1.049518</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.691023</td>\n",
       "      <td>0.622411</td>\n",
       "      <td>0.638495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>1.088089</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.745014</td>\n",
       "      <td>0.645716</td>\n",
       "      <td>0.673217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.047600</td>\n",
       "      <td>1.139142</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.798913</td>\n",
       "      <td>0.687651</td>\n",
       "      <td>0.716713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>1.152830</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.792086</td>\n",
       "      <td>0.710992</td>\n",
       "      <td>0.729412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>1.185607</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.793364</td>\n",
       "      <td>0.702396</td>\n",
       "      <td>0.726269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>1.234649</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.808519</td>\n",
       "      <td>0.713928</td>\n",
       "      <td>0.734818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>1.236556</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.793506</td>\n",
       "      <td>0.703467</td>\n",
       "      <td>0.724611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>1.255045</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.798816</td>\n",
       "      <td>0.744831</td>\n",
       "      <td>0.750889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>1.265196</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.791596</td>\n",
       "      <td>0.713374</td>\n",
       "      <td>0.730785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>1.267872</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.787151</td>\n",
       "      <td>0.705449</td>\n",
       "      <td>0.726085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>1.277246</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.802919</td>\n",
       "      <td>0.724809</td>\n",
       "      <td>0.740467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:38:01,437] Trial 39 finished with value: 0.7404671524632447 and parameters: {'learning_rate': 0.00013253735630179916, 'weight_decay': 0.009000000000000001, 'warmup_steps': 53}. Best is trial 35 with value: 0.7594440660912989.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 40 with params: {'learning_rate': 0.00012436274551017268, 'weight_decay': 0.0, 'warmup_steps': 37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:26 < 02:54, 30.16 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.075000</td>\n",
       "      <td>1.292103</td>\n",
       "      <td>0.740605</td>\n",
       "      <td>0.381365</td>\n",
       "      <td>0.391683</td>\n",
       "      <td>0.368192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.689400</td>\n",
       "      <td>1.047020</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.492000</td>\n",
       "      <td>0.479422</td>\n",
       "      <td>0.474726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.340800</td>\n",
       "      <td>0.989150</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.574796</td>\n",
       "      <td>0.541511</td>\n",
       "      <td>0.541973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.189200</td>\n",
       "      <td>1.019830</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.685082</td>\n",
       "      <td>0.603872</td>\n",
       "      <td>0.628382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.116000</td>\n",
       "      <td>1.035485</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.690299</td>\n",
       "      <td>0.617528</td>\n",
       "      <td>0.635862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:39:29,298] Trial 40 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 41 with params: {'learning_rate': 0.0002216100860329021, 'weight_decay': 0.0, 'warmup_steps': 26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:23, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.574500</td>\n",
       "      <td>1.054667</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.431765</td>\n",
       "      <td>0.459001</td>\n",
       "      <td>0.436005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.344000</td>\n",
       "      <td>0.990796</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.622569</td>\n",
       "      <td>0.579235</td>\n",
       "      <td>0.585162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.130200</td>\n",
       "      <td>1.072570</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.723161</td>\n",
       "      <td>0.645718</td>\n",
       "      <td>0.664601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>1.119638</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.790062</td>\n",
       "      <td>0.672433</td>\n",
       "      <td>0.710665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.040800</td>\n",
       "      <td>1.170836</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.791366</td>\n",
       "      <td>0.711515</td>\n",
       "      <td>0.734233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>1.222312</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.774312</td>\n",
       "      <td>0.679063</td>\n",
       "      <td>0.707403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>1.286571</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.798173</td>\n",
       "      <td>0.684722</td>\n",
       "      <td>0.717438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>1.278331</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.772696</td>\n",
       "      <td>0.718609</td>\n",
       "      <td>0.729551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>1.301972</td>\n",
       "      <td>0.804766</td>\n",
       "      <td>0.811447</td>\n",
       "      <td>0.719119</td>\n",
       "      <td>0.744972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>1.375505</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.805204</td>\n",
       "      <td>0.722767</td>\n",
       "      <td>0.744102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>1.404375</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.802169</td>\n",
       "      <td>0.708639</td>\n",
       "      <td>0.735644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>1.402283</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.799482</td>\n",
       "      <td>0.735810</td>\n",
       "      <td>0.749241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>1.430647</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.786522</td>\n",
       "      <td>0.726372</td>\n",
       "      <td>0.741391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.418805</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.728746</td>\n",
       "      <td>0.751639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.429481</td>\n",
       "      <td>0.806599</td>\n",
       "      <td>0.816375</td>\n",
       "      <td>0.739045</td>\n",
       "      <td>0.759315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:43:54,361] Trial 41 finished with value: 0.7593151714771309 and parameters: {'learning_rate': 0.0002216100860329021, 'weight_decay': 0.0, 'warmup_steps': 26}. Best is trial 35 with value: 0.7594440660912989.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 42 with params: {'learning_rate': 1.0600021319893152e-05, 'weight_decay': 0.005, 'warmup_steps': 49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:28 < 02:57, 29.55 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.572600</td>\n",
       "      <td>3.289061</td>\n",
       "      <td>0.342805</td>\n",
       "      <td>0.042988</td>\n",
       "      <td>0.070592</td>\n",
       "      <td>0.050293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.059700</td>\n",
       "      <td>2.875604</td>\n",
       "      <td>0.447296</td>\n",
       "      <td>0.108748</td>\n",
       "      <td>0.116003</td>\n",
       "      <td>0.100348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.685000</td>\n",
       "      <td>2.563314</td>\n",
       "      <td>0.494959</td>\n",
       "      <td>0.109420</td>\n",
       "      <td>0.141077</td>\n",
       "      <td>0.116378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.392900</td>\n",
       "      <td>2.321894</td>\n",
       "      <td>0.541705</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.173759</td>\n",
       "      <td>0.155802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.156100</td>\n",
       "      <td>2.136004</td>\n",
       "      <td>0.590284</td>\n",
       "      <td>0.251093</td>\n",
       "      <td>0.219675</td>\n",
       "      <td>0.203444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:45:24,222] Trial 42 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 43 with params: {'learning_rate': 0.00024680468112840877, 'weight_decay': 0.0, 'warmup_steps': 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:25, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.473000</td>\n",
       "      <td>1.037048</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.447927</td>\n",
       "      <td>0.474522</td>\n",
       "      <td>0.452579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.294100</td>\n",
       "      <td>0.998802</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.700334</td>\n",
       "      <td>0.621414</td>\n",
       "      <td>0.642356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.108200</td>\n",
       "      <td>1.075449</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.759272</td>\n",
       "      <td>0.694726</td>\n",
       "      <td>0.711261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>1.121760</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.807596</td>\n",
       "      <td>0.703013</td>\n",
       "      <td>0.735085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.034100</td>\n",
       "      <td>1.192193</td>\n",
       "      <td>0.805683</td>\n",
       "      <td>0.799816</td>\n",
       "      <td>0.724901</td>\n",
       "      <td>0.746347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>1.226431</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.818910</td>\n",
       "      <td>0.706659</td>\n",
       "      <td>0.740091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>1.295973</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.815621</td>\n",
       "      <td>0.706793</td>\n",
       "      <td>0.737959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.307988</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.801059</td>\n",
       "      <td>0.725024</td>\n",
       "      <td>0.743949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>1.374600</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.793341</td>\n",
       "      <td>0.722026</td>\n",
       "      <td>0.742294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>1.358015</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.809978</td>\n",
       "      <td>0.724414</td>\n",
       "      <td>0.747130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.421309</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.805401</td>\n",
       "      <td>0.721810</td>\n",
       "      <td>0.746018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.414016</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.802625</td>\n",
       "      <td>0.729651</td>\n",
       "      <td>0.748398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.409892</td>\n",
       "      <td>0.805683</td>\n",
       "      <td>0.813804</td>\n",
       "      <td>0.731124</td>\n",
       "      <td>0.755229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.408455</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.820622</td>\n",
       "      <td>0.739188</td>\n",
       "      <td>0.762406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.424546</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.821197</td>\n",
       "      <td>0.737601</td>\n",
       "      <td>0.761457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:49:51,369] Trial 43 finished with value: 0.7614573567738171 and parameters: {'learning_rate': 0.00024680468112840877, 'weight_decay': 0.0, 'warmup_steps': 18}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 44 with params: {'learning_rate': 0.0002733656803199959, 'weight_decay': 0.001, 'warmup_steps': 19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 03:02 < 01:31, 28.82 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.400200</td>\n",
       "      <td>1.022626</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.472187</td>\n",
       "      <td>0.479800</td>\n",
       "      <td>0.461996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.256100</td>\n",
       "      <td>1.016799</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.740003</td>\n",
       "      <td>0.639283</td>\n",
       "      <td>0.666293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.093200</td>\n",
       "      <td>1.113124</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.762688</td>\n",
       "      <td>0.682775</td>\n",
       "      <td>0.703596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>1.160813</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.828941</td>\n",
       "      <td>0.694659</td>\n",
       "      <td>0.735955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>1.223989</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.805993</td>\n",
       "      <td>0.720026</td>\n",
       "      <td>0.745111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>1.261537</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.804877</td>\n",
       "      <td>0.708194</td>\n",
       "      <td>0.738842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>1.315923</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.784836</td>\n",
       "      <td>0.705002</td>\n",
       "      <td>0.720892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>1.375143</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.793448</td>\n",
       "      <td>0.725041</td>\n",
       "      <td>0.740606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>1.420210</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.804441</td>\n",
       "      <td>0.714473</td>\n",
       "      <td>0.738916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>1.432115</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.800824</td>\n",
       "      <td>0.713020</td>\n",
       "      <td>0.736657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:52:54,555] Trial 44 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 45 with params: {'learning_rate': 0.0003707086290945264, 'weight_decay': 0.0, 'warmup_steps': 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 03:01 < 01:31, 28.85 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.193100</td>\n",
       "      <td>1.000822</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.516713</td>\n",
       "      <td>0.520263</td>\n",
       "      <td>0.504640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.173300</td>\n",
       "      <td>1.070531</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.737202</td>\n",
       "      <td>0.645712</td>\n",
       "      <td>0.669838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.063800</td>\n",
       "      <td>1.166224</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.787676</td>\n",
       "      <td>0.729472</td>\n",
       "      <td>0.740447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>1.263318</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.818599</td>\n",
       "      <td>0.708221</td>\n",
       "      <td>0.737846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>1.306428</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.789846</td>\n",
       "      <td>0.713454</td>\n",
       "      <td>0.734975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>1.393010</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.821730</td>\n",
       "      <td>0.702895</td>\n",
       "      <td>0.736189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>1.426687</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.768153</td>\n",
       "      <td>0.691606</td>\n",
       "      <td>0.711952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.496403</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.779654</td>\n",
       "      <td>0.724195</td>\n",
       "      <td>0.735942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.534069</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.778366</td>\n",
       "      <td>0.709809</td>\n",
       "      <td>0.723898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.509087</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.808507</td>\n",
       "      <td>0.707606</td>\n",
       "      <td>0.732605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:55:57,648] Trial 45 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 46 with params: {'learning_rate': 0.0001660129744875839, 'weight_decay': 0.0, 'warmup_steps': 22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:28 < 02:57, 29.58 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.798100</td>\n",
       "      <td>1.144022</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.421055</td>\n",
       "      <td>0.440833</td>\n",
       "      <td>0.419630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.493400</td>\n",
       "      <td>0.988858</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.574017</td>\n",
       "      <td>0.534182</td>\n",
       "      <td>0.533921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.210800</td>\n",
       "      <td>1.001307</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.689344</td>\n",
       "      <td>0.615632</td>\n",
       "      <td>0.632048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.108600</td>\n",
       "      <td>1.066251</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.716145</td>\n",
       "      <td>0.633010</td>\n",
       "      <td>0.657508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>1.100182</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.761175</td>\n",
       "      <td>0.689078</td>\n",
       "      <td>0.709413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 15:57:27,557] Trial 46 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 47 with params: {'learning_rate': 0.00019528036767985562, 'weight_decay': 0.002, 'warmup_steps': 15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:26, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.648800</td>\n",
       "      <td>1.092727</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.425906</td>\n",
       "      <td>0.451394</td>\n",
       "      <td>0.428972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.401700</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.625102</td>\n",
       "      <td>0.582287</td>\n",
       "      <td>0.587253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.158400</td>\n",
       "      <td>1.042020</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.726734</td>\n",
       "      <td>0.645729</td>\n",
       "      <td>0.665554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.079800</td>\n",
       "      <td>1.094353</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.763084</td>\n",
       "      <td>0.658349</td>\n",
       "      <td>0.693458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>1.131351</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.795781</td>\n",
       "      <td>0.723611</td>\n",
       "      <td>0.744625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>1.194931</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.789509</td>\n",
       "      <td>0.695307</td>\n",
       "      <td>0.724269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>1.251784</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.801060</td>\n",
       "      <td>0.697108</td>\n",
       "      <td>0.724614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>1.268923</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.803247</td>\n",
       "      <td>0.720643</td>\n",
       "      <td>0.738876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>1.291044</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.790769</td>\n",
       "      <td>0.713938</td>\n",
       "      <td>0.732637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>1.354426</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.800693</td>\n",
       "      <td>0.715339</td>\n",
       "      <td>0.734341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>1.371577</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.797438</td>\n",
       "      <td>0.730838</td>\n",
       "      <td>0.744093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>1.372450</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.793167</td>\n",
       "      <td>0.725406</td>\n",
       "      <td>0.740982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.404438</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.791970</td>\n",
       "      <td>0.724911</td>\n",
       "      <td>0.741640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.408637</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.813576</td>\n",
       "      <td>0.727179</td>\n",
       "      <td>0.748466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>1.411045</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.814598</td>\n",
       "      <td>0.733182</td>\n",
       "      <td>0.754982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 16:01:55,953] Trial 47 finished with value: 0.7549818038549151 and parameters: {'learning_rate': 0.00019528036767985562, 'weight_decay': 0.002, 'warmup_steps': 15}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 48 with params: {'learning_rate': 0.00030654958421000896, 'weight_decay': 0.0, 'warmup_steps': 31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:54 < 01:27, 30.05 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.348800</td>\n",
       "      <td>1.016664</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.474497</td>\n",
       "      <td>0.486248</td>\n",
       "      <td>0.471716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.222800</td>\n",
       "      <td>1.054986</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.752061</td>\n",
       "      <td>0.638129</td>\n",
       "      <td>0.669234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.081600</td>\n",
       "      <td>1.115013</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.760461</td>\n",
       "      <td>0.704854</td>\n",
       "      <td>0.714176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>1.217213</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.814962</td>\n",
       "      <td>0.686896</td>\n",
       "      <td>0.723035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>1.286146</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.792538</td>\n",
       "      <td>0.718235</td>\n",
       "      <td>0.729928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>1.291729</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.801415</td>\n",
       "      <td>0.720886</td>\n",
       "      <td>0.741199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>1.362294</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.763926</td>\n",
       "      <td>0.699307</td>\n",
       "      <td>0.709726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>1.387871</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.793921</td>\n",
       "      <td>0.728443</td>\n",
       "      <td>0.740960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>1.444538</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.801066</td>\n",
       "      <td>0.714910</td>\n",
       "      <td>0.734761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.453181</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.792028</td>\n",
       "      <td>0.722828</td>\n",
       "      <td>0.728057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 16:04:51,629] Trial 48 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 49 with params: {'learning_rate': 0.00032562008657011007, 'weight_decay': 0.0, 'warmup_steps': 17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:56 < 01:28, 29.67 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.274700</td>\n",
       "      <td>1.019665</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.500323</td>\n",
       "      <td>0.499312</td>\n",
       "      <td>0.485844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.203400</td>\n",
       "      <td>1.044708</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.726420</td>\n",
       "      <td>0.655212</td>\n",
       "      <td>0.673581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>1.139545</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.783305</td>\n",
       "      <td>0.731718</td>\n",
       "      <td>0.740069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>1.190928</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.823246</td>\n",
       "      <td>0.713875</td>\n",
       "      <td>0.744602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>1.317345</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.795814</td>\n",
       "      <td>0.709300</td>\n",
       "      <td>0.731120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>1.346438</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.819467</td>\n",
       "      <td>0.717201</td>\n",
       "      <td>0.747505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>1.454784</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.805598</td>\n",
       "      <td>0.701812</td>\n",
       "      <td>0.726987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>1.425999</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.791692</td>\n",
       "      <td>0.702544</td>\n",
       "      <td>0.722505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1.445811</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.788500</td>\n",
       "      <td>0.696898</td>\n",
       "      <td>0.723115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.520325</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.795014</td>\n",
       "      <td>0.706633</td>\n",
       "      <td>0.729667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 16:07:49,527] Trial 49 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 with params: {'learning_rate': 0.0003186834743092994, 'weight_decay': 0.002, 'warmup_steps': 31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:55 < 01:27, 29.98 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.322500</td>\n",
       "      <td>1.009114</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.488718</td>\n",
       "      <td>0.497965</td>\n",
       "      <td>0.483624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.212300</td>\n",
       "      <td>1.071272</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.708324</td>\n",
       "      <td>0.624715</td>\n",
       "      <td>0.645763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.077900</td>\n",
       "      <td>1.161519</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.773156</td>\n",
       "      <td>0.720794</td>\n",
       "      <td>0.730318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.039300</td>\n",
       "      <td>1.245341</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.835394</td>\n",
       "      <td>0.699367</td>\n",
       "      <td>0.737985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.025100</td>\n",
       "      <td>1.318093</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.803640</td>\n",
       "      <td>0.710656</td>\n",
       "      <td>0.738389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>1.337886</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.813473</td>\n",
       "      <td>0.705326</td>\n",
       "      <td>0.739405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>1.436570</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.810494</td>\n",
       "      <td>0.699847</td>\n",
       "      <td>0.729712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>1.437814</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.799907</td>\n",
       "      <td>0.719250</td>\n",
       "      <td>0.737495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>1.498787</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.786478</td>\n",
       "      <td>0.700265</td>\n",
       "      <td>0.722915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.540602</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.775186</td>\n",
       "      <td>0.698954</td>\n",
       "      <td>0.718796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 16:10:45,619] Trial 50 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 51 with params: {'learning_rate': 0.00023281979342328887, 'weight_decay': 0.003, 'warmup_steps': 13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:29, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.506000</td>\n",
       "      <td>1.048246</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.440287</td>\n",
       "      <td>0.469407</td>\n",
       "      <td>0.444667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.998708</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.640047</td>\n",
       "      <td>0.599452</td>\n",
       "      <td>0.602449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.119100</td>\n",
       "      <td>1.071617</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.742618</td>\n",
       "      <td>0.674002</td>\n",
       "      <td>0.691091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>1.105311</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.811786</td>\n",
       "      <td>0.706784</td>\n",
       "      <td>0.740778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>1.144164</td>\n",
       "      <td>0.805683</td>\n",
       "      <td>0.797791</td>\n",
       "      <td>0.720475</td>\n",
       "      <td>0.743057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>1.207784</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.809762</td>\n",
       "      <td>0.696381</td>\n",
       "      <td>0.730898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>1.248129</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.796143</td>\n",
       "      <td>0.701113</td>\n",
       "      <td>0.726338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>1.274865</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.797650</td>\n",
       "      <td>0.727202</td>\n",
       "      <td>0.746132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>1.354671</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.778513</td>\n",
       "      <td>0.725358</td>\n",
       "      <td>0.737000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1.368731</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.808752</td>\n",
       "      <td>0.729427</td>\n",
       "      <td>0.749472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>1.433650</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.806396</td>\n",
       "      <td>0.727628</td>\n",
       "      <td>0.748688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.402231</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.803026</td>\n",
       "      <td>0.723985</td>\n",
       "      <td>0.744077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.405371</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.804168</td>\n",
       "      <td>0.727251</td>\n",
       "      <td>0.748109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.420282</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.810622</td>\n",
       "      <td>0.724440</td>\n",
       "      <td>0.747745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.433400</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.811798</td>\n",
       "      <td>0.724157</td>\n",
       "      <td>0.747660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 16:15:16,581] Trial 51 finished with value: 0.7476596443437336 and parameters: {'learning_rate': 0.00023281979342328887, 'weight_decay': 0.003, 'warmup_steps': 13}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 52 with params: {'learning_rate': 0.00011668980669530862, 'weight_decay': 0.002, 'warmup_steps': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:26 < 02:53, 30.27 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.063400</td>\n",
       "      <td>1.322559</td>\n",
       "      <td>0.743355</td>\n",
       "      <td>0.411713</td>\n",
       "      <td>0.391492</td>\n",
       "      <td>0.375506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.725700</td>\n",
       "      <td>1.048254</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.452855</td>\n",
       "      <td>0.469392</td>\n",
       "      <td>0.449475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.366400</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.599305</td>\n",
       "      <td>0.545654</td>\n",
       "      <td>0.547469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.208300</td>\n",
       "      <td>1.026378</td>\n",
       "      <td>0.779102</td>\n",
       "      <td>0.637202</td>\n",
       "      <td>0.580850</td>\n",
       "      <td>0.595518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>1.040285</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.699434</td>\n",
       "      <td>0.623789</td>\n",
       "      <td>0.640029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 16:16:44,198] Trial 52 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 53 with params: {'learning_rate': 5.4372545807912146e-05, 'weight_decay': 0.003, 'warmup_steps': 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:54 < 01:27, 30.11 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.736300</td>\n",
       "      <td>1.988297</td>\n",
       "      <td>0.614115</td>\n",
       "      <td>0.260534</td>\n",
       "      <td>0.246468</td>\n",
       "      <td>0.229649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.451100</td>\n",
       "      <td>1.365308</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.383962</td>\n",
       "      <td>0.385368</td>\n",
       "      <td>0.367541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.921700</td>\n",
       "      <td>1.158616</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.447447</td>\n",
       "      <td>0.439613</td>\n",
       "      <td>0.424804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.653000</td>\n",
       "      <td>1.070519</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.449544</td>\n",
       "      <td>0.463644</td>\n",
       "      <td>0.446669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.490800</td>\n",
       "      <td>1.030979</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.499940</td>\n",
       "      <td>0.491979</td>\n",
       "      <td>0.485130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.383400</td>\n",
       "      <td>1.006745</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.514926</td>\n",
       "      <td>0.498735</td>\n",
       "      <td>0.494568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.301200</td>\n",
       "      <td>1.005039</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.555955</td>\n",
       "      <td>0.513353</td>\n",
       "      <td>0.511700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.249500</td>\n",
       "      <td>0.995978</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.595226</td>\n",
       "      <td>0.544343</td>\n",
       "      <td>0.550632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.211500</td>\n",
       "      <td>1.008551</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>0.598474</td>\n",
       "      <td>0.549443</td>\n",
       "      <td>0.559012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.181900</td>\n",
       "      <td>1.022222</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.642919</td>\n",
       "      <td>0.570005</td>\n",
       "      <td>0.585533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 16:19:39,472] Trial 53 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 54 with params: {'learning_rate': 0.00018505388513671345, 'weight_decay': 0.001, 'warmup_steps': 19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:59 < 01:29, 29.30 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.701800</td>\n",
       "      <td>1.108233</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.432916</td>\n",
       "      <td>0.448099</td>\n",
       "      <td>0.425315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.431800</td>\n",
       "      <td>0.981841</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>0.598392</td>\n",
       "      <td>0.545543</td>\n",
       "      <td>0.549212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.175800</td>\n",
       "      <td>1.027927</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.704964</td>\n",
       "      <td>0.632475</td>\n",
       "      <td>0.650119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.088800</td>\n",
       "      <td>1.085366</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.724426</td>\n",
       "      <td>0.646410</td>\n",
       "      <td>0.671194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.053200</td>\n",
       "      <td>1.124371</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.798774</td>\n",
       "      <td>0.716904</td>\n",
       "      <td>0.740131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>1.194287</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.778082</td>\n",
       "      <td>0.671009</td>\n",
       "      <td>0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>1.244809</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.791481</td>\n",
       "      <td>0.692411</td>\n",
       "      <td>0.720315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>1.242593</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.803828</td>\n",
       "      <td>0.732827</td>\n",
       "      <td>0.746154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>1.261483</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.795118</td>\n",
       "      <td>0.717299</td>\n",
       "      <td>0.736462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>1.322766</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.798977</td>\n",
       "      <td>0.711296</td>\n",
       "      <td>0.731602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 16:22:39,725] Trial 54 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 55 with params: {'learning_rate': 0.00017151642114437876, 'weight_decay': 0.002, 'warmup_steps': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:55 < 01:27, 29.93 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.758000</td>\n",
       "      <td>1.134736</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.439367</td>\n",
       "      <td>0.451321</td>\n",
       "      <td>0.429653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.472600</td>\n",
       "      <td>0.986848</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.568731</td>\n",
       "      <td>0.522977</td>\n",
       "      <td>0.521236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.199200</td>\n",
       "      <td>1.017571</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.683481</td>\n",
       "      <td>0.618674</td>\n",
       "      <td>0.632181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.102600</td>\n",
       "      <td>1.072778</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.704131</td>\n",
       "      <td>0.620288</td>\n",
       "      <td>0.645542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.061300</td>\n",
       "      <td>1.110647</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.788009</td>\n",
       "      <td>0.703468</td>\n",
       "      <td>0.729743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.042400</td>\n",
       "      <td>1.166988</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.771373</td>\n",
       "      <td>0.671380</td>\n",
       "      <td>0.701301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.029400</td>\n",
       "      <td>1.234042</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.793690</td>\n",
       "      <td>0.693019</td>\n",
       "      <td>0.720342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>1.235919</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.781922</td>\n",
       "      <td>0.733267</td>\n",
       "      <td>0.738520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>1.265089</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.790694</td>\n",
       "      <td>0.711753</td>\n",
       "      <td>0.732880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>1.314796</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.807970</td>\n",
       "      <td>0.705969</td>\n",
       "      <td>0.730167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 16:25:36,136] Trial 55 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 56 with params: {'learning_rate': 0.0004559917486250674, 'weight_decay': 0.008, 'warmup_steps': 47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:27 < 02:55, 29.84 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.143300</td>\n",
       "      <td>0.984420</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.562072</td>\n",
       "      <td>0.556493</td>\n",
       "      <td>0.549109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.137900</td>\n",
       "      <td>1.113497</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.730287</td>\n",
       "      <td>0.677563</td>\n",
       "      <td>0.687927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.052800</td>\n",
       "      <td>1.186081</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.764281</td>\n",
       "      <td>0.721945</td>\n",
       "      <td>0.727730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>1.287833</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.808684</td>\n",
       "      <td>0.691623</td>\n",
       "      <td>0.722155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>1.399917</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.764847</td>\n",
       "      <td>0.707379</td>\n",
       "      <td>0.718767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 16:27:05,143] Trial 56 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 57 with params: {'learning_rate': 0.00022026095138811904, 'weight_decay': 0.0, 'warmup_steps': 25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:24, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.576800</td>\n",
       "      <td>1.056191</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.423649</td>\n",
       "      <td>0.459001</td>\n",
       "      <td>0.432862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.346700</td>\n",
       "      <td>0.991478</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.619179</td>\n",
       "      <td>0.575994</td>\n",
       "      <td>0.581673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>1.073586</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.709626</td>\n",
       "      <td>0.640800</td>\n",
       "      <td>0.657209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>1.124066</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.792654</td>\n",
       "      <td>0.672375</td>\n",
       "      <td>0.712245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.040700</td>\n",
       "      <td>1.181803</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.790095</td>\n",
       "      <td>0.715100</td>\n",
       "      <td>0.735917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.029300</td>\n",
       "      <td>1.209414</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.774889</td>\n",
       "      <td>0.681868</td>\n",
       "      <td>0.709387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>1.297697</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.790595</td>\n",
       "      <td>0.695149</td>\n",
       "      <td>0.720683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>1.291734</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.784029</td>\n",
       "      <td>0.710981</td>\n",
       "      <td>0.729079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>1.303843</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.787103</td>\n",
       "      <td>0.715260</td>\n",
       "      <td>0.733548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>1.342404</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.800806</td>\n",
       "      <td>0.721474</td>\n",
       "      <td>0.741570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>1.399904</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.803440</td>\n",
       "      <td>0.713397</td>\n",
       "      <td>0.736748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.388005</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.814327</td>\n",
       "      <td>0.753892</td>\n",
       "      <td>0.766469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>1.409414</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.787529</td>\n",
       "      <td>0.733943</td>\n",
       "      <td>0.745831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.411115</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.808397</td>\n",
       "      <td>0.736128</td>\n",
       "      <td>0.754295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.419815</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.809973</td>\n",
       "      <td>0.737568</td>\n",
       "      <td>0.755349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 16:31:30,905] Trial 57 finished with value: 0.7553492696618385 and parameters: {'learning_rate': 0.00022026095138811904, 'weight_decay': 0.0, 'warmup_steps': 25}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 58 with params: {'learning_rate': 0.00022838128102949855, 'weight_decay': 0.001, 'warmup_steps': 31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:22, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.562700</td>\n",
       "      <td>1.048589</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.436533</td>\n",
       "      <td>0.461036</td>\n",
       "      <td>0.437074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.332800</td>\n",
       "      <td>0.987411</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.648160</td>\n",
       "      <td>0.594810</td>\n",
       "      <td>0.604872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.124700</td>\n",
       "      <td>1.064920</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.737778</td>\n",
       "      <td>0.662462</td>\n",
       "      <td>0.682332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.061600</td>\n",
       "      <td>1.123302</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.792143</td>\n",
       "      <td>0.681650</td>\n",
       "      <td>0.715810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>1.158282</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.800100</td>\n",
       "      <td>0.718936</td>\n",
       "      <td>0.743375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>1.207419</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.785659</td>\n",
       "      <td>0.693283</td>\n",
       "      <td>0.717546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>1.271012</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.709997</td>\n",
       "      <td>0.738434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>1.310009</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.793538</td>\n",
       "      <td>0.711828</td>\n",
       "      <td>0.730358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>1.310345</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.803729</td>\n",
       "      <td>0.707123</td>\n",
       "      <td>0.732107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>1.375498</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.806032</td>\n",
       "      <td>0.714362</td>\n",
       "      <td>0.736703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>1.396057</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.802488</td>\n",
       "      <td>0.715822</td>\n",
       "      <td>0.737908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.404838</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.789833</td>\n",
       "      <td>0.738838</td>\n",
       "      <td>0.748718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>1.429130</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.808128</td>\n",
       "      <td>0.727882</td>\n",
       "      <td>0.746974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.415164</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.817983</td>\n",
       "      <td>0.737436</td>\n",
       "      <td>0.757084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>1.419757</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.822561</td>\n",
       "      <td>0.734863</td>\n",
       "      <td>0.757218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 16:35:54,998] Trial 58 finished with value: 0.7572175863370011 and parameters: {'learning_rate': 0.00022838128102949855, 'weight_decay': 0.001, 'warmup_steps': 31}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 59 with params: {'learning_rate': 0.000488100307012158, 'weight_decay': 0.01, 'warmup_steps': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:54 < 01:27, 30.08 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.006300</td>\n",
       "      <td>0.997581</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.573430</td>\n",
       "      <td>0.565288</td>\n",
       "      <td>0.560727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.131200</td>\n",
       "      <td>1.103322</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.696587</td>\n",
       "      <td>0.691030</td>\n",
       "      <td>0.677517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.053300</td>\n",
       "      <td>1.280410</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.737157</td>\n",
       "      <td>0.727947</td>\n",
       "      <td>0.715913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>1.385798</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.813331</td>\n",
       "      <td>0.707312</td>\n",
       "      <td>0.733815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.020600</td>\n",
       "      <td>1.366357</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.790558</td>\n",
       "      <td>0.705210</td>\n",
       "      <td>0.728882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.393983</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.816740</td>\n",
       "      <td>0.714724</td>\n",
       "      <td>0.745153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>1.549152</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.752197</td>\n",
       "      <td>0.708204</td>\n",
       "      <td>0.714373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>1.519226</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.771071</td>\n",
       "      <td>0.742154</td>\n",
       "      <td>0.741973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>1.623640</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.772456</td>\n",
       "      <td>0.711596</td>\n",
       "      <td>0.725077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.699825</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.767737</td>\n",
       "      <td>0.701380</td>\n",
       "      <td>0.716489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 16:38:50,446] Trial 59 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 60 with params: {'learning_rate': 0.00014559095280735742, 'weight_decay': 0.003, 'warmup_steps': 52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:23, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.972600</td>\n",
       "      <td>1.215368</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.376941</td>\n",
       "      <td>0.399546</td>\n",
       "      <td>0.375155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.587600</td>\n",
       "      <td>1.014102</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.478613</td>\n",
       "      <td>0.487280</td>\n",
       "      <td>0.477455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.268300</td>\n",
       "      <td>0.982206</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.651684</td>\n",
       "      <td>0.589098</td>\n",
       "      <td>0.602177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.140800</td>\n",
       "      <td>1.026834</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.716049</td>\n",
       "      <td>0.622694</td>\n",
       "      <td>0.647812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.085100</td>\n",
       "      <td>1.062654</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.731383</td>\n",
       "      <td>0.651945</td>\n",
       "      <td>0.671658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.056900</td>\n",
       "      <td>1.110788</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.767143</td>\n",
       "      <td>0.658796</td>\n",
       "      <td>0.686476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>1.171508</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.802946</td>\n",
       "      <td>0.695672</td>\n",
       "      <td>0.722702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>1.173003</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.788141</td>\n",
       "      <td>0.704680</td>\n",
       "      <td>0.724447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>1.213168</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.798584</td>\n",
       "      <td>0.698719</td>\n",
       "      <td>0.724211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>1.269610</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.813769</td>\n",
       "      <td>0.710850</td>\n",
       "      <td>0.735595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>1.278070</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.799953</td>\n",
       "      <td>0.715443</td>\n",
       "      <td>0.733828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>1.292855</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.795892</td>\n",
       "      <td>0.745556</td>\n",
       "      <td>0.749760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>1.312122</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.793335</td>\n",
       "      <td>0.715596</td>\n",
       "      <td>0.732908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>1.311949</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.804842</td>\n",
       "      <td>0.722991</td>\n",
       "      <td>0.741075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>1.322257</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.807758</td>\n",
       "      <td>0.731079</td>\n",
       "      <td>0.747440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 16:43:15,600] Trial 60 finished with value: 0.7474401137474939 and parameters: {'learning_rate': 0.00014559095280735742, 'weight_decay': 0.003, 'warmup_steps': 52}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 61 with params: {'learning_rate': 0.0001710225097123558, 'weight_decay': 0.002, 'warmup_steps': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:28, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.795600</td>\n",
       "      <td>1.140007</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.421676</td>\n",
       "      <td>0.446403</td>\n",
       "      <td>0.422737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.479900</td>\n",
       "      <td>0.995792</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.570105</td>\n",
       "      <td>0.520719</td>\n",
       "      <td>0.520593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.202400</td>\n",
       "      <td>1.005992</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.690954</td>\n",
       "      <td>0.628003</td>\n",
       "      <td>0.643292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.103100</td>\n",
       "      <td>1.067135</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.739201</td>\n",
       "      <td>0.630473</td>\n",
       "      <td>0.664200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.061800</td>\n",
       "      <td>1.105650</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.795296</td>\n",
       "      <td>0.705978</td>\n",
       "      <td>0.731977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>1.164189</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.786537</td>\n",
       "      <td>0.679780</td>\n",
       "      <td>0.711388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.028800</td>\n",
       "      <td>1.218936</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.792570</td>\n",
       "      <td>0.692081</td>\n",
       "      <td>0.717738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>1.226201</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.794861</td>\n",
       "      <td>0.740195</td>\n",
       "      <td>0.746469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>1.269790</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.795732</td>\n",
       "      <td>0.717634</td>\n",
       "      <td>0.738632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>1.318711</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.814021</td>\n",
       "      <td>0.735107</td>\n",
       "      <td>0.754491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>1.328183</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.805762</td>\n",
       "      <td>0.731893</td>\n",
       "      <td>0.749595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>1.353612</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.783340</td>\n",
       "      <td>0.733019</td>\n",
       "      <td>0.742137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>1.373737</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.777937</td>\n",
       "      <td>0.725949</td>\n",
       "      <td>0.738555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>1.373958</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.800126</td>\n",
       "      <td>0.736315</td>\n",
       "      <td>0.751524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>1.381104</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.810956</td>\n",
       "      <td>0.730360</td>\n",
       "      <td>0.750533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 16:47:45,739] Trial 61 finished with value: 0.7505329953914958 and parameters: {'learning_rate': 0.0001710225097123558, 'weight_decay': 0.002, 'warmup_steps': 32}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 62 with params: {'learning_rate': 0.0001958626342476988, 'weight_decay': 0.0, 'warmup_steps': 34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:25, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.689900</td>\n",
       "      <td>1.090379</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.431576</td>\n",
       "      <td>0.449274</td>\n",
       "      <td>0.427890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.407100</td>\n",
       "      <td>0.986249</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.596929</td>\n",
       "      <td>0.553621</td>\n",
       "      <td>0.557786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.161500</td>\n",
       "      <td>1.040181</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.740311</td>\n",
       "      <td>0.647475</td>\n",
       "      <td>0.670526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.080400</td>\n",
       "      <td>1.098215</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.761979</td>\n",
       "      <td>0.657565</td>\n",
       "      <td>0.692591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.048800</td>\n",
       "      <td>1.145965</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.790970</td>\n",
       "      <td>0.718941</td>\n",
       "      <td>0.740006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.033800</td>\n",
       "      <td>1.223634</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.794371</td>\n",
       "      <td>0.683504</td>\n",
       "      <td>0.713113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>1.254593</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.794449</td>\n",
       "      <td>0.693766</td>\n",
       "      <td>0.719970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>1.262753</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.803916</td>\n",
       "      <td>0.721393</td>\n",
       "      <td>0.739047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>1.286861</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.778221</td>\n",
       "      <td>0.703967</td>\n",
       "      <td>0.723954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>1.341999</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.813309</td>\n",
       "      <td>0.720652</td>\n",
       "      <td>0.744876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>1.373520</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.806967</td>\n",
       "      <td>0.732070</td>\n",
       "      <td>0.751135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>1.386402</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.791649</td>\n",
       "      <td>0.729996</td>\n",
       "      <td>0.743237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>1.412115</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.782520</td>\n",
       "      <td>0.729904</td>\n",
       "      <td>0.740052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.414263</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.801863</td>\n",
       "      <td>0.717242</td>\n",
       "      <td>0.739028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>1.418684</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.805906</td>\n",
       "      <td>0.727481</td>\n",
       "      <td>0.745925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 16:52:12,455] Trial 62 finished with value: 0.7459247513678526 and parameters: {'learning_rate': 0.0001958626342476988, 'weight_decay': 0.0, 'warmup_steps': 34}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 63 with params: {'learning_rate': 0.0003618979921821318, 'weight_decay': 0.0, 'warmup_steps': 29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:23, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.233300</td>\n",
       "      <td>0.987719</td>\n",
       "      <td>0.778185</td>\n",
       "      <td>0.539375</td>\n",
       "      <td>0.514457</td>\n",
       "      <td>0.507656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.177900</td>\n",
       "      <td>1.055642</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.712420</td>\n",
       "      <td>0.640391</td>\n",
       "      <td>0.660404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.136807</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.794241</td>\n",
       "      <td>0.723805</td>\n",
       "      <td>0.743055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.033100</td>\n",
       "      <td>1.217102</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.826421</td>\n",
       "      <td>0.699802</td>\n",
       "      <td>0.736237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>1.282956</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.815242</td>\n",
       "      <td>0.728261</td>\n",
       "      <td>0.753199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>1.322119</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.813729</td>\n",
       "      <td>0.704269</td>\n",
       "      <td>0.736454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>1.410541</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.812483</td>\n",
       "      <td>0.721667</td>\n",
       "      <td>0.743605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.440624</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.783643</td>\n",
       "      <td>0.713674</td>\n",
       "      <td>0.726752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>1.473360</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.787556</td>\n",
       "      <td>0.734794</td>\n",
       "      <td>0.740014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>1.483653</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.799592</td>\n",
       "      <td>0.725142</td>\n",
       "      <td>0.743011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>1.539621</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.810125</td>\n",
       "      <td>0.710015</td>\n",
       "      <td>0.737993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.525756</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.813761</td>\n",
       "      <td>0.720142</td>\n",
       "      <td>0.745910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.536961</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.799447</td>\n",
       "      <td>0.720826</td>\n",
       "      <td>0.740531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.557059</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.811419</td>\n",
       "      <td>0.726292</td>\n",
       "      <td>0.749144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.545156</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.818175</td>\n",
       "      <td>0.726650</td>\n",
       "      <td>0.751726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 16:56:37,530] Trial 63 finished with value: 0.7517262413608128 and parameters: {'learning_rate': 0.0003618979921821318, 'weight_decay': 0.0, 'warmup_steps': 29}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 64 with params: {'learning_rate': 0.00018600237286757807, 'weight_decay': 0.0, 'warmup_steps': 26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:23, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.713600</td>\n",
       "      <td>1.104619</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.431412</td>\n",
       "      <td>0.446875</td>\n",
       "      <td>0.425033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.430900</td>\n",
       "      <td>0.980051</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.620949</td>\n",
       "      <td>0.566680</td>\n",
       "      <td>0.572319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.174800</td>\n",
       "      <td>1.018417</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.712830</td>\n",
       "      <td>0.636155</td>\n",
       "      <td>0.656489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.088100</td>\n",
       "      <td>1.078526</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.746030</td>\n",
       "      <td>0.642558</td>\n",
       "      <td>0.674761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.052800</td>\n",
       "      <td>1.121779</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.808254</td>\n",
       "      <td>0.721379</td>\n",
       "      <td>0.746869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.036500</td>\n",
       "      <td>1.202155</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.788366</td>\n",
       "      <td>0.670704</td>\n",
       "      <td>0.703439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>1.242350</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.810791</td>\n",
       "      <td>0.701382</td>\n",
       "      <td>0.729506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>1.229892</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.808271</td>\n",
       "      <td>0.726173</td>\n",
       "      <td>0.744380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.017800</td>\n",
       "      <td>1.254128</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.788614</td>\n",
       "      <td>0.702181</td>\n",
       "      <td>0.725641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>1.323011</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.808617</td>\n",
       "      <td>0.714862</td>\n",
       "      <td>0.736134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>1.353386</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.807295</td>\n",
       "      <td>0.723005</td>\n",
       "      <td>0.744834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>1.357260</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.800998</td>\n",
       "      <td>0.740911</td>\n",
       "      <td>0.753388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.390405</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.784370</td>\n",
       "      <td>0.713835</td>\n",
       "      <td>0.731325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.392914</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.814888</td>\n",
       "      <td>0.724227</td>\n",
       "      <td>0.747264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.396001</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.814486</td>\n",
       "      <td>0.718063</td>\n",
       "      <td>0.743789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 17:01:02,146] Trial 64 finished with value: 0.743789217878992 and parameters: {'learning_rate': 0.00018600237286757807, 'weight_decay': 0.0, 'warmup_steps': 26}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 65 with params: {'learning_rate': 3.80735517457004e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:29 < 02:59, 29.24 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.030700</td>\n",
       "      <td>2.364526</td>\n",
       "      <td>0.538955</td>\n",
       "      <td>0.214982</td>\n",
       "      <td>0.168600</td>\n",
       "      <td>0.151416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.873600</td>\n",
       "      <td>1.664928</td>\n",
       "      <td>0.695692</td>\n",
       "      <td>0.314260</td>\n",
       "      <td>0.315696</td>\n",
       "      <td>0.297956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.287900</td>\n",
       "      <td>1.350646</td>\n",
       "      <td>0.732356</td>\n",
       "      <td>0.380318</td>\n",
       "      <td>0.378613</td>\n",
       "      <td>0.358791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.961300</td>\n",
       "      <td>1.201541</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.399099</td>\n",
       "      <td>0.415860</td>\n",
       "      <td>0.393311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.758900</td>\n",
       "      <td>1.121272</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.475320</td>\n",
       "      <td>0.454250</td>\n",
       "      <td>0.443490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 17:02:32,862] Trial 65 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 66 with params: {'learning_rate': 0.0001936676378507846, 'weight_decay': 0.0, 'warmup_steps': 26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:23, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.680700</td>\n",
       "      <td>1.090102</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.437269</td>\n",
       "      <td>0.448140</td>\n",
       "      <td>0.426939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.409800</td>\n",
       "      <td>0.974939</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.624310</td>\n",
       "      <td>0.574303</td>\n",
       "      <td>0.580716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.163300</td>\n",
       "      <td>1.024008</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.734258</td>\n",
       "      <td>0.646007</td>\n",
       "      <td>0.669646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.081500</td>\n",
       "      <td>1.087722</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.750981</td>\n",
       "      <td>0.643330</td>\n",
       "      <td>0.677041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.049400</td>\n",
       "      <td>1.138873</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.808551</td>\n",
       "      <td>0.726979</td>\n",
       "      <td>0.751096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>1.198337</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.795063</td>\n",
       "      <td>0.670015</td>\n",
       "      <td>0.703533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>1.251718</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.814456</td>\n",
       "      <td>0.699970</td>\n",
       "      <td>0.730942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>1.227930</td>\n",
       "      <td>0.804766</td>\n",
       "      <td>0.818019</td>\n",
       "      <td>0.736631</td>\n",
       "      <td>0.753430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.016400</td>\n",
       "      <td>1.263813</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.788789</td>\n",
       "      <td>0.703458</td>\n",
       "      <td>0.725023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.326154</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.818400</td>\n",
       "      <td>0.718442</td>\n",
       "      <td>0.742689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>1.360762</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.812976</td>\n",
       "      <td>0.716757</td>\n",
       "      <td>0.740305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>1.368619</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.815715</td>\n",
       "      <td>0.738039</td>\n",
       "      <td>0.755439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>1.395132</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.792560</td>\n",
       "      <td>0.717448</td>\n",
       "      <td>0.737234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1.394361</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.816935</td>\n",
       "      <td>0.720357</td>\n",
       "      <td>0.746835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.400377</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.816091</td>\n",
       "      <td>0.717533</td>\n",
       "      <td>0.744485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 17:06:57,961] Trial 66 finished with value: 0.7444848795918415 and parameters: {'learning_rate': 0.0001936676378507846, 'weight_decay': 0.0, 'warmup_steps': 26}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 67 with params: {'learning_rate': 0.00020923283410242662, 'weight_decay': 0.002, 'warmup_steps': 27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:24, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.621500</td>\n",
       "      <td>1.066782</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.432200</td>\n",
       "      <td>0.451281</td>\n",
       "      <td>0.429562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.371000</td>\n",
       "      <td>0.978614</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.619435</td>\n",
       "      <td>0.576095</td>\n",
       "      <td>0.582264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.142700</td>\n",
       "      <td>1.044595</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.729305</td>\n",
       "      <td>0.648036</td>\n",
       "      <td>0.667227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>1.102748</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.786397</td>\n",
       "      <td>0.667431</td>\n",
       "      <td>0.705561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.043600</td>\n",
       "      <td>1.168062</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.789143</td>\n",
       "      <td>0.717432</td>\n",
       "      <td>0.736049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>1.206475</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.815223</td>\n",
       "      <td>0.696211</td>\n",
       "      <td>0.730586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>1.282636</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.797890</td>\n",
       "      <td>0.707938</td>\n",
       "      <td>0.730476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>1.285828</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.797336</td>\n",
       "      <td>0.724060</td>\n",
       "      <td>0.739482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>1.325891</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.772886</td>\n",
       "      <td>0.702755</td>\n",
       "      <td>0.721096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>1.365301</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.790115</td>\n",
       "      <td>0.723477</td>\n",
       "      <td>0.739531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>1.414351</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.806817</td>\n",
       "      <td>0.703236</td>\n",
       "      <td>0.731504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>1.396216</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.795751</td>\n",
       "      <td>0.725218</td>\n",
       "      <td>0.741408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>1.411739</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.794263</td>\n",
       "      <td>0.724675</td>\n",
       "      <td>0.741580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>1.418218</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.813158</td>\n",
       "      <td>0.729403</td>\n",
       "      <td>0.750914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>1.427410</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.818073</td>\n",
       "      <td>0.724688</td>\n",
       "      <td>0.749632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 17:11:23,605] Trial 67 finished with value: 0.7496323789255831 and parameters: {'learning_rate': 0.00020923283410242662, 'weight_decay': 0.002, 'warmup_steps': 27}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 68 with params: {'learning_rate': 0.00024411971233489693, 'weight_decay': 0.0, 'warmup_steps': 21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:24, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.489200</td>\n",
       "      <td>1.042042</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.436505</td>\n",
       "      <td>0.469587</td>\n",
       "      <td>0.442206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.300800</td>\n",
       "      <td>1.010998</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.668408</td>\n",
       "      <td>0.607740</td>\n",
       "      <td>0.619628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>1.087314</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.749611</td>\n",
       "      <td>0.690904</td>\n",
       "      <td>0.704378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.055400</td>\n",
       "      <td>1.139716</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.817453</td>\n",
       "      <td>0.703846</td>\n",
       "      <td>0.738687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.034900</td>\n",
       "      <td>1.178025</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.736174</td>\n",
       "      <td>0.751594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.025100</td>\n",
       "      <td>1.250435</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.800176</td>\n",
       "      <td>0.697429</td>\n",
       "      <td>0.727876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>1.318796</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.793433</td>\n",
       "      <td>0.715901</td>\n",
       "      <td>0.735213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>1.314361</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.791550</td>\n",
       "      <td>0.731612</td>\n",
       "      <td>0.741664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>1.378727</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.802363</td>\n",
       "      <td>0.721325</td>\n",
       "      <td>0.743744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>1.408560</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.809687</td>\n",
       "      <td>0.726097</td>\n",
       "      <td>0.748222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.435873</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.812773</td>\n",
       "      <td>0.733532</td>\n",
       "      <td>0.755681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>1.406704</td>\n",
       "      <td>0.804766</td>\n",
       "      <td>0.813960</td>\n",
       "      <td>0.742471</td>\n",
       "      <td>0.759862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.439994</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.808112</td>\n",
       "      <td>0.735230</td>\n",
       "      <td>0.755868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.432364</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.814116</td>\n",
       "      <td>0.734420</td>\n",
       "      <td>0.755064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.441004</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.813564</td>\n",
       "      <td>0.736557</td>\n",
       "      <td>0.756994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 17:15:49,600] Trial 68 finished with value: 0.7569942667986648 and parameters: {'learning_rate': 0.00024411971233489693, 'weight_decay': 0.0, 'warmup_steps': 21}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 69 with params: {'learning_rate': 0.0004057130166874689, 'weight_decay': 0.001, 'warmup_steps': 22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:54 < 01:27, 30.04 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.148700</td>\n",
       "      <td>0.996201</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.539523</td>\n",
       "      <td>0.540735</td>\n",
       "      <td>0.527873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.153800</td>\n",
       "      <td>1.089427</td>\n",
       "      <td>0.779102</td>\n",
       "      <td>0.703550</td>\n",
       "      <td>0.644560</td>\n",
       "      <td>0.657366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>1.221926</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.741492</td>\n",
       "      <td>0.723536</td>\n",
       "      <td>0.716888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>1.228943</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.814993</td>\n",
       "      <td>0.724105</td>\n",
       "      <td>0.747432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>1.335163</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.802727</td>\n",
       "      <td>0.730664</td>\n",
       "      <td>0.750033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>1.429819</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.819378</td>\n",
       "      <td>0.703746</td>\n",
       "      <td>0.738803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.426396</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.800772</td>\n",
       "      <td>0.728351</td>\n",
       "      <td>0.746821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>1.436127</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.797217</td>\n",
       "      <td>0.723134</td>\n",
       "      <td>0.740948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.506298</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.791771</td>\n",
       "      <td>0.705866</td>\n",
       "      <td>0.730354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.559281</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.813305</td>\n",
       "      <td>0.703850</td>\n",
       "      <td>0.734544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 17:18:45,350] Trial 69 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 70 with params: {'learning_rate': 0.00021393900311971698, 'weight_decay': 0.0, 'warmup_steps': 43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7607' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7607/7875 04:13 < 00:08, 29.94 it/s, Epoch 14.49/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.641200</td>\n",
       "      <td>1.068157</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.414044</td>\n",
       "      <td>0.451102</td>\n",
       "      <td>0.423898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.365500</td>\n",
       "      <td>0.996280</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.599517</td>\n",
       "      <td>0.561671</td>\n",
       "      <td>0.565783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.140800</td>\n",
       "      <td>1.040769</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.733437</td>\n",
       "      <td>0.644221</td>\n",
       "      <td>0.668679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>1.111449</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.777575</td>\n",
       "      <td>0.668909</td>\n",
       "      <td>0.701589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>1.149258</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.788463</td>\n",
       "      <td>0.717311</td>\n",
       "      <td>0.738327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.029400</td>\n",
       "      <td>1.218283</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.782249</td>\n",
       "      <td>0.677563</td>\n",
       "      <td>0.708338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>1.261164</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.782639</td>\n",
       "      <td>0.687207</td>\n",
       "      <td>0.712861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>1.290267</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.816504</td>\n",
       "      <td>0.733198</td>\n",
       "      <td>0.751836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>1.294208</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.795351</td>\n",
       "      <td>0.737061</td>\n",
       "      <td>0.752533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>1.363521</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.811816</td>\n",
       "      <td>0.718841</td>\n",
       "      <td>0.743085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>1.390279</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.805193</td>\n",
       "      <td>0.727812</td>\n",
       "      <td>0.749642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>1.427101</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.782183</td>\n",
       "      <td>0.727315</td>\n",
       "      <td>0.739192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>1.439624</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.783155</td>\n",
       "      <td>0.729725</td>\n",
       "      <td>0.741462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.439728</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.803623</td>\n",
       "      <td>0.731846</td>\n",
       "      <td>0.749719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 17:27:39,324] Trial 71 finished with value: 0.7511571494431414 and parameters: {'learning_rate': 0.00019324488581664128, 'weight_decay': 0.0, 'warmup_steps': 17}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 72 with params: {'learning_rate': 1.0579248993606617e-05, 'weight_decay': 0.001, 'warmup_steps': 24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:55 < 01:27, 29.92 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.561400</td>\n",
       "      <td>3.281887</td>\n",
       "      <td>0.343721</td>\n",
       "      <td>0.041842</td>\n",
       "      <td>0.070831</td>\n",
       "      <td>0.049721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>2.871706</td>\n",
       "      <td>0.449129</td>\n",
       "      <td>0.108133</td>\n",
       "      <td>0.116988</td>\n",
       "      <td>0.100976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.682000</td>\n",
       "      <td>2.561445</td>\n",
       "      <td>0.496792</td>\n",
       "      <td>0.129413</td>\n",
       "      <td>0.142019</td>\n",
       "      <td>0.117561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.391700</td>\n",
       "      <td>2.321326</td>\n",
       "      <td>0.543538</td>\n",
       "      <td>0.214580</td>\n",
       "      <td>0.176747</td>\n",
       "      <td>0.159263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.156000</td>\n",
       "      <td>2.136175</td>\n",
       "      <td>0.590284</td>\n",
       "      <td>0.250898</td>\n",
       "      <td>0.219675</td>\n",
       "      <td>0.203355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.973700</td>\n",
       "      <td>1.989987</td>\n",
       "      <td>0.607699</td>\n",
       "      <td>0.276230</td>\n",
       "      <td>0.234703</td>\n",
       "      <td>0.219357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.823800</td>\n",
       "      <td>1.873150</td>\n",
       "      <td>0.630614</td>\n",
       "      <td>0.269416</td>\n",
       "      <td>0.252817</td>\n",
       "      <td>0.236675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.708000</td>\n",
       "      <td>1.781676</td>\n",
       "      <td>0.659945</td>\n",
       "      <td>0.295498</td>\n",
       "      <td>0.275904</td>\n",
       "      <td>0.259059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.613300</td>\n",
       "      <td>1.707974</td>\n",
       "      <td>0.676444</td>\n",
       "      <td>0.329925</td>\n",
       "      <td>0.296440</td>\n",
       "      <td>0.280091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.536100</td>\n",
       "      <td>1.651296</td>\n",
       "      <td>0.682860</td>\n",
       "      <td>0.343086</td>\n",
       "      <td>0.302334</td>\n",
       "      <td>0.286006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 17:30:35,885] Trial 72 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 73 with params: {'learning_rate': 1.1597714681187563e-05, 'weight_decay': 0.01, 'warmup_steps': 46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:26 < 02:54, 30.16 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.547100</td>\n",
       "      <td>3.243661</td>\n",
       "      <td>0.349221</td>\n",
       "      <td>0.060739</td>\n",
       "      <td>0.072978</td>\n",
       "      <td>0.050427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.998700</td>\n",
       "      <td>2.806111</td>\n",
       "      <td>0.463795</td>\n",
       "      <td>0.108678</td>\n",
       "      <td>0.125013</td>\n",
       "      <td>0.106808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.602100</td>\n",
       "      <td>2.477805</td>\n",
       "      <td>0.510541</td>\n",
       "      <td>0.145431</td>\n",
       "      <td>0.152448</td>\n",
       "      <td>0.130669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.296500</td>\n",
       "      <td>2.231525</td>\n",
       "      <td>0.572869</td>\n",
       "      <td>0.223461</td>\n",
       "      <td>0.201348</td>\n",
       "      <td>0.186349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.052700</td>\n",
       "      <td>2.041326</td>\n",
       "      <td>0.602200</td>\n",
       "      <td>0.279574</td>\n",
       "      <td>0.232028</td>\n",
       "      <td>0.215506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 17:32:03,825] Trial 73 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 74 with params: {'learning_rate': 0.00021125465408003215, 'weight_decay': 0.0, 'warmup_steps': 19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:55 < 01:27, 29.92 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.596000</td>\n",
       "      <td>1.071731</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.428034</td>\n",
       "      <td>0.461627</td>\n",
       "      <td>0.435575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.364700</td>\n",
       "      <td>0.994984</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.618957</td>\n",
       "      <td>0.573232</td>\n",
       "      <td>0.576906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.139800</td>\n",
       "      <td>1.072540</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.714904</td>\n",
       "      <td>0.644095</td>\n",
       "      <td>0.661766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>1.110720</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.782517</td>\n",
       "      <td>0.674497</td>\n",
       "      <td>0.709223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.043400</td>\n",
       "      <td>1.144529</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.788220</td>\n",
       "      <td>0.728563</td>\n",
       "      <td>0.745866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>1.217567</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.783398</td>\n",
       "      <td>0.690105</td>\n",
       "      <td>0.717511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>1.285059</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.795947</td>\n",
       "      <td>0.691905</td>\n",
       "      <td>0.719427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>1.280820</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.779950</td>\n",
       "      <td>0.723362</td>\n",
       "      <td>0.735475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>1.350022</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.781367</td>\n",
       "      <td>0.716290</td>\n",
       "      <td>0.729510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>1.375788</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.787396</td>\n",
       "      <td>0.707224</td>\n",
       "      <td>0.728670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 17:35:00,289] Trial 74 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 75 with params: {'learning_rate': 0.0002693184568595071, 'weight_decay': 0.0, 'warmup_steps': 26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:24, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.428900</td>\n",
       "      <td>1.022661</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.477617</td>\n",
       "      <td>0.481045</td>\n",
       "      <td>0.464269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.263800</td>\n",
       "      <td>1.021115</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.723390</td>\n",
       "      <td>0.633820</td>\n",
       "      <td>0.656428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.096300</td>\n",
       "      <td>1.100843</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.750084</td>\n",
       "      <td>0.681985</td>\n",
       "      <td>0.698420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.048700</td>\n",
       "      <td>1.155289</td>\n",
       "      <td>0.804766</td>\n",
       "      <td>0.821202</td>\n",
       "      <td>0.713824</td>\n",
       "      <td>0.745956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>1.226586</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.794781</td>\n",
       "      <td>0.712688</td>\n",
       "      <td>0.736304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>1.248427</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.795959</td>\n",
       "      <td>0.708294</td>\n",
       "      <td>0.734310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>1.353295</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.791743</td>\n",
       "      <td>0.709977</td>\n",
       "      <td>0.730212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>1.350851</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.788743</td>\n",
       "      <td>0.721909</td>\n",
       "      <td>0.736055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>1.400038</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.786293</td>\n",
       "      <td>0.719201</td>\n",
       "      <td>0.736060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.440171</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.804884</td>\n",
       "      <td>0.714430</td>\n",
       "      <td>0.740225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>1.438619</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.790036</td>\n",
       "      <td>0.727126</td>\n",
       "      <td>0.742321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.440127</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.791702</td>\n",
       "      <td>0.726347</td>\n",
       "      <td>0.740214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>1.464651</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.786296</td>\n",
       "      <td>0.725934</td>\n",
       "      <td>0.740908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.443599</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.799418</td>\n",
       "      <td>0.725787</td>\n",
       "      <td>0.744040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.456862</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.802972</td>\n",
       "      <td>0.717368</td>\n",
       "      <td>0.738948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 17:39:26,980] Trial 75 finished with value: 0.7389478819994442 and parameters: {'learning_rate': 0.0002693184568595071, 'weight_decay': 0.0, 'warmup_steps': 26}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 76 with params: {'learning_rate': 8.607572187821745e-05, 'weight_decay': 0.0, 'warmup_steps': 27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:55 < 01:27, 29.84 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.377300</td>\n",
       "      <td>1.555238</td>\n",
       "      <td>0.698442</td>\n",
       "      <td>0.329498</td>\n",
       "      <td>0.326861</td>\n",
       "      <td>0.309861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.990300</td>\n",
       "      <td>1.132702</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.449641</td>\n",
       "      <td>0.447833</td>\n",
       "      <td>0.433766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.560200</td>\n",
       "      <td>1.036740</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.467125</td>\n",
       "      <td>0.483313</td>\n",
       "      <td>0.470271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.358000</td>\n",
       "      <td>0.999518</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.538227</td>\n",
       "      <td>0.510010</td>\n",
       "      <td>0.506201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.237600</td>\n",
       "      <td>0.990279</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.644272</td>\n",
       "      <td>0.582676</td>\n",
       "      <td>0.597660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.167800</td>\n",
       "      <td>1.016070</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.671895</td>\n",
       "      <td>0.607601</td>\n",
       "      <td>0.622723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>1.039301</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.692401</td>\n",
       "      <td>0.618631</td>\n",
       "      <td>0.637027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.095900</td>\n",
       "      <td>1.046291</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.717333</td>\n",
       "      <td>0.629914</td>\n",
       "      <td>0.652322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.078100</td>\n",
       "      <td>1.078653</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.703488</td>\n",
       "      <td>0.629274</td>\n",
       "      <td>0.647571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.063600</td>\n",
       "      <td>1.118888</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.726150</td>\n",
       "      <td>0.640917</td>\n",
       "      <td>0.662915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 17:42:24,221] Trial 76 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 77 with params: {'learning_rate': 0.0003326480917613857, 'weight_decay': 0.002, 'warmup_steps': 30}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:23, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.290600</td>\n",
       "      <td>0.996704</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.493698</td>\n",
       "      <td>0.500971</td>\n",
       "      <td>0.487001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.199400</td>\n",
       "      <td>1.066844</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.736944</td>\n",
       "      <td>0.643590</td>\n",
       "      <td>0.669485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.072800</td>\n",
       "      <td>1.166412</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.771106</td>\n",
       "      <td>0.718604</td>\n",
       "      <td>0.730451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>1.233389</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.831601</td>\n",
       "      <td>0.715500</td>\n",
       "      <td>0.749142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>1.278121</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.810407</td>\n",
       "      <td>0.712495</td>\n",
       "      <td>0.735304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>1.285451</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.802450</td>\n",
       "      <td>0.705629</td>\n",
       "      <td>0.734994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>1.386691</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.818577</td>\n",
       "      <td>0.714366</td>\n",
       "      <td>0.740728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>1.455107</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.800727</td>\n",
       "      <td>0.701464</td>\n",
       "      <td>0.725378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>1.473217</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.809296</td>\n",
       "      <td>0.697267</td>\n",
       "      <td>0.731059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>1.442048</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.797391</td>\n",
       "      <td>0.735529</td>\n",
       "      <td>0.745878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.501912</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.829788</td>\n",
       "      <td>0.710039</td>\n",
       "      <td>0.744765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.494819</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.823558</td>\n",
       "      <td>0.723290</td>\n",
       "      <td>0.750505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.527957</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.831677</td>\n",
       "      <td>0.721916</td>\n",
       "      <td>0.752705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>1.523674</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.812970</td>\n",
       "      <td>0.721018</td>\n",
       "      <td>0.747819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>1.534210</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.814365</td>\n",
       "      <td>0.721044</td>\n",
       "      <td>0.747810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 17:46:49,086] Trial 77 finished with value: 0.7478097189536502 and parameters: {'learning_rate': 0.0003326480917613857, 'weight_decay': 0.002, 'warmup_steps': 30}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 78 with params: {'learning_rate': 4.2739403038429994e-05, 'weight_decay': 0.005, 'warmup_steps': 47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:27 < 02:54, 30.10 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.950800</td>\n",
       "      <td>2.251523</td>\n",
       "      <td>0.567369</td>\n",
       "      <td>0.247147</td>\n",
       "      <td>0.195856</td>\n",
       "      <td>0.182189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.741200</td>\n",
       "      <td>1.559410</td>\n",
       "      <td>0.706691</td>\n",
       "      <td>0.321914</td>\n",
       "      <td>0.332422</td>\n",
       "      <td>0.311540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.165100</td>\n",
       "      <td>1.278785</td>\n",
       "      <td>0.742438</td>\n",
       "      <td>0.379272</td>\n",
       "      <td>0.398892</td>\n",
       "      <td>0.376209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.854500</td>\n",
       "      <td>1.149507</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.437526</td>\n",
       "      <td>0.436470</td>\n",
       "      <td>0.419364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.665400</td>\n",
       "      <td>1.086558</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.471736</td>\n",
       "      <td>0.463218</td>\n",
       "      <td>0.449263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 17:48:17,216] Trial 78 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 79 with params: {'learning_rate': 0.00022156741883185956, 'weight_decay': 0.0, 'warmup_steps': 24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:23, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.569600</td>\n",
       "      <td>1.055272</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.426521</td>\n",
       "      <td>0.459911</td>\n",
       "      <td>0.435046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.343700</td>\n",
       "      <td>0.996064</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.616017</td>\n",
       "      <td>0.575253</td>\n",
       "      <td>0.579072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>1.075054</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>0.632920</td>\n",
       "      <td>0.649510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>1.122568</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.789395</td>\n",
       "      <td>0.672628</td>\n",
       "      <td>0.709767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.040300</td>\n",
       "      <td>1.169313</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.793334</td>\n",
       "      <td>0.713313</td>\n",
       "      <td>0.737646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.028800</td>\n",
       "      <td>1.222373</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.800699</td>\n",
       "      <td>0.691253</td>\n",
       "      <td>0.723945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>1.302460</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.797190</td>\n",
       "      <td>0.685633</td>\n",
       "      <td>0.718054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>1.286108</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.774116</td>\n",
       "      <td>0.713292</td>\n",
       "      <td>0.726229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>1.318022</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.785236</td>\n",
       "      <td>0.703225</td>\n",
       "      <td>0.724552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>1.352986</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.805766</td>\n",
       "      <td>0.723623</td>\n",
       "      <td>0.744667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>1.408218</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.801301</td>\n",
       "      <td>0.721012</td>\n",
       "      <td>0.741808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>1.389963</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.791400</td>\n",
       "      <td>0.733402</td>\n",
       "      <td>0.745887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>1.411037</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.781273</td>\n",
       "      <td>0.715036</td>\n",
       "      <td>0.732629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.415171</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.791766</td>\n",
       "      <td>0.724528</td>\n",
       "      <td>0.742522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.426918</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.804355</td>\n",
       "      <td>0.717516</td>\n",
       "      <td>0.743038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 17:52:42,435] Trial 79 finished with value: 0.7430381833839068 and parameters: {'learning_rate': 0.00022156741883185956, 'weight_decay': 0.0, 'warmup_steps': 24}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 80 with params: {'learning_rate': 0.0004957651934502081, 'weight_decay': 0.0, 'warmup_steps': 23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:55 < 01:27, 29.94 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.041000</td>\n",
       "      <td>1.008247</td>\n",
       "      <td>0.779102</td>\n",
       "      <td>0.561410</td>\n",
       "      <td>0.544298</td>\n",
       "      <td>0.540201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.127700</td>\n",
       "      <td>1.145359</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.712165</td>\n",
       "      <td>0.663426</td>\n",
       "      <td>0.670152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.049100</td>\n",
       "      <td>1.273507</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>0.742655</td>\n",
       "      <td>0.716762</td>\n",
       "      <td>0.717981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>1.288861</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.810958</td>\n",
       "      <td>0.709322</td>\n",
       "      <td>0.740353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>1.438598</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.783102</td>\n",
       "      <td>0.727469</td>\n",
       "      <td>0.739816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.433441</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.813417</td>\n",
       "      <td>0.713738</td>\n",
       "      <td>0.744362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>1.525307</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.779024</td>\n",
       "      <td>0.720999</td>\n",
       "      <td>0.732923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.524702</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.797345</td>\n",
       "      <td>0.724365</td>\n",
       "      <td>0.743922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.603594</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.809286</td>\n",
       "      <td>0.716208</td>\n",
       "      <td>0.742105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.670404</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.796945</td>\n",
       "      <td>0.704121</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 17:55:38,673] Trial 80 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 81 with params: {'learning_rate': 1.0855908291649989e-05, 'weight_decay': 0.0, 'warmup_steps': 41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:54 < 01:27, 30.00 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.562700</td>\n",
       "      <td>3.274936</td>\n",
       "      <td>0.344638</td>\n",
       "      <td>0.041807</td>\n",
       "      <td>0.071194</td>\n",
       "      <td>0.049806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.041900</td>\n",
       "      <td>2.856313</td>\n",
       "      <td>0.450962</td>\n",
       "      <td>0.107809</td>\n",
       "      <td>0.117657</td>\n",
       "      <td>0.101462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.662200</td>\n",
       "      <td>2.540044</td>\n",
       "      <td>0.500458</td>\n",
       "      <td>0.128489</td>\n",
       "      <td>0.143822</td>\n",
       "      <td>0.119510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.366800</td>\n",
       "      <td>2.297519</td>\n",
       "      <td>0.548121</td>\n",
       "      <td>0.218534</td>\n",
       "      <td>0.180964</td>\n",
       "      <td>0.163247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.128500</td>\n",
       "      <td>2.110815</td>\n",
       "      <td>0.590284</td>\n",
       "      <td>0.251402</td>\n",
       "      <td>0.220059</td>\n",
       "      <td>0.202738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.944500</td>\n",
       "      <td>1.963695</td>\n",
       "      <td>0.610449</td>\n",
       "      <td>0.272911</td>\n",
       "      <td>0.236983</td>\n",
       "      <td>0.220907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.793700</td>\n",
       "      <td>1.846821</td>\n",
       "      <td>0.637947</td>\n",
       "      <td>0.267545</td>\n",
       "      <td>0.257410</td>\n",
       "      <td>0.240940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.677500</td>\n",
       "      <td>1.755653</td>\n",
       "      <td>0.668194</td>\n",
       "      <td>0.338906</td>\n",
       "      <td>0.285125</td>\n",
       "      <td>0.270183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.582600</td>\n",
       "      <td>1.682158</td>\n",
       "      <td>0.680110</td>\n",
       "      <td>0.337697</td>\n",
       "      <td>0.298674</td>\n",
       "      <td>0.282414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.505300</td>\n",
       "      <td>1.625962</td>\n",
       "      <td>0.687443</td>\n",
       "      <td>0.329212</td>\n",
       "      <td>0.305764</td>\n",
       "      <td>0.289472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 17:58:34,621] Trial 81 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 82 with params: {'learning_rate': 0.0002891902282670203, 'weight_decay': 0.0, 'warmup_steps': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 03:07 < 01:33, 27.96 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.331300</td>\n",
       "      <td>1.025506</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.495449</td>\n",
       "      <td>0.494917</td>\n",
       "      <td>0.482574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.238300</td>\n",
       "      <td>1.041964</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.716999</td>\n",
       "      <td>0.638235</td>\n",
       "      <td>0.659332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>1.116303</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.792314</td>\n",
       "      <td>0.718596</td>\n",
       "      <td>0.736787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>1.186444</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.804339</td>\n",
       "      <td>0.700265</td>\n",
       "      <td>0.729762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.028800</td>\n",
       "      <td>1.288338</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.808276</td>\n",
       "      <td>0.695346</td>\n",
       "      <td>0.729185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>1.350289</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.817239</td>\n",
       "      <td>0.712209</td>\n",
       "      <td>0.743021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>1.405231</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.805449</td>\n",
       "      <td>0.702453</td>\n",
       "      <td>0.730977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>1.360173</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.796157</td>\n",
       "      <td>0.720997</td>\n",
       "      <td>0.737786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>1.429174</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.799259</td>\n",
       "      <td>0.702365</td>\n",
       "      <td>0.725805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.464486</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.789314</td>\n",
       "      <td>0.705806</td>\n",
       "      <td>0.727930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 18:01:43,368] Trial 82 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 83 with params: {'learning_rate': 0.00019832646378364438, 'weight_decay': 0.003, 'warmup_steps': 19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:30, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.646200</td>\n",
       "      <td>1.087590</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.420090</td>\n",
       "      <td>0.451658</td>\n",
       "      <td>0.425077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.395700</td>\n",
       "      <td>0.985557</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.614996</td>\n",
       "      <td>0.570496</td>\n",
       "      <td>0.576622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.155800</td>\n",
       "      <td>1.047704</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.725358</td>\n",
       "      <td>0.641344</td>\n",
       "      <td>0.662207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.078500</td>\n",
       "      <td>1.100510</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.776903</td>\n",
       "      <td>0.675292</td>\n",
       "      <td>0.707320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.047600</td>\n",
       "      <td>1.141599</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.781993</td>\n",
       "      <td>0.722487</td>\n",
       "      <td>0.738725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>1.193870</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.786023</td>\n",
       "      <td>0.682282</td>\n",
       "      <td>0.713338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>1.253866</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.794253</td>\n",
       "      <td>0.694681</td>\n",
       "      <td>0.722309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>1.261803</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.791386</td>\n",
       "      <td>0.728580</td>\n",
       "      <td>0.739497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>1.279509</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.771067</td>\n",
       "      <td>0.703748</td>\n",
       "      <td>0.718530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>1.345941</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.804146</td>\n",
       "      <td>0.719470</td>\n",
       "      <td>0.741243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>1.357199</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.798991</td>\n",
       "      <td>0.725832</td>\n",
       "      <td>0.744584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1.373430</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.785655</td>\n",
       "      <td>0.722150</td>\n",
       "      <td>0.736980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>1.392098</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.788868</td>\n",
       "      <td>0.723603</td>\n",
       "      <td>0.739954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>1.398440</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.802582</td>\n",
       "      <td>0.728913</td>\n",
       "      <td>0.747953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.400370</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.810620</td>\n",
       "      <td>0.730949</td>\n",
       "      <td>0.752375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 18:06:15,070] Trial 83 finished with value: 0.7523746683231832 and parameters: {'learning_rate': 0.00019832646378364438, 'weight_decay': 0.003, 'warmup_steps': 19}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 84 with params: {'learning_rate': 0.0003687217369305351, 'weight_decay': 0.003, 'warmup_steps': 17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:27 < 02:54, 30.04 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.194300</td>\n",
       "      <td>1.001749</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.520167</td>\n",
       "      <td>0.525209</td>\n",
       "      <td>0.509704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.176300</td>\n",
       "      <td>1.075462</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.717784</td>\n",
       "      <td>0.632765</td>\n",
       "      <td>0.654865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.066100</td>\n",
       "      <td>1.191773</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.771108</td>\n",
       "      <td>0.721341</td>\n",
       "      <td>0.728532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>1.259847</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.813975</td>\n",
       "      <td>0.713880</td>\n",
       "      <td>0.744963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>1.285054</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.791925</td>\n",
       "      <td>0.702051</td>\n",
       "      <td>0.725034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 18:07:43,348] Trial 84 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 85 with params: {'learning_rate': 0.00018353869474219, 'weight_decay': 0.0, 'warmup_steps': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:25, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.737400</td>\n",
       "      <td>1.110794</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.428290</td>\n",
       "      <td>0.447077</td>\n",
       "      <td>0.424844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.440200</td>\n",
       "      <td>0.988153</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.597072</td>\n",
       "      <td>0.535694</td>\n",
       "      <td>0.540197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>1.021644</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.712352</td>\n",
       "      <td>0.633354</td>\n",
       "      <td>0.653923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.090500</td>\n",
       "      <td>1.083420</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.756592</td>\n",
       "      <td>0.653522</td>\n",
       "      <td>0.686257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>1.110541</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.804356</td>\n",
       "      <td>0.716099</td>\n",
       "      <td>0.741503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>1.180168</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.779897</td>\n",
       "      <td>0.671064</td>\n",
       "      <td>0.704494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>1.231575</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.790262</td>\n",
       "      <td>0.694845</td>\n",
       "      <td>0.719168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>1.225517</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.795614</td>\n",
       "      <td>0.719998</td>\n",
       "      <td>0.737175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>1.262912</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.787995</td>\n",
       "      <td>0.715548</td>\n",
       "      <td>0.734881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>1.323153</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.816041</td>\n",
       "      <td>0.730634</td>\n",
       "      <td>0.750846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>1.343671</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.806851</td>\n",
       "      <td>0.726446</td>\n",
       "      <td>0.744943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.351095</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.782655</td>\n",
       "      <td>0.730075</td>\n",
       "      <td>0.740789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>1.383773</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.791054</td>\n",
       "      <td>0.734437</td>\n",
       "      <td>0.747508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.385534</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.804659</td>\n",
       "      <td>0.726239</td>\n",
       "      <td>0.744748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.389745</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.819452</td>\n",
       "      <td>0.730571</td>\n",
       "      <td>0.752149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 18:12:11,211] Trial 85 finished with value: 0.752148995927677 and parameters: {'learning_rate': 0.00018353869474219, 'weight_decay': 0.0, 'warmup_steps': 32}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 86 with params: {'learning_rate': 4.0534446710776905e-05, 'weight_decay': 0.01, 'warmup_steps': 11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:27 < 02:54, 30.07 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.940100</td>\n",
       "      <td>2.276172</td>\n",
       "      <td>0.565536</td>\n",
       "      <td>0.239845</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.180334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.781800</td>\n",
       "      <td>1.596093</td>\n",
       "      <td>0.704858</td>\n",
       "      <td>0.341156</td>\n",
       "      <td>0.324496</td>\n",
       "      <td>0.308052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.211400</td>\n",
       "      <td>1.306585</td>\n",
       "      <td>0.741522</td>\n",
       "      <td>0.378610</td>\n",
       "      <td>0.395900</td>\n",
       "      <td>0.374655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.897300</td>\n",
       "      <td>1.171420</td>\n",
       "      <td>0.756187</td>\n",
       "      <td>0.439210</td>\n",
       "      <td>0.429720</td>\n",
       "      <td>0.415943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.704000</td>\n",
       "      <td>1.101656</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.477498</td>\n",
       "      <td>0.460128</td>\n",
       "      <td>0.448779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 18:13:39,523] Trial 86 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 87 with params: {'learning_rate': 0.00010223215028219842, 'weight_decay': 0.002, 'warmup_steps': 23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:54 < 01:27, 30.06 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.218200</td>\n",
       "      <td>1.412389</td>\n",
       "      <td>0.728689</td>\n",
       "      <td>0.351322</td>\n",
       "      <td>0.365910</td>\n",
       "      <td>0.341517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.834600</td>\n",
       "      <td>1.083690</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.426652</td>\n",
       "      <td>0.455373</td>\n",
       "      <td>0.431055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.445900</td>\n",
       "      <td>1.006231</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.480663</td>\n",
       "      <td>0.500983</td>\n",
       "      <td>0.483302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.266700</td>\n",
       "      <td>1.010143</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>0.624420</td>\n",
       "      <td>0.556927</td>\n",
       "      <td>0.570614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>1.016674</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.637821</td>\n",
       "      <td>0.595820</td>\n",
       "      <td>0.602334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.116700</td>\n",
       "      <td>1.048949</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.686869</td>\n",
       "      <td>0.606801</td>\n",
       "      <td>0.628601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.083400</td>\n",
       "      <td>1.071805</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.735709</td>\n",
       "      <td>0.651548</td>\n",
       "      <td>0.672015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>1.097301</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.812050</td>\n",
       "      <td>0.704523</td>\n",
       "      <td>0.729731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.052300</td>\n",
       "      <td>1.134763</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.789360</td>\n",
       "      <td>0.677722</td>\n",
       "      <td>0.708767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>1.178502</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.780714</td>\n",
       "      <td>0.695805</td>\n",
       "      <td>0.718053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 18:16:35,034] Trial 87 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 88 with params: {'learning_rate': 2.8421889789283416e-05, 'weight_decay': 0.007, 'warmup_steps': 25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:54 < 01:27, 30.00 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.173200</td>\n",
       "      <td>2.621999</td>\n",
       "      <td>0.485793</td>\n",
       "      <td>0.103814</td>\n",
       "      <td>0.135388</td>\n",
       "      <td>0.111409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.188000</td>\n",
       "      <td>1.950622</td>\n",
       "      <td>0.617782</td>\n",
       "      <td>0.270578</td>\n",
       "      <td>0.245207</td>\n",
       "      <td>0.224745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.614900</td>\n",
       "      <td>1.580114</td>\n",
       "      <td>0.703025</td>\n",
       "      <td>0.342244</td>\n",
       "      <td>0.323243</td>\n",
       "      <td>0.307764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.260800</td>\n",
       "      <td>1.372948</td>\n",
       "      <td>0.723190</td>\n",
       "      <td>0.360303</td>\n",
       "      <td>0.363947</td>\n",
       "      <td>0.342604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.026500</td>\n",
       "      <td>1.253776</td>\n",
       "      <td>0.743355</td>\n",
       "      <td>0.378037</td>\n",
       "      <td>0.400241</td>\n",
       "      <td>0.376715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.868600</td>\n",
       "      <td>1.172712</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.422683</td>\n",
       "      <td>0.431215</td>\n",
       "      <td>0.413143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.748300</td>\n",
       "      <td>1.121256</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.450157</td>\n",
       "      <td>0.446985</td>\n",
       "      <td>0.429996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.667500</td>\n",
       "      <td>1.090278</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.480686</td>\n",
       "      <td>0.464370</td>\n",
       "      <td>0.451802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.602600</td>\n",
       "      <td>1.072729</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.507844</td>\n",
       "      <td>0.474628</td>\n",
       "      <td>0.465409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.550800</td>\n",
       "      <td>1.057110</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.532428</td>\n",
       "      <td>0.479582</td>\n",
       "      <td>0.473011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 18:19:30,990] Trial 88 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 89 with params: {'learning_rate': 0.00021236351538358482, 'weight_decay': 0.002, 'warmup_steps': 21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:56 < 01:28, 29.68 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.595900</td>\n",
       "      <td>1.067597</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.425186</td>\n",
       "      <td>0.460230</td>\n",
       "      <td>0.433808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.362400</td>\n",
       "      <td>0.992832</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.617266</td>\n",
       "      <td>0.578889</td>\n",
       "      <td>0.581699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.138600</td>\n",
       "      <td>1.068973</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.716848</td>\n",
       "      <td>0.645023</td>\n",
       "      <td>0.663795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.069700</td>\n",
       "      <td>1.111979</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.790397</td>\n",
       "      <td>0.676502</td>\n",
       "      <td>0.715565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.043100</td>\n",
       "      <td>1.153710</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.782069</td>\n",
       "      <td>0.719234</td>\n",
       "      <td>0.737373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>1.210745</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.791610</td>\n",
       "      <td>0.688782</td>\n",
       "      <td>0.719714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>1.282017</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.791780</td>\n",
       "      <td>0.687726</td>\n",
       "      <td>0.716046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>1.279752</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.789770</td>\n",
       "      <td>0.713825</td>\n",
       "      <td>0.733956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>1.291146</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.791789</td>\n",
       "      <td>0.715631</td>\n",
       "      <td>0.735090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>1.351209</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.788604</td>\n",
       "      <td>0.716034</td>\n",
       "      <td>0.734323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 18:22:28,826] Trial 89 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 90 with params: {'learning_rate': 0.00021132069647997404, 'weight_decay': 0.0, 'warmup_steps': 15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:54 < 01:27, 30.14 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.585400</td>\n",
       "      <td>1.070158</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.434313</td>\n",
       "      <td>0.462762</td>\n",
       "      <td>0.439449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.362300</td>\n",
       "      <td>0.983667</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.615037</td>\n",
       "      <td>0.589782</td>\n",
       "      <td>0.588977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.138500</td>\n",
       "      <td>1.055049</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.723892</td>\n",
       "      <td>0.646640</td>\n",
       "      <td>0.663764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.069500</td>\n",
       "      <td>1.095825</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.788719</td>\n",
       "      <td>0.679743</td>\n",
       "      <td>0.714759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>1.133614</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.794762</td>\n",
       "      <td>0.720254</td>\n",
       "      <td>0.743519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>1.192623</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.814183</td>\n",
       "      <td>0.685922</td>\n",
       "      <td>0.724364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>1.246189</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.811855</td>\n",
       "      <td>0.697994</td>\n",
       "      <td>0.730969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>1.260379</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.795201</td>\n",
       "      <td>0.691847</td>\n",
       "      <td>0.719861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>1.302141</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.792023</td>\n",
       "      <td>0.728150</td>\n",
       "      <td>0.744936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>1.340954</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.798267</td>\n",
       "      <td>0.707658</td>\n",
       "      <td>0.731639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 18:25:23,959] Trial 90 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 91 with params: {'learning_rate': 0.00014745364610342952, 'weight_decay': 0.0, 'warmup_steps': 27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:22, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.908400</td>\n",
       "      <td>1.201298</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.417934</td>\n",
       "      <td>0.429086</td>\n",
       "      <td>0.411375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.567400</td>\n",
       "      <td>1.006971</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.479879</td>\n",
       "      <td>0.497004</td>\n",
       "      <td>0.482303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.255600</td>\n",
       "      <td>0.996254</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.649396</td>\n",
       "      <td>0.587373</td>\n",
       "      <td>0.599961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>1.054873</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.678785</td>\n",
       "      <td>0.601853</td>\n",
       "      <td>0.625677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.081300</td>\n",
       "      <td>1.070136</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.739475</td>\n",
       "      <td>0.667687</td>\n",
       "      <td>0.687225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>1.135798</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.769878</td>\n",
       "      <td>0.674188</td>\n",
       "      <td>0.700557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.038300</td>\n",
       "      <td>1.191172</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.796442</td>\n",
       "      <td>0.702069</td>\n",
       "      <td>0.724041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>1.187198</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.793522</td>\n",
       "      <td>0.721520</td>\n",
       "      <td>0.737511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>1.239887</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.789217</td>\n",
       "      <td>0.708200</td>\n",
       "      <td>0.727407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>1.277359</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.794827</td>\n",
       "      <td>0.726503</td>\n",
       "      <td>0.738724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>1.274270</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.805895</td>\n",
       "      <td>0.730287</td>\n",
       "      <td>0.747027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>1.298672</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.771880</td>\n",
       "      <td>0.728858</td>\n",
       "      <td>0.735475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>1.320713</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.785895</td>\n",
       "      <td>0.728557</td>\n",
       "      <td>0.740393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>1.323061</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.787705</td>\n",
       "      <td>0.727550</td>\n",
       "      <td>0.741908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.336039</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.799907</td>\n",
       "      <td>0.729748</td>\n",
       "      <td>0.746620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 18:29:48,288] Trial 91 finished with value: 0.7466199181329478 and parameters: {'learning_rate': 0.00014745364610342952, 'weight_decay': 0.0, 'warmup_steps': 27}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 92 with params: {'learning_rate': 0.00022444623275857606, 'weight_decay': 0.0, 'warmup_steps': 25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:25, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.562000</td>\n",
       "      <td>1.052070</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.431297</td>\n",
       "      <td>0.458963</td>\n",
       "      <td>0.436147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.338100</td>\n",
       "      <td>0.997316</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.619119</td>\n",
       "      <td>0.582135</td>\n",
       "      <td>0.586841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.127500</td>\n",
       "      <td>1.074886</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.706757</td>\n",
       "      <td>0.635832</td>\n",
       "      <td>0.653387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.063800</td>\n",
       "      <td>1.126029</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.785767</td>\n",
       "      <td>0.665809</td>\n",
       "      <td>0.704074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>1.167208</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.793218</td>\n",
       "      <td>0.712135</td>\n",
       "      <td>0.735282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.028200</td>\n",
       "      <td>1.219990</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.793201</td>\n",
       "      <td>0.696472</td>\n",
       "      <td>0.723930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>1.279549</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.794703</td>\n",
       "      <td>0.685131</td>\n",
       "      <td>0.715371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>1.295902</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.774358</td>\n",
       "      <td>0.715186</td>\n",
       "      <td>0.728624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>1.308391</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.779756</td>\n",
       "      <td>0.703746</td>\n",
       "      <td>0.723105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>1.383204</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.795439</td>\n",
       "      <td>0.721560</td>\n",
       "      <td>0.739554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>1.412320</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.806841</td>\n",
       "      <td>0.705280</td>\n",
       "      <td>0.734406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>1.395599</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.798190</td>\n",
       "      <td>0.735719</td>\n",
       "      <td>0.749467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>1.410367</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.787639</td>\n",
       "      <td>0.726295</td>\n",
       "      <td>0.742044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.414380</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.805579</td>\n",
       "      <td>0.720801</td>\n",
       "      <td>0.744440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>1.427801</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.818712</td>\n",
       "      <td>0.737200</td>\n",
       "      <td>0.758336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 18:34:15,134] Trial 92 finished with value: 0.7583362476463165 and parameters: {'learning_rate': 0.00022444623275857606, 'weight_decay': 0.0, 'warmup_steps': 25}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 93 with params: {'learning_rate': 0.00016270738163122646, 'weight_decay': 0.009000000000000001, 'warmup_steps': 12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:56 < 01:28, 29.73 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.791800</td>\n",
       "      <td>1.155212</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.421650</td>\n",
       "      <td>0.446212</td>\n",
       "      <td>0.423039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.501700</td>\n",
       "      <td>0.988433</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.552059</td>\n",
       "      <td>0.523574</td>\n",
       "      <td>0.519528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.216300</td>\n",
       "      <td>1.000687</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.643187</td>\n",
       "      <td>0.600822</td>\n",
       "      <td>0.606811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.112400</td>\n",
       "      <td>1.055753</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.721605</td>\n",
       "      <td>0.629220</td>\n",
       "      <td>0.656688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.067400</td>\n",
       "      <td>1.100757</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.759817</td>\n",
       "      <td>0.691261</td>\n",
       "      <td>0.711033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.046100</td>\n",
       "      <td>1.160984</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.762853</td>\n",
       "      <td>0.655154</td>\n",
       "      <td>0.685183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.032200</td>\n",
       "      <td>1.215389</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.791559</td>\n",
       "      <td>0.691511</td>\n",
       "      <td>0.718700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>1.203449</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.799624</td>\n",
       "      <td>0.735402</td>\n",
       "      <td>0.746821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>1.261960</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.783219</td>\n",
       "      <td>0.710995</td>\n",
       "      <td>0.728369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>1.301250</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.709508</td>\n",
       "      <td>0.729784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 18:37:12,522] Trial 93 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 94 with params: {'learning_rate': 0.0003193050618049994, 'weight_decay': 0.0, 'warmup_steps': 35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:59 < 01:29, 29.27 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.330100</td>\n",
       "      <td>1.010213</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.481552</td>\n",
       "      <td>0.484538</td>\n",
       "      <td>0.471660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.212300</td>\n",
       "      <td>1.066484</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.732715</td>\n",
       "      <td>0.636249</td>\n",
       "      <td>0.659602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>1.146333</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.758637</td>\n",
       "      <td>0.709654</td>\n",
       "      <td>0.717869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.040300</td>\n",
       "      <td>1.260390</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.824985</td>\n",
       "      <td>0.693148</td>\n",
       "      <td>0.731901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>1.252647</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.794083</td>\n",
       "      <td>0.720414</td>\n",
       "      <td>0.737742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>1.318067</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.793712</td>\n",
       "      <td>0.701370</td>\n",
       "      <td>0.723125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>1.369838</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.785370</td>\n",
       "      <td>0.695466</td>\n",
       "      <td>0.712464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>1.396246</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.785480</td>\n",
       "      <td>0.711258</td>\n",
       "      <td>0.726682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.520243</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.768005</td>\n",
       "      <td>0.717296</td>\n",
       "      <td>0.725950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>1.477016</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.777715</td>\n",
       "      <td>0.721450</td>\n",
       "      <td>0.729892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 18:40:12,983] Trial 94 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 95 with params: {'learning_rate': 0.00023822071579578048, 'weight_decay': 0.0, 'warmup_steps': 21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:23, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.507500</td>\n",
       "      <td>1.045757</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.441561</td>\n",
       "      <td>0.470436</td>\n",
       "      <td>0.445785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.311200</td>\n",
       "      <td>1.009107</td>\n",
       "      <td>0.778185</td>\n",
       "      <td>0.661051</td>\n",
       "      <td>0.605479</td>\n",
       "      <td>0.614456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.116100</td>\n",
       "      <td>1.087095</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.738409</td>\n",
       "      <td>0.662238</td>\n",
       "      <td>0.682665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.057900</td>\n",
       "      <td>1.142994</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.821570</td>\n",
       "      <td>0.703239</td>\n",
       "      <td>0.739260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>1.169389</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.800119</td>\n",
       "      <td>0.717486</td>\n",
       "      <td>0.740659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.026300</td>\n",
       "      <td>1.234681</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.810956</td>\n",
       "      <td>0.705715</td>\n",
       "      <td>0.735852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>1.323992</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.798914</td>\n",
       "      <td>0.697958</td>\n",
       "      <td>0.726027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>1.334612</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.801590</td>\n",
       "      <td>0.726031</td>\n",
       "      <td>0.742450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>1.356112</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.789714</td>\n",
       "      <td>0.718634</td>\n",
       "      <td>0.737559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>1.403568</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.808858</td>\n",
       "      <td>0.734844</td>\n",
       "      <td>0.754175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>1.434787</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.810904</td>\n",
       "      <td>0.735820</td>\n",
       "      <td>0.755577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>1.421442</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.810686</td>\n",
       "      <td>0.737900</td>\n",
       "      <td>0.756696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.431806</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.804573</td>\n",
       "      <td>0.734258</td>\n",
       "      <td>0.754558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.447466</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.814399</td>\n",
       "      <td>0.738695</td>\n",
       "      <td>0.758738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.454992</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.814336</td>\n",
       "      <td>0.736448</td>\n",
       "      <td>0.756946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 18:44:38,474] Trial 95 finished with value: 0.7569455197553512 and parameters: {'learning_rate': 0.00023822071579578048, 'weight_decay': 0.0, 'warmup_steps': 21}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 96 with params: {'learning_rate': 0.00033673304519787884, 'weight_decay': 0.0, 'warmup_steps': 24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:26, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.268300</td>\n",
       "      <td>1.003683</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.484569</td>\n",
       "      <td>0.497134</td>\n",
       "      <td>0.481564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.194100</td>\n",
       "      <td>1.078478</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.717641</td>\n",
       "      <td>0.646522</td>\n",
       "      <td>0.659485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>1.177050</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.783061</td>\n",
       "      <td>0.732527</td>\n",
       "      <td>0.739119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.036300</td>\n",
       "      <td>1.241735</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.801330</td>\n",
       "      <td>0.720349</td>\n",
       "      <td>0.736548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>1.341781</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.812752</td>\n",
       "      <td>0.698764</td>\n",
       "      <td>0.731664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>1.330974</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.817194</td>\n",
       "      <td>0.698350</td>\n",
       "      <td>0.732280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>1.402750</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.791199</td>\n",
       "      <td>0.706895</td>\n",
       "      <td>0.727156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>1.440652</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.801089</td>\n",
       "      <td>0.706124</td>\n",
       "      <td>0.732900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1.508214</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.808186</td>\n",
       "      <td>0.721853</td>\n",
       "      <td>0.744907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.496335</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.793951</td>\n",
       "      <td>0.726066</td>\n",
       "      <td>0.741226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.530833</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.807327</td>\n",
       "      <td>0.707532</td>\n",
       "      <td>0.735348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.534049</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.808046</td>\n",
       "      <td>0.714391</td>\n",
       "      <td>0.740391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.539427</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.806145</td>\n",
       "      <td>0.722204</td>\n",
       "      <td>0.745929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.545986</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.800551</td>\n",
       "      <td>0.728147</td>\n",
       "      <td>0.745859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.545231</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.806182</td>\n",
       "      <td>0.727187</td>\n",
       "      <td>0.748138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 18:49:06,115] Trial 96 finished with value: 0.7481376438758849 and parameters: {'learning_rate': 0.00033673304519787884, 'weight_decay': 0.0, 'warmup_steps': 24}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 97 with params: {'learning_rate': 0.00012531422646113865, 'weight_decay': 0.0, 'warmup_steps': 19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:55 < 01:27, 29.83 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.033100</td>\n",
       "      <td>1.284317</td>\n",
       "      <td>0.742438</td>\n",
       "      <td>0.386843</td>\n",
       "      <td>0.394330</td>\n",
       "      <td>0.373657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.676600</td>\n",
       "      <td>1.038145</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.475554</td>\n",
       "      <td>0.482008</td>\n",
       "      <td>0.471117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.330400</td>\n",
       "      <td>0.989601</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.601192</td>\n",
       "      <td>0.560089</td>\n",
       "      <td>0.562319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.182900</td>\n",
       "      <td>1.030524</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.667784</td>\n",
       "      <td>0.588890</td>\n",
       "      <td>0.611772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.112200</td>\n",
       "      <td>1.037813</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.686698</td>\n",
       "      <td>0.619709</td>\n",
       "      <td>0.635871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>1.098817</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.726445</td>\n",
       "      <td>0.631832</td>\n",
       "      <td>0.655168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.053500</td>\n",
       "      <td>1.131553</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.770570</td>\n",
       "      <td>0.668599</td>\n",
       "      <td>0.693921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>1.147055</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.801762</td>\n",
       "      <td>0.716693</td>\n",
       "      <td>0.736443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>1.180617</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.783714</td>\n",
       "      <td>0.689026</td>\n",
       "      <td>0.714560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>1.238666</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.793148</td>\n",
       "      <td>0.707268</td>\n",
       "      <td>0.724018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 18:52:02,972] Trial 97 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 98 with params: {'learning_rate': 0.00013299797880802797, 'weight_decay': 0.002, 'warmup_steps': 36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:56 < 01:28, 29.71 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.014200</td>\n",
       "      <td>1.254882</td>\n",
       "      <td>0.744271</td>\n",
       "      <td>0.385128</td>\n",
       "      <td>0.395805</td>\n",
       "      <td>0.374482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.641600</td>\n",
       "      <td>1.035298</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.475993</td>\n",
       "      <td>0.480928</td>\n",
       "      <td>0.471836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.306600</td>\n",
       "      <td>0.988472</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.603761</td>\n",
       "      <td>0.569229</td>\n",
       "      <td>0.573054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.166200</td>\n",
       "      <td>1.028276</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.674348</td>\n",
       "      <td>0.601324</td>\n",
       "      <td>0.622444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.101200</td>\n",
       "      <td>1.045210</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.686195</td>\n",
       "      <td>0.619806</td>\n",
       "      <td>0.635663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>1.112764</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.761750</td>\n",
       "      <td>0.658579</td>\n",
       "      <td>0.686031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>1.159552</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.804898</td>\n",
       "      <td>0.696553</td>\n",
       "      <td>0.722900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>1.168892</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.786572</td>\n",
       "      <td>0.702298</td>\n",
       "      <td>0.720860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.029700</td>\n",
       "      <td>1.201563</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.798089</td>\n",
       "      <td>0.697473</td>\n",
       "      <td>0.723268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>1.252131</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.805459</td>\n",
       "      <td>0.709774</td>\n",
       "      <td>0.731768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 18:55:00,570] Trial 98 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 99 with params: {'learning_rate': 0.0002852207883885828, 'weight_decay': 0.0, 'warmup_steps': 19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:55 < 01:27, 29.93 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.370300</td>\n",
       "      <td>1.018670</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.478306</td>\n",
       "      <td>0.483149</td>\n",
       "      <td>0.466719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.240800</td>\n",
       "      <td>1.028592</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.735762</td>\n",
       "      <td>0.637079</td>\n",
       "      <td>0.662222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>1.127788</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.759275</td>\n",
       "      <td>0.697272</td>\n",
       "      <td>0.710976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>1.185486</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.825537</td>\n",
       "      <td>0.695661</td>\n",
       "      <td>0.735880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>1.213190</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.796125</td>\n",
       "      <td>0.733746</td>\n",
       "      <td>0.747580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>1.280735</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.817908</td>\n",
       "      <td>0.712345</td>\n",
       "      <td>0.743070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>1.375015</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.788551</td>\n",
       "      <td>0.702514</td>\n",
       "      <td>0.722507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>1.399865</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.791533</td>\n",
       "      <td>0.712669</td>\n",
       "      <td>0.730331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>1.433290</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.807669</td>\n",
       "      <td>0.721074</td>\n",
       "      <td>0.743726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>1.465977</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.793808</td>\n",
       "      <td>0.717189</td>\n",
       "      <td>0.734604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 18:57:56,813] Trial 99 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 with params: {'learning_rate': 0.00027722459123952225, 'weight_decay': 0.002, 'warmup_steps': 25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:25, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.405200</td>\n",
       "      <td>1.019569</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.477397</td>\n",
       "      <td>0.482835</td>\n",
       "      <td>0.465380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.253300</td>\n",
       "      <td>1.031520</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.720029</td>\n",
       "      <td>0.633332</td>\n",
       "      <td>0.654135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.093300</td>\n",
       "      <td>1.103340</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.747428</td>\n",
       "      <td>0.692007</td>\n",
       "      <td>0.702084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>1.185938</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.824902</td>\n",
       "      <td>0.697278</td>\n",
       "      <td>0.735459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.029200</td>\n",
       "      <td>1.224787</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.779386</td>\n",
       "      <td>0.715859</td>\n",
       "      <td>0.731521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>1.280092</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.815585</td>\n",
       "      <td>0.701589</td>\n",
       "      <td>0.733916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>1.359021</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.804027</td>\n",
       "      <td>0.691831</td>\n",
       "      <td>0.719821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>1.330823</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.791962</td>\n",
       "      <td>0.732905</td>\n",
       "      <td>0.747222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.387956</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.808934</td>\n",
       "      <td>0.725041</td>\n",
       "      <td>0.747478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.421648</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.804502</td>\n",
       "      <td>0.739271</td>\n",
       "      <td>0.754951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>1.467563</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.807575</td>\n",
       "      <td>0.729683</td>\n",
       "      <td>0.748573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.443002</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.804315</td>\n",
       "      <td>0.741539</td>\n",
       "      <td>0.753804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.465413</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.799121</td>\n",
       "      <td>0.735886</td>\n",
       "      <td>0.751402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.436450</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.810160</td>\n",
       "      <td>0.730208</td>\n",
       "      <td>0.749864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.455854</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.809274</td>\n",
       "      <td>0.729508</td>\n",
       "      <td>0.749247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 19:02:24,317] Trial 100 finished with value: 0.7492466028265045 and parameters: {'learning_rate': 0.00027722459123952225, 'weight_decay': 0.002, 'warmup_steps': 25}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 101 with params: {'learning_rate': 0.00021102178947558206, 'weight_decay': 0.0, 'warmup_steps': 22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:25, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.603200</td>\n",
       "      <td>1.067744</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.424366</td>\n",
       "      <td>0.460625</td>\n",
       "      <td>0.434155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.365600</td>\n",
       "      <td>0.990098</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.611705</td>\n",
       "      <td>0.572096</td>\n",
       "      <td>0.575548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.140100</td>\n",
       "      <td>1.066132</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.716590</td>\n",
       "      <td>0.643392</td>\n",
       "      <td>0.661557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>1.113204</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.791641</td>\n",
       "      <td>0.674936</td>\n",
       "      <td>0.713488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.043400</td>\n",
       "      <td>1.158735</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.791350</td>\n",
       "      <td>0.710063</td>\n",
       "      <td>0.733348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>1.199160</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.802749</td>\n",
       "      <td>0.688778</td>\n",
       "      <td>0.722556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>1.284387</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.787472</td>\n",
       "      <td>0.693848</td>\n",
       "      <td>0.719795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>1.283825</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.787632</td>\n",
       "      <td>0.712062</td>\n",
       "      <td>0.730182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>1.306771</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.779994</td>\n",
       "      <td>0.712585</td>\n",
       "      <td>0.728360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>1.365645</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.799469</td>\n",
       "      <td>0.723418</td>\n",
       "      <td>0.741086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>1.413757</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.804702</td>\n",
       "      <td>0.704698</td>\n",
       "      <td>0.731160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>1.405372</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.790488</td>\n",
       "      <td>0.737190</td>\n",
       "      <td>0.746164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.419455</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.779187</td>\n",
       "      <td>0.724535</td>\n",
       "      <td>0.737550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.415504</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.808203</td>\n",
       "      <td>0.739446</td>\n",
       "      <td>0.756327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.422404</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.812066</td>\n",
       "      <td>0.735406</td>\n",
       "      <td>0.755016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 19:06:51,609] Trial 101 finished with value: 0.7550164025005508 and parameters: {'learning_rate': 0.00021102178947558206, 'weight_decay': 0.0, 'warmup_steps': 22}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 102 with params: {'learning_rate': 0.0001949924979053275, 'weight_decay': 0.0, 'warmup_steps': 27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:24, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.677600</td>\n",
       "      <td>1.088435</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.437112</td>\n",
       "      <td>0.447925</td>\n",
       "      <td>0.426862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.406700</td>\n",
       "      <td>0.973796</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.622945</td>\n",
       "      <td>0.574859</td>\n",
       "      <td>0.581077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.161700</td>\n",
       "      <td>1.025031</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.729752</td>\n",
       "      <td>0.646007</td>\n",
       "      <td>0.666665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.080600</td>\n",
       "      <td>1.088683</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.762169</td>\n",
       "      <td>0.656761</td>\n",
       "      <td>0.687849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.048800</td>\n",
       "      <td>1.136006</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.804322</td>\n",
       "      <td>0.720009</td>\n",
       "      <td>0.744608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.033800</td>\n",
       "      <td>1.205321</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.787723</td>\n",
       "      <td>0.682053</td>\n",
       "      <td>0.710915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>1.254955</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.811677</td>\n",
       "      <td>0.706333</td>\n",
       "      <td>0.734449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>1.230188</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.813846</td>\n",
       "      <td>0.736153</td>\n",
       "      <td>0.752081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>1.273028</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.786883</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.732874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>1.326388</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>0.718835</td>\n",
       "      <td>0.739571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>1.361262</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.800790</td>\n",
       "      <td>0.728457</td>\n",
       "      <td>0.743827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>1.367783</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.773687</td>\n",
       "      <td>0.726185</td>\n",
       "      <td>0.735520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>1.395165</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.782893</td>\n",
       "      <td>0.723881</td>\n",
       "      <td>0.735653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.395792</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.816938</td>\n",
       "      <td>0.729121</td>\n",
       "      <td>0.751310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>1.403931</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.812653</td>\n",
       "      <td>0.719754</td>\n",
       "      <td>0.744426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 19:11:17,791] Trial 102 finished with value: 0.7444258680569698 and parameters: {'learning_rate': 0.0001949924979053275, 'weight_decay': 0.0, 'warmup_steps': 27}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 103 with params: {'learning_rate': 0.00023123369442023856, 'weight_decay': 0.0, 'warmup_steps': 23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:23, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.534200</td>\n",
       "      <td>1.047065</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.445120</td>\n",
       "      <td>0.464633</td>\n",
       "      <td>0.440450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.324300</td>\n",
       "      <td>1.007515</td>\n",
       "      <td>0.779102</td>\n",
       "      <td>0.607487</td>\n",
       "      <td>0.578908</td>\n",
       "      <td>0.579541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>1.075992</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.711672</td>\n",
       "      <td>0.646838</td>\n",
       "      <td>0.662708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.061100</td>\n",
       "      <td>1.117502</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.777942</td>\n",
       "      <td>0.668954</td>\n",
       "      <td>0.703364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.038100</td>\n",
       "      <td>1.176484</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.807797</td>\n",
       "      <td>0.712545</td>\n",
       "      <td>0.740703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>1.230822</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.788031</td>\n",
       "      <td>0.689111</td>\n",
       "      <td>0.718779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>1.314367</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.771317</td>\n",
       "      <td>0.682724</td>\n",
       "      <td>0.705759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>1.311870</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.784367</td>\n",
       "      <td>0.710119</td>\n",
       "      <td>0.728802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>1.340078</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.790144</td>\n",
       "      <td>0.725008</td>\n",
       "      <td>0.741010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>1.388225</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.812286</td>\n",
       "      <td>0.725093</td>\n",
       "      <td>0.748942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>1.425073</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.811272</td>\n",
       "      <td>0.721111</td>\n",
       "      <td>0.746325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.404573</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.799017</td>\n",
       "      <td>0.725417</td>\n",
       "      <td>0.742051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.426808</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.796139</td>\n",
       "      <td>0.728114</td>\n",
       "      <td>0.745610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>1.434752</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.815251</td>\n",
       "      <td>0.727084</td>\n",
       "      <td>0.751474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.443577</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.813827</td>\n",
       "      <td>0.733598</td>\n",
       "      <td>0.755064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 19:15:42,903] Trial 103 finished with value: 0.7550644983354465 and parameters: {'learning_rate': 0.00023123369442023856, 'weight_decay': 0.0, 'warmup_steps': 23}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 104 with params: {'learning_rate': 0.00025269094715993617, 'weight_decay': 0.0, 'warmup_steps': 23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:24, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.468300</td>\n",
       "      <td>1.034592</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.470724</td>\n",
       "      <td>0.477329</td>\n",
       "      <td>0.458086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.287400</td>\n",
       "      <td>1.010739</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>0.669529</td>\n",
       "      <td>0.604861</td>\n",
       "      <td>0.618666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.105500</td>\n",
       "      <td>1.101912</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.753634</td>\n",
       "      <td>0.689278</td>\n",
       "      <td>0.705994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>1.148898</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.820677</td>\n",
       "      <td>0.707714</td>\n",
       "      <td>0.743016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.033400</td>\n",
       "      <td>1.191628</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.798511</td>\n",
       "      <td>0.718536</td>\n",
       "      <td>0.740236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>1.236551</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.805105</td>\n",
       "      <td>0.709490</td>\n",
       "      <td>0.736025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>1.330288</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.794211</td>\n",
       "      <td>0.694347</td>\n",
       "      <td>0.720859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>1.344695</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.801960</td>\n",
       "      <td>0.739353</td>\n",
       "      <td>0.753373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>1.414139</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.793177</td>\n",
       "      <td>0.715352</td>\n",
       "      <td>0.737543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.419370</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.808544</td>\n",
       "      <td>0.736518</td>\n",
       "      <td>0.754706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.466389</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.810858</td>\n",
       "      <td>0.730959</td>\n",
       "      <td>0.753256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>1.435004</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.796181</td>\n",
       "      <td>0.725720</td>\n",
       "      <td>0.741331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>1.433410</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.784047</td>\n",
       "      <td>0.724483</td>\n",
       "      <td>0.738796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.456047</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.816611</td>\n",
       "      <td>0.730662</td>\n",
       "      <td>0.753325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.454590</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.810921</td>\n",
       "      <td>0.726249</td>\n",
       "      <td>0.748337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 19:20:09,331] Trial 104 finished with value: 0.7483373707957668 and parameters: {'learning_rate': 0.00025269094715993617, 'weight_decay': 0.0, 'warmup_steps': 23}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 105 with params: {'learning_rate': 0.0002523073998035621, 'weight_decay': 0.001, 'warmup_steps': 30}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:22, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.485300</td>\n",
       "      <td>1.030514</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.435887</td>\n",
       "      <td>0.464364</td>\n",
       "      <td>0.442512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.289800</td>\n",
       "      <td>1.009915</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.664135</td>\n",
       "      <td>0.612745</td>\n",
       "      <td>0.623546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.106100</td>\n",
       "      <td>1.072136</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.744300</td>\n",
       "      <td>0.656480</td>\n",
       "      <td>0.679715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>1.135736</td>\n",
       "      <td>0.804766</td>\n",
       "      <td>0.819261</td>\n",
       "      <td>0.704160</td>\n",
       "      <td>0.740661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.033800</td>\n",
       "      <td>1.182982</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.801037</td>\n",
       "      <td>0.725432</td>\n",
       "      <td>0.744485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>1.232134</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.813685</td>\n",
       "      <td>0.696499</td>\n",
       "      <td>0.728508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>1.317860</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.776591</td>\n",
       "      <td>0.693542</td>\n",
       "      <td>0.714704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>1.315716</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.792300</td>\n",
       "      <td>0.731964</td>\n",
       "      <td>0.743606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.360814</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.795809</td>\n",
       "      <td>0.725628</td>\n",
       "      <td>0.744137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>1.421061</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.800002</td>\n",
       "      <td>0.736472</td>\n",
       "      <td>0.749580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1.430755</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.790179</td>\n",
       "      <td>0.723581</td>\n",
       "      <td>0.741357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>1.430640</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.799504</td>\n",
       "      <td>0.732562</td>\n",
       "      <td>0.747219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.459561</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.804201</td>\n",
       "      <td>0.726261</td>\n",
       "      <td>0.747558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>1.446269</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.803324</td>\n",
       "      <td>0.734667</td>\n",
       "      <td>0.752230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.448553</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.813244</td>\n",
       "      <td>0.735785</td>\n",
       "      <td>0.755636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 19:24:33,645] Trial 105 finished with value: 0.7556358967145542 and parameters: {'learning_rate': 0.0002523073998035621, 'weight_decay': 0.001, 'warmup_steps': 30}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 106 with params: {'learning_rate': 0.0002586995153481563, 'weight_decay': 0.0, 'warmup_steps': 35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:24, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.478900</td>\n",
       "      <td>1.028582</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.437095</td>\n",
       "      <td>0.461697</td>\n",
       "      <td>0.439673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.281800</td>\n",
       "      <td>1.012196</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.674490</td>\n",
       "      <td>0.616803</td>\n",
       "      <td>0.629665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>1.099101</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.734044</td>\n",
       "      <td>0.656894</td>\n",
       "      <td>0.677598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.050800</td>\n",
       "      <td>1.143148</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.822195</td>\n",
       "      <td>0.704279</td>\n",
       "      <td>0.741297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.032800</td>\n",
       "      <td>1.176076</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.804944</td>\n",
       "      <td>0.715739</td>\n",
       "      <td>0.739068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>1.253940</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.787480</td>\n",
       "      <td>0.704130</td>\n",
       "      <td>0.726720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>1.328750</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.805160</td>\n",
       "      <td>0.707951</td>\n",
       "      <td>0.732896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>1.340167</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.798432</td>\n",
       "      <td>0.707669</td>\n",
       "      <td>0.730254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>1.384876</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.800536</td>\n",
       "      <td>0.714079</td>\n",
       "      <td>0.734952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>1.438387</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.809227</td>\n",
       "      <td>0.714438</td>\n",
       "      <td>0.739326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.476513</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.807337</td>\n",
       "      <td>0.703523</td>\n",
       "      <td>0.732280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.449047</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.815279</td>\n",
       "      <td>0.728905</td>\n",
       "      <td>0.749920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.477425</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.800316</td>\n",
       "      <td>0.716193</td>\n",
       "      <td>0.738373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.479927</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.808994</td>\n",
       "      <td>0.723880</td>\n",
       "      <td>0.745317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.482750</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.810714</td>\n",
       "      <td>0.724764</td>\n",
       "      <td>0.746602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 19:28:59,473] Trial 106 finished with value: 0.7466024206307607 and parameters: {'learning_rate': 0.0002586995153481563, 'weight_decay': 0.0, 'warmup_steps': 35}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 107 with params: {'learning_rate': 0.0004979241829976273, 'weight_decay': 0.002, 'warmup_steps': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:23, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.059600</td>\n",
       "      <td>1.027521</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.525383</td>\n",
       "      <td>0.555018</td>\n",
       "      <td>0.532989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.107579</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.771993</td>\n",
       "      <td>0.700530</td>\n",
       "      <td>0.717920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.048800</td>\n",
       "      <td>1.219461</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.789689</td>\n",
       "      <td>0.711444</td>\n",
       "      <td>0.731116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.026900</td>\n",
       "      <td>1.283285</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.827269</td>\n",
       "      <td>0.711185</td>\n",
       "      <td>0.744720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>1.368419</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.812290</td>\n",
       "      <td>0.729930</td>\n",
       "      <td>0.755618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>1.414745</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.818398</td>\n",
       "      <td>0.725881</td>\n",
       "      <td>0.748737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>1.493519</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.813255</td>\n",
       "      <td>0.721259</td>\n",
       "      <td>0.747572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>1.510804</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.797647</td>\n",
       "      <td>0.732132</td>\n",
       "      <td>0.749101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.578563</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.809411</td>\n",
       "      <td>0.715268</td>\n",
       "      <td>0.744413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.618742</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.775912</td>\n",
       "      <td>0.725212</td>\n",
       "      <td>0.736676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>1.617588</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.814229</td>\n",
       "      <td>0.684917</td>\n",
       "      <td>0.724625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.626161</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.788920</td>\n",
       "      <td>0.700404</td>\n",
       "      <td>0.725821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.646101</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.786033</td>\n",
       "      <td>0.716833</td>\n",
       "      <td>0.734278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.633021</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.798707</td>\n",
       "      <td>0.709984</td>\n",
       "      <td>0.734895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.635585</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.803133</td>\n",
       "      <td>0.709578</td>\n",
       "      <td>0.735843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 19:33:24,427] Trial 107 finished with value: 0.7358429845934819 and parameters: {'learning_rate': 0.0004979241829976273, 'weight_decay': 0.002, 'warmup_steps': 32}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 108 with params: {'learning_rate': 0.00019711131424837047, 'weight_decay': 0.003, 'warmup_steps': 37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:23, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.691900</td>\n",
       "      <td>1.091588</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.422127</td>\n",
       "      <td>0.447463</td>\n",
       "      <td>0.422442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.991763</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>0.596737</td>\n",
       "      <td>0.550400</td>\n",
       "      <td>0.556853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.160800</td>\n",
       "      <td>1.045939</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.736961</td>\n",
       "      <td>0.645095</td>\n",
       "      <td>0.668209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.079500</td>\n",
       "      <td>1.100660</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.788314</td>\n",
       "      <td>0.669935</td>\n",
       "      <td>0.706508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.048300</td>\n",
       "      <td>1.153428</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.803378</td>\n",
       "      <td>0.723953</td>\n",
       "      <td>0.745876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.033100</td>\n",
       "      <td>1.232995</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.783431</td>\n",
       "      <td>0.684474</td>\n",
       "      <td>0.711826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>1.265639</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.793656</td>\n",
       "      <td>0.692168</td>\n",
       "      <td>0.719326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>1.273315</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.800734</td>\n",
       "      <td>0.716527</td>\n",
       "      <td>0.734252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>1.297400</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.801318</td>\n",
       "      <td>0.728556</td>\n",
       "      <td>0.748063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>1.356570</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.818836</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.745729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>1.395415</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.805786</td>\n",
       "      <td>0.718912</td>\n",
       "      <td>0.741709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>1.420005</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.766870</td>\n",
       "      <td>0.728509</td>\n",
       "      <td>0.735439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.427850</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.767625</td>\n",
       "      <td>0.721657</td>\n",
       "      <td>0.731430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>1.431644</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.800620</td>\n",
       "      <td>0.727189</td>\n",
       "      <td>0.745786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>1.446083</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.802655</td>\n",
       "      <td>0.719547</td>\n",
       "      <td>0.740939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 19:37:49,723] Trial 108 finished with value: 0.7409389116974938 and parameters: {'learning_rate': 0.00019711131424837047, 'weight_decay': 0.003, 'warmup_steps': 37}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 109 with params: {'learning_rate': 0.0001762451893065269, 'weight_decay': 0.001, 'warmup_steps': 33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:23, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.773100</td>\n",
       "      <td>1.129173</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.423652</td>\n",
       "      <td>0.448459</td>\n",
       "      <td>0.423885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.463200</td>\n",
       "      <td>0.994804</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.572639</td>\n",
       "      <td>0.524468</td>\n",
       "      <td>0.526472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.193000</td>\n",
       "      <td>1.013540</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.693672</td>\n",
       "      <td>0.630639</td>\n",
       "      <td>0.646338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.097700</td>\n",
       "      <td>1.068483</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.764286</td>\n",
       "      <td>0.649746</td>\n",
       "      <td>0.685766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>1.116380</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.797335</td>\n",
       "      <td>0.707733</td>\n",
       "      <td>0.733925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>1.170464</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.789674</td>\n",
       "      <td>0.686707</td>\n",
       "      <td>0.716058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>1.220538</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.791381</td>\n",
       "      <td>0.691900</td>\n",
       "      <td>0.716892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>1.230603</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.794215</td>\n",
       "      <td>0.737939</td>\n",
       "      <td>0.745056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>1.270713</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.796090</td>\n",
       "      <td>0.705827</td>\n",
       "      <td>0.730774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>1.333149</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.803619</td>\n",
       "      <td>0.721858</td>\n",
       "      <td>0.741093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.334360</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.797683</td>\n",
       "      <td>0.728145</td>\n",
       "      <td>0.745123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>1.353772</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.790018</td>\n",
       "      <td>0.733551</td>\n",
       "      <td>0.745525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>1.385283</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.772810</td>\n",
       "      <td>0.722553</td>\n",
       "      <td>0.734842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>1.384439</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.807341</td>\n",
       "      <td>0.728533</td>\n",
       "      <td>0.747573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>1.392084</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.813462</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.750292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 19:42:15,423] Trial 109 finished with value: 0.7502924084340395 and parameters: {'learning_rate': 0.0001762451893065269, 'weight_decay': 0.001, 'warmup_steps': 33}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 110 with params: {'learning_rate': 0.00022169023375838217, 'weight_decay': 0.001, 'warmup_steps': 29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:25, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.580800</td>\n",
       "      <td>1.053450</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.436574</td>\n",
       "      <td>0.458528</td>\n",
       "      <td>0.435690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.344800</td>\n",
       "      <td>0.983482</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.623907</td>\n",
       "      <td>0.585103</td>\n",
       "      <td>0.591404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>1.057857</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.749030</td>\n",
       "      <td>0.664942</td>\n",
       "      <td>0.685096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.064600</td>\n",
       "      <td>1.114785</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.788026</td>\n",
       "      <td>0.675956</td>\n",
       "      <td>0.712382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>1.167208</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.798966</td>\n",
       "      <td>0.720106</td>\n",
       "      <td>0.743180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>1.211372</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.790030</td>\n",
       "      <td>0.689707</td>\n",
       "      <td>0.719618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>1.265686</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.815485</td>\n",
       "      <td>0.708620</td>\n",
       "      <td>0.737385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>1.294907</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.784589</td>\n",
       "      <td>0.725351</td>\n",
       "      <td>0.736633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>1.297171</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.790765</td>\n",
       "      <td>0.712557</td>\n",
       "      <td>0.732949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>1.354915</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.815207</td>\n",
       "      <td>0.724153</td>\n",
       "      <td>0.747436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>1.392057</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.813835</td>\n",
       "      <td>0.738837</td>\n",
       "      <td>0.758076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>1.386577</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.809767</td>\n",
       "      <td>0.740200</td>\n",
       "      <td>0.757169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>1.410962</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.805999</td>\n",
       "      <td>0.725513</td>\n",
       "      <td>0.747640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.412964</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.803247</td>\n",
       "      <td>0.725842</td>\n",
       "      <td>0.746632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.421224</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.818384</td>\n",
       "      <td>0.733908</td>\n",
       "      <td>0.756505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 19:46:42,489] Trial 110 finished with value: 0.7565047850668336 and parameters: {'learning_rate': 0.00022169023375838217, 'weight_decay': 0.001, 'warmup_steps': 29}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 111 with params: {'learning_rate': 0.00028611167841864334, 'weight_decay': 0.002, 'warmup_steps': 37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:23, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.411600</td>\n",
       "      <td>1.012860</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.478265</td>\n",
       "      <td>0.483913</td>\n",
       "      <td>0.468052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.246300</td>\n",
       "      <td>1.041615</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.727839</td>\n",
       "      <td>0.641362</td>\n",
       "      <td>0.660777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.090100</td>\n",
       "      <td>1.110381</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.766811</td>\n",
       "      <td>0.697269</td>\n",
       "      <td>0.713629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.045300</td>\n",
       "      <td>1.176580</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.824894</td>\n",
       "      <td>0.709503</td>\n",
       "      <td>0.742982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>1.221083</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.792959</td>\n",
       "      <td>0.710765</td>\n",
       "      <td>0.734915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>1.269257</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.815030</td>\n",
       "      <td>0.705739</td>\n",
       "      <td>0.735845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>1.350842</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.796673</td>\n",
       "      <td>0.716012</td>\n",
       "      <td>0.733533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.346182</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.808073</td>\n",
       "      <td>0.726243</td>\n",
       "      <td>0.744912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>1.385339</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.785699</td>\n",
       "      <td>0.732554</td>\n",
       "      <td>0.743724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.460881</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.826334</td>\n",
       "      <td>0.725022</td>\n",
       "      <td>0.752496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>1.482112</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.795453</td>\n",
       "      <td>0.733115</td>\n",
       "      <td>0.745686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.464698</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.813700</td>\n",
       "      <td>0.736316</td>\n",
       "      <td>0.754938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.480491</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.812385</td>\n",
       "      <td>0.741050</td>\n",
       "      <td>0.755979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.488680</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.815935</td>\n",
       "      <td>0.730144</td>\n",
       "      <td>0.750731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.491212</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.810471</td>\n",
       "      <td>0.731698</td>\n",
       "      <td>0.750667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 19:51:07,481] Trial 111 finished with value: 0.7506670070074365 and parameters: {'learning_rate': 0.00028611167841864334, 'weight_decay': 0.002, 'warmup_steps': 37}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 112 with params: {'learning_rate': 0.00016484828255446262, 'weight_decay': 0.002, 'warmup_steps': 30}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:27 < 02:55, 29.98 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.821600</td>\n",
       "      <td>1.153078</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.423322</td>\n",
       "      <td>0.443886</td>\n",
       "      <td>0.422828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.500900</td>\n",
       "      <td>0.995392</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.564934</td>\n",
       "      <td>0.518968</td>\n",
       "      <td>0.515558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.214400</td>\n",
       "      <td>0.998614</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.653403</td>\n",
       "      <td>0.607860</td>\n",
       "      <td>0.615647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.110100</td>\n",
       "      <td>1.063095</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.708539</td>\n",
       "      <td>0.619561</td>\n",
       "      <td>0.647791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.066100</td>\n",
       "      <td>1.099372</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.786036</td>\n",
       "      <td>0.702245</td>\n",
       "      <td>0.727006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 19:52:35,880] Trial 112 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 113 with params: {'learning_rate': 0.00024227916778208096, 'weight_decay': 0.001, 'warmup_steps': 29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:31, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.513100</td>\n",
       "      <td>1.036932</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.437919</td>\n",
       "      <td>0.462787</td>\n",
       "      <td>0.440375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.306400</td>\n",
       "      <td>1.002504</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.669194</td>\n",
       "      <td>0.606000</td>\n",
       "      <td>0.620049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.113500</td>\n",
       "      <td>1.069964</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.735260</td>\n",
       "      <td>0.655183</td>\n",
       "      <td>0.676707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.056600</td>\n",
       "      <td>1.127600</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.795978</td>\n",
       "      <td>0.681306</td>\n",
       "      <td>0.718972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>1.199812</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.789550</td>\n",
       "      <td>0.710435</td>\n",
       "      <td>0.734050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>1.227617</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.807696</td>\n",
       "      <td>0.707009</td>\n",
       "      <td>0.733955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>1.291624</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.790174</td>\n",
       "      <td>0.699080</td>\n",
       "      <td>0.723487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>1.309078</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.804526</td>\n",
       "      <td>0.733065</td>\n",
       "      <td>0.749259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>1.322450</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.801145</td>\n",
       "      <td>0.705788</td>\n",
       "      <td>0.731755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>1.399180</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.813822</td>\n",
       "      <td>0.723284</td>\n",
       "      <td>0.747895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>1.425072</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.801089</td>\n",
       "      <td>0.712178</td>\n",
       "      <td>0.735799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1.435172</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.804229</td>\n",
       "      <td>0.736813</td>\n",
       "      <td>0.751490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>1.438452</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.790014</td>\n",
       "      <td>0.725595</td>\n",
       "      <td>0.742443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.439552</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.809380</td>\n",
       "      <td>0.733813</td>\n",
       "      <td>0.752302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.446862</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.806386</td>\n",
       "      <td>0.733598</td>\n",
       "      <td>0.750372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 19:57:09,140] Trial 113 finished with value: 0.7503720250041747 and parameters: {'learning_rate': 0.00024227916778208096, 'weight_decay': 0.001, 'warmup_steps': 29}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 114 with params: {'learning_rate': 0.00026433630023306123, 'weight_decay': 0.001, 'warmup_steps': 27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:24, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.444400</td>\n",
       "      <td>1.024348</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.465258</td>\n",
       "      <td>0.473450</td>\n",
       "      <td>0.455130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.270700</td>\n",
       "      <td>1.010772</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.705507</td>\n",
       "      <td>0.626082</td>\n",
       "      <td>0.644744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.098400</td>\n",
       "      <td>1.108685</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.744786</td>\n",
       "      <td>0.677593</td>\n",
       "      <td>0.693051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1.174203</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.823730</td>\n",
       "      <td>0.709022</td>\n",
       "      <td>0.744406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>1.190183</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.792044</td>\n",
       "      <td>0.714325</td>\n",
       "      <td>0.738191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>1.315335</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.805071</td>\n",
       "      <td>0.699219</td>\n",
       "      <td>0.730201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>1.372543</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.793613</td>\n",
       "      <td>0.692438</td>\n",
       "      <td>0.720178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>1.327056</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.806554</td>\n",
       "      <td>0.712231</td>\n",
       "      <td>0.736400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>1.408985</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.790479</td>\n",
       "      <td>0.723351</td>\n",
       "      <td>0.741359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.452065</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.802059</td>\n",
       "      <td>0.718343</td>\n",
       "      <td>0.741103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.474602</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.802852</td>\n",
       "      <td>0.724769</td>\n",
       "      <td>0.745054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>1.470107</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.813875</td>\n",
       "      <td>0.725485</td>\n",
       "      <td>0.748202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.490271</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.814942</td>\n",
       "      <td>0.726171</td>\n",
       "      <td>0.749441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.484557</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.808553</td>\n",
       "      <td>0.726935</td>\n",
       "      <td>0.748612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.488549</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.809005</td>\n",
       "      <td>0.726823</td>\n",
       "      <td>0.748778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 20:01:34,990] Trial 114 finished with value: 0.7487784671980193 and parameters: {'learning_rate': 0.00026433630023306123, 'weight_decay': 0.001, 'warmup_steps': 27}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 115 with params: {'learning_rate': 0.00028898255544382984, 'weight_decay': 0.0, 'warmup_steps': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:38, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.392400</td>\n",
       "      <td>1.010311</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.476416</td>\n",
       "      <td>0.475922</td>\n",
       "      <td>0.461695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.241200</td>\n",
       "      <td>1.039173</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.739518</td>\n",
       "      <td>0.634981</td>\n",
       "      <td>0.661415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>1.108041</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.762051</td>\n",
       "      <td>0.695581</td>\n",
       "      <td>0.712166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.044400</td>\n",
       "      <td>1.188445</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.809121</td>\n",
       "      <td>0.689622</td>\n",
       "      <td>0.725302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>1.215630</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.801242</td>\n",
       "      <td>0.713768</td>\n",
       "      <td>0.738484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>1.302737</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.797112</td>\n",
       "      <td>0.704298</td>\n",
       "      <td>0.731236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.368104</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.761803</td>\n",
       "      <td>0.708780</td>\n",
       "      <td>0.718385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>1.383414</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.799028</td>\n",
       "      <td>0.724442</td>\n",
       "      <td>0.741534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>1.438217</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.795581</td>\n",
       "      <td>0.711200</td>\n",
       "      <td>0.732392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>1.443222</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.823715</td>\n",
       "      <td>0.724199</td>\n",
       "      <td>0.750957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>1.501982</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.788310</td>\n",
       "      <td>0.717912</td>\n",
       "      <td>0.734469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.451335</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.799842</td>\n",
       "      <td>0.715448</td>\n",
       "      <td>0.737674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.514111</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.801453</td>\n",
       "      <td>0.729816</td>\n",
       "      <td>0.746240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.497883</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.807662</td>\n",
       "      <td>0.739411</td>\n",
       "      <td>0.755053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.499586</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.802365</td>\n",
       "      <td>0.739341</td>\n",
       "      <td>0.752414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 20:06:14,461] Trial 115 finished with value: 0.75241362335037 and parameters: {'learning_rate': 0.00028898255544382984, 'weight_decay': 0.0, 'warmup_steps': 32}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 116 with params: {'learning_rate': 0.00028128286124663276, 'weight_decay': 0.0, 'warmup_steps': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:35, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.373600</td>\n",
       "      <td>1.018324</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.475502</td>\n",
       "      <td>0.489062</td>\n",
       "      <td>0.469252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.246600</td>\n",
       "      <td>1.030546</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.737343</td>\n",
       "      <td>0.646261</td>\n",
       "      <td>0.670203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.090400</td>\n",
       "      <td>1.114647</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.752826</td>\n",
       "      <td>0.691975</td>\n",
       "      <td>0.705786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>1.136188</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.819077</td>\n",
       "      <td>0.693028</td>\n",
       "      <td>0.731874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.029200</td>\n",
       "      <td>1.198730</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.792437</td>\n",
       "      <td>0.722916</td>\n",
       "      <td>0.737953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>1.276953</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.806349</td>\n",
       "      <td>0.699944</td>\n",
       "      <td>0.734388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>1.391791</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.795247</td>\n",
       "      <td>0.720319</td>\n",
       "      <td>0.736224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>1.409644</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.800195</td>\n",
       "      <td>0.723447</td>\n",
       "      <td>0.740875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>1.447427</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.809159</td>\n",
       "      <td>0.715628</td>\n",
       "      <td>0.740746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1.464120</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.801407</td>\n",
       "      <td>0.722755</td>\n",
       "      <td>0.742808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>1.487439</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.799349</td>\n",
       "      <td>0.720517</td>\n",
       "      <td>0.738801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.481385</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.796555</td>\n",
       "      <td>0.727842</td>\n",
       "      <td>0.743963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.489681</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.788995</td>\n",
       "      <td>0.722026</td>\n",
       "      <td>0.738222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.500899</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.787772</td>\n",
       "      <td>0.719600</td>\n",
       "      <td>0.737180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.514561</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.797407</td>\n",
       "      <td>0.721398</td>\n",
       "      <td>0.741280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 20:10:51,282] Trial 116 finished with value: 0.7412799608499024 and parameters: {'learning_rate': 0.00028128286124663276, 'weight_decay': 0.0, 'warmup_steps': 16}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 117 with params: {'learning_rate': 0.00015138066752833573, 'weight_decay': 0.001, 'warmup_steps': 28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:35, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.888300</td>\n",
       "      <td>1.189333</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.419697</td>\n",
       "      <td>0.432476</td>\n",
       "      <td>0.413805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.551000</td>\n",
       "      <td>1.002602</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.478910</td>\n",
       "      <td>0.497474</td>\n",
       "      <td>0.482107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.245100</td>\n",
       "      <td>0.995226</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.651949</td>\n",
       "      <td>0.588641</td>\n",
       "      <td>0.601902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.128500</td>\n",
       "      <td>1.053976</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.693662</td>\n",
       "      <td>0.610699</td>\n",
       "      <td>0.635464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>1.077703</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.740246</td>\n",
       "      <td>0.669800</td>\n",
       "      <td>0.689710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.051900</td>\n",
       "      <td>1.138995</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.777531</td>\n",
       "      <td>0.676097</td>\n",
       "      <td>0.705326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.036300</td>\n",
       "      <td>1.196288</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.796391</td>\n",
       "      <td>0.702284</td>\n",
       "      <td>0.723936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>1.193086</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.796454</td>\n",
       "      <td>0.737615</td>\n",
       "      <td>0.748613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>1.242984</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.781597</td>\n",
       "      <td>0.718201</td>\n",
       "      <td>0.733528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>1.277342</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.783002</td>\n",
       "      <td>0.726301</td>\n",
       "      <td>0.735972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.015500</td>\n",
       "      <td>1.281543</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.799475</td>\n",
       "      <td>0.727786</td>\n",
       "      <td>0.743089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>1.307700</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.774721</td>\n",
       "      <td>0.732858</td>\n",
       "      <td>0.739173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>1.329158</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.782885</td>\n",
       "      <td>0.729250</td>\n",
       "      <td>0.741146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>1.332254</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.789036</td>\n",
       "      <td>0.729368</td>\n",
       "      <td>0.743487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>1.343296</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.800650</td>\n",
       "      <td>0.730797</td>\n",
       "      <td>0.747591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 20:15:28,391] Trial 117 finished with value: 0.7475914714331914 and parameters: {'learning_rate': 0.00015138066752833573, 'weight_decay': 0.001, 'warmup_steps': 28}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 118 with params: {'learning_rate': 0.00012755064561990304, 'weight_decay': 0.0, 'warmup_steps': 31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:58 < 01:29, 29.34 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.039600</td>\n",
       "      <td>1.274897</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.391265</td>\n",
       "      <td>0.397057</td>\n",
       "      <td>0.377321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.667200</td>\n",
       "      <td>1.039499</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.473863</td>\n",
       "      <td>0.477813</td>\n",
       "      <td>0.469147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.324800</td>\n",
       "      <td>0.988809</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.603029</td>\n",
       "      <td>0.567833</td>\n",
       "      <td>0.572130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.178700</td>\n",
       "      <td>1.027778</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.673177</td>\n",
       "      <td>0.600444</td>\n",
       "      <td>0.621322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.109100</td>\n",
       "      <td>1.043621</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.684726</td>\n",
       "      <td>0.618717</td>\n",
       "      <td>0.634645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>1.102923</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.750004</td>\n",
       "      <td>0.651449</td>\n",
       "      <td>0.678025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.051700</td>\n",
       "      <td>1.140301</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.797234</td>\n",
       "      <td>0.689186</td>\n",
       "      <td>0.716743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1.156135</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.799122</td>\n",
       "      <td>0.717053</td>\n",
       "      <td>0.735514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>1.194294</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.785404</td>\n",
       "      <td>0.689057</td>\n",
       "      <td>0.714231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.025100</td>\n",
       "      <td>1.239861</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.806006</td>\n",
       "      <td>0.713102</td>\n",
       "      <td>0.733672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 20:18:28,172] Trial 118 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 119 with params: {'learning_rate': 0.00026286043324977326, 'weight_decay': 0.002, 'warmup_steps': 26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:28, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.446300</td>\n",
       "      <td>1.025080</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.471121</td>\n",
       "      <td>0.475661</td>\n",
       "      <td>0.458287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.272900</td>\n",
       "      <td>1.006730</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.711732</td>\n",
       "      <td>0.630895</td>\n",
       "      <td>0.650308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.099400</td>\n",
       "      <td>1.099363</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.752684</td>\n",
       "      <td>0.679703</td>\n",
       "      <td>0.697748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1.162507</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.821796</td>\n",
       "      <td>0.711345</td>\n",
       "      <td>0.744579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.031400</td>\n",
       "      <td>1.178853</td>\n",
       "      <td>0.806599</td>\n",
       "      <td>0.793067</td>\n",
       "      <td>0.723458</td>\n",
       "      <td>0.743802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>1.285358</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.795657</td>\n",
       "      <td>0.714388</td>\n",
       "      <td>0.737996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.015500</td>\n",
       "      <td>1.346769</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.789178</td>\n",
       "      <td>0.697532</td>\n",
       "      <td>0.722873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>1.332444</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.807398</td>\n",
       "      <td>0.720035</td>\n",
       "      <td>0.744216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.414648</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.785890</td>\n",
       "      <td>0.707161</td>\n",
       "      <td>0.726639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>1.442106</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.806280</td>\n",
       "      <td>0.723680</td>\n",
       "      <td>0.746272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1.489227</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.787568</td>\n",
       "      <td>0.719401</td>\n",
       "      <td>0.736413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.469834</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.792334</td>\n",
       "      <td>0.728735</td>\n",
       "      <td>0.742835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>1.488457</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.796047</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.745974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.493952</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.804253</td>\n",
       "      <td>0.729192</td>\n",
       "      <td>0.748557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.484528</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.805081</td>\n",
       "      <td>0.731848</td>\n",
       "      <td>0.750453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 20:22:57,712] Trial 119 finished with value: 0.750452832364819 and parameters: {'learning_rate': 0.00026286043324977326, 'weight_decay': 0.002, 'warmup_steps': 26}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 120 with params: {'learning_rate': 0.0002472976711967465, 'weight_decay': 0.0, 'warmup_steps': 25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:28, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.488300</td>\n",
       "      <td>1.034767</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.439435</td>\n",
       "      <td>0.468471</td>\n",
       "      <td>0.444568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.296500</td>\n",
       "      <td>1.011748</td>\n",
       "      <td>0.779102</td>\n",
       "      <td>0.656657</td>\n",
       "      <td>0.601354</td>\n",
       "      <td>0.611862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.109300</td>\n",
       "      <td>1.082567</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.737518</td>\n",
       "      <td>0.655370</td>\n",
       "      <td>0.677813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>1.141569</td>\n",
       "      <td>0.807516</td>\n",
       "      <td>0.807449</td>\n",
       "      <td>0.691519</td>\n",
       "      <td>0.726752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>1.186851</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.791263</td>\n",
       "      <td>0.723271</td>\n",
       "      <td>0.742238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>1.270477</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.793517</td>\n",
       "      <td>0.692903</td>\n",
       "      <td>0.723824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>1.339865</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.777273</td>\n",
       "      <td>0.678980</td>\n",
       "      <td>0.705669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>1.309631</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.805617</td>\n",
       "      <td>0.724831</td>\n",
       "      <td>0.747272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.358372</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.796026</td>\n",
       "      <td>0.725243</td>\n",
       "      <td>0.744338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>1.411381</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.812646</td>\n",
       "      <td>0.716707</td>\n",
       "      <td>0.744346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.442387</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.809530</td>\n",
       "      <td>0.723101</td>\n",
       "      <td>0.747060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>1.423663</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.796836</td>\n",
       "      <td>0.733270</td>\n",
       "      <td>0.748725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.452657</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.785876</td>\n",
       "      <td>0.731108</td>\n",
       "      <td>0.744757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.447258</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.814530</td>\n",
       "      <td>0.737691</td>\n",
       "      <td>0.758325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.456231</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.812825</td>\n",
       "      <td>0.726161</td>\n",
       "      <td>0.749751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 20:27:28,419] Trial 120 finished with value: 0.7497509051832413 and parameters: {'learning_rate': 0.0002472976711967465, 'weight_decay': 0.0, 'warmup_steps': 25}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 121 with params: {'learning_rate': 0.00021059484737596867, 'weight_decay': 0.0, 'warmup_steps': 21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:28, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.602500</td>\n",
       "      <td>1.069200</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.424646</td>\n",
       "      <td>0.459742</td>\n",
       "      <td>0.433335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.991789</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.617480</td>\n",
       "      <td>0.579127</td>\n",
       "      <td>0.581944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.140500</td>\n",
       "      <td>1.067339</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.720787</td>\n",
       "      <td>0.645023</td>\n",
       "      <td>0.665031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.070600</td>\n",
       "      <td>1.111359</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.790106</td>\n",
       "      <td>0.679490</td>\n",
       "      <td>0.717078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.043800</td>\n",
       "      <td>1.154084</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.791601</td>\n",
       "      <td>0.714624</td>\n",
       "      <td>0.738520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>1.203931</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.792643</td>\n",
       "      <td>0.691330</td>\n",
       "      <td>0.720892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>1.267773</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.787880</td>\n",
       "      <td>0.683981</td>\n",
       "      <td>0.712789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>1.289950</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.784406</td>\n",
       "      <td>0.709581</td>\n",
       "      <td>0.727767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>1.308882</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.789114</td>\n",
       "      <td>0.716211</td>\n",
       "      <td>0.733966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>1.359456</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.808619</td>\n",
       "      <td>0.722690</td>\n",
       "      <td>0.743013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1.404700</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.810800</td>\n",
       "      <td>0.711127</td>\n",
       "      <td>0.737373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>1.406419</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.791107</td>\n",
       "      <td>0.733814</td>\n",
       "      <td>0.745433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.424053</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.793381</td>\n",
       "      <td>0.727449</td>\n",
       "      <td>0.744694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.415789</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.812378</td>\n",
       "      <td>0.738630</td>\n",
       "      <td>0.757222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>1.426476</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.819784</td>\n",
       "      <td>0.737848</td>\n",
       "      <td>0.758933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 20:31:58,840] Trial 121 finished with value: 0.7589326278735906 and parameters: {'learning_rate': 0.00021059484737596867, 'weight_decay': 0.0, 'warmup_steps': 21}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 122 with params: {'learning_rate': 0.00018250113902552832, 'weight_decay': 0.0, 'warmup_steps': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:26, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.715300</td>\n",
       "      <td>1.111533</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.430717</td>\n",
       "      <td>0.446445</td>\n",
       "      <td>0.423179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.439100</td>\n",
       "      <td>0.981934</td>\n",
       "      <td>0.779102</td>\n",
       "      <td>0.598082</td>\n",
       "      <td>0.543195</td>\n",
       "      <td>0.546038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.179800</td>\n",
       "      <td>1.023135</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.702731</td>\n",
       "      <td>0.630021</td>\n",
       "      <td>0.649546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>1.084520</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.723936</td>\n",
       "      <td>0.647410</td>\n",
       "      <td>0.671568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>1.122177</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.804233</td>\n",
       "      <td>0.715315</td>\n",
       "      <td>0.741202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>1.193614</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.772069</td>\n",
       "      <td>0.670201</td>\n",
       "      <td>0.700748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.026700</td>\n",
       "      <td>1.249801</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.782824</td>\n",
       "      <td>0.692612</td>\n",
       "      <td>0.714339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>1.241840</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.808535</td>\n",
       "      <td>0.733410</td>\n",
       "      <td>0.748841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>1.268911</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.798154</td>\n",
       "      <td>0.711494</td>\n",
       "      <td>0.733313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>1.323109</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.805738</td>\n",
       "      <td>0.714032</td>\n",
       "      <td>0.736368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>1.348821</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.789123</td>\n",
       "      <td>0.731258</td>\n",
       "      <td>0.742596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>1.359429</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.808531</td>\n",
       "      <td>0.741703</td>\n",
       "      <td>0.755418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>1.393152</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.783050</td>\n",
       "      <td>0.722305</td>\n",
       "      <td>0.736176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>1.387917</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.816400</td>\n",
       "      <td>0.726081</td>\n",
       "      <td>0.749084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>1.388520</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.814707</td>\n",
       "      <td>0.730981</td>\n",
       "      <td>0.752357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 20:36:27,434] Trial 122 finished with value: 0.7523571752469066 and parameters: {'learning_rate': 0.00018250113902552832, 'weight_decay': 0.0, 'warmup_steps': 20}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 123 with params: {'learning_rate': 0.00011876356812732051, 'weight_decay': 0.0, 'warmup_steps': 19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:31 < 03:03, 28.67 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.079700</td>\n",
       "      <td>1.314955</td>\n",
       "      <td>0.742438</td>\n",
       "      <td>0.387211</td>\n",
       "      <td>0.393414</td>\n",
       "      <td>0.371505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.715900</td>\n",
       "      <td>1.048954</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.470034</td>\n",
       "      <td>0.472388</td>\n",
       "      <td>0.463097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.358700</td>\n",
       "      <td>0.990562</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.605961</td>\n",
       "      <td>0.546943</td>\n",
       "      <td>0.552123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.202700</td>\n",
       "      <td>1.025412</td>\n",
       "      <td>0.779102</td>\n",
       "      <td>0.645977</td>\n",
       "      <td>0.577241</td>\n",
       "      <td>0.595646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.125400</td>\n",
       "      <td>1.032408</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.683075</td>\n",
       "      <td>0.618528</td>\n",
       "      <td>0.633897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 20:37:59,865] Trial 123 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 124 with params: {'learning_rate': 0.0003830353687624567, 'weight_decay': 0.0, 'warmup_steps': 24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:27, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.187100</td>\n",
       "      <td>1.009573</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.552442</td>\n",
       "      <td>0.531274</td>\n",
       "      <td>0.523628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.166700</td>\n",
       "      <td>1.081845</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.719877</td>\n",
       "      <td>0.648694</td>\n",
       "      <td>0.666361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.061300</td>\n",
       "      <td>1.231619</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.773495</td>\n",
       "      <td>0.737622</td>\n",
       "      <td>0.738406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.032800</td>\n",
       "      <td>1.225840</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.800667</td>\n",
       "      <td>0.714841</td>\n",
       "      <td>0.735379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>1.292222</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.787202</td>\n",
       "      <td>0.727031</td>\n",
       "      <td>0.740053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>1.328178</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.837746</td>\n",
       "      <td>0.723968</td>\n",
       "      <td>0.758859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>1.460276</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.787043</td>\n",
       "      <td>0.725642</td>\n",
       "      <td>0.741170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>1.460432</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.778320</td>\n",
       "      <td>0.717181</td>\n",
       "      <td>0.734010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.543519</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.808021</td>\n",
       "      <td>0.710518</td>\n",
       "      <td>0.740884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.564367</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.789831</td>\n",
       "      <td>0.719152</td>\n",
       "      <td>0.740143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.556342</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.813288</td>\n",
       "      <td>0.706525</td>\n",
       "      <td>0.738611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.553151</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.809107</td>\n",
       "      <td>0.719167</td>\n",
       "      <td>0.747727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.558899</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.797658</td>\n",
       "      <td>0.714574</td>\n",
       "      <td>0.739071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.573906</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.801252</td>\n",
       "      <td>0.712596</td>\n",
       "      <td>0.738795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.577483</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.807142</td>\n",
       "      <td>0.714317</td>\n",
       "      <td>0.741794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 20:42:29,021] Trial 124 finished with value: 0.7417938715066441 and parameters: {'learning_rate': 0.0003830353687624567, 'weight_decay': 0.0, 'warmup_steps': 24}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 125 with params: {'learning_rate': 0.00034992243489958674, 'weight_decay': 0.0, 'warmup_steps': 15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:32 < 03:04, 28.44 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.223800</td>\n",
       "      <td>1.004777</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.533918</td>\n",
       "      <td>0.516155</td>\n",
       "      <td>0.504875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.187200</td>\n",
       "      <td>1.079810</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>0.720376</td>\n",
       "      <td>0.642368</td>\n",
       "      <td>0.660648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.070700</td>\n",
       "      <td>1.130233</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.781201</td>\n",
       "      <td>0.728818</td>\n",
       "      <td>0.738493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>1.246857</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.823274</td>\n",
       "      <td>0.704497</td>\n",
       "      <td>0.737995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>1.287273</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.793744</td>\n",
       "      <td>0.696299</td>\n",
       "      <td>0.722507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 20:44:02,251] Trial 125 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 126 with params: {'learning_rate': 0.00019099471169581992, 'weight_decay': 0.007, 'warmup_steps': 35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:34, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.712400</td>\n",
       "      <td>1.101220</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.417703</td>\n",
       "      <td>0.446482</td>\n",
       "      <td>0.420515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.420700</td>\n",
       "      <td>0.990862</td>\n",
       "      <td>0.779102</td>\n",
       "      <td>0.593859</td>\n",
       "      <td>0.545648</td>\n",
       "      <td>0.551487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.169500</td>\n",
       "      <td>1.036288</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.737056</td>\n",
       "      <td>0.644400</td>\n",
       "      <td>0.669513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.084200</td>\n",
       "      <td>1.090235</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.778909</td>\n",
       "      <td>0.665595</td>\n",
       "      <td>0.702019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.050700</td>\n",
       "      <td>1.139208</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.804486</td>\n",
       "      <td>0.719196</td>\n",
       "      <td>0.742995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>1.206290</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.781071</td>\n",
       "      <td>0.673584</td>\n",
       "      <td>0.704775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>1.237690</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.794905</td>\n",
       "      <td>0.713888</td>\n",
       "      <td>0.734385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>1.248570</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.790371</td>\n",
       "      <td>0.711729</td>\n",
       "      <td>0.728855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>1.280712</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.794425</td>\n",
       "      <td>0.725255</td>\n",
       "      <td>0.743446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>1.362750</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.815190</td>\n",
       "      <td>0.727569</td>\n",
       "      <td>0.748940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>1.369665</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.803545</td>\n",
       "      <td>0.718539</td>\n",
       "      <td>0.737881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>1.388510</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.785847</td>\n",
       "      <td>0.729560</td>\n",
       "      <td>0.741749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>1.410916</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.783253</td>\n",
       "      <td>0.723713</td>\n",
       "      <td>0.738184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1.413734</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.801567</td>\n",
       "      <td>0.722383</td>\n",
       "      <td>0.741251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.419482</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.799308</td>\n",
       "      <td>0.722963</td>\n",
       "      <td>0.741479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 20:48:38,283] Trial 126 finished with value: 0.7414787201603622 and parameters: {'learning_rate': 0.00019099471169581992, 'weight_decay': 0.007, 'warmup_steps': 35}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 127 with params: {'learning_rate': 0.00013712317084921553, 'weight_decay': 0.002, 'warmup_steps': 21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:30 < 03:00, 29.11 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.958500</td>\n",
       "      <td>1.235224</td>\n",
       "      <td>0.744271</td>\n",
       "      <td>0.391510</td>\n",
       "      <td>0.398902</td>\n",
       "      <td>0.379131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.613600</td>\n",
       "      <td>1.018923</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.479713</td>\n",
       "      <td>0.485152</td>\n",
       "      <td>0.475149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.286200</td>\n",
       "      <td>0.988159</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.629696</td>\n",
       "      <td>0.579354</td>\n",
       "      <td>0.585974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.153700</td>\n",
       "      <td>1.036074</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.693557</td>\n",
       "      <td>0.616699</td>\n",
       "      <td>0.639188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.093500</td>\n",
       "      <td>1.050406</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.688578</td>\n",
       "      <td>0.619298</td>\n",
       "      <td>0.636395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 20:50:09,317] Trial 127 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 128 with params: {'learning_rate': 0.00029317115299699333, 'weight_decay': 0.0, 'warmup_steps': 30}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:58 < 01:29, 29.47 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.377200</td>\n",
       "      <td>1.014413</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.473801</td>\n",
       "      <td>0.485412</td>\n",
       "      <td>0.470065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.237100</td>\n",
       "      <td>1.046101</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.739585</td>\n",
       "      <td>0.637117</td>\n",
       "      <td>0.662915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>1.126031</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.748175</td>\n",
       "      <td>0.706604</td>\n",
       "      <td>0.711588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.044300</td>\n",
       "      <td>1.166564</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.824475</td>\n",
       "      <td>0.706529</td>\n",
       "      <td>0.741706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>1.257734</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.799118</td>\n",
       "      <td>0.712133</td>\n",
       "      <td>0.737770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>1.292385</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.779807</td>\n",
       "      <td>0.702296</td>\n",
       "      <td>0.722854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>1.381695</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.779215</td>\n",
       "      <td>0.722862</td>\n",
       "      <td>0.734279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>1.380840</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.792911</td>\n",
       "      <td>0.721456</td>\n",
       "      <td>0.737316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>1.433458</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.794034</td>\n",
       "      <td>0.720123</td>\n",
       "      <td>0.738441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.446218</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.791880</td>\n",
       "      <td>0.714903</td>\n",
       "      <td>0.733758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 20:53:08,350] Trial 128 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 129 with params: {'learning_rate': 0.00028605110574087016, 'weight_decay': 0.002, 'warmup_steps': 23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:32, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.377000</td>\n",
       "      <td>1.015350</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.475582</td>\n",
       "      <td>0.482142</td>\n",
       "      <td>0.464849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.242400</td>\n",
       "      <td>1.042764</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.746782</td>\n",
       "      <td>0.642863</td>\n",
       "      <td>0.669893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.087800</td>\n",
       "      <td>1.103939</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.763245</td>\n",
       "      <td>0.690830</td>\n",
       "      <td>0.706867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>1.170905</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.817256</td>\n",
       "      <td>0.711010</td>\n",
       "      <td>0.743336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>1.234377</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.799015</td>\n",
       "      <td>0.715497</td>\n",
       "      <td>0.738176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.263358</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.810751</td>\n",
       "      <td>0.728790</td>\n",
       "      <td>0.749373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>1.370972</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.776783</td>\n",
       "      <td>0.699584</td>\n",
       "      <td>0.716272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>1.371852</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.768706</td>\n",
       "      <td>0.720358</td>\n",
       "      <td>0.726720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>1.445267</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.802037</td>\n",
       "      <td>0.710564</td>\n",
       "      <td>0.734818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.443235</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.801252</td>\n",
       "      <td>0.728541</td>\n",
       "      <td>0.744373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>1.473388</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.816928</td>\n",
       "      <td>0.718035</td>\n",
       "      <td>0.744026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>1.432533</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.806601</td>\n",
       "      <td>0.727737</td>\n",
       "      <td>0.747434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.446858</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.801714</td>\n",
       "      <td>0.724980</td>\n",
       "      <td>0.743957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.451470</td>\n",
       "      <td>0.805683</td>\n",
       "      <td>0.821602</td>\n",
       "      <td>0.734024</td>\n",
       "      <td>0.757778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.467077</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.814361</td>\n",
       "      <td>0.728849</td>\n",
       "      <td>0.750491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 20:57:42,145] Trial 129 finished with value: 0.7504907032096793 and parameters: {'learning_rate': 0.00028605110574087016, 'weight_decay': 0.002, 'warmup_steps': 23}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 130 with params: {'learning_rate': 0.00010571983924941356, 'weight_decay': 0.01, 'warmup_steps': 36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 03:02 < 01:31, 28.73 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.215300</td>\n",
       "      <td>1.397910</td>\n",
       "      <td>0.731439</td>\n",
       "      <td>0.364706</td>\n",
       "      <td>0.372166</td>\n",
       "      <td>0.350219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.815200</td>\n",
       "      <td>1.078390</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.427667</td>\n",
       "      <td>0.456090</td>\n",
       "      <td>0.434607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>1.002864</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.472830</td>\n",
       "      <td>0.495929</td>\n",
       "      <td>0.479447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.255800</td>\n",
       "      <td>1.013784</td>\n",
       "      <td>0.778185</td>\n",
       "      <td>0.607845</td>\n",
       "      <td>0.546774</td>\n",
       "      <td>0.556726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>1.019009</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.681802</td>\n",
       "      <td>0.615357</td>\n",
       "      <td>0.631274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.110400</td>\n",
       "      <td>1.058596</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.691344</td>\n",
       "      <td>0.605460</td>\n",
       "      <td>0.628322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.077900</td>\n",
       "      <td>1.079119</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.716831</td>\n",
       "      <td>0.640164</td>\n",
       "      <td>0.659149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.060400</td>\n",
       "      <td>1.100953</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.804490</td>\n",
       "      <td>0.704333</td>\n",
       "      <td>0.729594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>1.140247</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.796206</td>\n",
       "      <td>0.690392</td>\n",
       "      <td>0.719902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>1.182472</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.792793</td>\n",
       "      <td>0.704462</td>\n",
       "      <td>0.724910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 21:00:45,805] Trial 130 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 131 with params: {'learning_rate': 0.000186818886898241, 'weight_decay': 0.0, 'warmup_steps': 22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:32, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.700900</td>\n",
       "      <td>1.102498</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.423792</td>\n",
       "      <td>0.447951</td>\n",
       "      <td>0.424231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.426900</td>\n",
       "      <td>0.977954</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.601072</td>\n",
       "      <td>0.550050</td>\n",
       "      <td>0.553851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.172800</td>\n",
       "      <td>1.025464</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.704562</td>\n",
       "      <td>0.631955</td>\n",
       "      <td>0.650776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>1.085198</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.762140</td>\n",
       "      <td>0.651706</td>\n",
       "      <td>0.685160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.052400</td>\n",
       "      <td>1.125716</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.802491</td>\n",
       "      <td>0.717242</td>\n",
       "      <td>0.741668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>1.195038</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.810518</td>\n",
       "      <td>0.692821</td>\n",
       "      <td>0.726487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>1.256318</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.799341</td>\n",
       "      <td>0.688946</td>\n",
       "      <td>0.718798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>1.239148</td>\n",
       "      <td>0.805683</td>\n",
       "      <td>0.814548</td>\n",
       "      <td>0.734799</td>\n",
       "      <td>0.752445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>1.265257</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.789323</td>\n",
       "      <td>0.709664</td>\n",
       "      <td>0.729317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>1.330151</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.812916</td>\n",
       "      <td>0.725603</td>\n",
       "      <td>0.745206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>1.351635</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.797939</td>\n",
       "      <td>0.738375</td>\n",
       "      <td>0.750270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>1.359861</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.803801</td>\n",
       "      <td>0.747270</td>\n",
       "      <td>0.758759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>1.398296</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.782090</td>\n",
       "      <td>0.722954</td>\n",
       "      <td>0.737609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.387611</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.819002</td>\n",
       "      <td>0.726951</td>\n",
       "      <td>0.750712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1.390452</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.819864</td>\n",
       "      <td>0.736604</td>\n",
       "      <td>0.756811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 21:05:19,567] Trial 131 finished with value: 0.756810667448188 and parameters: {'learning_rate': 0.000186818886898241, 'weight_decay': 0.0, 'warmup_steps': 22}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 132 with params: {'learning_rate': 0.00012236202286405423, 'weight_decay': 0.0, 'warmup_steps': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 03:02 < 01:31, 28.79 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.024500</td>\n",
       "      <td>1.293612</td>\n",
       "      <td>0.742438</td>\n",
       "      <td>0.381322</td>\n",
       "      <td>0.393030</td>\n",
       "      <td>0.370708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.689200</td>\n",
       "      <td>1.037555</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.484512</td>\n",
       "      <td>0.482670</td>\n",
       "      <td>0.474831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.340800</td>\n",
       "      <td>0.990782</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.598950</td>\n",
       "      <td>0.560212</td>\n",
       "      <td>0.560492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.190300</td>\n",
       "      <td>1.030706</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.645515</td>\n",
       "      <td>0.578380</td>\n",
       "      <td>0.596411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.117000</td>\n",
       "      <td>1.035384</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.686120</td>\n",
       "      <td>0.618809</td>\n",
       "      <td>0.634593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.079400</td>\n",
       "      <td>1.096472</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.724871</td>\n",
       "      <td>0.633690</td>\n",
       "      <td>0.656328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.056300</td>\n",
       "      <td>1.131468</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.770820</td>\n",
       "      <td>0.671136</td>\n",
       "      <td>0.695424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.043400</td>\n",
       "      <td>1.149211</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.801149</td>\n",
       "      <td>0.716450</td>\n",
       "      <td>0.734763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.035600</td>\n",
       "      <td>1.180332</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.786725</td>\n",
       "      <td>0.699821</td>\n",
       "      <td>0.722111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>1.234927</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.782288</td>\n",
       "      <td>0.706092</td>\n",
       "      <td>0.720978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 21:08:22,840] Trial 132 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 133 with params: {'learning_rate': 0.0001583018986052076, 'weight_decay': 0.0, 'warmup_steps': 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:31 < 03:02, 28.78 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.829100</td>\n",
       "      <td>1.164547</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.423509</td>\n",
       "      <td>0.438298</td>\n",
       "      <td>0.418641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.519700</td>\n",
       "      <td>0.992997</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.533608</td>\n",
       "      <td>0.515234</td>\n",
       "      <td>0.510121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.226500</td>\n",
       "      <td>0.995240</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.645586</td>\n",
       "      <td>0.597742</td>\n",
       "      <td>0.605889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.118100</td>\n",
       "      <td>1.056115</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.705994</td>\n",
       "      <td>0.621350</td>\n",
       "      <td>0.647905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>1.086919</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.754338</td>\n",
       "      <td>0.681763</td>\n",
       "      <td>0.700686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 21:09:55,201] Trial 133 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 134 with params: {'learning_rate': 0.000246707626667932, 'weight_decay': 0.0, 'warmup_steps': 24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:43, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>1.036367</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.439455</td>\n",
       "      <td>0.468368</td>\n",
       "      <td>0.444451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.297500</td>\n",
       "      <td>1.013068</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>0.663563</td>\n",
       "      <td>0.605819</td>\n",
       "      <td>0.616526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.109900</td>\n",
       "      <td>1.082511</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.745890</td>\n",
       "      <td>0.665371</td>\n",
       "      <td>0.685581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>1.127784</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.822620</td>\n",
       "      <td>0.709242</td>\n",
       "      <td>0.743470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>1.181495</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.793929</td>\n",
       "      <td>0.717006</td>\n",
       "      <td>0.739665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>1.250523</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.815299</td>\n",
       "      <td>0.707647</td>\n",
       "      <td>0.739656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>1.328836</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.790153</td>\n",
       "      <td>0.682584</td>\n",
       "      <td>0.713398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>1.320774</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.794791</td>\n",
       "      <td>0.735505</td>\n",
       "      <td>0.748008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>1.347179</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.799321</td>\n",
       "      <td>0.715623</td>\n",
       "      <td>0.737558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>1.401607</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.817185</td>\n",
       "      <td>0.718764</td>\n",
       "      <td>0.746535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.422555</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.811447</td>\n",
       "      <td>0.733622</td>\n",
       "      <td>0.754861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>1.405604</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.800020</td>\n",
       "      <td>0.733122</td>\n",
       "      <td>0.748207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.441260</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.794282</td>\n",
       "      <td>0.725553</td>\n",
       "      <td>0.743519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.433373</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.811150</td>\n",
       "      <td>0.720246</td>\n",
       "      <td>0.743975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.442788</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.819109</td>\n",
       "      <td>0.718419</td>\n",
       "      <td>0.745797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 21:14:40,092] Trial 134 finished with value: 0.7457965746717565 and parameters: {'learning_rate': 0.000246707626667932, 'weight_decay': 0.0, 'warmup_steps': 24}. Best is trial 43 with value: 0.7614573567738171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 135 with params: {'learning_rate': 8.338465745809332e-05, 'weight_decay': 0.006, 'warmup_steps': 23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:28 < 02:57, 29.59 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.397400</td>\n",
       "      <td>1.580758</td>\n",
       "      <td>0.696609</td>\n",
       "      <td>0.334820</td>\n",
       "      <td>0.325545</td>\n",
       "      <td>0.309035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.017400</td>\n",
       "      <td>1.142907</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.448130</td>\n",
       "      <td>0.443655</td>\n",
       "      <td>0.429263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.581000</td>\n",
       "      <td>1.042020</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.467776</td>\n",
       "      <td>0.483718</td>\n",
       "      <td>0.469975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.375100</td>\n",
       "      <td>1.001436</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.539532</td>\n",
       "      <td>0.507827</td>\n",
       "      <td>0.503649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.990145</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.623104</td>\n",
       "      <td>0.572780</td>\n",
       "      <td>0.583887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 21:16:09,714] Trial 135 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 136 with params: {'learning_rate': 0.00017198531425921562, 'weight_decay': 0.0, 'warmup_steps': 25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2282' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2282/7875 01:17 < 03:10, 29.37 it/s, Epoch 4.34/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.775700</td>\n",
       "      <td>1.131487</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.413033</td>\n",
       "      <td>0.442284</td>\n",
       "      <td>0.417473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.474400</td>\n",
       "      <td>0.986329</td>\n",
       "      <td>0.778185</td>\n",
       "      <td>0.595577</td>\n",
       "      <td>0.541703</td>\n",
       "      <td>0.545274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.199500</td>\n",
       "      <td>1.004754</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.690234</td>\n",
       "      <td>0.623200</td>\n",
       "      <td>0.637726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.101800</td>\n",
       "      <td>1.068647</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.721785</td>\n",
       "      <td>0.632165</td>\n",
       "      <td>0.659724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-03-26 21:17:28,414] Trial 136 failed with parameters: {'learning_rate': 0.00017198531425921562, 'weight_decay': 0.0, 'warmup_steps': 25} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/transformers/integrations/integration_utils.py\", line 250, in _objective\n",
      "    trainer.train(resume_from_checkpoint=checkpoint, trial=trial)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2241, in train\n",
      "    return inner_training_loop(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2553, in _inner_training_loop\n",
      "    and (torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step))\n",
      "KeyboardInterrupt\n",
      "[W 2025-03-26 21:17:28,416] Trial 136 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_trial3 \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparameter_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptuna\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhp_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhp_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_objective\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_f1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpruner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpruner\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTest-base-aug\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3588\u001b[0m, in \u001b[0;36mTrainer.hyperparameter_search\u001b[0;34m(self, hp_space, compute_objective, n_trials, direction, backend, hp_name, **kwargs)\u001b[0m\n\u001b[1;32m   3585\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhp_name \u001b[38;5;241m=\u001b[39m hp_name\n\u001b[1;32m   3586\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_objective \u001b[38;5;241m=\u001b[39m default_compute_objective \u001b[38;5;28;01mif\u001b[39;00m compute_objective \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m compute_objective\n\u001b[0;32m-> 3588\u001b[0m best_run \u001b[38;5;241m=\u001b[39m \u001b[43mbackend_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3590\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhp_search_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_run\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/hyperparameter_search.py:72\u001b[0m, in \u001b[0;36mOptunaBackend.run\u001b[0;34m(self, trainer, n_trials, direction, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer, n_trials: \u001b[38;5;28mint\u001b[39m, direction: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_hp_search_optuna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/integrations/integration_utils.py:268\u001b[0m, in \u001b[0;36mrun_hp_search_optuna\u001b[0;34m(trainer, n_trials, direction, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m direction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m directions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m direction\n\u001b[1;32m    267\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39mdirection, directions\u001b[38;5;241m=\u001b[39mdirections, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 268\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_objective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m study\u001b[38;5;241m.\u001b[39m_is_multi_objective():\n\u001b[1;32m    270\u001b[0m     best_trial \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_trial\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/integrations/integration_utils.py:250\u001b[0m, in \u001b[0;36mrun_hp_search_optuna.<locals>._objective\u001b[0;34m(trial, checkpoint_dir)\u001b[0m\n\u001b[1;32m    248\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mtrain(resume_from_checkpoint\u001b[38;5;241m=\u001b[39mcheckpoint, trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 250\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# If there hasn't been any evaluation during the training loop.\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2553\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2547\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2548\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2551\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2552\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2553\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2554\u001b[0m ):\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2556\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2557\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_trial_normal_aug = trainer.hyperparameter_search(\n",
    "    direction=\"maximize\",\n",
    "    backend=\"optuna\",\n",
    "    hp_space=hp_space,\n",
    "    compute_objective=lambda metrics: metrics[\"eval_f1\"],\n",
    "    pruner=pruner,\n",
    "    sampler=sampler,\n",
    "    study_name=\"Test-base-aug\",\n",
    "    n_trials=150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a68e47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_trial_normal_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60102d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2204bfa",
   "metadata": {},
   "source": [
    "## Prohledávání s destilací nad augmentovaným datasetem\n",
    "Konfigurace jednotlivých tréninků."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "799ac624",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bert-distill-aug_fine_hp-search\", logging_dir=f\"~/logs/{DATASET}/bert-distill-aug_fine_hp-search\", remove_unused_columns=False, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e627c20",
   "metadata": {},
   "source": [
    "Definice hledaných hyperparametrů a jejich rozmezí, rozšířeno o hyperparametry destilace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca79d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_space(trial):\n",
    "    params =  {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 5e-4, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0, 1e-2, step=1e-3),\n",
    "        \"warmup_steps\" : trial.suggest_int(\"warmup_steps\", 0, warm_up),\n",
    "        \"lambda_param\": trial.suggest_float(\"lambda_param\",0,1,step=.1),\n",
    "        \"temperature\": trial.suggest_float(\"temperature\", 2,7, step=.5)\n",
    "    }\n",
    "    print(f\"Trial {trial.number} with params: {params}\")\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5d1296",
   "metadata": {},
   "source": [
    "Konfigurace Optuny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4c11b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pruner = optuna.pruners.HyperbandPruner(min_resource=min_r, max_resource=max_r, reduction_factor=2, bootstrap_count=2)\n",
    "sampler = optuna.samplers.TPESampler(seed=42, multivariate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287c4047",
   "metadata": {},
   "source": [
    "Konfigurace destilačního trenéra pro jednotlivé tréninky. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b353692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer = base.DistilTrainer(\n",
    "    args=training_args,\n",
    "    train_dataset=train_aug,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    model_init = lambda: get_Bert()\n",
    ")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8278b9bf",
   "metadata": {},
   "source": [
    "Nastavení prohledávání."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f6e26f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 21:17:39,670] A new study created in memory with name: Test-Distill-aug\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 with params: {'learning_rate': 4.3284502212938785e-05, 'weight_decay': 0.01, 'warmup_steps': 39, 'lambda_param': 0.6000000000000001, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:33 < 03:06, 28.18 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.867200</td>\n",
       "      <td>1.424818</td>\n",
       "      <td>0.568286</td>\n",
       "      <td>0.233504</td>\n",
       "      <td>0.194461</td>\n",
       "      <td>0.180431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.113900</td>\n",
       "      <td>1.006380</td>\n",
       "      <td>0.703941</td>\n",
       "      <td>0.327727</td>\n",
       "      <td>0.310110</td>\n",
       "      <td>0.289055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.770400</td>\n",
       "      <td>0.844506</td>\n",
       "      <td>0.725940</td>\n",
       "      <td>0.329570</td>\n",
       "      <td>0.344225</td>\n",
       "      <td>0.319838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.591900</td>\n",
       "      <td>0.769759</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.409864</td>\n",
       "      <td>0.395760</td>\n",
       "      <td>0.382859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.483900</td>\n",
       "      <td>0.725176</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.467335</td>\n",
       "      <td>0.429483</td>\n",
       "      <td>0.422567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 21:19:14,028] Trial 0 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 with params: {'learning_rate': 1.8408992080552506e-05, 'weight_decay': 0.0, 'warmup_steps': 46, 'lambda_param': 0.6000000000000001, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 03:07 < 01:33, 27.93 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.155300</td>\n",
       "      <td>1.886796</td>\n",
       "      <td>0.433547</td>\n",
       "      <td>0.111172</td>\n",
       "      <td>0.107404</td>\n",
       "      <td>0.091547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.676100</td>\n",
       "      <td>1.524248</td>\n",
       "      <td>0.534372</td>\n",
       "      <td>0.185234</td>\n",
       "      <td>0.164608</td>\n",
       "      <td>0.144515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.358700</td>\n",
       "      <td>1.292609</td>\n",
       "      <td>0.611366</td>\n",
       "      <td>0.276662</td>\n",
       "      <td>0.232775</td>\n",
       "      <td>0.220938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.140900</td>\n",
       "      <td>1.132281</td>\n",
       "      <td>0.677360</td>\n",
       "      <td>0.271022</td>\n",
       "      <td>0.282613</td>\n",
       "      <td>0.263858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.982000</td>\n",
       "      <td>1.021030</td>\n",
       "      <td>0.687443</td>\n",
       "      <td>0.256528</td>\n",
       "      <td>0.289775</td>\n",
       "      <td>0.263951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.869800</td>\n",
       "      <td>0.946549</td>\n",
       "      <td>0.708524</td>\n",
       "      <td>0.305590</td>\n",
       "      <td>0.314129</td>\n",
       "      <td>0.293213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.783300</td>\n",
       "      <td>0.893389</td>\n",
       "      <td>0.716774</td>\n",
       "      <td>0.319496</td>\n",
       "      <td>0.324012</td>\n",
       "      <td>0.299977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.722700</td>\n",
       "      <td>0.857051</td>\n",
       "      <td>0.724106</td>\n",
       "      <td>0.325415</td>\n",
       "      <td>0.336216</td>\n",
       "      <td>0.312990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.674900</td>\n",
       "      <td>0.830223</td>\n",
       "      <td>0.726856</td>\n",
       "      <td>0.327737</td>\n",
       "      <td>0.341308</td>\n",
       "      <td>0.317423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.635700</td>\n",
       "      <td>0.812256</td>\n",
       "      <td>0.730522</td>\n",
       "      <td>0.357735</td>\n",
       "      <td>0.352436</td>\n",
       "      <td>0.332309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 21:22:22,935] Trial 1 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 with params: {'learning_rate': 1.0838581269344744e-05, 'weight_decay': 0.01, 'warmup_steps': 44, 'lambda_param': 0.2, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:32 < 03:06, 28.22 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.261500</td>\n",
       "      <td>2.079233</td>\n",
       "      <td>0.346471</td>\n",
       "      <td>0.070799</td>\n",
       "      <td>0.072089</td>\n",
       "      <td>0.050804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.938200</td>\n",
       "      <td>1.815149</td>\n",
       "      <td>0.460128</td>\n",
       "      <td>0.107051</td>\n",
       "      <td>0.122784</td>\n",
       "      <td>0.104818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.697600</td>\n",
       "      <td>1.617504</td>\n",
       "      <td>0.502291</td>\n",
       "      <td>0.138476</td>\n",
       "      <td>0.147729</td>\n",
       "      <td>0.124519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.513300</td>\n",
       "      <td>1.468852</td>\n",
       "      <td>0.546288</td>\n",
       "      <td>0.225718</td>\n",
       "      <td>0.173858</td>\n",
       "      <td>0.155669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.366700</td>\n",
       "      <td>1.354156</td>\n",
       "      <td>0.588451</td>\n",
       "      <td>0.249750</td>\n",
       "      <td>0.211437</td>\n",
       "      <td>0.196148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 21:23:56,917] Trial 2 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 with params: {'learning_rate': 2.049268011541735e-05, 'weight_decay': 0.003, 'warmup_steps': 28, 'lambda_param': 0.4, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 03:00 < 01:30, 29.00 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.119500</td>\n",
       "      <td>1.833186</td>\n",
       "      <td>0.455545</td>\n",
       "      <td>0.107661</td>\n",
       "      <td>0.118924</td>\n",
       "      <td>0.100757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.609200</td>\n",
       "      <td>1.457748</td>\n",
       "      <td>0.558203</td>\n",
       "      <td>0.214635</td>\n",
       "      <td>0.182249</td>\n",
       "      <td>0.164731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.282000</td>\n",
       "      <td>1.223375</td>\n",
       "      <td>0.647113</td>\n",
       "      <td>0.271988</td>\n",
       "      <td>0.260727</td>\n",
       "      <td>0.247697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.062500</td>\n",
       "      <td>1.067356</td>\n",
       "      <td>0.682860</td>\n",
       "      <td>0.257785</td>\n",
       "      <td>0.284352</td>\n",
       "      <td>0.260410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.906700</td>\n",
       "      <td>0.964824</td>\n",
       "      <td>0.703025</td>\n",
       "      <td>0.288267</td>\n",
       "      <td>0.306032</td>\n",
       "      <td>0.281832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.799200</td>\n",
       "      <td>0.898095</td>\n",
       "      <td>0.717690</td>\n",
       "      <td>0.314864</td>\n",
       "      <td>0.326693</td>\n",
       "      <td>0.304450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.716500</td>\n",
       "      <td>0.851239</td>\n",
       "      <td>0.725023</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>0.339074</td>\n",
       "      <td>0.316077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.819497</td>\n",
       "      <td>0.728689</td>\n",
       "      <td>0.346056</td>\n",
       "      <td>0.348640</td>\n",
       "      <td>0.328033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.615200</td>\n",
       "      <td>0.797187</td>\n",
       "      <td>0.730522</td>\n",
       "      <td>0.353584</td>\n",
       "      <td>0.356958</td>\n",
       "      <td>0.337361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.578200</td>\n",
       "      <td>0.782196</td>\n",
       "      <td>0.740605</td>\n",
       "      <td>0.389777</td>\n",
       "      <td>0.377902</td>\n",
       "      <td>0.361128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 21:26:58,809] Trial 3 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 with params: {'learning_rate': 0.00010952662748632558, 'weight_decay': 0.001, 'warmup_steps': 15, 'lambda_param': 0.4, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 03:01 < 01:31, 28.84 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.379400</td>\n",
       "      <td>0.898934</td>\n",
       "      <td>0.720440</td>\n",
       "      <td>0.331071</td>\n",
       "      <td>0.329918</td>\n",
       "      <td>0.305141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.555900</td>\n",
       "      <td>0.720243</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.474910</td>\n",
       "      <td>0.446025</td>\n",
       "      <td>0.439547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.335800</td>\n",
       "      <td>0.662921</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.556938</td>\n",
       "      <td>0.512069</td>\n",
       "      <td>0.510193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.230100</td>\n",
       "      <td>0.649787</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.635974</td>\n",
       "      <td>0.555602</td>\n",
       "      <td>0.573167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.174700</td>\n",
       "      <td>0.645456</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.667146</td>\n",
       "      <td>0.615607</td>\n",
       "      <td>0.624179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.144600</td>\n",
       "      <td>0.638353</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.706646</td>\n",
       "      <td>0.627185</td>\n",
       "      <td>0.648862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.126400</td>\n",
       "      <td>0.638341</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.731939</td>\n",
       "      <td>0.640181</td>\n",
       "      <td>0.664322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.115100</td>\n",
       "      <td>0.638088</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.729741</td>\n",
       "      <td>0.651220</td>\n",
       "      <td>0.671329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.106900</td>\n",
       "      <td>0.642829</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.771110</td>\n",
       "      <td>0.672112</td>\n",
       "      <td>0.700855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.100500</td>\n",
       "      <td>0.654328</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.753872</td>\n",
       "      <td>0.673648</td>\n",
       "      <td>0.695856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 21:30:01,814] Trial 4 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 with params: {'learning_rate': 0.0002157696745589684, 'weight_decay': 0.002, 'warmup_steps': 27, 'lambda_param': 0.6000000000000001, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:40, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.052300</td>\n",
       "      <td>0.725032</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.429626</td>\n",
       "      <td>0.425340</td>\n",
       "      <td>0.411861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.305400</td>\n",
       "      <td>0.643991</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.609284</td>\n",
       "      <td>0.567188</td>\n",
       "      <td>0.574325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.167200</td>\n",
       "      <td>0.649918</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.696634</td>\n",
       "      <td>0.629973</td>\n",
       "      <td>0.645928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.120800</td>\n",
       "      <td>0.662573</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.752054</td>\n",
       "      <td>0.634963</td>\n",
       "      <td>0.670027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.101600</td>\n",
       "      <td>0.657606</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.765290</td>\n",
       "      <td>0.674646</td>\n",
       "      <td>0.700381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.091100</td>\n",
       "      <td>0.649584</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.770861</td>\n",
       "      <td>0.668097</td>\n",
       "      <td>0.699744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.665144</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.809048</td>\n",
       "      <td>0.707134</td>\n",
       "      <td>0.738059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.080600</td>\n",
       "      <td>0.661790</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.806990</td>\n",
       "      <td>0.716651</td>\n",
       "      <td>0.742393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.077400</td>\n",
       "      <td>0.665049</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.806166</td>\n",
       "      <td>0.720945</td>\n",
       "      <td>0.745294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.673218</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.808677</td>\n",
       "      <td>0.724367</td>\n",
       "      <td>0.747917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.073200</td>\n",
       "      <td>0.666878</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.799069</td>\n",
       "      <td>0.724371</td>\n",
       "      <td>0.745990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.668472</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.804144</td>\n",
       "      <td>0.726082</td>\n",
       "      <td>0.749069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.070700</td>\n",
       "      <td>0.664849</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.807615</td>\n",
       "      <td>0.722407</td>\n",
       "      <td>0.746491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.661147</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.817229</td>\n",
       "      <td>0.728709</td>\n",
       "      <td>0.755069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.069700</td>\n",
       "      <td>0.662531</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.819438</td>\n",
       "      <td>0.727655</td>\n",
       "      <td>0.754941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 21:34:43,816] Trial 5 finished with value: 0.7549412251809023 and parameters: {'learning_rate': 0.0002157696745589684, 'weight_decay': 0.002, 'warmup_steps': 27, 'lambda_param': 0.6000000000000001, 'temperature': 2.0}. Best is trial 5 with value: 0.7549412251809023.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 with params: {'learning_rate': 0.00010769622478263136, 'weight_decay': 0.001, 'warmup_steps': 3, 'lambda_param': 1.0, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 03:02 < 01:31, 28.80 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.371100</td>\n",
       "      <td>0.899925</td>\n",
       "      <td>0.717690</td>\n",
       "      <td>0.323206</td>\n",
       "      <td>0.325772</td>\n",
       "      <td>0.299958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.560300</td>\n",
       "      <td>0.723385</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.449081</td>\n",
       "      <td>0.437775</td>\n",
       "      <td>0.427450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.339400</td>\n",
       "      <td>0.668963</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.510455</td>\n",
       "      <td>0.500577</td>\n",
       "      <td>0.492147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.233600</td>\n",
       "      <td>0.652519</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.640527</td>\n",
       "      <td>0.551436</td>\n",
       "      <td>0.573084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.178100</td>\n",
       "      <td>0.646480</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.666451</td>\n",
       "      <td>0.614243</td>\n",
       "      <td>0.622952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.147300</td>\n",
       "      <td>0.642453</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.697238</td>\n",
       "      <td>0.626364</td>\n",
       "      <td>0.645427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.128200</td>\n",
       "      <td>0.637582</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.691093</td>\n",
       "      <td>0.631636</td>\n",
       "      <td>0.647149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.116500</td>\n",
       "      <td>0.635386</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.720272</td>\n",
       "      <td>0.653018</td>\n",
       "      <td>0.669684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.108100</td>\n",
       "      <td>0.646516</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.727004</td>\n",
       "      <td>0.652117</td>\n",
       "      <td>0.671890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.101300</td>\n",
       "      <td>0.652863</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.723398</td>\n",
       "      <td>0.655973</td>\n",
       "      <td>0.672694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 21:37:47,279] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 with params: {'learning_rate': 0.000236288641842364, 'weight_decay': 0.003, 'warmup_steps': 5, 'lambda_param': 0.7000000000000001, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:38, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.975200</td>\n",
       "      <td>0.715762</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.444790</td>\n",
       "      <td>0.444696</td>\n",
       "      <td>0.431947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.276300</td>\n",
       "      <td>0.649771</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.603783</td>\n",
       "      <td>0.576167</td>\n",
       "      <td>0.578968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.154700</td>\n",
       "      <td>0.654674</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.688429</td>\n",
       "      <td>0.631922</td>\n",
       "      <td>0.647301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.114100</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.750861</td>\n",
       "      <td>0.630670</td>\n",
       "      <td>0.667248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>0.660894</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.740629</td>\n",
       "      <td>0.684009</td>\n",
       "      <td>0.698154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.087700</td>\n",
       "      <td>0.653076</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.784906</td>\n",
       "      <td>0.703466</td>\n",
       "      <td>0.728963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.081800</td>\n",
       "      <td>0.657942</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.805487</td>\n",
       "      <td>0.719958</td>\n",
       "      <td>0.746528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.078700</td>\n",
       "      <td>0.663643</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.813434</td>\n",
       "      <td>0.714118</td>\n",
       "      <td>0.743161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.661124</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.808726</td>\n",
       "      <td>0.721465</td>\n",
       "      <td>0.747188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.072900</td>\n",
       "      <td>0.676176</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.812715</td>\n",
       "      <td>0.719091</td>\n",
       "      <td>0.748202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.672756</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.791608</td>\n",
       "      <td>0.721729</td>\n",
       "      <td>0.743092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.070600</td>\n",
       "      <td>0.668679</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.809385</td>\n",
       "      <td>0.722712</td>\n",
       "      <td>0.748120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.069500</td>\n",
       "      <td>0.668232</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.792558</td>\n",
       "      <td>0.712147</td>\n",
       "      <td>0.738070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.667737</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.799772</td>\n",
       "      <td>0.720696</td>\n",
       "      <td>0.746443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.666170</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.808298</td>\n",
       "      <td>0.722917</td>\n",
       "      <td>0.749288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 21:42:27,862] Trial 7 finished with value: 0.7492883805070879 and parameters: {'learning_rate': 0.000236288641842364, 'weight_decay': 0.003, 'warmup_steps': 5, 'lambda_param': 0.7000000000000001, 'temperature': 4.0}. Best is trial 5 with value: 0.7549412251809023.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 with params: {'learning_rate': 1.6119044727609182e-05, 'weight_decay': 0.005, 'warmup_steps': 1, 'lambda_param': 1.0, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 03:01 < 01:31, 28.84 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.168100</td>\n",
       "      <td>1.930833</td>\n",
       "      <td>0.416132</td>\n",
       "      <td>0.097131</td>\n",
       "      <td>0.096793</td>\n",
       "      <td>0.080935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.740600</td>\n",
       "      <td>1.595704</td>\n",
       "      <td>0.511457</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.152533</td>\n",
       "      <td>0.130495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.444000</td>\n",
       "      <td>1.373219</td>\n",
       "      <td>0.584785</td>\n",
       "      <td>0.229412</td>\n",
       "      <td>0.210122</td>\n",
       "      <td>0.193738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.234500</td>\n",
       "      <td>1.214399</td>\n",
       "      <td>0.652612</td>\n",
       "      <td>0.279950</td>\n",
       "      <td>0.259541</td>\n",
       "      <td>0.246907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.076800</td>\n",
       "      <td>1.097992</td>\n",
       "      <td>0.677360</td>\n",
       "      <td>0.254510</td>\n",
       "      <td>0.280483</td>\n",
       "      <td>0.257643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.961600</td>\n",
       "      <td>1.014810</td>\n",
       "      <td>0.690192</td>\n",
       "      <td>0.276179</td>\n",
       "      <td>0.291802</td>\n",
       "      <td>0.266993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.871500</td>\n",
       "      <td>0.954319</td>\n",
       "      <td>0.710357</td>\n",
       "      <td>0.313156</td>\n",
       "      <td>0.310820</td>\n",
       "      <td>0.288659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.806700</td>\n",
       "      <td>0.912523</td>\n",
       "      <td>0.713107</td>\n",
       "      <td>0.323665</td>\n",
       "      <td>0.320588</td>\n",
       "      <td>0.296829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.755700</td>\n",
       "      <td>0.880194</td>\n",
       "      <td>0.717690</td>\n",
       "      <td>0.316843</td>\n",
       "      <td>0.324989</td>\n",
       "      <td>0.301288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.714200</td>\n",
       "      <td>0.858133</td>\n",
       "      <td>0.723190</td>\n",
       "      <td>0.323863</td>\n",
       "      <td>0.334697</td>\n",
       "      <td>0.311005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 21:45:31,002] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 with params: {'learning_rate': 0.00013353819088790598, 'weight_decay': 0.003, 'warmup_steps': 28, 'lambda_param': 0.6000000000000001, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:41, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.289000</td>\n",
       "      <td>0.834961</td>\n",
       "      <td>0.732356</td>\n",
       "      <td>0.378500</td>\n",
       "      <td>0.361061</td>\n",
       "      <td>0.342909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.472100</td>\n",
       "      <td>0.688384</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.501207</td>\n",
       "      <td>0.473144</td>\n",
       "      <td>0.472248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.272500</td>\n",
       "      <td>0.651342</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.576381</td>\n",
       "      <td>0.530581</td>\n",
       "      <td>0.534847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.653136</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.673790</td>\n",
       "      <td>0.594159</td>\n",
       "      <td>0.615987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.145200</td>\n",
       "      <td>0.652714</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.685631</td>\n",
       "      <td>0.626076</td>\n",
       "      <td>0.641690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.123200</td>\n",
       "      <td>0.644991</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.727943</td>\n",
       "      <td>0.635756</td>\n",
       "      <td>0.662961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.108700</td>\n",
       "      <td>0.642806</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.744081</td>\n",
       "      <td>0.655631</td>\n",
       "      <td>0.680075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.100300</td>\n",
       "      <td>0.647454</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.737840</td>\n",
       "      <td>0.658040</td>\n",
       "      <td>0.682253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.094200</td>\n",
       "      <td>0.648155</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.787243</td>\n",
       "      <td>0.679687</td>\n",
       "      <td>0.712008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.089300</td>\n",
       "      <td>0.661976</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.780949</td>\n",
       "      <td>0.689758</td>\n",
       "      <td>0.716625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.086800</td>\n",
       "      <td>0.652236</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.780950</td>\n",
       "      <td>0.684393</td>\n",
       "      <td>0.713967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.083900</td>\n",
       "      <td>0.656384</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.789395</td>\n",
       "      <td>0.693112</td>\n",
       "      <td>0.721625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.082500</td>\n",
       "      <td>0.653416</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.772336</td>\n",
       "      <td>0.698993</td>\n",
       "      <td>0.719976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.081100</td>\n",
       "      <td>0.649984</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.771632</td>\n",
       "      <td>0.701002</td>\n",
       "      <td>0.719356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.080700</td>\n",
       "      <td>0.652726</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.782555</td>\n",
       "      <td>0.702431</td>\n",
       "      <td>0.724549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 21:50:13,989] Trial 9 finished with value: 0.7245488761821971 and parameters: {'learning_rate': 0.00013353819088790598, 'weight_decay': 0.003, 'warmup_steps': 28, 'lambda_param': 0.6000000000000001, 'temperature': 3.0}. Best is trial 5 with value: 0.7549412251809023.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 with params: {'learning_rate': 0.0003740714100285732, 'weight_decay': 0.003, 'warmup_steps': 32, 'lambda_param': 0.1, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:26, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.829800</td>\n",
       "      <td>0.674561</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.502379</td>\n",
       "      <td>0.494060</td>\n",
       "      <td>0.489083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.190100</td>\n",
       "      <td>0.666642</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.698037</td>\n",
       "      <td>0.630011</td>\n",
       "      <td>0.641412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.115100</td>\n",
       "      <td>0.652990</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.744329</td>\n",
       "      <td>0.674087</td>\n",
       "      <td>0.692775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.092500</td>\n",
       "      <td>0.668328</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.796945</td>\n",
       "      <td>0.696600</td>\n",
       "      <td>0.725567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.675508</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.808964</td>\n",
       "      <td>0.701099</td>\n",
       "      <td>0.733070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.076500</td>\n",
       "      <td>0.674247</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.804600</td>\n",
       "      <td>0.708220</td>\n",
       "      <td>0.738564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.073100</td>\n",
       "      <td>0.681904</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.809079</td>\n",
       "      <td>0.716277</td>\n",
       "      <td>0.744052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.071400</td>\n",
       "      <td>0.686214</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.789033</td>\n",
       "      <td>0.693392</td>\n",
       "      <td>0.722878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.069600</td>\n",
       "      <td>0.695215</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.794165</td>\n",
       "      <td>0.714599</td>\n",
       "      <td>0.736073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067700</td>\n",
       "      <td>0.694528</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.808100</td>\n",
       "      <td>0.705329</td>\n",
       "      <td>0.734897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.067100</td>\n",
       "      <td>0.677335</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.799111</td>\n",
       "      <td>0.711980</td>\n",
       "      <td>0.735815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.668701</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.799496</td>\n",
       "      <td>0.719941</td>\n",
       "      <td>0.740221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.065300</td>\n",
       "      <td>0.659476</td>\n",
       "      <td>0.804766</td>\n",
       "      <td>0.809423</td>\n",
       "      <td>0.715629</td>\n",
       "      <td>0.742068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.064600</td>\n",
       "      <td>0.666219</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.806580</td>\n",
       "      <td>0.715805</td>\n",
       "      <td>0.740837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.664969</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.809812</td>\n",
       "      <td>0.716719</td>\n",
       "      <td>0.742891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 21:54:41,736] Trial 10 finished with value: 0.7428912800689917 and parameters: {'learning_rate': 0.0003740714100285732, 'weight_decay': 0.003, 'warmup_steps': 32, 'lambda_param': 0.1, 'temperature': 2.0}. Best is trial 5 with value: 0.7549412251809023.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 with params: {'learning_rate': 0.00026589184366630346, 'weight_decay': 0.002, 'warmup_steps': 3, 'lambda_param': 0.6000000000000001, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:25, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.919700</td>\n",
       "      <td>0.702581</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.460778</td>\n",
       "      <td>0.454911</td>\n",
       "      <td>0.440924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.249800</td>\n",
       "      <td>0.641957</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.640488</td>\n",
       "      <td>0.590090</td>\n",
       "      <td>0.601189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.141900</td>\n",
       "      <td>0.650434</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.715019</td>\n",
       "      <td>0.634091</td>\n",
       "      <td>0.657371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.106300</td>\n",
       "      <td>0.658249</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.772746</td>\n",
       "      <td>0.654844</td>\n",
       "      <td>0.690135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.092400</td>\n",
       "      <td>0.652306</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.808792</td>\n",
       "      <td>0.713001</td>\n",
       "      <td>0.743771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.084100</td>\n",
       "      <td>0.649106</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.823599</td>\n",
       "      <td>0.715375</td>\n",
       "      <td>0.752109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.078600</td>\n",
       "      <td>0.672719</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.818406</td>\n",
       "      <td>0.716770</td>\n",
       "      <td>0.749500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.076100</td>\n",
       "      <td>0.663368</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.820350</td>\n",
       "      <td>0.720876</td>\n",
       "      <td>0.753428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.073300</td>\n",
       "      <td>0.670742</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.806162</td>\n",
       "      <td>0.713787</td>\n",
       "      <td>0.739557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>0.677706</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.823857</td>\n",
       "      <td>0.720509</td>\n",
       "      <td>0.753216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>0.674941</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.812231</td>\n",
       "      <td>0.719445</td>\n",
       "      <td>0.748355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.662277</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.796769</td>\n",
       "      <td>0.732340</td>\n",
       "      <td>0.750506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.068200</td>\n",
       "      <td>0.659548</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.801654</td>\n",
       "      <td>0.717085</td>\n",
       "      <td>0.742906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.067400</td>\n",
       "      <td>0.664008</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.811929</td>\n",
       "      <td>0.721334</td>\n",
       "      <td>0.749520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.661881</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.805697</td>\n",
       "      <td>0.720847</td>\n",
       "      <td>0.745821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 21:59:08,734] Trial 11 finished with value: 0.745820604275408 and parameters: {'learning_rate': 0.00026589184366630346, 'weight_decay': 0.002, 'warmup_steps': 3, 'lambda_param': 0.6000000000000001, 'temperature': 3.0}. Best is trial 5 with value: 0.7549412251809023.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 with params: {'learning_rate': 0.0002657573253284101, 'weight_decay': 0.001, 'warmup_steps': 20, 'lambda_param': 1.0, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:23, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.948500</td>\n",
       "      <td>0.707429</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.466409</td>\n",
       "      <td>0.453520</td>\n",
       "      <td>0.440560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.250600</td>\n",
       "      <td>0.642582</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.635446</td>\n",
       "      <td>0.592819</td>\n",
       "      <td>0.599644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>0.655641</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.698247</td>\n",
       "      <td>0.633112</td>\n",
       "      <td>0.650078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.106400</td>\n",
       "      <td>0.661206</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.776469</td>\n",
       "      <td>0.679395</td>\n",
       "      <td>0.709467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.092100</td>\n",
       "      <td>0.667944</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.798910</td>\n",
       "      <td>0.702999</td>\n",
       "      <td>0.733889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.084200</td>\n",
       "      <td>0.659482</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.798785</td>\n",
       "      <td>0.704385</td>\n",
       "      <td>0.735360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.078600</td>\n",
       "      <td>0.663006</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.796789</td>\n",
       "      <td>0.706567</td>\n",
       "      <td>0.732659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.076200</td>\n",
       "      <td>0.661184</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.817124</td>\n",
       "      <td>0.709817</td>\n",
       "      <td>0.740541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.073700</td>\n",
       "      <td>0.670784</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.799635</td>\n",
       "      <td>0.703904</td>\n",
       "      <td>0.731258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>0.681305</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.813515</td>\n",
       "      <td>0.723044</td>\n",
       "      <td>0.749373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.679730</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.810765</td>\n",
       "      <td>0.713087</td>\n",
       "      <td>0.741777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.676722</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.807791</td>\n",
       "      <td>0.725562</td>\n",
       "      <td>0.748643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.068100</td>\n",
       "      <td>0.670650</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.798545</td>\n",
       "      <td>0.710921</td>\n",
       "      <td>0.736999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.067400</td>\n",
       "      <td>0.673165</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.801531</td>\n",
       "      <td>0.707242</td>\n",
       "      <td>0.736242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.067100</td>\n",
       "      <td>0.673802</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.797239</td>\n",
       "      <td>0.709423</td>\n",
       "      <td>0.735292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 22:03:34,272] Trial 12 finished with value: 0.7352923247120513 and parameters: {'learning_rate': 0.0002657573253284101, 'weight_decay': 0.001, 'warmup_steps': 20, 'lambda_param': 1.0, 'temperature': 4.5}. Best is trial 5 with value: 0.7549412251809023.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13 with params: {'learning_rate': 0.000329847374420809, 'weight_decay': 0.008, 'warmup_steps': 23, 'lambda_param': 0.7000000000000001, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:56 < 01:28, 29.77 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.865600</td>\n",
       "      <td>0.694612</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.496184</td>\n",
       "      <td>0.490303</td>\n",
       "      <td>0.482927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.208800</td>\n",
       "      <td>0.659241</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.698650</td>\n",
       "      <td>0.628051</td>\n",
       "      <td>0.640141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.122800</td>\n",
       "      <td>0.662466</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.770017</td>\n",
       "      <td>0.680392</td>\n",
       "      <td>0.705737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>0.660278</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.799012</td>\n",
       "      <td>0.681191</td>\n",
       "      <td>0.716874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.085400</td>\n",
       "      <td>0.668515</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.810635</td>\n",
       "      <td>0.714976</td>\n",
       "      <td>0.745907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>0.681543</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.788807</td>\n",
       "      <td>0.719433</td>\n",
       "      <td>0.741330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.074700</td>\n",
       "      <td>0.684377</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.790349</td>\n",
       "      <td>0.700093</td>\n",
       "      <td>0.726210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.072600</td>\n",
       "      <td>0.692038</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.801522</td>\n",
       "      <td>0.706677</td>\n",
       "      <td>0.734887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.692351</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.812090</td>\n",
       "      <td>0.710353</td>\n",
       "      <td>0.740543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.068700</td>\n",
       "      <td>0.699949</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.800691</td>\n",
       "      <td>0.718612</td>\n",
       "      <td>0.741309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 22:06:31,681] Trial 13 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 with params: {'learning_rate': 0.00038226914326652676, 'weight_decay': 0.0, 'warmup_steps': 41, 'lambda_param': 0.5, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:23, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.836000</td>\n",
       "      <td>0.679528</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.520415</td>\n",
       "      <td>0.496123</td>\n",
       "      <td>0.495901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.187000</td>\n",
       "      <td>0.651844</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.715983</td>\n",
       "      <td>0.637795</td>\n",
       "      <td>0.655297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.114000</td>\n",
       "      <td>0.688554</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.774427</td>\n",
       "      <td>0.688089</td>\n",
       "      <td>0.710344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.092300</td>\n",
       "      <td>0.676134</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.780673</td>\n",
       "      <td>0.698287</td>\n",
       "      <td>0.722060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>0.669607</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.804321</td>\n",
       "      <td>0.687196</td>\n",
       "      <td>0.722628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.076900</td>\n",
       "      <td>0.682974</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.824540</td>\n",
       "      <td>0.723074</td>\n",
       "      <td>0.750084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.073600</td>\n",
       "      <td>0.679375</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.817323</td>\n",
       "      <td>0.699105</td>\n",
       "      <td>0.731374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.691009</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.797973</td>\n",
       "      <td>0.691562</td>\n",
       "      <td>0.720369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.069300</td>\n",
       "      <td>0.688469</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.816652</td>\n",
       "      <td>0.708992</td>\n",
       "      <td>0.737882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067900</td>\n",
       "      <td>0.701010</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.816918</td>\n",
       "      <td>0.717586</td>\n",
       "      <td>0.744788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>0.700439</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.805702</td>\n",
       "      <td>0.701949</td>\n",
       "      <td>0.730742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.065800</td>\n",
       "      <td>0.691199</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.815201</td>\n",
       "      <td>0.716738</td>\n",
       "      <td>0.744516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>0.684541</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.817337</td>\n",
       "      <td>0.727631</td>\n",
       "      <td>0.751488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.064600</td>\n",
       "      <td>0.682529</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.822084</td>\n",
       "      <td>0.722867</td>\n",
       "      <td>0.750902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>0.686706</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.813717</td>\n",
       "      <td>0.721984</td>\n",
       "      <td>0.747455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 22:10:56,728] Trial 14 finished with value: 0.7474553171642878 and parameters: {'learning_rate': 0.00038226914326652676, 'weight_decay': 0.0, 'warmup_steps': 41, 'lambda_param': 0.5, 'temperature': 2.0}. Best is trial 5 with value: 0.7549412251809023.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 with params: {'learning_rate': 4.805219737775734e-05, 'weight_decay': 0.004, 'warmup_steps': 0, 'lambda_param': 0.6000000000000001, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:55 < 01:27, 29.87 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.785900</td>\n",
       "      <td>1.343651</td>\n",
       "      <td>0.601283</td>\n",
       "      <td>0.264645</td>\n",
       "      <td>0.223177</td>\n",
       "      <td>0.211525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.029500</td>\n",
       "      <td>0.948364</td>\n",
       "      <td>0.710357</td>\n",
       "      <td>0.320335</td>\n",
       "      <td>0.317366</td>\n",
       "      <td>0.292277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.703600</td>\n",
       "      <td>0.809216</td>\n",
       "      <td>0.732356</td>\n",
       "      <td>0.384246</td>\n",
       "      <td>0.358505</td>\n",
       "      <td>0.340039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.538200</td>\n",
       "      <td>0.745135</td>\n",
       "      <td>0.754354</td>\n",
       "      <td>0.461153</td>\n",
       "      <td>0.427510</td>\n",
       "      <td>0.419528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.437100</td>\n",
       "      <td>0.706978</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.523105</td>\n",
       "      <td>0.467780</td>\n",
       "      <td>0.462390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.369800</td>\n",
       "      <td>0.689927</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.493623</td>\n",
       "      <td>0.472738</td>\n",
       "      <td>0.467338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.317000</td>\n",
       "      <td>0.669410</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.532157</td>\n",
       "      <td>0.503107</td>\n",
       "      <td>0.501958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.279900</td>\n",
       "      <td>0.657162</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.567180</td>\n",
       "      <td>0.511064</td>\n",
       "      <td>0.514434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.253000</td>\n",
       "      <td>0.655007</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.576221</td>\n",
       "      <td>0.517075</td>\n",
       "      <td>0.519591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.649977</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.576403</td>\n",
       "      <td>0.523613</td>\n",
       "      <td>0.525697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 22:13:53,393] Trial 15 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16 with params: {'learning_rate': 0.00010034827545605993, 'weight_decay': 0.007, 'warmup_steps': 5, 'lambda_param': 0.30000000000000004, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:27 < 02:55, 29.94 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.414000</td>\n",
       "      <td>0.933546</td>\n",
       "      <td>0.712191</td>\n",
       "      <td>0.318662</td>\n",
       "      <td>0.316984</td>\n",
       "      <td>0.294214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.595700</td>\n",
       "      <td>0.733735</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.446690</td>\n",
       "      <td>0.428132</td>\n",
       "      <td>0.418613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.366800</td>\n",
       "      <td>0.668949</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.511980</td>\n",
       "      <td>0.500155</td>\n",
       "      <td>0.494431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.253200</td>\n",
       "      <td>0.651152</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.639858</td>\n",
       "      <td>0.546256</td>\n",
       "      <td>0.565635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.191500</td>\n",
       "      <td>0.643072</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.643855</td>\n",
       "      <td>0.591222</td>\n",
       "      <td>0.601088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 22:15:22,105] Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17 with params: {'learning_rate': 0.00044246075223732244, 'weight_decay': 0.006, 'warmup_steps': 9, 'lambda_param': 0.6000000000000001, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:23, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.736200</td>\n",
       "      <td>0.651002</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.521286</td>\n",
       "      <td>0.528690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.167700</td>\n",
       "      <td>0.668431</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.702076</td>\n",
       "      <td>0.635704</td>\n",
       "      <td>0.650732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.106700</td>\n",
       "      <td>0.666396</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.748153</td>\n",
       "      <td>0.677292</td>\n",
       "      <td>0.696389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.087900</td>\n",
       "      <td>0.661817</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.823196</td>\n",
       "      <td>0.729110</td>\n",
       "      <td>0.757380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.707514</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>0.790483</td>\n",
       "      <td>0.696888</td>\n",
       "      <td>0.721143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.705944</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.812546</td>\n",
       "      <td>0.708048</td>\n",
       "      <td>0.738370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.708032</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.813621</td>\n",
       "      <td>0.712841</td>\n",
       "      <td>0.743934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.695116</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.805551</td>\n",
       "      <td>0.713200</td>\n",
       "      <td>0.741398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068300</td>\n",
       "      <td>0.711574</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.820581</td>\n",
       "      <td>0.716059</td>\n",
       "      <td>0.746186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066900</td>\n",
       "      <td>0.719645</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.805716</td>\n",
       "      <td>0.717903</td>\n",
       "      <td>0.744842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.688294</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.804071</td>\n",
       "      <td>0.726346</td>\n",
       "      <td>0.747994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.065300</td>\n",
       "      <td>0.688389</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.811179</td>\n",
       "      <td>0.732360</td>\n",
       "      <td>0.756411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.064700</td>\n",
       "      <td>0.697267</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.815031</td>\n",
       "      <td>0.723427</td>\n",
       "      <td>0.750591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.063900</td>\n",
       "      <td>0.684687</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.830723</td>\n",
       "      <td>0.718493</td>\n",
       "      <td>0.753938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.063800</td>\n",
       "      <td>0.687859</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.829896</td>\n",
       "      <td>0.728047</td>\n",
       "      <td>0.759327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 22:19:46,980] Trial 17 finished with value: 0.7593272693182541 and parameters: {'learning_rate': 0.00044246075223732244, 'weight_decay': 0.006, 'warmup_steps': 9, 'lambda_param': 0.6000000000000001, 'temperature': 6.0}. Best is trial 17 with value: 0.7593272693182541.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18 with params: {'learning_rate': 0.0003114789869713292, 'weight_decay': 0.005, 'warmup_steps': 10, 'lambda_param': 0.2, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:24, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.867100</td>\n",
       "      <td>0.690117</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.534213</td>\n",
       "      <td>0.507210</td>\n",
       "      <td>0.508347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.218800</td>\n",
       "      <td>0.647092</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.681202</td>\n",
       "      <td>0.607646</td>\n",
       "      <td>0.627089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.127400</td>\n",
       "      <td>0.660736</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.746077</td>\n",
       "      <td>0.674508</td>\n",
       "      <td>0.693828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.098800</td>\n",
       "      <td>0.678635</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.813886</td>\n",
       "      <td>0.701766</td>\n",
       "      <td>0.735175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.087200</td>\n",
       "      <td>0.664142</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.815417</td>\n",
       "      <td>0.705985</td>\n",
       "      <td>0.738267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.658535</td>\n",
       "      <td>0.805683</td>\n",
       "      <td>0.821685</td>\n",
       "      <td>0.726803</td>\n",
       "      <td>0.755879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.674482</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.821178</td>\n",
       "      <td>0.710439</td>\n",
       "      <td>0.748340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.073400</td>\n",
       "      <td>0.663738</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.809551</td>\n",
       "      <td>0.716256</td>\n",
       "      <td>0.743201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.071600</td>\n",
       "      <td>0.685485</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.806681</td>\n",
       "      <td>0.724124</td>\n",
       "      <td>0.747261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.069500</td>\n",
       "      <td>0.677126</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.827924</td>\n",
       "      <td>0.714085</td>\n",
       "      <td>0.749853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.679853</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.796679</td>\n",
       "      <td>0.717902</td>\n",
       "      <td>0.740044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.067400</td>\n",
       "      <td>0.674123</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.810787</td>\n",
       "      <td>0.708944</td>\n",
       "      <td>0.738656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.671579</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.817084</td>\n",
       "      <td>0.719309</td>\n",
       "      <td>0.747466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.672251</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.814321</td>\n",
       "      <td>0.723434</td>\n",
       "      <td>0.751265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.065800</td>\n",
       "      <td>0.672888</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.816538</td>\n",
       "      <td>0.724502</td>\n",
       "      <td>0.752479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 22:24:12,679] Trial 18 finished with value: 0.7524786463434122 and parameters: {'learning_rate': 0.0003114789869713292, 'weight_decay': 0.005, 'warmup_steps': 10, 'lambda_param': 0.2, 'temperature': 6.5}. Best is trial 17 with value: 0.7593272693182541.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 19 with params: {'learning_rate': 0.00018763871193579055, 'weight_decay': 0.006, 'warmup_steps': 9, 'lambda_param': 0.9, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:21, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.093100</td>\n",
       "      <td>0.747857</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.439814</td>\n",
       "      <td>0.419272</td>\n",
       "      <td>0.410522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.346200</td>\n",
       "      <td>0.647800</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.580684</td>\n",
       "      <td>0.532083</td>\n",
       "      <td>0.535614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.191000</td>\n",
       "      <td>0.647088</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.645107</td>\n",
       "      <td>0.593926</td>\n",
       "      <td>0.603840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.134600</td>\n",
       "      <td>0.651783</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.723802</td>\n",
       "      <td>0.624181</td>\n",
       "      <td>0.653998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.110900</td>\n",
       "      <td>0.663951</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.742287</td>\n",
       "      <td>0.653561</td>\n",
       "      <td>0.680354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.097700</td>\n",
       "      <td>0.652682</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.769180</td>\n",
       "      <td>0.654337</td>\n",
       "      <td>0.689424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.088700</td>\n",
       "      <td>0.655090</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.812564</td>\n",
       "      <td>0.713640</td>\n",
       "      <td>0.742524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.084600</td>\n",
       "      <td>0.660331</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.813336</td>\n",
       "      <td>0.720306</td>\n",
       "      <td>0.745705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.080600</td>\n",
       "      <td>0.660575</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.800011</td>\n",
       "      <td>0.708809</td>\n",
       "      <td>0.734551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.077500</td>\n",
       "      <td>0.671691</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.811852</td>\n",
       "      <td>0.712549</td>\n",
       "      <td>0.740864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>0.661555</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.811164</td>\n",
       "      <td>0.725467</td>\n",
       "      <td>0.751131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.663942</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.796752</td>\n",
       "      <td>0.735345</td>\n",
       "      <td>0.753015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.073100</td>\n",
       "      <td>0.661607</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.805025</td>\n",
       "      <td>0.736224</td>\n",
       "      <td>0.755116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.814923</td>\n",
       "      <td>0.735240</td>\n",
       "      <td>0.758995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.071900</td>\n",
       "      <td>0.660737</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.818330</td>\n",
       "      <td>0.735240</td>\n",
       "      <td>0.760019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 22:28:35,777] Trial 19 finished with value: 0.7600185253294757 and parameters: {'learning_rate': 0.00018763871193579055, 'weight_decay': 0.006, 'warmup_steps': 9, 'lambda_param': 0.9, 'temperature': 7.0}. Best is trial 19 with value: 0.7600185253294757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 with params: {'learning_rate': 0.00011894522730480247, 'weight_decay': 0.006, 'warmup_steps': 23, 'lambda_param': 0.7000000000000001, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:53 < 01:26, 30.18 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.343400</td>\n",
       "      <td>0.870033</td>\n",
       "      <td>0.725023</td>\n",
       "      <td>0.338397</td>\n",
       "      <td>0.341511</td>\n",
       "      <td>0.316263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.519700</td>\n",
       "      <td>0.706234</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.487846</td>\n",
       "      <td>0.456846</td>\n",
       "      <td>0.455017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.307600</td>\n",
       "      <td>0.659132</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.578365</td>\n",
       "      <td>0.529688</td>\n",
       "      <td>0.533118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.210400</td>\n",
       "      <td>0.652627</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.651846</td>\n",
       "      <td>0.562075</td>\n",
       "      <td>0.584481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.161500</td>\n",
       "      <td>0.648671</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.666630</td>\n",
       "      <td>0.619740</td>\n",
       "      <td>0.629401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.135100</td>\n",
       "      <td>0.643262</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.729568</td>\n",
       "      <td>0.635067</td>\n",
       "      <td>0.662668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.118400</td>\n",
       "      <td>0.638753</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.740353</td>\n",
       "      <td>0.643731</td>\n",
       "      <td>0.671196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.108500</td>\n",
       "      <td>0.640603</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.729278</td>\n",
       "      <td>0.652077</td>\n",
       "      <td>0.673268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.101000</td>\n",
       "      <td>0.645869</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.735482</td>\n",
       "      <td>0.649859</td>\n",
       "      <td>0.672604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.095300</td>\n",
       "      <td>0.657568</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.750552</td>\n",
       "      <td>0.673609</td>\n",
       "      <td>0.695912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 22:31:30,648] Trial 20 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 21 with params: {'learning_rate': 0.00021034558437245743, 'weight_decay': 0.01, 'warmup_steps': 12, 'lambda_param': 0.9, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:28, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.043600</td>\n",
       "      <td>0.727383</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.442097</td>\n",
       "      <td>0.432245</td>\n",
       "      <td>0.420891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.310300</td>\n",
       "      <td>0.649230</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.607359</td>\n",
       "      <td>0.559058</td>\n",
       "      <td>0.566679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.170400</td>\n",
       "      <td>0.648252</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.712290</td>\n",
       "      <td>0.637015</td>\n",
       "      <td>0.655701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.123200</td>\n",
       "      <td>0.652755</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.748429</td>\n",
       "      <td>0.632113</td>\n",
       "      <td>0.668577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.103100</td>\n",
       "      <td>0.661333</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.662941</td>\n",
       "      <td>0.691572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.092500</td>\n",
       "      <td>0.658759</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.793824</td>\n",
       "      <td>0.677176</td>\n",
       "      <td>0.713755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.085100</td>\n",
       "      <td>0.660307</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.806093</td>\n",
       "      <td>0.702993</td>\n",
       "      <td>0.734074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.081400</td>\n",
       "      <td>0.661722</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.818127</td>\n",
       "      <td>0.714872</td>\n",
       "      <td>0.745248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.661655</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.810157</td>\n",
       "      <td>0.710916</td>\n",
       "      <td>0.738914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.679697</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.813789</td>\n",
       "      <td>0.707716</td>\n",
       "      <td>0.740332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.073700</td>\n",
       "      <td>0.664549</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.805297</td>\n",
       "      <td>0.725046</td>\n",
       "      <td>0.746914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.666327</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.805346</td>\n",
       "      <td>0.727642</td>\n",
       "      <td>0.749653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>0.664328</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.818780</td>\n",
       "      <td>0.728539</td>\n",
       "      <td>0.755470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.661140</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.814342</td>\n",
       "      <td>0.729794</td>\n",
       "      <td>0.755820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.660358</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.813648</td>\n",
       "      <td>0.730113</td>\n",
       "      <td>0.755825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 22:36:01,739] Trial 21 finished with value: 0.7558249197907113 and parameters: {'learning_rate': 0.00021034558437245743, 'weight_decay': 0.01, 'warmup_steps': 12, 'lambda_param': 0.9, 'temperature': 7.0}. Best is trial 19 with value: 0.7600185253294757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 22 with params: {'learning_rate': 0.00036966704825076467, 'weight_decay': 0.008, 'warmup_steps': 7, 'lambda_param': 0.8, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:26, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.794600</td>\n",
       "      <td>0.680150</td>\n",
       "      <td>0.779102</td>\n",
       "      <td>0.496131</td>\n",
       "      <td>0.499811</td>\n",
       "      <td>0.492054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>0.664932</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.703535</td>\n",
       "      <td>0.630601</td>\n",
       "      <td>0.645275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.115900</td>\n",
       "      <td>0.658276</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.747757</td>\n",
       "      <td>0.681439</td>\n",
       "      <td>0.698657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.093600</td>\n",
       "      <td>0.666409</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.795601</td>\n",
       "      <td>0.698620</td>\n",
       "      <td>0.728369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.082600</td>\n",
       "      <td>0.676988</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.799607</td>\n",
       "      <td>0.706300</td>\n",
       "      <td>0.734164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.077800</td>\n",
       "      <td>0.679546</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.803826</td>\n",
       "      <td>0.718576</td>\n",
       "      <td>0.744381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.073800</td>\n",
       "      <td>0.685131</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.809153</td>\n",
       "      <td>0.699579</td>\n",
       "      <td>0.735031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.684717</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.811697</td>\n",
       "      <td>0.728665</td>\n",
       "      <td>0.754425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>0.685774</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.804900</td>\n",
       "      <td>0.719397</td>\n",
       "      <td>0.745287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.068300</td>\n",
       "      <td>0.698638</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.805696</td>\n",
       "      <td>0.713257</td>\n",
       "      <td>0.742195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.067400</td>\n",
       "      <td>0.684663</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.801033</td>\n",
       "      <td>0.718083</td>\n",
       "      <td>0.740412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.066100</td>\n",
       "      <td>0.664985</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.803527</td>\n",
       "      <td>0.733296</td>\n",
       "      <td>0.754469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>0.667812</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.803783</td>\n",
       "      <td>0.724422</td>\n",
       "      <td>0.747212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.064800</td>\n",
       "      <td>0.666982</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.810976</td>\n",
       "      <td>0.716837</td>\n",
       "      <td>0.746127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.064600</td>\n",
       "      <td>0.664303</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.813467</td>\n",
       "      <td>0.718628</td>\n",
       "      <td>0.748648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 22:40:30,504] Trial 22 finished with value: 0.7486478503420895 and parameters: {'learning_rate': 0.00036966704825076467, 'weight_decay': 0.008, 'warmup_steps': 7, 'lambda_param': 0.8, 'temperature': 7.0}. Best is trial 19 with value: 0.7600185253294757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 23 with params: {'learning_rate': 0.0002112380926140512, 'weight_decay': 0.01, 'warmup_steps': 25, 'lambda_param': 1.0, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:29, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.059200</td>\n",
       "      <td>0.728525</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.430299</td>\n",
       "      <td>0.423833</td>\n",
       "      <td>0.410903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.311800</td>\n",
       "      <td>0.647470</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.611484</td>\n",
       "      <td>0.568606</td>\n",
       "      <td>0.576237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.170800</td>\n",
       "      <td>0.649829</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.704073</td>\n",
       "      <td>0.630513</td>\n",
       "      <td>0.648707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.123100</td>\n",
       "      <td>0.665848</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.727718</td>\n",
       "      <td>0.624514</td>\n",
       "      <td>0.655095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.103000</td>\n",
       "      <td>0.662114</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.776666</td>\n",
       "      <td>0.674640</td>\n",
       "      <td>0.705170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.092100</td>\n",
       "      <td>0.651099</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.768622</td>\n",
       "      <td>0.667734</td>\n",
       "      <td>0.698881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.084600</td>\n",
       "      <td>0.663929</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.808221</td>\n",
       "      <td>0.705925</td>\n",
       "      <td>0.736690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.081000</td>\n",
       "      <td>0.665898</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.812511</td>\n",
       "      <td>0.716305</td>\n",
       "      <td>0.744870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.077800</td>\n",
       "      <td>0.663836</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.805968</td>\n",
       "      <td>0.711032</td>\n",
       "      <td>0.738442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.675487</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.805963</td>\n",
       "      <td>0.723432</td>\n",
       "      <td>0.746781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>0.669110</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.815589</td>\n",
       "      <td>0.725144</td>\n",
       "      <td>0.751330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.667320</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.806146</td>\n",
       "      <td>0.725085</td>\n",
       "      <td>0.749238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.667601</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.808106</td>\n",
       "      <td>0.726851</td>\n",
       "      <td>0.750907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.663334</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.813945</td>\n",
       "      <td>0.726024</td>\n",
       "      <td>0.752006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.665574</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.811780</td>\n",
       "      <td>0.726329</td>\n",
       "      <td>0.751983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 22:45:01,953] Trial 23 finished with value: 0.7519826693593987 and parameters: {'learning_rate': 0.0002112380926140512, 'weight_decay': 0.01, 'warmup_steps': 25, 'lambda_param': 1.0, 'temperature': 7.0}. Best is trial 19 with value: 0.7600185253294757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 24 with params: {'learning_rate': 0.00011615859910711042, 'weight_decay': 0.01, 'warmup_steps': 5, 'lambda_param': 0.6000000000000001, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:56 < 01:28, 29.70 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.333600</td>\n",
       "      <td>0.874633</td>\n",
       "      <td>0.723190</td>\n",
       "      <td>0.326870</td>\n",
       "      <td>0.335474</td>\n",
       "      <td>0.310969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.527600</td>\n",
       "      <td>0.709148</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.494946</td>\n",
       "      <td>0.451680</td>\n",
       "      <td>0.449517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.314200</td>\n",
       "      <td>0.656365</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.588513</td>\n",
       "      <td>0.537491</td>\n",
       "      <td>0.543510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.215200</td>\n",
       "      <td>0.647123</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.631933</td>\n",
       "      <td>0.555288</td>\n",
       "      <td>0.572289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.164800</td>\n",
       "      <td>0.645612</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.662675</td>\n",
       "      <td>0.621259</td>\n",
       "      <td>0.628119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.137600</td>\n",
       "      <td>0.640107</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.736064</td>\n",
       "      <td>0.638308</td>\n",
       "      <td>0.667341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.120400</td>\n",
       "      <td>0.635177</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.743328</td>\n",
       "      <td>0.658005</td>\n",
       "      <td>0.681068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.110100</td>\n",
       "      <td>0.636906</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.755575</td>\n",
       "      <td>0.672582</td>\n",
       "      <td>0.696113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.102600</td>\n",
       "      <td>0.643409</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.766302</td>\n",
       "      <td>0.670699</td>\n",
       "      <td>0.698379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.096600</td>\n",
       "      <td>0.653778</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.748273</td>\n",
       "      <td>0.672356</td>\n",
       "      <td>0.693951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 22:47:59,702] Trial 24 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 with params: {'learning_rate': 0.0003596274888695727, 'weight_decay': 0.004, 'warmup_steps': 6, 'lambda_param': 0.6000000000000001, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:27, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.805100</td>\n",
       "      <td>0.676196</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.515256</td>\n",
       "      <td>0.515998</td>\n",
       "      <td>0.506792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.195000</td>\n",
       "      <td>0.636602</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.702527</td>\n",
       "      <td>0.641626</td>\n",
       "      <td>0.654482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.117800</td>\n",
       "      <td>0.654661</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.747357</td>\n",
       "      <td>0.675122</td>\n",
       "      <td>0.695898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.093800</td>\n",
       "      <td>0.655611</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.788393</td>\n",
       "      <td>0.685982</td>\n",
       "      <td>0.717842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.083400</td>\n",
       "      <td>0.668861</td>\n",
       "      <td>0.805683</td>\n",
       "      <td>0.833220</td>\n",
       "      <td>0.719463</td>\n",
       "      <td>0.754988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.667958</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.821258</td>\n",
       "      <td>0.710351</td>\n",
       "      <td>0.746818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.675318</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.824706</td>\n",
       "      <td>0.705519</td>\n",
       "      <td>0.742906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.672610</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.806979</td>\n",
       "      <td>0.715629</td>\n",
       "      <td>0.741662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.069800</td>\n",
       "      <td>0.693686</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.806974</td>\n",
       "      <td>0.724856</td>\n",
       "      <td>0.750545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.683582</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.821655</td>\n",
       "      <td>0.722318</td>\n",
       "      <td>0.754881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.067500</td>\n",
       "      <td>0.677680</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.797838</td>\n",
       "      <td>0.707044</td>\n",
       "      <td>0.731164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.066300</td>\n",
       "      <td>0.665268</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.812472</td>\n",
       "      <td>0.713787</td>\n",
       "      <td>0.740789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.065600</td>\n",
       "      <td>0.666693</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.817797</td>\n",
       "      <td>0.720772</td>\n",
       "      <td>0.750717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.670541</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.826828</td>\n",
       "      <td>0.717396</td>\n",
       "      <td>0.753139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.064800</td>\n",
       "      <td>0.666890</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.817814</td>\n",
       "      <td>0.710184</td>\n",
       "      <td>0.742684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 22:52:28,704] Trial 25 finished with value: 0.7426835668181938 and parameters: {'learning_rate': 0.0003596274888695727, 'weight_decay': 0.004, 'warmup_steps': 6, 'lambda_param': 0.6000000000000001, 'temperature': 6.5}. Best is trial 19 with value: 0.7600185253294757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 with params: {'learning_rate': 5.542464595560726e-05, 'weight_decay': 0.008, 'warmup_steps': 14, 'lambda_param': 0.9, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:57 < 01:28, 29.53 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.732400</td>\n",
       "      <td>1.261327</td>\n",
       "      <td>0.626948</td>\n",
       "      <td>0.282626</td>\n",
       "      <td>0.247458</td>\n",
       "      <td>0.236524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.936100</td>\n",
       "      <td>0.888421</td>\n",
       "      <td>0.723190</td>\n",
       "      <td>0.343556</td>\n",
       "      <td>0.336293</td>\n",
       "      <td>0.314120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.625500</td>\n",
       "      <td>0.772650</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.411964</td>\n",
       "      <td>0.397728</td>\n",
       "      <td>0.385247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.474400</td>\n",
       "      <td>0.721467</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.472433</td>\n",
       "      <td>0.451237</td>\n",
       "      <td>0.443811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.379500</td>\n",
       "      <td>0.687285</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.502705</td>\n",
       "      <td>0.483123</td>\n",
       "      <td>0.480541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.314600</td>\n",
       "      <td>0.669917</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.514792</td>\n",
       "      <td>0.490225</td>\n",
       "      <td>0.490054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.266800</td>\n",
       "      <td>0.654693</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.561301</td>\n",
       "      <td>0.514010</td>\n",
       "      <td>0.518244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.235100</td>\n",
       "      <td>0.646553</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.609205</td>\n",
       "      <td>0.543073</td>\n",
       "      <td>0.553446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.212000</td>\n",
       "      <td>0.645854</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.620874</td>\n",
       "      <td>0.554138</td>\n",
       "      <td>0.564543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.193900</td>\n",
       "      <td>0.643955</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.652629</td>\n",
       "      <td>0.585230</td>\n",
       "      <td>0.601819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 22:55:27,391] Trial 26 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 27 with params: {'learning_rate': 0.00027302085104871567, 'weight_decay': 0.006, 'warmup_steps': 1, 'lambda_param': 1.0, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:27, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.904600</td>\n",
       "      <td>0.703146</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.478610</td>\n",
       "      <td>0.455535</td>\n",
       "      <td>0.443459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.243100</td>\n",
       "      <td>0.651096</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.645104</td>\n",
       "      <td>0.590696</td>\n",
       "      <td>0.601118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.139000</td>\n",
       "      <td>0.654470</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.698107</td>\n",
       "      <td>0.633992</td>\n",
       "      <td>0.650168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.661917</td>\n",
       "      <td>0.804766</td>\n",
       "      <td>0.787027</td>\n",
       "      <td>0.669846</td>\n",
       "      <td>0.706181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.091200</td>\n",
       "      <td>0.663175</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.812960</td>\n",
       "      <td>0.702420</td>\n",
       "      <td>0.738970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.670641</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.812135</td>\n",
       "      <td>0.714426</td>\n",
       "      <td>0.747007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.078300</td>\n",
       "      <td>0.673128</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.795907</td>\n",
       "      <td>0.699889</td>\n",
       "      <td>0.731113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.654787</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.822937</td>\n",
       "      <td>0.718691</td>\n",
       "      <td>0.750714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.073200</td>\n",
       "      <td>0.667802</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.803574</td>\n",
       "      <td>0.724246</td>\n",
       "      <td>0.746771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.671061</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.817497</td>\n",
       "      <td>0.722953</td>\n",
       "      <td>0.752447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.069700</td>\n",
       "      <td>0.674705</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.810350</td>\n",
       "      <td>0.721972</td>\n",
       "      <td>0.748090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.669055</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.805383</td>\n",
       "      <td>0.713329</td>\n",
       "      <td>0.740165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.667209</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.806043</td>\n",
       "      <td>0.713256</td>\n",
       "      <td>0.740711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.067300</td>\n",
       "      <td>0.671138</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.814136</td>\n",
       "      <td>0.714157</td>\n",
       "      <td>0.744899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.670242</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.808744</td>\n",
       "      <td>0.714938</td>\n",
       "      <td>0.742179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 22:59:56,388] Trial 27 finished with value: 0.7421789819990695 and parameters: {'learning_rate': 0.00027302085104871567, 'weight_decay': 0.006, 'warmup_steps': 1, 'lambda_param': 1.0, 'temperature': 6.0}. Best is trial 19 with value: 0.7600185253294757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 28 with params: {'learning_rate': 0.00036741108261561275, 'weight_decay': 0.01, 'warmup_steps': 9, 'lambda_param': 0.9, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:31, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.801300</td>\n",
       "      <td>0.677133</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.498969</td>\n",
       "      <td>0.499456</td>\n",
       "      <td>0.492616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.191200</td>\n",
       "      <td>0.659738</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.696858</td>\n",
       "      <td>0.619263</td>\n",
       "      <td>0.638235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.116200</td>\n",
       "      <td>0.657667</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.740581</td>\n",
       "      <td>0.662484</td>\n",
       "      <td>0.682021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.093100</td>\n",
       "      <td>0.667461</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.819829</td>\n",
       "      <td>0.701902</td>\n",
       "      <td>0.738352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.082800</td>\n",
       "      <td>0.672836</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.836663</td>\n",
       "      <td>0.713678</td>\n",
       "      <td>0.752788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.077600</td>\n",
       "      <td>0.686860</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.792899</td>\n",
       "      <td>0.691859</td>\n",
       "      <td>0.723300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>0.677232</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.815550</td>\n",
       "      <td>0.720519</td>\n",
       "      <td>0.751213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.685723</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.806966</td>\n",
       "      <td>0.736862</td>\n",
       "      <td>0.759999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.683288</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.801313</td>\n",
       "      <td>0.737650</td>\n",
       "      <td>0.757560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.068200</td>\n",
       "      <td>0.675948</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.820043</td>\n",
       "      <td>0.716266</td>\n",
       "      <td>0.750105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.067300</td>\n",
       "      <td>0.684515</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.807845</td>\n",
       "      <td>0.718712</td>\n",
       "      <td>0.747613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.675967</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.809130</td>\n",
       "      <td>0.740588</td>\n",
       "      <td>0.760685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.665666</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.813676</td>\n",
       "      <td>0.730297</td>\n",
       "      <td>0.757235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.671147</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.826057</td>\n",
       "      <td>0.731542</td>\n",
       "      <td>0.763667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.064800</td>\n",
       "      <td>0.664189</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.816840</td>\n",
       "      <td>0.731008</td>\n",
       "      <td>0.758942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 23:04:29,934] Trial 28 finished with value: 0.7589415855310878 and parameters: {'learning_rate': 0.00036741108261561275, 'weight_decay': 0.01, 'warmup_steps': 9, 'lambda_param': 0.9, 'temperature': 4.5}. Best is trial 19 with value: 0.7600185253294757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 29 with params: {'learning_rate': 0.0001489003810410246, 'weight_decay': 0.01, 'warmup_steps': 6, 'lambda_param': 0.8, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:56 < 01:28, 29.75 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.203300</td>\n",
       "      <td>0.800334</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.414419</td>\n",
       "      <td>0.373694</td>\n",
       "      <td>0.358812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.426000</td>\n",
       "      <td>0.673343</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.522796</td>\n",
       "      <td>0.489779</td>\n",
       "      <td>0.491306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.241100</td>\n",
       "      <td>0.643810</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.606413</td>\n",
       "      <td>0.557855</td>\n",
       "      <td>0.563971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.166100</td>\n",
       "      <td>0.652343</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.688174</td>\n",
       "      <td>0.607859</td>\n",
       "      <td>0.628647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.132200</td>\n",
       "      <td>0.658318</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.684024</td>\n",
       "      <td>0.623761</td>\n",
       "      <td>0.638156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.113000</td>\n",
       "      <td>0.644476</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.751865</td>\n",
       "      <td>0.659429</td>\n",
       "      <td>0.688000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.100900</td>\n",
       "      <td>0.646532</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.774130</td>\n",
       "      <td>0.668677</td>\n",
       "      <td>0.700251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.093900</td>\n",
       "      <td>0.653380</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.689624</td>\n",
       "      <td>0.716248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.088700</td>\n",
       "      <td>0.654366</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.768709</td>\n",
       "      <td>0.688764</td>\n",
       "      <td>0.710460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.084500</td>\n",
       "      <td>0.670770</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.762183</td>\n",
       "      <td>0.681587</td>\n",
       "      <td>0.705886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 23:07:27,275] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 with params: {'learning_rate': 0.0002970354897818153, 'weight_decay': 0.008, 'warmup_steps': 22, 'lambda_param': 1.0, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:28, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.905300</td>\n",
       "      <td>0.699111</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.499933</td>\n",
       "      <td>0.471220</td>\n",
       "      <td>0.468171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.227300</td>\n",
       "      <td>0.653273</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.686509</td>\n",
       "      <td>0.615193</td>\n",
       "      <td>0.631174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.131100</td>\n",
       "      <td>0.660651</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.698791</td>\n",
       "      <td>0.632322</td>\n",
       "      <td>0.649791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.101100</td>\n",
       "      <td>0.678342</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.772685</td>\n",
       "      <td>0.674129</td>\n",
       "      <td>0.702085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>0.666308</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.814802</td>\n",
       "      <td>0.698963</td>\n",
       "      <td>0.734890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.081300</td>\n",
       "      <td>0.671173</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.805965</td>\n",
       "      <td>0.703604</td>\n",
       "      <td>0.736060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.076600</td>\n",
       "      <td>0.682925</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.781696</td>\n",
       "      <td>0.688795</td>\n",
       "      <td>0.718411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.074200</td>\n",
       "      <td>0.673123</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.800347</td>\n",
       "      <td>0.713202</td>\n",
       "      <td>0.741251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.071900</td>\n",
       "      <td>0.668903</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.818950</td>\n",
       "      <td>0.716340</td>\n",
       "      <td>0.748549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.689072</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.813915</td>\n",
       "      <td>0.719659</td>\n",
       "      <td>0.749528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>0.679268</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.815967</td>\n",
       "      <td>0.715296</td>\n",
       "      <td>0.743932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.067900</td>\n",
       "      <td>0.676261</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.805739</td>\n",
       "      <td>0.714495</td>\n",
       "      <td>0.743502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.067100</td>\n",
       "      <td>0.669433</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.799778</td>\n",
       "      <td>0.699461</td>\n",
       "      <td>0.730112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.675898</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.802684</td>\n",
       "      <td>0.717622</td>\n",
       "      <td>0.745315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.676569</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.811878</td>\n",
       "      <td>0.716127</td>\n",
       "      <td>0.745100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 23:11:57,325] Trial 30 finished with value: 0.7451001856233275 and parameters: {'learning_rate': 0.0002970354897818153, 'weight_decay': 0.008, 'warmup_steps': 22, 'lambda_param': 1.0, 'temperature': 5.0}. Best is trial 19 with value: 0.7600185253294757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 31 with params: {'learning_rate': 0.0004253205164729637, 'weight_decay': 0.01, 'warmup_steps': 10, 'lambda_param': 0.8, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:57 < 01:28, 29.59 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.750400</td>\n",
       "      <td>0.668114</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.526444</td>\n",
       "      <td>0.503091</td>\n",
       "      <td>0.496948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.705652</td>\n",
       "      <td>0.638729</td>\n",
       "      <td>0.655685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.108800</td>\n",
       "      <td>0.686785</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.748592</td>\n",
       "      <td>0.678774</td>\n",
       "      <td>0.698611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.089200</td>\n",
       "      <td>0.664468</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.806991</td>\n",
       "      <td>0.720365</td>\n",
       "      <td>0.746885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.080700</td>\n",
       "      <td>0.690673</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.819557</td>\n",
       "      <td>0.728401</td>\n",
       "      <td>0.754206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>0.672626</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.808442</td>\n",
       "      <td>0.739944</td>\n",
       "      <td>0.759421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072300</td>\n",
       "      <td>0.689227</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.798915</td>\n",
       "      <td>0.733234</td>\n",
       "      <td>0.749484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.692025</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.792558</td>\n",
       "      <td>0.726979</td>\n",
       "      <td>0.743676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>0.698522</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.790474</td>\n",
       "      <td>0.738205</td>\n",
       "      <td>0.752223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067400</td>\n",
       "      <td>0.694882</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.790293</td>\n",
       "      <td>0.729318</td>\n",
       "      <td>0.744714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 23:14:55,757] Trial 31 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 32 with params: {'learning_rate': 0.00010832473126308801, 'weight_decay': 0.01, 'warmup_steps': 10, 'lambda_param': 1.0, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:57 < 01:28, 29.65 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.377600</td>\n",
       "      <td>0.900200</td>\n",
       "      <td>0.721357</td>\n",
       "      <td>0.343738</td>\n",
       "      <td>0.330424</td>\n",
       "      <td>0.307672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.558800</td>\n",
       "      <td>0.722170</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.450264</td>\n",
       "      <td>0.436046</td>\n",
       "      <td>0.425250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.338500</td>\n",
       "      <td>0.664726</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.560809</td>\n",
       "      <td>0.515349</td>\n",
       "      <td>0.513840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.650052</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.635792</td>\n",
       "      <td>0.551050</td>\n",
       "      <td>0.569908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.176700</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.664282</td>\n",
       "      <td>0.615119</td>\n",
       "      <td>0.623140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.146400</td>\n",
       "      <td>0.640286</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.707607</td>\n",
       "      <td>0.627286</td>\n",
       "      <td>0.649707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.127700</td>\n",
       "      <td>0.638296</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.722192</td>\n",
       "      <td>0.641884</td>\n",
       "      <td>0.662920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.116200</td>\n",
       "      <td>0.636671</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.732199</td>\n",
       "      <td>0.652305</td>\n",
       "      <td>0.673572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.107800</td>\n",
       "      <td>0.644588</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.759438</td>\n",
       "      <td>0.672112</td>\n",
       "      <td>0.696346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.101100</td>\n",
       "      <td>0.653470</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.748959</td>\n",
       "      <td>0.674804</td>\n",
       "      <td>0.695355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 23:17:53,740] Trial 32 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 33 with params: {'learning_rate': 0.00037173515654081735, 'weight_decay': 0.006, 'warmup_steps': 14, 'lambda_param': 0.7000000000000001, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:27, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.808100</td>\n",
       "      <td>0.678153</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.502106</td>\n",
       "      <td>0.503779</td>\n",
       "      <td>0.494757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.190600</td>\n",
       "      <td>0.660481</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.693521</td>\n",
       "      <td>0.642357</td>\n",
       "      <td>0.652978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.116200</td>\n",
       "      <td>0.651732</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.742267</td>\n",
       "      <td>0.660355</td>\n",
       "      <td>0.685391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.093000</td>\n",
       "      <td>0.671037</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.799498</td>\n",
       "      <td>0.702129</td>\n",
       "      <td>0.731546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.083100</td>\n",
       "      <td>0.676677</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.804124</td>\n",
       "      <td>0.690653</td>\n",
       "      <td>0.724932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.077400</td>\n",
       "      <td>0.677056</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.812108</td>\n",
       "      <td>0.705363</td>\n",
       "      <td>0.740713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.073600</td>\n",
       "      <td>0.673293</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.810423</td>\n",
       "      <td>0.712676</td>\n",
       "      <td>0.742676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.071600</td>\n",
       "      <td>0.670544</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.817340</td>\n",
       "      <td>0.718731</td>\n",
       "      <td>0.750689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>0.699324</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.815967</td>\n",
       "      <td>0.710128</td>\n",
       "      <td>0.742950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.691228</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.820090</td>\n",
       "      <td>0.710863</td>\n",
       "      <td>0.745326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.067500</td>\n",
       "      <td>0.690165</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.807866</td>\n",
       "      <td>0.707404</td>\n",
       "      <td>0.738618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.066100</td>\n",
       "      <td>0.675520</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.803483</td>\n",
       "      <td>0.713991</td>\n",
       "      <td>0.741262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.065600</td>\n",
       "      <td>0.677211</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.807763</td>\n",
       "      <td>0.710476</td>\n",
       "      <td>0.740928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.673541</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.818776</td>\n",
       "      <td>0.711603</td>\n",
       "      <td>0.745523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.064800</td>\n",
       "      <td>0.674184</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.810507</td>\n",
       "      <td>0.711052</td>\n",
       "      <td>0.741327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 23:22:23,306] Trial 33 finished with value: 0.7413270866084656 and parameters: {'learning_rate': 0.00037173515654081735, 'weight_decay': 0.006, 'warmup_steps': 14, 'lambda_param': 0.7000000000000001, 'temperature': 5.5}. Best is trial 19 with value: 0.7600185253294757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 34 with params: {'learning_rate': 1.5205336589627063e-05, 'weight_decay': 0.007, 'warmup_steps': 28, 'lambda_param': 0.8, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:56 < 01:28, 29.66 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.192100</td>\n",
       "      <td>1.961166</td>\n",
       "      <td>0.401467</td>\n",
       "      <td>0.098368</td>\n",
       "      <td>0.089825</td>\n",
       "      <td>0.072463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.776900</td>\n",
       "      <td>1.633149</td>\n",
       "      <td>0.502291</td>\n",
       "      <td>0.137760</td>\n",
       "      <td>0.147415</td>\n",
       "      <td>0.124073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.486100</td>\n",
       "      <td>1.411949</td>\n",
       "      <td>0.580202</td>\n",
       "      <td>0.237275</td>\n",
       "      <td>0.206920</td>\n",
       "      <td>0.192076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.278200</td>\n",
       "      <td>1.253280</td>\n",
       "      <td>0.624198</td>\n",
       "      <td>0.277163</td>\n",
       "      <td>0.241053</td>\n",
       "      <td>0.230137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.120400</td>\n",
       "      <td>1.134856</td>\n",
       "      <td>0.672777</td>\n",
       "      <td>0.259150</td>\n",
       "      <td>0.276275</td>\n",
       "      <td>0.255996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.003800</td>\n",
       "      <td>1.048402</td>\n",
       "      <td>0.685610</td>\n",
       "      <td>0.256095</td>\n",
       "      <td>0.285320</td>\n",
       "      <td>0.260142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.912100</td>\n",
       "      <td>0.984796</td>\n",
       "      <td>0.696609</td>\n",
       "      <td>0.269928</td>\n",
       "      <td>0.298718</td>\n",
       "      <td>0.273678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.845500</td>\n",
       "      <td>0.940257</td>\n",
       "      <td>0.708524</td>\n",
       "      <td>0.323371</td>\n",
       "      <td>0.315027</td>\n",
       "      <td>0.294612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.792900</td>\n",
       "      <td>0.905510</td>\n",
       "      <td>0.713107</td>\n",
       "      <td>0.322617</td>\n",
       "      <td>0.321189</td>\n",
       "      <td>0.297072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.750300</td>\n",
       "      <td>0.881427</td>\n",
       "      <td>0.717690</td>\n",
       "      <td>0.318022</td>\n",
       "      <td>0.326292</td>\n",
       "      <td>0.303246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 23:25:21,209] Trial 34 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 35 with params: {'learning_rate': 6.087267598950881e-05, 'weight_decay': 0.005, 'warmup_steps': 0, 'lambda_param': 0.8, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 02:00 < 04:01, 21.78 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.672000</td>\n",
       "      <td>1.200107</td>\n",
       "      <td>0.655362</td>\n",
       "      <td>0.282972</td>\n",
       "      <td>0.263550</td>\n",
       "      <td>0.252334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.873900</td>\n",
       "      <td>0.854799</td>\n",
       "      <td>0.722273</td>\n",
       "      <td>0.355417</td>\n",
       "      <td>0.344840</td>\n",
       "      <td>0.325922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.578700</td>\n",
       "      <td>0.752430</td>\n",
       "      <td>0.755270</td>\n",
       "      <td>0.443038</td>\n",
       "      <td>0.418770</td>\n",
       "      <td>0.406547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.435600</td>\n",
       "      <td>0.706276</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.528063</td>\n",
       "      <td>0.477964</td>\n",
       "      <td>0.477185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.342600</td>\n",
       "      <td>0.671215</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>0.522079</td>\n",
       "      <td>0.498519</td>\n",
       "      <td>0.494480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jovyan/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--recall/11f90e583db35601050aed380d48e83202a896976b9608432fba9244fb447f24 (last modified on Fri Jan 10 23:14:00 2025) since it couldn't be found locally at evaluate-metric--recall, or remotely on the Hugging Face Hub.\n",
      "[I 2025-03-26 23:27:23,066] Trial 35 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 36 with params: {'learning_rate': 0.0002599795583855664, 'weight_decay': 0.01, 'warmup_steps': 11, 'lambda_param': 0.9, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:27, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.945800</td>\n",
       "      <td>0.710302</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.471748</td>\n",
       "      <td>0.452345</td>\n",
       "      <td>0.439543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>0.646478</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.635328</td>\n",
       "      <td>0.593114</td>\n",
       "      <td>0.599856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>0.652069</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.703010</td>\n",
       "      <td>0.646040</td>\n",
       "      <td>0.658926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.108200</td>\n",
       "      <td>0.661572</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.750507</td>\n",
       "      <td>0.646102</td>\n",
       "      <td>0.676160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.093300</td>\n",
       "      <td>0.663557</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.796175</td>\n",
       "      <td>0.713258</td>\n",
       "      <td>0.739336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.085200</td>\n",
       "      <td>0.656498</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.818304</td>\n",
       "      <td>0.709416</td>\n",
       "      <td>0.744265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.079600</td>\n",
       "      <td>0.667694</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.801932</td>\n",
       "      <td>0.705475</td>\n",
       "      <td>0.736822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.076400</td>\n",
       "      <td>0.670510</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.814497</td>\n",
       "      <td>0.713995</td>\n",
       "      <td>0.744087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.074100</td>\n",
       "      <td>0.683006</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.800471</td>\n",
       "      <td>0.710647</td>\n",
       "      <td>0.737542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.071700</td>\n",
       "      <td>0.682690</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.817392</td>\n",
       "      <td>0.710671</td>\n",
       "      <td>0.741838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.070600</td>\n",
       "      <td>0.676750</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.797142</td>\n",
       "      <td>0.707421</td>\n",
       "      <td>0.733830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.069400</td>\n",
       "      <td>0.673004</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.800948</td>\n",
       "      <td>0.712518</td>\n",
       "      <td>0.739437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.672391</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.808198</td>\n",
       "      <td>0.719826</td>\n",
       "      <td>0.746341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.667649</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.806718</td>\n",
       "      <td>0.720635</td>\n",
       "      <td>0.746099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.067600</td>\n",
       "      <td>0.667934</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.809823</td>\n",
       "      <td>0.722744</td>\n",
       "      <td>0.748336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 23:31:52,007] Trial 36 finished with value: 0.7483363102569595 and parameters: {'learning_rate': 0.0002599795583855664, 'weight_decay': 0.01, 'warmup_steps': 11, 'lambda_param': 0.9, 'temperature': 6.5}. Best is trial 19 with value: 0.7600185253294757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 37 with params: {'learning_rate': 1.0728159166824396e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 2, 'lambda_param': 0.4, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:27 < 02:55, 29.87 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.250400</td>\n",
       "      <td>2.073695</td>\n",
       "      <td>0.349221</td>\n",
       "      <td>0.070858</td>\n",
       "      <td>0.073143</td>\n",
       "      <td>0.051965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.935100</td>\n",
       "      <td>1.814251</td>\n",
       "      <td>0.459212</td>\n",
       "      <td>0.106445</td>\n",
       "      <td>0.122520</td>\n",
       "      <td>0.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.698600</td>\n",
       "      <td>1.619600</td>\n",
       "      <td>0.502291</td>\n",
       "      <td>0.138324</td>\n",
       "      <td>0.147729</td>\n",
       "      <td>0.124465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.516800</td>\n",
       "      <td>1.472792</td>\n",
       "      <td>0.546288</td>\n",
       "      <td>0.226418</td>\n",
       "      <td>0.173820</td>\n",
       "      <td>0.156091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.372000</td>\n",
       "      <td>1.359288</td>\n",
       "      <td>0.587534</td>\n",
       "      <td>0.251077</td>\n",
       "      <td>0.210949</td>\n",
       "      <td>0.195738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 23:33:20,988] Trial 37 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 38 with params: {'learning_rate': 2.4269221144679105e-05, 'weight_decay': 0.005, 'warmup_steps': 35, 'lambda_param': 0.30000000000000004, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:27 < 02:55, 29.85 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.074700</td>\n",
       "      <td>1.751875</td>\n",
       "      <td>0.480293</td>\n",
       "      <td>0.105902</td>\n",
       "      <td>0.133662</td>\n",
       "      <td>0.110845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.505500</td>\n",
       "      <td>1.354619</td>\n",
       "      <td>0.595784</td>\n",
       "      <td>0.269290</td>\n",
       "      <td>0.217419</td>\n",
       "      <td>0.202569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.162500</td>\n",
       "      <td>1.117745</td>\n",
       "      <td>0.679193</td>\n",
       "      <td>0.271906</td>\n",
       "      <td>0.283509</td>\n",
       "      <td>0.262373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.942400</td>\n",
       "      <td>0.975678</td>\n",
       "      <td>0.703025</td>\n",
       "      <td>0.297432</td>\n",
       "      <td>0.310316</td>\n",
       "      <td>0.288070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.794100</td>\n",
       "      <td>0.889312</td>\n",
       "      <td>0.716774</td>\n",
       "      <td>0.322179</td>\n",
       "      <td>0.324102</td>\n",
       "      <td>0.301155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 23:34:49,867] Trial 38 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 39 with params: {'learning_rate': 0.0003962293213782471, 'weight_decay': 0.003, 'warmup_steps': 22, 'lambda_param': 0.9, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:27, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.796700</td>\n",
       "      <td>0.679678</td>\n",
       "      <td>0.778185</td>\n",
       "      <td>0.502948</td>\n",
       "      <td>0.502401</td>\n",
       "      <td>0.494795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.181600</td>\n",
       "      <td>0.663835</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.708402</td>\n",
       "      <td>0.646877</td>\n",
       "      <td>0.659692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.112200</td>\n",
       "      <td>0.671654</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.768524</td>\n",
       "      <td>0.702468</td>\n",
       "      <td>0.719009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.091200</td>\n",
       "      <td>0.655425</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.789589</td>\n",
       "      <td>0.684903</td>\n",
       "      <td>0.716544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.081800</td>\n",
       "      <td>0.660173</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.812534</td>\n",
       "      <td>0.713136</td>\n",
       "      <td>0.742081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.076700</td>\n",
       "      <td>0.674599</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.815552</td>\n",
       "      <td>0.716809</td>\n",
       "      <td>0.749036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.073600</td>\n",
       "      <td>0.672335</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.799991</td>\n",
       "      <td>0.705689</td>\n",
       "      <td>0.734261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>0.671901</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.799659</td>\n",
       "      <td>0.710232</td>\n",
       "      <td>0.737582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.069400</td>\n",
       "      <td>0.695778</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.792392</td>\n",
       "      <td>0.716238</td>\n",
       "      <td>0.735209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067500</td>\n",
       "      <td>0.686443</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.791848</td>\n",
       "      <td>0.714360</td>\n",
       "      <td>0.737009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>0.678109</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.802573</td>\n",
       "      <td>0.714235</td>\n",
       "      <td>0.737824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>0.670864</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.804624</td>\n",
       "      <td>0.736964</td>\n",
       "      <td>0.754685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.065200</td>\n",
       "      <td>0.667100</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.797065</td>\n",
       "      <td>0.729677</td>\n",
       "      <td>0.746206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.669924</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.808794</td>\n",
       "      <td>0.723786</td>\n",
       "      <td>0.749167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>0.668933</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.799963</td>\n",
       "      <td>0.724083</td>\n",
       "      <td>0.744742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 23:39:19,027] Trial 39 finished with value: 0.7447416821710183 and parameters: {'learning_rate': 0.0003962293213782471, 'weight_decay': 0.003, 'warmup_steps': 22, 'lambda_param': 0.9, 'temperature': 7.0}. Best is trial 19 with value: 0.7600185253294757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 40 with params: {'learning_rate': 8.788434110215489e-05, 'weight_decay': 0.001, 'warmup_steps': 49, 'lambda_param': 0.6000000000000001, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:28 < 02:57, 29.56 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.538400</td>\n",
       "      <td>1.010105</td>\n",
       "      <td>0.699358</td>\n",
       "      <td>0.304788</td>\n",
       "      <td>0.304749</td>\n",
       "      <td>0.284802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.671900</td>\n",
       "      <td>0.758142</td>\n",
       "      <td>0.748854</td>\n",
       "      <td>0.418533</td>\n",
       "      <td>0.406561</td>\n",
       "      <td>0.394858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.422800</td>\n",
       "      <td>0.695719</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.504402</td>\n",
       "      <td>0.483787</td>\n",
       "      <td>0.480263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.299800</td>\n",
       "      <td>0.668679</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>0.565306</td>\n",
       "      <td>0.507386</td>\n",
       "      <td>0.517081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.226500</td>\n",
       "      <td>0.648239</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.648972</td>\n",
       "      <td>0.565386</td>\n",
       "      <td>0.582369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 23:40:48,689] Trial 40 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 41 with params: {'learning_rate': 0.00022121801488502837, 'weight_decay': 0.001, 'warmup_steps': 25, 'lambda_param': 0.6000000000000001, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:25, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.038200</td>\n",
       "      <td>0.721113</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.432607</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>0.417962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.298500</td>\n",
       "      <td>0.646878</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.610878</td>\n",
       "      <td>0.573757</td>\n",
       "      <td>0.578235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.163600</td>\n",
       "      <td>0.651481</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.699838</td>\n",
       "      <td>0.628626</td>\n",
       "      <td>0.645752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.118600</td>\n",
       "      <td>0.664587</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.755093</td>\n",
       "      <td>0.632649</td>\n",
       "      <td>0.669968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.100100</td>\n",
       "      <td>0.660312</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.778670</td>\n",
       "      <td>0.688789</td>\n",
       "      <td>0.715589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.651949</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.759145</td>\n",
       "      <td>0.668525</td>\n",
       "      <td>0.697813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.083200</td>\n",
       "      <td>0.666428</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.810921</td>\n",
       "      <td>0.712183</td>\n",
       "      <td>0.741811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>0.665278</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.820285</td>\n",
       "      <td>0.716839</td>\n",
       "      <td>0.748092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.076900</td>\n",
       "      <td>0.664222</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.812827</td>\n",
       "      <td>0.720623</td>\n",
       "      <td>0.747384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.074100</td>\n",
       "      <td>0.676155</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.811912</td>\n",
       "      <td>0.724695</td>\n",
       "      <td>0.749748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.072500</td>\n",
       "      <td>0.666254</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.810650</td>\n",
       "      <td>0.723961</td>\n",
       "      <td>0.750134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.071300</td>\n",
       "      <td>0.671539</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.818912</td>\n",
       "      <td>0.727084</td>\n",
       "      <td>0.755579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.666756</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.795119</td>\n",
       "      <td>0.710262</td>\n",
       "      <td>0.737512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.069500</td>\n",
       "      <td>0.664000</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.810519</td>\n",
       "      <td>0.715382</td>\n",
       "      <td>0.745462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.069300</td>\n",
       "      <td>0.664478</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.807067</td>\n",
       "      <td>0.716909</td>\n",
       "      <td>0.745171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 23:45:15,463] Trial 41 finished with value: 0.7451705705566783 and parameters: {'learning_rate': 0.00022121801488502837, 'weight_decay': 0.001, 'warmup_steps': 25, 'lambda_param': 0.6000000000000001, 'temperature': 2.0}. Best is trial 19 with value: 0.7600185253294757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 42 with params: {'learning_rate': 0.00044248034786486986, 'weight_decay': 0.01, 'warmup_steps': 0, 'lambda_param': 1.0, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:58 < 01:29, 29.46 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.718300</td>\n",
       "      <td>0.685821</td>\n",
       "      <td>0.778185</td>\n",
       "      <td>0.582094</td>\n",
       "      <td>0.522056</td>\n",
       "      <td>0.527640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.167100</td>\n",
       "      <td>0.669550</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.673595</td>\n",
       "      <td>0.634073</td>\n",
       "      <td>0.637807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.106300</td>\n",
       "      <td>0.674500</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.771757</td>\n",
       "      <td>0.701094</td>\n",
       "      <td>0.720334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.088100</td>\n",
       "      <td>0.690778</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.811691</td>\n",
       "      <td>0.727413</td>\n",
       "      <td>0.749035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.079600</td>\n",
       "      <td>0.696013</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.806958</td>\n",
       "      <td>0.732927</td>\n",
       "      <td>0.755132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.074700</td>\n",
       "      <td>0.673151</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.810480</td>\n",
       "      <td>0.716407</td>\n",
       "      <td>0.743438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.702034</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.802818</td>\n",
       "      <td>0.713791</td>\n",
       "      <td>0.740575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.705551</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.825763</td>\n",
       "      <td>0.721870</td>\n",
       "      <td>0.754321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068200</td>\n",
       "      <td>0.716383</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.804769</td>\n",
       "      <td>0.700922</td>\n",
       "      <td>0.731153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066700</td>\n",
       "      <td>0.723533</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.805468</td>\n",
       "      <td>0.716054</td>\n",
       "      <td>0.740380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 23:48:14,869] Trial 42 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 43 with params: {'learning_rate': 0.00041559190163094063, 'weight_decay': 0.003, 'warmup_steps': 23, 'lambda_param': 0.9, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:26, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.780900</td>\n",
       "      <td>0.676699</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.527431</td>\n",
       "      <td>0.505251</td>\n",
       "      <td>0.501083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.175300</td>\n",
       "      <td>0.666276</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.701037</td>\n",
       "      <td>0.648877</td>\n",
       "      <td>0.657123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.110100</td>\n",
       "      <td>0.674592</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.785028</td>\n",
       "      <td>0.708106</td>\n",
       "      <td>0.729241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.668650</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.819275</td>\n",
       "      <td>0.728825</td>\n",
       "      <td>0.756859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.080700</td>\n",
       "      <td>0.683719</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.799733</td>\n",
       "      <td>0.708552</td>\n",
       "      <td>0.734129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>0.685208</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.818741</td>\n",
       "      <td>0.729465</td>\n",
       "      <td>0.755572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072800</td>\n",
       "      <td>0.710258</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.793005</td>\n",
       "      <td>0.716674</td>\n",
       "      <td>0.735516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.682481</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.813977</td>\n",
       "      <td>0.719633</td>\n",
       "      <td>0.745787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.069300</td>\n",
       "      <td>0.697208</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.804990</td>\n",
       "      <td>0.723469</td>\n",
       "      <td>0.743304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067600</td>\n",
       "      <td>0.694424</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.804243</td>\n",
       "      <td>0.714905</td>\n",
       "      <td>0.738059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.689286</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.810370</td>\n",
       "      <td>0.715369</td>\n",
       "      <td>0.741739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>0.688105</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.808389</td>\n",
       "      <td>0.726970</td>\n",
       "      <td>0.746482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.679463</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.805121</td>\n",
       "      <td>0.725539</td>\n",
       "      <td>0.746781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>0.681645</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.814154</td>\n",
       "      <td>0.723282</td>\n",
       "      <td>0.747707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.064100</td>\n",
       "      <td>0.682766</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.811596</td>\n",
       "      <td>0.723072</td>\n",
       "      <td>0.746461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 23:52:42,861] Trial 43 finished with value: 0.746460643495475 and parameters: {'learning_rate': 0.00041559190163094063, 'weight_decay': 0.003, 'warmup_steps': 23, 'lambda_param': 0.9, 'temperature': 2.0}. Best is trial 19 with value: 0.7600185253294757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 44 with params: {'learning_rate': 5.8679697914208696e-05, 'weight_decay': 0.002, 'warmup_steps': 45, 'lambda_param': 0.4, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:28 < 02:57, 29.64 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.736100</td>\n",
       "      <td>1.242909</td>\n",
       "      <td>0.629698</td>\n",
       "      <td>0.279414</td>\n",
       "      <td>0.246738</td>\n",
       "      <td>0.235578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.910400</td>\n",
       "      <td>0.873133</td>\n",
       "      <td>0.722273</td>\n",
       "      <td>0.339135</td>\n",
       "      <td>0.337323</td>\n",
       "      <td>0.314828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.601800</td>\n",
       "      <td>0.761232</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.447478</td>\n",
       "      <td>0.404894</td>\n",
       "      <td>0.395153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.453200</td>\n",
       "      <td>0.713322</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.477479</td>\n",
       "      <td>0.467272</td>\n",
       "      <td>0.459935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.358700</td>\n",
       "      <td>0.678056</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.497588</td>\n",
       "      <td>0.484887</td>\n",
       "      <td>0.482543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 23:54:12,298] Trial 44 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 45 with params: {'learning_rate': 0.0004400351450582787, 'weight_decay': 0.009000000000000001, 'warmup_steps': 5, 'lambda_param': 0.30000000000000004, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:56 < 01:28, 29.75 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.734900</td>\n",
       "      <td>0.656418</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.565741</td>\n",
       "      <td>0.525040</td>\n",
       "      <td>0.529480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.167700</td>\n",
       "      <td>0.641065</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.706116</td>\n",
       "      <td>0.660668</td>\n",
       "      <td>0.670401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.106800</td>\n",
       "      <td>0.664303</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.772422</td>\n",
       "      <td>0.697043</td>\n",
       "      <td>0.717623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.088200</td>\n",
       "      <td>0.668833</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.809467</td>\n",
       "      <td>0.717977</td>\n",
       "      <td>0.746480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.079800</td>\n",
       "      <td>0.673670</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.805543</td>\n",
       "      <td>0.716830</td>\n",
       "      <td>0.741346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.658705</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.822719</td>\n",
       "      <td>0.713001</td>\n",
       "      <td>0.746591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.697599</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.808593</td>\n",
       "      <td>0.702182</td>\n",
       "      <td>0.731840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.695166</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.797821</td>\n",
       "      <td>0.709478</td>\n",
       "      <td>0.732951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.709260</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.792440</td>\n",
       "      <td>0.724690</td>\n",
       "      <td>0.742730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067100</td>\n",
       "      <td>0.692999</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.816150</td>\n",
       "      <td>0.706215</td>\n",
       "      <td>0.735396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 23:57:09,743] Trial 45 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 46 with params: {'learning_rate': 0.00043974319957485277, 'weight_decay': 0.006, 'warmup_steps': 3, 'lambda_param': 0.5, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:57 < 01:28, 29.58 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.730300</td>\n",
       "      <td>0.674102</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.538176</td>\n",
       "      <td>0.522740</td>\n",
       "      <td>0.516854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.168200</td>\n",
       "      <td>0.665521</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.726835</td>\n",
       "      <td>0.659144</td>\n",
       "      <td>0.674462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.690644</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.729513</td>\n",
       "      <td>0.683418</td>\n",
       "      <td>0.691823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.676429</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.811203</td>\n",
       "      <td>0.722068</td>\n",
       "      <td>0.746776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.079800</td>\n",
       "      <td>0.697013</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.812554</td>\n",
       "      <td>0.730729</td>\n",
       "      <td>0.755179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075200</td>\n",
       "      <td>0.685663</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.827123</td>\n",
       "      <td>0.718355</td>\n",
       "      <td>0.752360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.704202</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.802527</td>\n",
       "      <td>0.713216</td>\n",
       "      <td>0.737999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.712653</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.800739</td>\n",
       "      <td>0.712673</td>\n",
       "      <td>0.738315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.706876</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.800313</td>\n",
       "      <td>0.727775</td>\n",
       "      <td>0.749264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067300</td>\n",
       "      <td>0.702005</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.792899</td>\n",
       "      <td>0.714249</td>\n",
       "      <td>0.738180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 00:00:08,186] Trial 46 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 47 with params: {'learning_rate': 0.00015215383624977904, 'weight_decay': 0.007, 'warmup_steps': 15, 'lambda_param': 0.9, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:55 < 01:28, 29.82 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.205200</td>\n",
       "      <td>0.796133</td>\n",
       "      <td>0.738772</td>\n",
       "      <td>0.413702</td>\n",
       "      <td>0.379663</td>\n",
       "      <td>0.365719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.420800</td>\n",
       "      <td>0.670716</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>0.530892</td>\n",
       "      <td>0.498850</td>\n",
       "      <td>0.500686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.237200</td>\n",
       "      <td>0.640469</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.615051</td>\n",
       "      <td>0.561897</td>\n",
       "      <td>0.570429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.652206</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.697592</td>\n",
       "      <td>0.608533</td>\n",
       "      <td>0.634509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.130300</td>\n",
       "      <td>0.657647</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.723775</td>\n",
       "      <td>0.648563</td>\n",
       "      <td>0.670019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.111600</td>\n",
       "      <td>0.643000</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.757914</td>\n",
       "      <td>0.662517</td>\n",
       "      <td>0.693030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.099800</td>\n",
       "      <td>0.645558</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.783304</td>\n",
       "      <td>0.673311</td>\n",
       "      <td>0.706547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.093000</td>\n",
       "      <td>0.654944</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.784997</td>\n",
       "      <td>0.696143</td>\n",
       "      <td>0.721864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.653601</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.788223</td>\n",
       "      <td>0.694632</td>\n",
       "      <td>0.721258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.083900</td>\n",
       "      <td>0.668226</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.781203</td>\n",
       "      <td>0.692286</td>\n",
       "      <td>0.717882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 00:03:05,336] Trial 47 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 48 with params: {'learning_rate': 0.0003077516411329231, 'weight_decay': 0.01, 'warmup_steps': 27, 'lambda_param': 1.0, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:25, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.898000</td>\n",
       "      <td>0.695806</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.501555</td>\n",
       "      <td>0.485274</td>\n",
       "      <td>0.479361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.221700</td>\n",
       "      <td>0.652579</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.657724</td>\n",
       "      <td>0.595389</td>\n",
       "      <td>0.607421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.128500</td>\n",
       "      <td>0.651745</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.705853</td>\n",
       "      <td>0.642560</td>\n",
       "      <td>0.659888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.818311</td>\n",
       "      <td>0.697155</td>\n",
       "      <td>0.734701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.087300</td>\n",
       "      <td>0.656998</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.808749</td>\n",
       "      <td>0.686004</td>\n",
       "      <td>0.724251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.674112</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.814868</td>\n",
       "      <td>0.714886</td>\n",
       "      <td>0.746496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.694150</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.820700</td>\n",
       "      <td>0.703626</td>\n",
       "      <td>0.741536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.073200</td>\n",
       "      <td>0.677641</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.814937</td>\n",
       "      <td>0.699643</td>\n",
       "      <td>0.736457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.071400</td>\n",
       "      <td>0.683134</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.804788</td>\n",
       "      <td>0.717714</td>\n",
       "      <td>0.743700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.069200</td>\n",
       "      <td>0.696895</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.812057</td>\n",
       "      <td>0.711925</td>\n",
       "      <td>0.743504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.068300</td>\n",
       "      <td>0.699303</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.819837</td>\n",
       "      <td>0.714007</td>\n",
       "      <td>0.748304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.067500</td>\n",
       "      <td>0.685887</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.805866</td>\n",
       "      <td>0.724356</td>\n",
       "      <td>0.748503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.066700</td>\n",
       "      <td>0.671664</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.811191</td>\n",
       "      <td>0.724636</td>\n",
       "      <td>0.750719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.065800</td>\n",
       "      <td>0.674952</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.818619</td>\n",
       "      <td>0.723907</td>\n",
       "      <td>0.752558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.672803</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.810358</td>\n",
       "      <td>0.723315</td>\n",
       "      <td>0.748640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 00:07:32,743] Trial 48 finished with value: 0.7486403418034737 and parameters: {'learning_rate': 0.0003077516411329231, 'weight_decay': 0.01, 'warmup_steps': 27, 'lambda_param': 1.0, 'temperature': 3.0}. Best is trial 19 with value: 0.7600185253294757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 49 with params: {'learning_rate': 0.0003937805064293631, 'weight_decay': 0.001, 'warmup_steps': 31, 'lambda_param': 0.6000000000000001, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:25, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.810200</td>\n",
       "      <td>0.690728</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.495508</td>\n",
       "      <td>0.497928</td>\n",
       "      <td>0.486501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.181400</td>\n",
       "      <td>0.658804</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.701316</td>\n",
       "      <td>0.630373</td>\n",
       "      <td>0.645358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.112000</td>\n",
       "      <td>0.676276</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.775818</td>\n",
       "      <td>0.692402</td>\n",
       "      <td>0.714856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.090600</td>\n",
       "      <td>0.688143</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.796319</td>\n",
       "      <td>0.707183</td>\n",
       "      <td>0.733062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.081300</td>\n",
       "      <td>0.694597</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.824723</td>\n",
       "      <td>0.704682</td>\n",
       "      <td>0.739059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.076200</td>\n",
       "      <td>0.687491</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.811315</td>\n",
       "      <td>0.730045</td>\n",
       "      <td>0.752956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072800</td>\n",
       "      <td>0.708428</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.813128</td>\n",
       "      <td>0.702227</td>\n",
       "      <td>0.733621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>0.685248</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.807151</td>\n",
       "      <td>0.713583</td>\n",
       "      <td>0.738854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.717326</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.814843</td>\n",
       "      <td>0.724051</td>\n",
       "      <td>0.749501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067600</td>\n",
       "      <td>0.705008</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.819238</td>\n",
       "      <td>0.726423</td>\n",
       "      <td>0.755108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.067100</td>\n",
       "      <td>0.706605</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.801465</td>\n",
       "      <td>0.715822</td>\n",
       "      <td>0.735850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.065800</td>\n",
       "      <td>0.683255</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.809892</td>\n",
       "      <td>0.737049</td>\n",
       "      <td>0.758472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.065300</td>\n",
       "      <td>0.679760</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.819116</td>\n",
       "      <td>0.723842</td>\n",
       "      <td>0.754961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.064600</td>\n",
       "      <td>0.681014</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.817785</td>\n",
       "      <td>0.732867</td>\n",
       "      <td>0.760387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.680751</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.820155</td>\n",
       "      <td>0.726562</td>\n",
       "      <td>0.754853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 00:12:00,092] Trial 49 finished with value: 0.754853385443597 and parameters: {'learning_rate': 0.0003937805064293631, 'weight_decay': 0.001, 'warmup_steps': 31, 'lambda_param': 0.6000000000000001, 'temperature': 4.0}. Best is trial 19 with value: 0.7600185253294757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 with params: {'learning_rate': 0.00043095971529618233, 'weight_decay': 0.006, 'warmup_steps': 18, 'lambda_param': 0.4, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:26, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.762200</td>\n",
       "      <td>0.675808</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.495409</td>\n",
       "      <td>0.498824</td>\n",
       "      <td>0.489851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>0.669856</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.689196</td>\n",
       "      <td>0.635756</td>\n",
       "      <td>0.644707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.108600</td>\n",
       "      <td>0.678554</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.746339</td>\n",
       "      <td>0.682019</td>\n",
       "      <td>0.698940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.089300</td>\n",
       "      <td>0.688248</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.787845</td>\n",
       "      <td>0.715823</td>\n",
       "      <td>0.733275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.680452</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.798364</td>\n",
       "      <td>0.718954</td>\n",
       "      <td>0.739887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075200</td>\n",
       "      <td>0.684377</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.807936</td>\n",
       "      <td>0.727278</td>\n",
       "      <td>0.751319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072300</td>\n",
       "      <td>0.725451</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.790355</td>\n",
       "      <td>0.712910</td>\n",
       "      <td>0.733597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.699643</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.811863</td>\n",
       "      <td>0.700117</td>\n",
       "      <td>0.734728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.697055</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.791836</td>\n",
       "      <td>0.709673</td>\n",
       "      <td>0.734166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066900</td>\n",
       "      <td>0.708925</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.811981</td>\n",
       "      <td>0.719145</td>\n",
       "      <td>0.748248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.707740</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.796749</td>\n",
       "      <td>0.707744</td>\n",
       "      <td>0.732101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>0.693325</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.798005</td>\n",
       "      <td>0.716568</td>\n",
       "      <td>0.742230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>0.690090</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.789319</td>\n",
       "      <td>0.713999</td>\n",
       "      <td>0.735046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.690150</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.802799</td>\n",
       "      <td>0.713700</td>\n",
       "      <td>0.740918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.064100</td>\n",
       "      <td>0.690168</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.801222</td>\n",
       "      <td>0.715861</td>\n",
       "      <td>0.740698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 00:16:28,022] Trial 50 finished with value: 0.7406982393506796 and parameters: {'learning_rate': 0.00043095971529618233, 'weight_decay': 0.006, 'warmup_steps': 18, 'lambda_param': 0.4, 'temperature': 7.0}. Best is trial 19 with value: 0.7600185253294757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 51 with params: {'learning_rate': 0.00042580526682643374, 'weight_decay': 0.003, 'warmup_steps': 40, 'lambda_param': 0.8, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:24, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.686040</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.515832</td>\n",
       "      <td>0.497350</td>\n",
       "      <td>0.490900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.172700</td>\n",
       "      <td>0.675604</td>\n",
       "      <td>0.778185</td>\n",
       "      <td>0.675438</td>\n",
       "      <td>0.625220</td>\n",
       "      <td>0.632599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.108900</td>\n",
       "      <td>0.668837</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.788940</td>\n",
       "      <td>0.721520</td>\n",
       "      <td>0.738959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.088700</td>\n",
       "      <td>0.665248</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.829340</td>\n",
       "      <td>0.719853</td>\n",
       "      <td>0.753110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.682409</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.828498</td>\n",
       "      <td>0.726233</td>\n",
       "      <td>0.756194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>0.683485</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.810341</td>\n",
       "      <td>0.728691</td>\n",
       "      <td>0.751272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.717004</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.815342</td>\n",
       "      <td>0.712246</td>\n",
       "      <td>0.741604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>0.692499</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.807719</td>\n",
       "      <td>0.715608</td>\n",
       "      <td>0.742294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.710038</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.798540</td>\n",
       "      <td>0.727930</td>\n",
       "      <td>0.749887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.709444</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.795021</td>\n",
       "      <td>0.715596</td>\n",
       "      <td>0.740521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.702299</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.820511</td>\n",
       "      <td>0.720856</td>\n",
       "      <td>0.751222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>0.694959</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.821137</td>\n",
       "      <td>0.717654</td>\n",
       "      <td>0.749494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.064600</td>\n",
       "      <td>0.684119</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.827036</td>\n",
       "      <td>0.728625</td>\n",
       "      <td>0.759276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.064100</td>\n",
       "      <td>0.677463</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.828146</td>\n",
       "      <td>0.738593</td>\n",
       "      <td>0.764239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.679554</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.823864</td>\n",
       "      <td>0.737421</td>\n",
       "      <td>0.762131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 00:20:54,307] Trial 51 finished with value: 0.7621312725763352 and parameters: {'learning_rate': 0.00042580526682643374, 'weight_decay': 0.003, 'warmup_steps': 40, 'lambda_param': 0.8, 'temperature': 4.5}. Best is trial 51 with value: 0.7621312725763352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 52 with params: {'learning_rate': 0.00024320473429530182, 'weight_decay': 0.003, 'warmup_steps': 41, 'lambda_param': 0.8, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:27, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.017500</td>\n",
       "      <td>0.715999</td>\n",
       "      <td>0.769019</td>\n",
       "      <td>0.448881</td>\n",
       "      <td>0.447546</td>\n",
       "      <td>0.436059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.274900</td>\n",
       "      <td>0.643116</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.591901</td>\n",
       "      <td>0.574086</td>\n",
       "      <td>0.571826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.151000</td>\n",
       "      <td>0.656500</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.704420</td>\n",
       "      <td>0.637627</td>\n",
       "      <td>0.656258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.111300</td>\n",
       "      <td>0.658957</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.761717</td>\n",
       "      <td>0.636131</td>\n",
       "      <td>0.675993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.095100</td>\n",
       "      <td>0.660604</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.770438</td>\n",
       "      <td>0.701534</td>\n",
       "      <td>0.721727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>0.652477</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.785426</td>\n",
       "      <td>0.679567</td>\n",
       "      <td>0.709241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.080600</td>\n",
       "      <td>0.660546</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.791302</td>\n",
       "      <td>0.700641</td>\n",
       "      <td>0.725514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.077700</td>\n",
       "      <td>0.656414</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.799968</td>\n",
       "      <td>0.708721</td>\n",
       "      <td>0.736235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.666637</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.808372</td>\n",
       "      <td>0.721526</td>\n",
       "      <td>0.744539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.680266</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.804024</td>\n",
       "      <td>0.723357</td>\n",
       "      <td>0.746161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>0.669126</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.805640</td>\n",
       "      <td>0.709860</td>\n",
       "      <td>0.739645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.069900</td>\n",
       "      <td>0.667977</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.806328</td>\n",
       "      <td>0.725036</td>\n",
       "      <td>0.748493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.664566</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.796562</td>\n",
       "      <td>0.712219</td>\n",
       "      <td>0.737025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.660021</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.808889</td>\n",
       "      <td>0.710898</td>\n",
       "      <td>0.740847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.068100</td>\n",
       "      <td>0.663425</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.803805</td>\n",
       "      <td>0.710850</td>\n",
       "      <td>0.739297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 00:25:23,249] Trial 52 finished with value: 0.7392967418844495 and parameters: {'learning_rate': 0.00024320473429530182, 'weight_decay': 0.003, 'warmup_steps': 41, 'lambda_param': 0.8, 'temperature': 4.5}. Best is trial 51 with value: 0.7621312725763352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 53 with params: {'learning_rate': 0.00046218411755430524, 'weight_decay': 0.004, 'warmup_steps': 52, 'lambda_param': 0.6000000000000001, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:24, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.786900</td>\n",
       "      <td>0.668436</td>\n",
       "      <td>0.778185</td>\n",
       "      <td>0.556157</td>\n",
       "      <td>0.501349</td>\n",
       "      <td>0.500480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.166300</td>\n",
       "      <td>0.671971</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.689949</td>\n",
       "      <td>0.628088</td>\n",
       "      <td>0.638641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.700240</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.782077</td>\n",
       "      <td>0.701331</td>\n",
       "      <td>0.722094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.087600</td>\n",
       "      <td>0.703605</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.801775</td>\n",
       "      <td>0.707636</td>\n",
       "      <td>0.735244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.079500</td>\n",
       "      <td>0.690088</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.809424</td>\n",
       "      <td>0.707380</td>\n",
       "      <td>0.739668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075200</td>\n",
       "      <td>0.737824</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.833793</td>\n",
       "      <td>0.719207</td>\n",
       "      <td>0.755172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072300</td>\n",
       "      <td>0.705841</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.813321</td>\n",
       "      <td>0.706885</td>\n",
       "      <td>0.737780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.069700</td>\n",
       "      <td>0.728427</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.815932</td>\n",
       "      <td>0.719382</td>\n",
       "      <td>0.749777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068200</td>\n",
       "      <td>0.738613</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.817967</td>\n",
       "      <td>0.712882</td>\n",
       "      <td>0.745681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066900</td>\n",
       "      <td>0.730296</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.711801</td>\n",
       "      <td>0.743389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.708575</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.808685</td>\n",
       "      <td>0.710375</td>\n",
       "      <td>0.740090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.064900</td>\n",
       "      <td>0.711972</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.791051</td>\n",
       "      <td>0.719149</td>\n",
       "      <td>0.740779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>0.695721</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.812026</td>\n",
       "      <td>0.704914</td>\n",
       "      <td>0.737342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.063900</td>\n",
       "      <td>0.704329</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.813685</td>\n",
       "      <td>0.719852</td>\n",
       "      <td>0.747538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.063600</td>\n",
       "      <td>0.709290</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.808830</td>\n",
       "      <td>0.720337</td>\n",
       "      <td>0.746378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 00:29:49,425] Trial 53 finished with value: 0.7463780969218667 and parameters: {'learning_rate': 0.00046218411755430524, 'weight_decay': 0.004, 'warmup_steps': 52, 'lambda_param': 0.6000000000000001, 'temperature': 5.5}. Best is trial 51 with value: 0.7621312725763352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 54 with params: {'learning_rate': 2.2869967933363696e-05, 'weight_decay': 0.007, 'warmup_steps': 45, 'lambda_param': 1.0, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:27 < 02:55, 29.93 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.097600</td>\n",
       "      <td>1.785137</td>\n",
       "      <td>0.472961</td>\n",
       "      <td>0.108522</td>\n",
       "      <td>0.130445</td>\n",
       "      <td>0.109234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.545700</td>\n",
       "      <td>1.392995</td>\n",
       "      <td>0.584785</td>\n",
       "      <td>0.245193</td>\n",
       "      <td>0.210871</td>\n",
       "      <td>0.196953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.205800</td>\n",
       "      <td>1.154546</td>\n",
       "      <td>0.670027</td>\n",
       "      <td>0.270742</td>\n",
       "      <td>0.277688</td>\n",
       "      <td>0.258672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.984200</td>\n",
       "      <td>1.006436</td>\n",
       "      <td>0.696609</td>\n",
       "      <td>0.274844</td>\n",
       "      <td>0.299355</td>\n",
       "      <td>0.275607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.832700</td>\n",
       "      <td>0.914099</td>\n",
       "      <td>0.708524</td>\n",
       "      <td>0.322099</td>\n",
       "      <td>0.316248</td>\n",
       "      <td>0.292869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 00:31:18,045] Trial 54 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 55 with params: {'learning_rate': 0.0004482970235527668, 'weight_decay': 0.002, 'warmup_steps': 37, 'lambda_param': 0.9, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:57 < 01:28, 29.62 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.774900</td>\n",
       "      <td>0.662315</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.529734</td>\n",
       "      <td>0.508625</td>\n",
       "      <td>0.504247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.166600</td>\n",
       "      <td>0.657271</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.717436</td>\n",
       "      <td>0.666788</td>\n",
       "      <td>0.676002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.106600</td>\n",
       "      <td>0.664644</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.769965</td>\n",
       "      <td>0.708046</td>\n",
       "      <td>0.722556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>0.681766</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.783296</td>\n",
       "      <td>0.684065</td>\n",
       "      <td>0.714722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.079800</td>\n",
       "      <td>0.685247</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.803853</td>\n",
       "      <td>0.710827</td>\n",
       "      <td>0.737886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.704536</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.813310</td>\n",
       "      <td>0.691745</td>\n",
       "      <td>0.728593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.701902</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.800887</td>\n",
       "      <td>0.695881</td>\n",
       "      <td>0.727154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.702193</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.787462</td>\n",
       "      <td>0.697117</td>\n",
       "      <td>0.723094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068100</td>\n",
       "      <td>0.710400</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.782856</td>\n",
       "      <td>0.709941</td>\n",
       "      <td>0.729741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066700</td>\n",
       "      <td>0.716712</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.794673</td>\n",
       "      <td>0.702788</td>\n",
       "      <td>0.729731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 00:34:16,286] Trial 55 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 56 with params: {'learning_rate': 0.00014720454397539664, 'weight_decay': 0.009000000000000001, 'warmup_steps': 50, 'lambda_param': 0.6000000000000001, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:28 < 02:57, 29.58 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.269500</td>\n",
       "      <td>0.814201</td>\n",
       "      <td>0.735105</td>\n",
       "      <td>0.368061</td>\n",
       "      <td>0.360141</td>\n",
       "      <td>0.338038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.439000</td>\n",
       "      <td>0.678672</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.527626</td>\n",
       "      <td>0.494758</td>\n",
       "      <td>0.496519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.248600</td>\n",
       "      <td>0.644338</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.579576</td>\n",
       "      <td>0.542120</td>\n",
       "      <td>0.546126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.170600</td>\n",
       "      <td>0.656273</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.677466</td>\n",
       "      <td>0.590471</td>\n",
       "      <td>0.615279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.134600</td>\n",
       "      <td>0.655234</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.700039</td>\n",
       "      <td>0.624662</td>\n",
       "      <td>0.645568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 00:35:45,941] Trial 56 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 57 with params: {'learning_rate': 0.00025929682944343565, 'weight_decay': 0.005, 'warmup_steps': 51, 'lambda_param': 0.4, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:25, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.004200</td>\n",
       "      <td>0.706180</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.447611</td>\n",
       "      <td>0.454661</td>\n",
       "      <td>0.442126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.260700</td>\n",
       "      <td>0.642225</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.599018</td>\n",
       "      <td>0.573684</td>\n",
       "      <td>0.573202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.144400</td>\n",
       "      <td>0.662658</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.709215</td>\n",
       "      <td>0.631806</td>\n",
       "      <td>0.655855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.107900</td>\n",
       "      <td>0.650568</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.766612</td>\n",
       "      <td>0.653768</td>\n",
       "      <td>0.685961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.092700</td>\n",
       "      <td>0.648658</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.771403</td>\n",
       "      <td>0.683297</td>\n",
       "      <td>0.710754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.084800</td>\n",
       "      <td>0.655560</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.827528</td>\n",
       "      <td>0.703538</td>\n",
       "      <td>0.740532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.079100</td>\n",
       "      <td>0.662504</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.787261</td>\n",
       "      <td>0.691453</td>\n",
       "      <td>0.717967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.076400</td>\n",
       "      <td>0.651391</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.820616</td>\n",
       "      <td>0.725231</td>\n",
       "      <td>0.752978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.073700</td>\n",
       "      <td>0.657249</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.822304</td>\n",
       "      <td>0.716532</td>\n",
       "      <td>0.747560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.071600</td>\n",
       "      <td>0.670517</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.812106</td>\n",
       "      <td>0.720096</td>\n",
       "      <td>0.746057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.795776</td>\n",
       "      <td>0.707727</td>\n",
       "      <td>0.734136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.667997</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.805842</td>\n",
       "      <td>0.714262</td>\n",
       "      <td>0.740342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.673207</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.801570</td>\n",
       "      <td>0.711098</td>\n",
       "      <td>0.738380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.067600</td>\n",
       "      <td>0.668269</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.807835</td>\n",
       "      <td>0.712075</td>\n",
       "      <td>0.741746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.067400</td>\n",
       "      <td>0.667789</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.802190</td>\n",
       "      <td>0.709853</td>\n",
       "      <td>0.738319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 00:40:13,300] Trial 57 finished with value: 0.7383194081881118 and parameters: {'learning_rate': 0.00025929682944343565, 'weight_decay': 0.005, 'warmup_steps': 51, 'lambda_param': 0.4, 'temperature': 3.0}. Best is trial 51 with value: 0.7621312725763352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 58 with params: {'learning_rate': 0.00033159441463755617, 'weight_decay': 0.007, 'warmup_steps': 8, 'lambda_param': 1.0, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:38, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.837600</td>\n",
       "      <td>0.690736</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.509691</td>\n",
       "      <td>0.503557</td>\n",
       "      <td>0.499336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.206600</td>\n",
       "      <td>0.649496</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.690424</td>\n",
       "      <td>0.631157</td>\n",
       "      <td>0.644744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>0.653988</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.736202</td>\n",
       "      <td>0.667764</td>\n",
       "      <td>0.686290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.096400</td>\n",
       "      <td>0.672610</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.774202</td>\n",
       "      <td>0.672768</td>\n",
       "      <td>0.701859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.085100</td>\n",
       "      <td>0.670700</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.786609</td>\n",
       "      <td>0.698635</td>\n",
       "      <td>0.722901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.078800</td>\n",
       "      <td>0.662532</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.822528</td>\n",
       "      <td>0.717208</td>\n",
       "      <td>0.748214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.679438</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.809638</td>\n",
       "      <td>0.710301</td>\n",
       "      <td>0.742713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.677692</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.810294</td>\n",
       "      <td>0.709336</td>\n",
       "      <td>0.739557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.681263</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.804201</td>\n",
       "      <td>0.705237</td>\n",
       "      <td>0.734269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>0.681345</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.805663</td>\n",
       "      <td>0.714925</td>\n",
       "      <td>0.744735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.690293</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.808294</td>\n",
       "      <td>0.704865</td>\n",
       "      <td>0.735566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.066900</td>\n",
       "      <td>0.676009</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.811590</td>\n",
       "      <td>0.710972</td>\n",
       "      <td>0.740347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.066300</td>\n",
       "      <td>0.667012</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.809918</td>\n",
       "      <td>0.712507</td>\n",
       "      <td>0.741313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>0.668966</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.812567</td>\n",
       "      <td>0.704649</td>\n",
       "      <td>0.737289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>0.667311</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.816975</td>\n",
       "      <td>0.715310</td>\n",
       "      <td>0.745919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 00:44:52,835] Trial 58 finished with value: 0.7459187170709238 and parameters: {'learning_rate': 0.00033159441463755617, 'weight_decay': 0.007, 'warmup_steps': 8, 'lambda_param': 1.0, 'temperature': 3.5}. Best is trial 51 with value: 0.7621312725763352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 59 with params: {'learning_rate': 9.856270612834072e-05, 'weight_decay': 0.001, 'warmup_steps': 21, 'lambda_param': 0.30000000000000004, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:27 < 02:54, 30.01 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.441700</td>\n",
       "      <td>0.941909</td>\n",
       "      <td>0.714940</td>\n",
       "      <td>0.328485</td>\n",
       "      <td>0.318337</td>\n",
       "      <td>0.293131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.604500</td>\n",
       "      <td>0.736012</td>\n",
       "      <td>0.755270</td>\n",
       "      <td>0.435499</td>\n",
       "      <td>0.419143</td>\n",
       "      <td>0.408768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.374300</td>\n",
       "      <td>0.677375</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.500088</td>\n",
       "      <td>0.488166</td>\n",
       "      <td>0.483342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.260400</td>\n",
       "      <td>0.659205</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.626823</td>\n",
       "      <td>0.540772</td>\n",
       "      <td>0.562789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.196800</td>\n",
       "      <td>0.646680</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.651679</td>\n",
       "      <td>0.590892</td>\n",
       "      <td>0.602952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 00:46:21,205] Trial 59 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 60 with params: {'learning_rate': 2.9068676100418608e-05, 'weight_decay': 0.0, 'warmup_steps': 7, 'lambda_param': 1.0, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:55 < 01:27, 29.98 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.999500</td>\n",
       "      <td>1.645242</td>\n",
       "      <td>0.501375</td>\n",
       "      <td>0.161658</td>\n",
       "      <td>0.146233</td>\n",
       "      <td>0.122252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.379700</td>\n",
       "      <td>1.236079</td>\n",
       "      <td>0.631531</td>\n",
       "      <td>0.279453</td>\n",
       "      <td>0.250064</td>\n",
       "      <td>0.236581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.030300</td>\n",
       "      <td>1.012637</td>\n",
       "      <td>0.703941</td>\n",
       "      <td>0.327938</td>\n",
       "      <td>0.307753</td>\n",
       "      <td>0.287884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.818900</td>\n",
       "      <td>0.892699</td>\n",
       "      <td>0.710357</td>\n",
       "      <td>0.311574</td>\n",
       "      <td>0.319760</td>\n",
       "      <td>0.294161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.682900</td>\n",
       "      <td>0.824123</td>\n",
       "      <td>0.729606</td>\n",
       "      <td>0.327506</td>\n",
       "      <td>0.348586</td>\n",
       "      <td>0.325386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.594400</td>\n",
       "      <td>0.781707</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.413674</td>\n",
       "      <td>0.381027</td>\n",
       "      <td>0.370421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.527300</td>\n",
       "      <td>0.752109</td>\n",
       "      <td>0.751604</td>\n",
       "      <td>0.422634</td>\n",
       "      <td>0.404278</td>\n",
       "      <td>0.393609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.482100</td>\n",
       "      <td>0.730687</td>\n",
       "      <td>0.756187</td>\n",
       "      <td>0.464640</td>\n",
       "      <td>0.428457</td>\n",
       "      <td>0.422158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.446500</td>\n",
       "      <td>0.720323</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.486492</td>\n",
       "      <td>0.451564</td>\n",
       "      <td>0.446136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.417200</td>\n",
       "      <td>0.710333</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.477576</td>\n",
       "      <td>0.458101</td>\n",
       "      <td>0.451425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 00:49:17,261] Trial 60 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 61 with params: {'learning_rate': 0.0002744501800271801, 'weight_decay': 0.003, 'warmup_steps': 38, 'lambda_param': 0.6000000000000001, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:55 < 01:27, 29.85 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.961700</td>\n",
       "      <td>0.700102</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.444239</td>\n",
       "      <td>0.446145</td>\n",
       "      <td>0.431536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.245800</td>\n",
       "      <td>0.643356</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.624870</td>\n",
       "      <td>0.594946</td>\n",
       "      <td>0.595625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.137900</td>\n",
       "      <td>0.659690</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.691436</td>\n",
       "      <td>0.637580</td>\n",
       "      <td>0.650042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>0.665798</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.789079</td>\n",
       "      <td>0.678172</td>\n",
       "      <td>0.712396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.091400</td>\n",
       "      <td>0.662331</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.762259</td>\n",
       "      <td>0.673887</td>\n",
       "      <td>0.700127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.083700</td>\n",
       "      <td>0.655808</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.779562</td>\n",
       "      <td>0.678955</td>\n",
       "      <td>0.710047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.078100</td>\n",
       "      <td>0.657894</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.787024</td>\n",
       "      <td>0.681545</td>\n",
       "      <td>0.713213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.660953</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.801219</td>\n",
       "      <td>0.708265</td>\n",
       "      <td>0.736882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.072900</td>\n",
       "      <td>0.675135</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.785998</td>\n",
       "      <td>0.702683</td>\n",
       "      <td>0.729737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.686919</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.789536</td>\n",
       "      <td>0.709618</td>\n",
       "      <td>0.733468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 00:52:14,127] Trial 61 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 62 with params: {'learning_rate': 6.19670485759995e-05, 'weight_decay': 0.007, 'warmup_steps': 9, 'lambda_param': 0.2, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:56 < 01:28, 29.70 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.673100</td>\n",
       "      <td>1.191568</td>\n",
       "      <td>0.659028</td>\n",
       "      <td>0.282645</td>\n",
       "      <td>0.266096</td>\n",
       "      <td>0.254074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.863000</td>\n",
       "      <td>0.847308</td>\n",
       "      <td>0.724106</td>\n",
       "      <td>0.330821</td>\n",
       "      <td>0.342975</td>\n",
       "      <td>0.321597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.569100</td>\n",
       "      <td>0.748878</td>\n",
       "      <td>0.755270</td>\n",
       "      <td>0.437279</td>\n",
       "      <td>0.415597</td>\n",
       "      <td>0.403798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.427700</td>\n",
       "      <td>0.703969</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.500894</td>\n",
       "      <td>0.473986</td>\n",
       "      <td>0.471061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.336200</td>\n",
       "      <td>0.670801</td>\n",
       "      <td>0.779102</td>\n",
       "      <td>0.519320</td>\n",
       "      <td>0.493988</td>\n",
       "      <td>0.493132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.276000</td>\n",
       "      <td>0.656442</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.563917</td>\n",
       "      <td>0.514729</td>\n",
       "      <td>0.519142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.233000</td>\n",
       "      <td>0.644614</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.602093</td>\n",
       "      <td>0.538662</td>\n",
       "      <td>0.545568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.205200</td>\n",
       "      <td>0.639857</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.642949</td>\n",
       "      <td>0.566243</td>\n",
       "      <td>0.581992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.185300</td>\n",
       "      <td>0.639331</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.655456</td>\n",
       "      <td>0.589741</td>\n",
       "      <td>0.605358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.169900</td>\n",
       "      <td>0.640106</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.663407</td>\n",
       "      <td>0.607629</td>\n",
       "      <td>0.619636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 00:55:11,797] Trial 62 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 63 with params: {'learning_rate': 0.0003269851540147738, 'weight_decay': 0.002, 'warmup_steps': 22, 'lambda_param': 0.5, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:26, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.867600</td>\n",
       "      <td>0.696021</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.497307</td>\n",
       "      <td>0.492134</td>\n",
       "      <td>0.485432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.209800</td>\n",
       "      <td>0.655411</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.702589</td>\n",
       "      <td>0.621441</td>\n",
       "      <td>0.638917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.123700</td>\n",
       "      <td>0.665752</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.761469</td>\n",
       "      <td>0.671028</td>\n",
       "      <td>0.697546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.097000</td>\n",
       "      <td>0.651311</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.778872</td>\n",
       "      <td>0.694826</td>\n",
       "      <td>0.720336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.085500</td>\n",
       "      <td>0.672783</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.809480</td>\n",
       "      <td>0.699690</td>\n",
       "      <td>0.732375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.079300</td>\n",
       "      <td>0.678606</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.795330</td>\n",
       "      <td>0.711397</td>\n",
       "      <td>0.738334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.676565</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.785395</td>\n",
       "      <td>0.698010</td>\n",
       "      <td>0.724095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.072700</td>\n",
       "      <td>0.692875</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.798342</td>\n",
       "      <td>0.709902</td>\n",
       "      <td>0.735396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.686182</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.812139</td>\n",
       "      <td>0.723526</td>\n",
       "      <td>0.749231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.682928</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.820592</td>\n",
       "      <td>0.726007</td>\n",
       "      <td>0.752914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.068200</td>\n",
       "      <td>0.678504</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.809795</td>\n",
       "      <td>0.718709</td>\n",
       "      <td>0.743942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.678255</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.800719</td>\n",
       "      <td>0.728103</td>\n",
       "      <td>0.748975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.669003</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.802437</td>\n",
       "      <td>0.727591</td>\n",
       "      <td>0.749536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.065800</td>\n",
       "      <td>0.669204</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.823681</td>\n",
       "      <td>0.728444</td>\n",
       "      <td>0.758103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.065600</td>\n",
       "      <td>0.671729</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.815923</td>\n",
       "      <td>0.738532</td>\n",
       "      <td>0.761753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 00:59:39,680] Trial 63 finished with value: 0.7617530399634793 and parameters: {'learning_rate': 0.0003269851540147738, 'weight_decay': 0.002, 'warmup_steps': 22, 'lambda_param': 0.5, 'temperature': 5.5}. Best is trial 51 with value: 0.7621312725763352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 64 with params: {'learning_rate': 5.986275918990953e-05, 'weight_decay': 0.008, 'warmup_steps': 47, 'lambda_param': 0.0, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:56 < 01:28, 29.75 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.728500</td>\n",
       "      <td>1.231550</td>\n",
       "      <td>0.630614</td>\n",
       "      <td>0.278078</td>\n",
       "      <td>0.247167</td>\n",
       "      <td>0.235616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.898000</td>\n",
       "      <td>0.866160</td>\n",
       "      <td>0.721357</td>\n",
       "      <td>0.338254</td>\n",
       "      <td>0.336960</td>\n",
       "      <td>0.314310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.591900</td>\n",
       "      <td>0.756884</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.447885</td>\n",
       "      <td>0.407765</td>\n",
       "      <td>0.397739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.445000</td>\n",
       "      <td>0.710508</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.494200</td>\n",
       "      <td>0.472312</td>\n",
       "      <td>0.467090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.350900</td>\n",
       "      <td>0.675188</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.514958</td>\n",
       "      <td>0.488887</td>\n",
       "      <td>0.489156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.288500</td>\n",
       "      <td>0.660490</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.545438</td>\n",
       "      <td>0.504379</td>\n",
       "      <td>0.506780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.243900</td>\n",
       "      <td>0.648022</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.575879</td>\n",
       "      <td>0.521185</td>\n",
       "      <td>0.524646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.214800</td>\n",
       "      <td>0.641883</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.643451</td>\n",
       "      <td>0.564010</td>\n",
       "      <td>0.581621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.193700</td>\n",
       "      <td>0.640963</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.659441</td>\n",
       "      <td>0.581935</td>\n",
       "      <td>0.601218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.177400</td>\n",
       "      <td>0.641473</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.666350</td>\n",
       "      <td>0.599465</td>\n",
       "      <td>0.614709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 01:02:37,005] Trial 64 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 65 with params: {'learning_rate': 0.0003438151739495363, 'weight_decay': 0.001, 'warmup_steps': 16, 'lambda_param': 0.5, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:57 < 01:28, 29.59 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.840400</td>\n",
       "      <td>0.691580</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.495745</td>\n",
       "      <td>0.493002</td>\n",
       "      <td>0.484089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.202400</td>\n",
       "      <td>0.647193</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.712331</td>\n",
       "      <td>0.633285</td>\n",
       "      <td>0.655642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.666176</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.734555</td>\n",
       "      <td>0.663001</td>\n",
       "      <td>0.684555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.094800</td>\n",
       "      <td>0.679100</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.789966</td>\n",
       "      <td>0.707784</td>\n",
       "      <td>0.731728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.084200</td>\n",
       "      <td>0.674661</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.790397</td>\n",
       "      <td>0.693744</td>\n",
       "      <td>0.720806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.078600</td>\n",
       "      <td>0.660323</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.809083</td>\n",
       "      <td>0.719577</td>\n",
       "      <td>0.743781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>0.669862</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.828767</td>\n",
       "      <td>0.703522</td>\n",
       "      <td>0.743855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.669829</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.805549</td>\n",
       "      <td>0.699646</td>\n",
       "      <td>0.732162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.694448</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.807601</td>\n",
       "      <td>0.708641</td>\n",
       "      <td>0.736697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.068500</td>\n",
       "      <td>0.696348</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.808474</td>\n",
       "      <td>0.708529</td>\n",
       "      <td>0.738198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 01:05:35,656] Trial 65 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 66 with params: {'learning_rate': 0.00023577468506900238, 'weight_decay': 0.002, 'warmup_steps': 38, 'lambda_param': 0.5, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:25, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.027200</td>\n",
       "      <td>0.718113</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.430890</td>\n",
       "      <td>0.440722</td>\n",
       "      <td>0.425999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.282800</td>\n",
       "      <td>0.640934</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.588613</td>\n",
       "      <td>0.576663</td>\n",
       "      <td>0.573444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>0.652044</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.699222</td>\n",
       "      <td>0.638928</td>\n",
       "      <td>0.653732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.113600</td>\n",
       "      <td>0.661820</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.758893</td>\n",
       "      <td>0.645535</td>\n",
       "      <td>0.679582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>0.663945</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.765485</td>\n",
       "      <td>0.674081</td>\n",
       "      <td>0.701921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.087300</td>\n",
       "      <td>0.645708</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.782387</td>\n",
       "      <td>0.668388</td>\n",
       "      <td>0.702141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.081300</td>\n",
       "      <td>0.658874</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.788866</td>\n",
       "      <td>0.684551</td>\n",
       "      <td>0.714497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.078300</td>\n",
       "      <td>0.657993</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.818288</td>\n",
       "      <td>0.713714</td>\n",
       "      <td>0.744428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.664133</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.813143</td>\n",
       "      <td>0.712203</td>\n",
       "      <td>0.742539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>0.674755</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.809842</td>\n",
       "      <td>0.720639</td>\n",
       "      <td>0.746272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.669136</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.813718</td>\n",
       "      <td>0.720351</td>\n",
       "      <td>0.748351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>0.671132</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.803165</td>\n",
       "      <td>0.722090</td>\n",
       "      <td>0.744883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.069400</td>\n",
       "      <td>0.665484</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.789276</td>\n",
       "      <td>0.712989</td>\n",
       "      <td>0.734673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.660644</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.806257</td>\n",
       "      <td>0.713293</td>\n",
       "      <td>0.742756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.068500</td>\n",
       "      <td>0.662139</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.800888</td>\n",
       "      <td>0.712870</td>\n",
       "      <td>0.740010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 01:10:02,557] Trial 66 finished with value: 0.7400104937027346 and parameters: {'learning_rate': 0.00023577468506900238, 'weight_decay': 0.002, 'warmup_steps': 38, 'lambda_param': 0.5, 'temperature': 6.0}. Best is trial 51 with value: 0.7621312725763352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 67 with params: {'learning_rate': 0.000380476328390809, 'weight_decay': 0.003, 'warmup_steps': 18, 'lambda_param': 0.5, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:24, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.805800</td>\n",
       "      <td>0.686745</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.500522</td>\n",
       "      <td>0.500627</td>\n",
       "      <td>0.491683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.187100</td>\n",
       "      <td>0.655962</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.700220</td>\n",
       "      <td>0.645078</td>\n",
       "      <td>0.656547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.114200</td>\n",
       "      <td>0.660142</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.769045</td>\n",
       "      <td>0.683008</td>\n",
       "      <td>0.708175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.092400</td>\n",
       "      <td>0.677648</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.810696</td>\n",
       "      <td>0.700510</td>\n",
       "      <td>0.731860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.082700</td>\n",
       "      <td>0.660755</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.800096</td>\n",
       "      <td>0.699820</td>\n",
       "      <td>0.729690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.077300</td>\n",
       "      <td>0.684727</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.797536</td>\n",
       "      <td>0.703199</td>\n",
       "      <td>0.731759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.073800</td>\n",
       "      <td>0.690934</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.809759</td>\n",
       "      <td>0.718071</td>\n",
       "      <td>0.745959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.676464</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.804200</td>\n",
       "      <td>0.709161</td>\n",
       "      <td>0.736857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.069900</td>\n",
       "      <td>0.671888</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.817274</td>\n",
       "      <td>0.722114</td>\n",
       "      <td>0.750713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.684374</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.814394</td>\n",
       "      <td>0.727042</td>\n",
       "      <td>0.753902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.067100</td>\n",
       "      <td>0.685361</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.806685</td>\n",
       "      <td>0.713245</td>\n",
       "      <td>0.738074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.683832</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.798479</td>\n",
       "      <td>0.721681</td>\n",
       "      <td>0.743970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>0.678346</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.804813</td>\n",
       "      <td>0.721171</td>\n",
       "      <td>0.746826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.064700</td>\n",
       "      <td>0.680165</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.823101</td>\n",
       "      <td>0.723115</td>\n",
       "      <td>0.752539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.064600</td>\n",
       "      <td>0.678464</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.809790</td>\n",
       "      <td>0.719305</td>\n",
       "      <td>0.745368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 01:14:28,509] Trial 67 finished with value: 0.7453675686363961 and parameters: {'learning_rate': 0.000380476328390809, 'weight_decay': 0.003, 'warmup_steps': 18, 'lambda_param': 0.5, 'temperature': 5.0}. Best is trial 51 with value: 0.7621312725763352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 68 with params: {'learning_rate': 0.00010517624896066003, 'weight_decay': 0.002, 'warmup_steps': 29, 'lambda_param': 0.30000000000000004, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:28 < 02:56, 29.66 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.417900</td>\n",
       "      <td>0.917855</td>\n",
       "      <td>0.715857</td>\n",
       "      <td>0.335640</td>\n",
       "      <td>0.324830</td>\n",
       "      <td>0.301841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.576200</td>\n",
       "      <td>0.725190</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.462813</td>\n",
       "      <td>0.440435</td>\n",
       "      <td>0.432572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.351000</td>\n",
       "      <td>0.668662</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>0.536085</td>\n",
       "      <td>0.507654</td>\n",
       "      <td>0.504594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.242300</td>\n",
       "      <td>0.654256</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.637335</td>\n",
       "      <td>0.549298</td>\n",
       "      <td>0.568573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.183200</td>\n",
       "      <td>0.646858</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.648770</td>\n",
       "      <td>0.601119</td>\n",
       "      <td>0.608025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 01:15:57,867] Trial 68 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 69 with params: {'learning_rate': 0.00022627704070743494, 'weight_decay': 0.005, 'warmup_steps': 9, 'lambda_param': 0.8, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:26, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.004300</td>\n",
       "      <td>0.719738</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.435726</td>\n",
       "      <td>0.440367</td>\n",
       "      <td>0.425580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.288500</td>\n",
       "      <td>0.648481</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.620137</td>\n",
       "      <td>0.572783</td>\n",
       "      <td>0.582103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.160200</td>\n",
       "      <td>0.651158</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.706835</td>\n",
       "      <td>0.632862</td>\n",
       "      <td>0.650816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.117600</td>\n",
       "      <td>0.658402</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.747477</td>\n",
       "      <td>0.638374</td>\n",
       "      <td>0.672075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.099400</td>\n",
       "      <td>0.657907</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.733545</td>\n",
       "      <td>0.667642</td>\n",
       "      <td>0.685503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.089300</td>\n",
       "      <td>0.657561</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.813159</td>\n",
       "      <td>0.712860</td>\n",
       "      <td>0.746680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.082900</td>\n",
       "      <td>0.661984</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.794154</td>\n",
       "      <td>0.714184</td>\n",
       "      <td>0.738575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>0.664089</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.814586</td>\n",
       "      <td>0.710869</td>\n",
       "      <td>0.740901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.076600</td>\n",
       "      <td>0.663471</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.816287</td>\n",
       "      <td>0.718887</td>\n",
       "      <td>0.747597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.073800</td>\n",
       "      <td>0.680816</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.815470</td>\n",
       "      <td>0.722454</td>\n",
       "      <td>0.749808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.671243</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.804569</td>\n",
       "      <td>0.719702</td>\n",
       "      <td>0.743794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>0.668931</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.814874</td>\n",
       "      <td>0.724610</td>\n",
       "      <td>0.751367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>0.661130</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.804150</td>\n",
       "      <td>0.719976</td>\n",
       "      <td>0.743236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.069300</td>\n",
       "      <td>0.663862</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.807910</td>\n",
       "      <td>0.724234</td>\n",
       "      <td>0.748949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.069200</td>\n",
       "      <td>0.663678</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.802669</td>\n",
       "      <td>0.722953</td>\n",
       "      <td>0.745944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 01:20:26,090] Trial 69 finished with value: 0.7459437290185895 and parameters: {'learning_rate': 0.00022627704070743494, 'weight_decay': 0.005, 'warmup_steps': 9, 'lambda_param': 0.8, 'temperature': 7.0}. Best is trial 51 with value: 0.7621312725763352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 70 with params: {'learning_rate': 0.00020217971206811072, 'weight_decay': 0.01, 'warmup_steps': 11, 'lambda_param': 1.0, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:26, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.060800</td>\n",
       "      <td>0.734107</td>\n",
       "      <td>0.758020</td>\n",
       "      <td>0.419002</td>\n",
       "      <td>0.416056</td>\n",
       "      <td>0.401513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.322200</td>\n",
       "      <td>0.645009</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.611649</td>\n",
       "      <td>0.557525</td>\n",
       "      <td>0.566122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.177200</td>\n",
       "      <td>0.648086</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.687606</td>\n",
       "      <td>0.618272</td>\n",
       "      <td>0.632472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.127000</td>\n",
       "      <td>0.652751</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.753242</td>\n",
       "      <td>0.635492</td>\n",
       "      <td>0.671016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.105800</td>\n",
       "      <td>0.664142</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.755158</td>\n",
       "      <td>0.659737</td>\n",
       "      <td>0.687301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.094300</td>\n",
       "      <td>0.657386</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.795496</td>\n",
       "      <td>0.668796</td>\n",
       "      <td>0.708931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>0.658272</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.812138</td>\n",
       "      <td>0.707810</td>\n",
       "      <td>0.738850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.082400</td>\n",
       "      <td>0.663254</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.807208</td>\n",
       "      <td>0.712892</td>\n",
       "      <td>0.739858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>0.654954</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.807713</td>\n",
       "      <td>0.721326</td>\n",
       "      <td>0.745746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>0.675895</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.814127</td>\n",
       "      <td>0.708282</td>\n",
       "      <td>0.740716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.662734</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.797172</td>\n",
       "      <td>0.721615</td>\n",
       "      <td>0.742378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.073100</td>\n",
       "      <td>0.664834</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.804128</td>\n",
       "      <td>0.727957</td>\n",
       "      <td>0.749785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.071700</td>\n",
       "      <td>0.663402</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.812751</td>\n",
       "      <td>0.729775</td>\n",
       "      <td>0.754525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.659144</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.815131</td>\n",
       "      <td>0.729138</td>\n",
       "      <td>0.755669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.070700</td>\n",
       "      <td>0.659294</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.816310</td>\n",
       "      <td>0.729027</td>\n",
       "      <td>0.756016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 01:24:53,995] Trial 70 finished with value: 0.7560155310479446 and parameters: {'learning_rate': 0.00020217971206811072, 'weight_decay': 0.01, 'warmup_steps': 11, 'lambda_param': 1.0, 'temperature': 7.0}. Best is trial 51 with value: 0.7621312725763352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 71 with params: {'learning_rate': 0.00019228065670426477, 'weight_decay': 0.009000000000000001, 'warmup_steps': 19, 'lambda_param': 0.8, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:29 < 02:59, 29.24 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.094900</td>\n",
       "      <td>0.743743</td>\n",
       "      <td>0.757104</td>\n",
       "      <td>0.447858</td>\n",
       "      <td>0.429810</td>\n",
       "      <td>0.421825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.340100</td>\n",
       "      <td>0.649476</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.589543</td>\n",
       "      <td>0.541860</td>\n",
       "      <td>0.546339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.186800</td>\n",
       "      <td>0.649104</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.695376</td>\n",
       "      <td>0.622458</td>\n",
       "      <td>0.637824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.132500</td>\n",
       "      <td>0.654482</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.731291</td>\n",
       "      <td>0.621651</td>\n",
       "      <td>0.654213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.109300</td>\n",
       "      <td>0.665222</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.753293</td>\n",
       "      <td>0.669653</td>\n",
       "      <td>0.691980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 01:26:24,669] Trial 71 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 72 with params: {'learning_rate': 0.0003257924720701566, 'weight_decay': 0.006, 'warmup_steps': 44, 'lambda_param': 0.9, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:28, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.901000</td>\n",
       "      <td>0.684889</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.491416</td>\n",
       "      <td>0.479780</td>\n",
       "      <td>0.474971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.212800</td>\n",
       "      <td>0.651668</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.690841</td>\n",
       "      <td>0.622798</td>\n",
       "      <td>0.637314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.123900</td>\n",
       "      <td>0.657049</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.763305</td>\n",
       "      <td>0.673014</td>\n",
       "      <td>0.699211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.097300</td>\n",
       "      <td>0.673325</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.785190</td>\n",
       "      <td>0.682819</td>\n",
       "      <td>0.709713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.085700</td>\n",
       "      <td>0.672598</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.787728</td>\n",
       "      <td>0.690401</td>\n",
       "      <td>0.717362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.078800</td>\n",
       "      <td>0.657726</td>\n",
       "      <td>0.805683</td>\n",
       "      <td>0.813876</td>\n",
       "      <td>0.709288</td>\n",
       "      <td>0.740667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>0.675247</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.824159</td>\n",
       "      <td>0.710864</td>\n",
       "      <td>0.745068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.072600</td>\n",
       "      <td>0.669140</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.827511</td>\n",
       "      <td>0.705943</td>\n",
       "      <td>0.742266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.689093</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.819741</td>\n",
       "      <td>0.730121</td>\n",
       "      <td>0.756304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.068700</td>\n",
       "      <td>0.696196</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.802840</td>\n",
       "      <td>0.713847</td>\n",
       "      <td>0.742599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.067900</td>\n",
       "      <td>0.689332</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.816874</td>\n",
       "      <td>0.721469</td>\n",
       "      <td>0.747633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.066700</td>\n",
       "      <td>0.685035</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.808275</td>\n",
       "      <td>0.722368</td>\n",
       "      <td>0.746057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.678885</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.787841</td>\n",
       "      <td>0.710543</td>\n",
       "      <td>0.734129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>0.675968</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.812704</td>\n",
       "      <td>0.716830</td>\n",
       "      <td>0.747753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.065200</td>\n",
       "      <td>0.675917</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.806429</td>\n",
       "      <td>0.715777</td>\n",
       "      <td>0.743719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 01:30:54,481] Trial 72 finished with value: 0.7437193687737823 and parameters: {'learning_rate': 0.0003257924720701566, 'weight_decay': 0.006, 'warmup_steps': 44, 'lambda_param': 0.9, 'temperature': 4.5}. Best is trial 51 with value: 0.7621312725763352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 73 with params: {'learning_rate': 0.00029835040132382163, 'weight_decay': 0.009000000000000001, 'warmup_steps': 4, 'lambda_param': 1.0, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:30, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.873600</td>\n",
       "      <td>0.691822</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.501040</td>\n",
       "      <td>0.475855</td>\n",
       "      <td>0.471194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.226300</td>\n",
       "      <td>0.644820</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.645437</td>\n",
       "      <td>0.600673</td>\n",
       "      <td>0.609131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.654592</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.731772</td>\n",
       "      <td>0.648381</td>\n",
       "      <td>0.673268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.100600</td>\n",
       "      <td>0.664407</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.787915</td>\n",
       "      <td>0.665829</td>\n",
       "      <td>0.701940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.088700</td>\n",
       "      <td>0.651003</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.824590</td>\n",
       "      <td>0.701015</td>\n",
       "      <td>0.740927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.081200</td>\n",
       "      <td>0.664014</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.813838</td>\n",
       "      <td>0.712031</td>\n",
       "      <td>0.745700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.076700</td>\n",
       "      <td>0.670995</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.807955</td>\n",
       "      <td>0.717376</td>\n",
       "      <td>0.746068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.673551</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.814667</td>\n",
       "      <td>0.716805</td>\n",
       "      <td>0.749544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.071900</td>\n",
       "      <td>0.672307</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.822201</td>\n",
       "      <td>0.724623</td>\n",
       "      <td>0.753870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>0.672689</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.818501</td>\n",
       "      <td>0.722116</td>\n",
       "      <td>0.753087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.662999</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.809568</td>\n",
       "      <td>0.727336</td>\n",
       "      <td>0.752896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.067900</td>\n",
       "      <td>0.666059</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.806111</td>\n",
       "      <td>0.718635</td>\n",
       "      <td>0.747365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.067300</td>\n",
       "      <td>0.657787</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.806029</td>\n",
       "      <td>0.713941</td>\n",
       "      <td>0.744641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.066700</td>\n",
       "      <td>0.659103</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.810185</td>\n",
       "      <td>0.710235</td>\n",
       "      <td>0.741839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.657399</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.799445</td>\n",
       "      <td>0.709790</td>\n",
       "      <td>0.738977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 01:35:26,526] Trial 73 finished with value: 0.7389774858643093 and parameters: {'learning_rate': 0.00029835040132382163, 'weight_decay': 0.009000000000000001, 'warmup_steps': 4, 'lambda_param': 1.0, 'temperature': 7.0}. Best is trial 51 with value: 0.7621312725763352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 74 with params: {'learning_rate': 0.00034269616032774053, 'weight_decay': 0.004, 'warmup_steps': 26, 'lambda_param': 0.6000000000000001, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:57 < 01:28, 29.55 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.854700</td>\n",
       "      <td>0.694119</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.488080</td>\n",
       "      <td>0.488214</td>\n",
       "      <td>0.479500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.202800</td>\n",
       "      <td>0.668045</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.696733</td>\n",
       "      <td>0.626772</td>\n",
       "      <td>0.639431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>0.666724</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.727740</td>\n",
       "      <td>0.657505</td>\n",
       "      <td>0.675267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.095400</td>\n",
       "      <td>0.663261</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.767453</td>\n",
       "      <td>0.691515</td>\n",
       "      <td>0.711069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.084400</td>\n",
       "      <td>0.657855</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.807414</td>\n",
       "      <td>0.710052</td>\n",
       "      <td>0.737578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.665557</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.793410</td>\n",
       "      <td>0.708172</td>\n",
       "      <td>0.734774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.678235</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.805154</td>\n",
       "      <td>0.703618</td>\n",
       "      <td>0.732914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.675363</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.815063</td>\n",
       "      <td>0.700077</td>\n",
       "      <td>0.735391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.684677</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.803735</td>\n",
       "      <td>0.703723</td>\n",
       "      <td>0.732545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.695758</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.804414</td>\n",
       "      <td>0.706335</td>\n",
       "      <td>0.735297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 01:38:25,125] Trial 74 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 75 with params: {'learning_rate': 0.000422780629913313, 'weight_decay': 0.003, 'warmup_steps': 35, 'lambda_param': 0.7000000000000001, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:58 < 01:29, 29.37 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.790900</td>\n",
       "      <td>0.676400</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.522243</td>\n",
       "      <td>0.503039</td>\n",
       "      <td>0.496618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.173400</td>\n",
       "      <td>0.668050</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.725727</td>\n",
       "      <td>0.656050</td>\n",
       "      <td>0.671435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.109100</td>\n",
       "      <td>0.656462</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.779077</td>\n",
       "      <td>0.721034</td>\n",
       "      <td>0.734503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.089600</td>\n",
       "      <td>0.669552</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.808224</td>\n",
       "      <td>0.705545</td>\n",
       "      <td>0.733845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.689774</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.779704</td>\n",
       "      <td>0.720700</td>\n",
       "      <td>0.732403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075800</td>\n",
       "      <td>0.688187</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.805137</td>\n",
       "      <td>0.722968</td>\n",
       "      <td>0.746541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.071900</td>\n",
       "      <td>0.700129</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.805525</td>\n",
       "      <td>0.720344</td>\n",
       "      <td>0.745523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>0.689968</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.804306</td>\n",
       "      <td>0.725321</td>\n",
       "      <td>0.746283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.706064</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.809437</td>\n",
       "      <td>0.730387</td>\n",
       "      <td>0.753290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067400</td>\n",
       "      <td>0.706657</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.807798</td>\n",
       "      <td>0.705440</td>\n",
       "      <td>0.738373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 01:41:24,807] Trial 75 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 76 with params: {'learning_rate': 0.00015790650376126586, 'weight_decay': 0.002, 'warmup_steps': 33, 'lambda_param': 0.9, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:57 < 01:28, 29.56 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.210600</td>\n",
       "      <td>0.791616</td>\n",
       "      <td>0.738772</td>\n",
       "      <td>0.411606</td>\n",
       "      <td>0.381076</td>\n",
       "      <td>0.367346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.667548</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.530006</td>\n",
       "      <td>0.499888</td>\n",
       "      <td>0.498404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.229000</td>\n",
       "      <td>0.641516</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.616928</td>\n",
       "      <td>0.557077</td>\n",
       "      <td>0.568278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.157900</td>\n",
       "      <td>0.658653</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.696022</td>\n",
       "      <td>0.607091</td>\n",
       "      <td>0.631895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.126500</td>\n",
       "      <td>0.657932</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.689529</td>\n",
       "      <td>0.623248</td>\n",
       "      <td>0.640748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.108900</td>\n",
       "      <td>0.642311</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.761603</td>\n",
       "      <td>0.662802</td>\n",
       "      <td>0.694959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.651625</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.774740</td>\n",
       "      <td>0.668699</td>\n",
       "      <td>0.700426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.091300</td>\n",
       "      <td>0.655276</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.782296</td>\n",
       "      <td>0.690752</td>\n",
       "      <td>0.717880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.086400</td>\n",
       "      <td>0.653950</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.785680</td>\n",
       "      <td>0.691894</td>\n",
       "      <td>0.719174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.082700</td>\n",
       "      <td>0.667410</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.790575</td>\n",
       "      <td>0.698842</td>\n",
       "      <td>0.727975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 01:44:23,402] Trial 76 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 77 with params: {'learning_rate': 0.0001778617002751221, 'weight_decay': 0.009000000000000001, 'warmup_steps': 7, 'lambda_param': 1.0, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:28 < 02:57, 29.52 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.116100</td>\n",
       "      <td>0.760226</td>\n",
       "      <td>0.755270</td>\n",
       "      <td>0.434546</td>\n",
       "      <td>0.411782</td>\n",
       "      <td>0.401372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.363200</td>\n",
       "      <td>0.657349</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.554498</td>\n",
       "      <td>0.517261</td>\n",
       "      <td>0.521166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.201000</td>\n",
       "      <td>0.646259</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.624238</td>\n",
       "      <td>0.586181</td>\n",
       "      <td>0.592537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.140800</td>\n",
       "      <td>0.652867</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.695588</td>\n",
       "      <td>0.616415</td>\n",
       "      <td>0.639290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.115100</td>\n",
       "      <td>0.661416</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.718233</td>\n",
       "      <td>0.637060</td>\n",
       "      <td>0.660185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 01:45:53,262] Trial 77 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 78 with params: {'learning_rate': 0.00021926733388471974, 'weight_decay': 0.009000000000000001, 'warmup_steps': 15, 'lambda_param': 0.8, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:27, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.028500</td>\n",
       "      <td>0.721152</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.432366</td>\n",
       "      <td>0.435290</td>\n",
       "      <td>0.421423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.299100</td>\n",
       "      <td>0.647133</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.613567</td>\n",
       "      <td>0.564610</td>\n",
       "      <td>0.571967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.164300</td>\n",
       "      <td>0.654196</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.705868</td>\n",
       "      <td>0.628974</td>\n",
       "      <td>0.647482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.119500</td>\n",
       "      <td>0.655786</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.746609</td>\n",
       "      <td>0.634811</td>\n",
       "      <td>0.668988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.100700</td>\n",
       "      <td>0.663684</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.753995</td>\n",
       "      <td>0.679814</td>\n",
       "      <td>0.700910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.090700</td>\n",
       "      <td>0.659698</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.784500</td>\n",
       "      <td>0.677857</td>\n",
       "      <td>0.709627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.083800</td>\n",
       "      <td>0.657052</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.808606</td>\n",
       "      <td>0.708264</td>\n",
       "      <td>0.738735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.662452</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.813879</td>\n",
       "      <td>0.710238</td>\n",
       "      <td>0.739908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.077300</td>\n",
       "      <td>0.661801</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.812887</td>\n",
       "      <td>0.706658</td>\n",
       "      <td>0.738591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.680349</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.820693</td>\n",
       "      <td>0.719899</td>\n",
       "      <td>0.751934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.072800</td>\n",
       "      <td>0.662795</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.805247</td>\n",
       "      <td>0.726107</td>\n",
       "      <td>0.748168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.668380</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.810692</td>\n",
       "      <td>0.726938</td>\n",
       "      <td>0.751874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.663733</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.818860</td>\n",
       "      <td>0.724156</td>\n",
       "      <td>0.750954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.069600</td>\n",
       "      <td>0.660682</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.823077</td>\n",
       "      <td>0.723202</td>\n",
       "      <td>0.753739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.069400</td>\n",
       "      <td>0.661657</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.823688</td>\n",
       "      <td>0.724152</td>\n",
       "      <td>0.753345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 01:50:22,464] Trial 78 finished with value: 0.7533454381226101 and parameters: {'learning_rate': 0.00021926733388471974, 'weight_decay': 0.009000000000000001, 'warmup_steps': 15, 'lambda_param': 0.8, 'temperature': 4.5}. Best is trial 51 with value: 0.7621312725763352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 79 with params: {'learning_rate': 0.0001636841920990703, 'weight_decay': 0.01, 'warmup_steps': 18, 'lambda_param': 0.9, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:57 < 01:28, 29.58 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.172600</td>\n",
       "      <td>0.778256</td>\n",
       "      <td>0.740605</td>\n",
       "      <td>0.394483</td>\n",
       "      <td>0.380329</td>\n",
       "      <td>0.363992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.394800</td>\n",
       "      <td>0.665249</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.552646</td>\n",
       "      <td>0.519473</td>\n",
       "      <td>0.523547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.219900</td>\n",
       "      <td>0.642167</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.612560</td>\n",
       "      <td>0.565023</td>\n",
       "      <td>0.573068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.152300</td>\n",
       "      <td>0.654993</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.715180</td>\n",
       "      <td>0.618771</td>\n",
       "      <td>0.648458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.122900</td>\n",
       "      <td>0.660162</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.746774</td>\n",
       "      <td>0.659327</td>\n",
       "      <td>0.684956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.106300</td>\n",
       "      <td>0.644510</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.771131</td>\n",
       "      <td>0.662711</td>\n",
       "      <td>0.698329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.095500</td>\n",
       "      <td>0.651300</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.781803</td>\n",
       "      <td>0.672106</td>\n",
       "      <td>0.704494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.089900</td>\n",
       "      <td>0.657828</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.784070</td>\n",
       "      <td>0.703759</td>\n",
       "      <td>0.726587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.085200</td>\n",
       "      <td>0.660360</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.773301</td>\n",
       "      <td>0.694621</td>\n",
       "      <td>0.712986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.081500</td>\n",
       "      <td>0.670365</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.798081</td>\n",
       "      <td>0.711435</td>\n",
       "      <td>0.736090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 01:53:20,949] Trial 79 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 80 with params: {'learning_rate': 0.0002787420748443775, 'weight_decay': 0.007, 'warmup_steps': 38, 'lambda_param': 0.0, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:59 < 01:29, 29.27 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.955200</td>\n",
       "      <td>0.696971</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.447873</td>\n",
       "      <td>0.449768</td>\n",
       "      <td>0.435195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.242200</td>\n",
       "      <td>0.647720</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.628644</td>\n",
       "      <td>0.600024</td>\n",
       "      <td>0.599291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.136300</td>\n",
       "      <td>0.659104</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.690584</td>\n",
       "      <td>0.635961</td>\n",
       "      <td>0.648101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.103800</td>\n",
       "      <td>0.667655</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.787028</td>\n",
       "      <td>0.666107</td>\n",
       "      <td>0.702008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.090900</td>\n",
       "      <td>0.664326</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.768772</td>\n",
       "      <td>0.678058</td>\n",
       "      <td>0.702922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.082900</td>\n",
       "      <td>0.654745</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.784465</td>\n",
       "      <td>0.670967</td>\n",
       "      <td>0.706312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.077900</td>\n",
       "      <td>0.663110</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.782504</td>\n",
       "      <td>0.684919</td>\n",
       "      <td>0.715422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.672506</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.806190</td>\n",
       "      <td>0.700834</td>\n",
       "      <td>0.730968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.072700</td>\n",
       "      <td>0.681132</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.782023</td>\n",
       "      <td>0.707585</td>\n",
       "      <td>0.729625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>0.687410</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.784714</td>\n",
       "      <td>0.706272</td>\n",
       "      <td>0.728117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 01:56:21,212] Trial 80 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 81 with params: {'learning_rate': 0.00041886493671855284, 'weight_decay': 0.0, 'warmup_steps': 33, 'lambda_param': 0.4, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:59 < 01:29, 29.21 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.791900</td>\n",
       "      <td>0.674488</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.518334</td>\n",
       "      <td>0.499932</td>\n",
       "      <td>0.492506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.173900</td>\n",
       "      <td>0.674323</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.676440</td>\n",
       "      <td>0.637927</td>\n",
       "      <td>0.638798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.108600</td>\n",
       "      <td>0.678635</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.771622</td>\n",
       "      <td>0.703270</td>\n",
       "      <td>0.720245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.089300</td>\n",
       "      <td>0.666289</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.821906</td>\n",
       "      <td>0.712628</td>\n",
       "      <td>0.745921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.080400</td>\n",
       "      <td>0.690158</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.812283</td>\n",
       "      <td>0.710360</td>\n",
       "      <td>0.741075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.680707</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.821236</td>\n",
       "      <td>0.722714</td>\n",
       "      <td>0.753289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072300</td>\n",
       "      <td>0.696706</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.815548</td>\n",
       "      <td>0.716976</td>\n",
       "      <td>0.745642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.705038</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.810141</td>\n",
       "      <td>0.705421</td>\n",
       "      <td>0.735100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>0.686215</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.811365</td>\n",
       "      <td>0.724414</td>\n",
       "      <td>0.749556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.706534</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.798737</td>\n",
       "      <td>0.710859</td>\n",
       "      <td>0.735620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 01:59:21,881] Trial 81 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 82 with params: {'learning_rate': 0.00019287931040767018, 'weight_decay': 0.0, 'warmup_steps': 38, 'lambda_param': 0.6000000000000001, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:28 < 02:56, 29.67 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.120200</td>\n",
       "      <td>0.748811</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.445675</td>\n",
       "      <td>0.432537</td>\n",
       "      <td>0.423952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.342600</td>\n",
       "      <td>0.649975</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.569260</td>\n",
       "      <td>0.533250</td>\n",
       "      <td>0.535129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.647017</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.646206</td>\n",
       "      <td>0.591871</td>\n",
       "      <td>0.601255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.133500</td>\n",
       "      <td>0.657608</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.753494</td>\n",
       "      <td>0.643386</td>\n",
       "      <td>0.676556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.109400</td>\n",
       "      <td>0.668825</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.755086</td>\n",
       "      <td>0.671580</td>\n",
       "      <td>0.694544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 02:00:51,246] Trial 82 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 83 with params: {'learning_rate': 0.00024889333178909064, 'weight_decay': 0.001, 'warmup_steps': 22, 'lambda_param': 0.6000000000000001, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:26, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.980200</td>\n",
       "      <td>0.711215</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.446176</td>\n",
       "      <td>0.449485</td>\n",
       "      <td>0.435783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.267300</td>\n",
       "      <td>0.646183</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.620443</td>\n",
       "      <td>0.583358</td>\n",
       "      <td>0.588309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>0.655976</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.711417</td>\n",
       "      <td>0.647133</td>\n",
       "      <td>0.663941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.110500</td>\n",
       "      <td>0.663139</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.785371</td>\n",
       "      <td>0.653522</td>\n",
       "      <td>0.695915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.094600</td>\n",
       "      <td>0.670393</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.781125</td>\n",
       "      <td>0.705655</td>\n",
       "      <td>0.728375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.085800</td>\n",
       "      <td>0.657547</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.806929</td>\n",
       "      <td>0.693255</td>\n",
       "      <td>0.727126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.673316</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.807540</td>\n",
       "      <td>0.691682</td>\n",
       "      <td>0.727702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.077100</td>\n",
       "      <td>0.673124</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.812105</td>\n",
       "      <td>0.704304</td>\n",
       "      <td>0.737585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.668472</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.814756</td>\n",
       "      <td>0.721361</td>\n",
       "      <td>0.749683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.687519</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.814844</td>\n",
       "      <td>0.708665</td>\n",
       "      <td>0.741045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.070600</td>\n",
       "      <td>0.680089</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.817289</td>\n",
       "      <td>0.715774</td>\n",
       "      <td>0.745975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.069600</td>\n",
       "      <td>0.666087</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.805773</td>\n",
       "      <td>0.719900</td>\n",
       "      <td>0.743215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.672749</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.800521</td>\n",
       "      <td>0.710846</td>\n",
       "      <td>0.737879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.668970</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.801588</td>\n",
       "      <td>0.706496</td>\n",
       "      <td>0.735366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.670437</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.805672</td>\n",
       "      <td>0.710065</td>\n",
       "      <td>0.739455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 02:05:19,175] Trial 83 finished with value: 0.7394552401280714 and parameters: {'learning_rate': 0.00024889333178909064, 'weight_decay': 0.001, 'warmup_steps': 22, 'lambda_param': 0.6000000000000001, 'temperature': 5.5}. Best is trial 51 with value: 0.7621312725763352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 84 with params: {'learning_rate': 0.0003112612834598753, 'weight_decay': 0.0, 'warmup_steps': 34, 'lambda_param': 0.7000000000000001, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:58 < 01:29, 29.36 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.904900</td>\n",
       "      <td>0.697209</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.494296</td>\n",
       "      <td>0.476805</td>\n",
       "      <td>0.470046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.655687</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.654523</td>\n",
       "      <td>0.601756</td>\n",
       "      <td>0.608251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.127200</td>\n",
       "      <td>0.647965</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.725533</td>\n",
       "      <td>0.671107</td>\n",
       "      <td>0.684647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.098500</td>\n",
       "      <td>0.663246</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.809474</td>\n",
       "      <td>0.696258</td>\n",
       "      <td>0.730353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.086900</td>\n",
       "      <td>0.673594</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.799864</td>\n",
       "      <td>0.723139</td>\n",
       "      <td>0.742059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>0.676786</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.828575</td>\n",
       "      <td>0.731353</td>\n",
       "      <td>0.761943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.075600</td>\n",
       "      <td>0.687532</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.801703</td>\n",
       "      <td>0.709724</td>\n",
       "      <td>0.735769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.073200</td>\n",
       "      <td>0.681125</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.820692</td>\n",
       "      <td>0.713534</td>\n",
       "      <td>0.746770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>0.686808</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.810892</td>\n",
       "      <td>0.709751</td>\n",
       "      <td>0.739568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.069200</td>\n",
       "      <td>0.689917</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.811437</td>\n",
       "      <td>0.709063</td>\n",
       "      <td>0.739606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 02:08:18,891] Trial 84 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 85 with params: {'learning_rate': 6.256012751877123e-05, 'weight_decay': 0.003, 'warmup_steps': 19, 'lambda_param': 1.0, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:58 < 01:29, 29.38 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.678400</td>\n",
       "      <td>1.190022</td>\n",
       "      <td>0.659028</td>\n",
       "      <td>0.279415</td>\n",
       "      <td>0.266005</td>\n",
       "      <td>0.253452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.859900</td>\n",
       "      <td>0.845661</td>\n",
       "      <td>0.725023</td>\n",
       "      <td>0.340615</td>\n",
       "      <td>0.345767</td>\n",
       "      <td>0.326015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.565900</td>\n",
       "      <td>0.747696</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.424525</td>\n",
       "      <td>0.413805</td>\n",
       "      <td>0.400526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.703224</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.501424</td>\n",
       "      <td>0.474350</td>\n",
       "      <td>0.471512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.333600</td>\n",
       "      <td>0.669595</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>0.514823</td>\n",
       "      <td>0.494659</td>\n",
       "      <td>0.492377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.273400</td>\n",
       "      <td>0.655818</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.573989</td>\n",
       "      <td>0.517971</td>\n",
       "      <td>0.523305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.230700</td>\n",
       "      <td>0.644980</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.602255</td>\n",
       "      <td>0.537814</td>\n",
       "      <td>0.545332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.203000</td>\n",
       "      <td>0.640692</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.644775</td>\n",
       "      <td>0.566347</td>\n",
       "      <td>0.582671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.183300</td>\n",
       "      <td>0.640349</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.663226</td>\n",
       "      <td>0.598846</td>\n",
       "      <td>0.612550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.168300</td>\n",
       "      <td>0.641160</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.663979</td>\n",
       "      <td>0.607193</td>\n",
       "      <td>0.619718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 02:11:18,607] Trial 85 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 86 with params: {'learning_rate': 0.0004333510509755652, 'weight_decay': 0.01, 'warmup_steps': 17, 'lambda_param': 1.0, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:54 < 01:27, 30.01 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.759400</td>\n",
       "      <td>0.692221</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.508493</td>\n",
       "      <td>0.502015</td>\n",
       "      <td>0.491187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.170800</td>\n",
       "      <td>0.685575</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.694518</td>\n",
       "      <td>0.640003</td>\n",
       "      <td>0.652792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.107800</td>\n",
       "      <td>0.689572</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.743123</td>\n",
       "      <td>0.674592</td>\n",
       "      <td>0.692616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.680827</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.797730</td>\n",
       "      <td>0.697430</td>\n",
       "      <td>0.726717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.678227</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.819970</td>\n",
       "      <td>0.703909</td>\n",
       "      <td>0.737846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075800</td>\n",
       "      <td>0.666032</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.805543</td>\n",
       "      <td>0.712444</td>\n",
       "      <td>0.740816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.692522</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.788572</td>\n",
       "      <td>0.703787</td>\n",
       "      <td>0.730314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.697609</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.803006</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>0.735202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.694945</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.805873</td>\n",
       "      <td>0.705323</td>\n",
       "      <td>0.736499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.700298</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.806682</td>\n",
       "      <td>0.716267</td>\n",
       "      <td>0.743643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 02:14:14,465] Trial 86 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 87 with params: {'learning_rate': 0.000454956825370539, 'weight_decay': 0.003, 'warmup_steps': 53, 'lambda_param': 0.8, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 03:00 < 01:30, 29.15 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.793200</td>\n",
       "      <td>0.671402</td>\n",
       "      <td>0.779102</td>\n",
       "      <td>0.545103</td>\n",
       "      <td>0.504756</td>\n",
       "      <td>0.502473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.168300</td>\n",
       "      <td>0.654031</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.744271</td>\n",
       "      <td>0.651835</td>\n",
       "      <td>0.680910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.106300</td>\n",
       "      <td>0.696870</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.779617</td>\n",
       "      <td>0.693135</td>\n",
       "      <td>0.720274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.681531</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.812210</td>\n",
       "      <td>0.705673</td>\n",
       "      <td>0.734869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.079600</td>\n",
       "      <td>0.682886</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.817202</td>\n",
       "      <td>0.730495</td>\n",
       "      <td>0.754798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.689731</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.802850</td>\n",
       "      <td>0.690321</td>\n",
       "      <td>0.723032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.071400</td>\n",
       "      <td>0.706570</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>0.789922</td>\n",
       "      <td>0.689544</td>\n",
       "      <td>0.719639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.069800</td>\n",
       "      <td>0.713161</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.810413</td>\n",
       "      <td>0.685531</td>\n",
       "      <td>0.722091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068500</td>\n",
       "      <td>0.718895</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.802289</td>\n",
       "      <td>0.702479</td>\n",
       "      <td>0.729105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>0.720306</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.805860</td>\n",
       "      <td>0.699215</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 02:17:15,528] Trial 87 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 88 with params: {'learning_rate': 0.00046987899906866565, 'weight_decay': 0.01, 'warmup_steps': 4, 'lambda_param': 0.9, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:25, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.712400</td>\n",
       "      <td>0.663725</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.599671</td>\n",
       "      <td>0.534764</td>\n",
       "      <td>0.547629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.687865</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.691263</td>\n",
       "      <td>0.649439</td>\n",
       "      <td>0.657628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>0.727399</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.766620</td>\n",
       "      <td>0.708145</td>\n",
       "      <td>0.720379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.087700</td>\n",
       "      <td>0.671171</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.803823</td>\n",
       "      <td>0.718494</td>\n",
       "      <td>0.741978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.079300</td>\n",
       "      <td>0.678191</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.798991</td>\n",
       "      <td>0.725038</td>\n",
       "      <td>0.746043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>0.686910</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.812618</td>\n",
       "      <td>0.726562</td>\n",
       "      <td>0.752470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.712378</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.809842</td>\n",
       "      <td>0.711443</td>\n",
       "      <td>0.739138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.069400</td>\n",
       "      <td>0.697191</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.797311</td>\n",
       "      <td>0.724020</td>\n",
       "      <td>0.743245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.702724</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.808865</td>\n",
       "      <td>0.737460</td>\n",
       "      <td>0.759443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.709416</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.797981</td>\n",
       "      <td>0.728046</td>\n",
       "      <td>0.745973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.065600</td>\n",
       "      <td>0.699980</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.736632</td>\n",
       "      <td>0.750676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.065200</td>\n",
       "      <td>0.698501</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.810228</td>\n",
       "      <td>0.741548</td>\n",
       "      <td>0.759778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.699008</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.800163</td>\n",
       "      <td>0.744465</td>\n",
       "      <td>0.756966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.691597</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.809938</td>\n",
       "      <td>0.739806</td>\n",
       "      <td>0.759390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.063400</td>\n",
       "      <td>0.688825</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.809682</td>\n",
       "      <td>0.743876</td>\n",
       "      <td>0.761416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 02:21:42,775] Trial 88 finished with value: 0.7614159257587808 and parameters: {'learning_rate': 0.00046987899906866565, 'weight_decay': 0.01, 'warmup_steps': 4, 'lambda_param': 0.9, 'temperature': 3.5}. Best is trial 51 with value: 0.7621312725763352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 89 with params: {'learning_rate': 0.00046088735144171096, 'weight_decay': 0.009000000000000001, 'warmup_steps': 9, 'lambda_param': 0.7000000000000001, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:55 < 01:27, 29.97 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.722200</td>\n",
       "      <td>0.655089</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.577130</td>\n",
       "      <td>0.536899</td>\n",
       "      <td>0.535648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.163800</td>\n",
       "      <td>0.660456</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.737965</td>\n",
       "      <td>0.657017</td>\n",
       "      <td>0.677887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.104700</td>\n",
       "      <td>0.678954</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.734382</td>\n",
       "      <td>0.687181</td>\n",
       "      <td>0.697028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.681826</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.806207</td>\n",
       "      <td>0.721130</td>\n",
       "      <td>0.746754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.078800</td>\n",
       "      <td>0.710602</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.810555</td>\n",
       "      <td>0.728072</td>\n",
       "      <td>0.751161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>0.672098</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.813513</td>\n",
       "      <td>0.728739</td>\n",
       "      <td>0.752080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.071900</td>\n",
       "      <td>0.714714</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.788023</td>\n",
       "      <td>0.717940</td>\n",
       "      <td>0.737446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.069500</td>\n",
       "      <td>0.675884</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.779898</td>\n",
       "      <td>0.707852</td>\n",
       "      <td>0.725935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.678681</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.797321</td>\n",
       "      <td>0.731651</td>\n",
       "      <td>0.748581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067100</td>\n",
       "      <td>0.700027</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.799148</td>\n",
       "      <td>0.717971</td>\n",
       "      <td>0.741373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 02:24:38,838] Trial 89 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 90 with params: {'learning_rate': 0.00041772560018200775, 'weight_decay': 0.01, 'warmup_steps': 9, 'lambda_param': 1.0, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:25, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.755500</td>\n",
       "      <td>0.664481</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.517320</td>\n",
       "      <td>0.504899</td>\n",
       "      <td>0.497248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.173600</td>\n",
       "      <td>0.668419</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.676919</td>\n",
       "      <td>0.631699</td>\n",
       "      <td>0.641738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.109100</td>\n",
       "      <td>0.669811</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.732191</td>\n",
       "      <td>0.682736</td>\n",
       "      <td>0.694869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.089500</td>\n",
       "      <td>0.664600</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.806011</td>\n",
       "      <td>0.715755</td>\n",
       "      <td>0.743624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.683066</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.803749</td>\n",
       "      <td>0.726589</td>\n",
       "      <td>0.749837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>0.678554</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.815655</td>\n",
       "      <td>0.726911</td>\n",
       "      <td>0.753628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.703945</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.788573</td>\n",
       "      <td>0.715380</td>\n",
       "      <td>0.737092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.677641</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.805962</td>\n",
       "      <td>0.731670</td>\n",
       "      <td>0.750151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.695895</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.808580</td>\n",
       "      <td>0.727331</td>\n",
       "      <td>0.748317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067400</td>\n",
       "      <td>0.698286</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.807631</td>\n",
       "      <td>0.727785</td>\n",
       "      <td>0.751889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.678941</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.807705</td>\n",
       "      <td>0.712907</td>\n",
       "      <td>0.738784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>0.672444</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.801303</td>\n",
       "      <td>0.728080</td>\n",
       "      <td>0.745645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>0.679057</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.812302</td>\n",
       "      <td>0.728708</td>\n",
       "      <td>0.750846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>0.677519</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.813093</td>\n",
       "      <td>0.727480</td>\n",
       "      <td>0.751091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.064100</td>\n",
       "      <td>0.676725</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.813700</td>\n",
       "      <td>0.727718</td>\n",
       "      <td>0.751509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 02:29:06,164] Trial 90 finished with value: 0.7515088403108894 and parameters: {'learning_rate': 0.00041772560018200775, 'weight_decay': 0.01, 'warmup_steps': 9, 'lambda_param': 1.0, 'temperature': 3.0}. Best is trial 51 with value: 0.7621312725763352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 91 with params: {'learning_rate': 0.00019999234429283712, 'weight_decay': 0.008, 'warmup_steps': 3, 'lambda_param': 0.7000000000000001, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:46, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.049700</td>\n",
       "      <td>0.736608</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.432960</td>\n",
       "      <td>0.432277</td>\n",
       "      <td>0.420376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.322900</td>\n",
       "      <td>0.648758</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.611686</td>\n",
       "      <td>0.557331</td>\n",
       "      <td>0.565436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.178400</td>\n",
       "      <td>0.647008</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.668094</td>\n",
       "      <td>0.611929</td>\n",
       "      <td>0.623896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.127300</td>\n",
       "      <td>0.650836</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.755216</td>\n",
       "      <td>0.632401</td>\n",
       "      <td>0.670299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.105800</td>\n",
       "      <td>0.651806</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.735396</td>\n",
       "      <td>0.663194</td>\n",
       "      <td>0.683107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.094100</td>\n",
       "      <td>0.644862</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.748077</td>\n",
       "      <td>0.664531</td>\n",
       "      <td>0.691824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>0.652296</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.810627</td>\n",
       "      <td>0.707454</td>\n",
       "      <td>0.739688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.082700</td>\n",
       "      <td>0.650720</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.812079</td>\n",
       "      <td>0.725579</td>\n",
       "      <td>0.750333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.079200</td>\n",
       "      <td>0.658650</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.802001</td>\n",
       "      <td>0.720137</td>\n",
       "      <td>0.745598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.076100</td>\n",
       "      <td>0.668978</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.814499</td>\n",
       "      <td>0.717861</td>\n",
       "      <td>0.746896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.658606</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.819644</td>\n",
       "      <td>0.728158</td>\n",
       "      <td>0.756622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.073100</td>\n",
       "      <td>0.660801</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.798017</td>\n",
       "      <td>0.735922</td>\n",
       "      <td>0.754068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.656575</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.802853</td>\n",
       "      <td>0.728623</td>\n",
       "      <td>0.750834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>0.658446</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.809414</td>\n",
       "      <td>0.726933</td>\n",
       "      <td>0.752021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.658795</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.816596</td>\n",
       "      <td>0.725099</td>\n",
       "      <td>0.753137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 02:33:54,468] Trial 91 finished with value: 0.7531369567121389 and parameters: {'learning_rate': 0.00019999234429283712, 'weight_decay': 0.008, 'warmup_steps': 3, 'lambda_param': 0.7000000000000001, 'temperature': 5.5}. Best is trial 51 with value: 0.7621312725763352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 92 with params: {'learning_rate': 0.0004922578519032032, 'weight_decay': 0.008, 'warmup_steps': 6, 'lambda_param': 1.0, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:27, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.699500</td>\n",
       "      <td>0.658343</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.583285</td>\n",
       "      <td>0.535980</td>\n",
       "      <td>0.541213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.155900</td>\n",
       "      <td>0.667620</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.735033</td>\n",
       "      <td>0.661338</td>\n",
       "      <td>0.677852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.102100</td>\n",
       "      <td>0.665423</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.772590</td>\n",
       "      <td>0.715973</td>\n",
       "      <td>0.728441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.085900</td>\n",
       "      <td>0.687791</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.795279</td>\n",
       "      <td>0.731258</td>\n",
       "      <td>0.747571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.078100</td>\n",
       "      <td>0.720140</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.805389</td>\n",
       "      <td>0.730091</td>\n",
       "      <td>0.746613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.073900</td>\n",
       "      <td>0.690937</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.807294</td>\n",
       "      <td>0.737379</td>\n",
       "      <td>0.756175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.693691</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.810638</td>\n",
       "      <td>0.731036</td>\n",
       "      <td>0.753822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.689324</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.799652</td>\n",
       "      <td>0.736334</td>\n",
       "      <td>0.752324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.067700</td>\n",
       "      <td>0.720453</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.799598</td>\n",
       "      <td>0.732047</td>\n",
       "      <td>0.746340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066600</td>\n",
       "      <td>0.717346</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.814258</td>\n",
       "      <td>0.737241</td>\n",
       "      <td>0.759720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.065600</td>\n",
       "      <td>0.701254</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.785673</td>\n",
       "      <td>0.748242</td>\n",
       "      <td>0.754090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.064700</td>\n",
       "      <td>0.687607</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.801362</td>\n",
       "      <td>0.750981</td>\n",
       "      <td>0.762857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.695278</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.795046</td>\n",
       "      <td>0.745446</td>\n",
       "      <td>0.759155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.700672</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.808412</td>\n",
       "      <td>0.745135</td>\n",
       "      <td>0.763822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.063300</td>\n",
       "      <td>0.697003</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.808971</td>\n",
       "      <td>0.746004</td>\n",
       "      <td>0.764452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 02:38:23,729] Trial 92 finished with value: 0.7644517643387146 and parameters: {'learning_rate': 0.0004922578519032032, 'weight_decay': 0.008, 'warmup_steps': 6, 'lambda_param': 1.0, 'temperature': 4.0}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 93 with params: {'learning_rate': 0.0004920237513932797, 'weight_decay': 0.008, 'warmup_steps': 7, 'lambda_param': 0.9, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:27, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.700500</td>\n",
       "      <td>0.662033</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.599624</td>\n",
       "      <td>0.548762</td>\n",
       "      <td>0.552814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.156200</td>\n",
       "      <td>0.667579</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.720201</td>\n",
       "      <td>0.658583</td>\n",
       "      <td>0.672911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.101900</td>\n",
       "      <td>0.667530</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.782350</td>\n",
       "      <td>0.726772</td>\n",
       "      <td>0.738842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.086100</td>\n",
       "      <td>0.705966</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.815567</td>\n",
       "      <td>0.722792</td>\n",
       "      <td>0.750012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.078500</td>\n",
       "      <td>0.689834</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.815164</td>\n",
       "      <td>0.708252</td>\n",
       "      <td>0.741718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.694127</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.842628</td>\n",
       "      <td>0.733455</td>\n",
       "      <td>0.767516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.712043</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>0.803384</td>\n",
       "      <td>0.714663</td>\n",
       "      <td>0.740876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.069800</td>\n",
       "      <td>0.712244</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.818252</td>\n",
       "      <td>0.716712</td>\n",
       "      <td>0.746762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.709023</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>0.774604</td>\n",
       "      <td>0.730246</td>\n",
       "      <td>0.737404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.812277</td>\n",
       "      <td>0.728898</td>\n",
       "      <td>0.753230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.705821</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.809625</td>\n",
       "      <td>0.720030</td>\n",
       "      <td>0.743335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>0.700350</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.804945</td>\n",
       "      <td>0.731432</td>\n",
       "      <td>0.749843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>0.707681</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.815970</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.755818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.063700</td>\n",
       "      <td>0.704416</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.830263</td>\n",
       "      <td>0.731314</td>\n",
       "      <td>0.761904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.063400</td>\n",
       "      <td>0.702766</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.822903</td>\n",
       "      <td>0.733915</td>\n",
       "      <td>0.760797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 02:42:53,107] Trial 93 finished with value: 0.7607969747995779 and parameters: {'learning_rate': 0.0004920237513932797, 'weight_decay': 0.008, 'warmup_steps': 7, 'lambda_param': 0.9, 'temperature': 4.0}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 94 with params: {'learning_rate': 0.00037109539198303706, 'weight_decay': 0.007, 'warmup_steps': 4, 'lambda_param': 0.9, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:57 < 01:28, 29.58 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.792000</td>\n",
       "      <td>0.667562</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.558389</td>\n",
       "      <td>0.518438</td>\n",
       "      <td>0.520431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.190200</td>\n",
       "      <td>0.646888</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.722155</td>\n",
       "      <td>0.639136</td>\n",
       "      <td>0.657682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.115900</td>\n",
       "      <td>0.651468</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.707214</td>\n",
       "      <td>0.654353</td>\n",
       "      <td>0.665600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.092600</td>\n",
       "      <td>0.656821</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.785617</td>\n",
       "      <td>0.690785</td>\n",
       "      <td>0.717733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.082400</td>\n",
       "      <td>0.665996</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.809557</td>\n",
       "      <td>0.698635</td>\n",
       "      <td>0.730422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.077300</td>\n",
       "      <td>0.700938</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.803062</td>\n",
       "      <td>0.702839</td>\n",
       "      <td>0.734281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.073900</td>\n",
       "      <td>0.695373</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.787109</td>\n",
       "      <td>0.712210</td>\n",
       "      <td>0.731342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.071600</td>\n",
       "      <td>0.679080</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.721549</td>\n",
       "      <td>0.746949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.069700</td>\n",
       "      <td>0.688091</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.803416</td>\n",
       "      <td>0.720373</td>\n",
       "      <td>0.742684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.068500</td>\n",
       "      <td>0.685219</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.819265</td>\n",
       "      <td>0.711946</td>\n",
       "      <td>0.744709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 02:45:51,533] Trial 94 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 95 with params: {'learning_rate': 0.000279973895831848, 'weight_decay': 0.01, 'warmup_steps': 11, 'lambda_param': 1.0, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:27, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.914600</td>\n",
       "      <td>0.705240</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.474713</td>\n",
       "      <td>0.460313</td>\n",
       "      <td>0.447762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.239200</td>\n",
       "      <td>0.643209</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.647926</td>\n",
       "      <td>0.588141</td>\n",
       "      <td>0.603050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.136700</td>\n",
       "      <td>0.652464</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.726015</td>\n",
       "      <td>0.645318</td>\n",
       "      <td>0.667316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.104400</td>\n",
       "      <td>0.671544</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.775070</td>\n",
       "      <td>0.650957</td>\n",
       "      <td>0.687722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.090800</td>\n",
       "      <td>0.654440</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.814278</td>\n",
       "      <td>0.709206</td>\n",
       "      <td>0.741610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.082900</td>\n",
       "      <td>0.654603</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.823127</td>\n",
       "      <td>0.721390</td>\n",
       "      <td>0.755152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.077900</td>\n",
       "      <td>0.670092</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.813542</td>\n",
       "      <td>0.718357</td>\n",
       "      <td>0.746436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>0.661426</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.818445</td>\n",
       "      <td>0.714559</td>\n",
       "      <td>0.745061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.072900</td>\n",
       "      <td>0.672944</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.817703</td>\n",
       "      <td>0.724277</td>\n",
       "      <td>0.750339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.674359</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.825338</td>\n",
       "      <td>0.720849</td>\n",
       "      <td>0.751335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.069500</td>\n",
       "      <td>0.683527</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.814117</td>\n",
       "      <td>0.718091</td>\n",
       "      <td>0.745089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.676685</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.808174</td>\n",
       "      <td>0.721346</td>\n",
       "      <td>0.746338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.671074</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.813769</td>\n",
       "      <td>0.725743</td>\n",
       "      <td>0.751578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.067100</td>\n",
       "      <td>0.672015</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.813567</td>\n",
       "      <td>0.724095</td>\n",
       "      <td>0.749904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.671610</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.817344</td>\n",
       "      <td>0.722585</td>\n",
       "      <td>0.750709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 02:50:20,880] Trial 95 finished with value: 0.750708681805861 and parameters: {'learning_rate': 0.000279973895831848, 'weight_decay': 0.01, 'warmup_steps': 11, 'lambda_param': 1.0, 'temperature': 4.5}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 96 with params: {'learning_rate': 1.0675005523304308e-05, 'weight_decay': 0.0, 'warmup_steps': 43, 'lambda_param': 0.30000000000000004, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:33 < 03:07, 27.98 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.263600</td>\n",
       "      <td>2.083632</td>\n",
       "      <td>0.346471</td>\n",
       "      <td>0.070881</td>\n",
       "      <td>0.072089</td>\n",
       "      <td>0.050887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.944300</td>\n",
       "      <td>1.822462</td>\n",
       "      <td>0.457379</td>\n",
       "      <td>0.107089</td>\n",
       "      <td>0.121229</td>\n",
       "      <td>0.103648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.706200</td>\n",
       "      <td>1.626155</td>\n",
       "      <td>0.501375</td>\n",
       "      <td>0.135240</td>\n",
       "      <td>0.147241</td>\n",
       "      <td>0.123733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.523200</td>\n",
       "      <td>1.478107</td>\n",
       "      <td>0.543538</td>\n",
       "      <td>0.224975</td>\n",
       "      <td>0.172036</td>\n",
       "      <td>0.154484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.377400</td>\n",
       "      <td>1.363869</td>\n",
       "      <td>0.587534</td>\n",
       "      <td>0.255111</td>\n",
       "      <td>0.210689</td>\n",
       "      <td>0.195545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 02:51:55,559] Trial 96 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 97 with params: {'learning_rate': 0.0004532253306997267, 'weight_decay': 0.009000000000000001, 'warmup_steps': 15, 'lambda_param': 0.9, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:56 < 01:28, 29.67 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.739200</td>\n",
       "      <td>0.663945</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.515160</td>\n",
       "      <td>0.511017</td>\n",
       "      <td>0.504953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.165200</td>\n",
       "      <td>0.651811</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.687312</td>\n",
       "      <td>0.644018</td>\n",
       "      <td>0.653908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.105700</td>\n",
       "      <td>0.665063</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.763309</td>\n",
       "      <td>0.697278</td>\n",
       "      <td>0.713898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.087900</td>\n",
       "      <td>0.661039</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.815281</td>\n",
       "      <td>0.720041</td>\n",
       "      <td>0.749705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.079200</td>\n",
       "      <td>0.675285</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.816164</td>\n",
       "      <td>0.733915</td>\n",
       "      <td>0.758856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075200</td>\n",
       "      <td>0.676748</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.792607</td>\n",
       "      <td>0.715563</td>\n",
       "      <td>0.737421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.697914</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.811263</td>\n",
       "      <td>0.723288</td>\n",
       "      <td>0.750664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.069600</td>\n",
       "      <td>0.683697</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.792964</td>\n",
       "      <td>0.726549</td>\n",
       "      <td>0.743768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.670961</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.798213</td>\n",
       "      <td>0.730764</td>\n",
       "      <td>0.749686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066900</td>\n",
       "      <td>0.685611</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.794821</td>\n",
       "      <td>0.712302</td>\n",
       "      <td>0.737038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 02:54:53,516] Trial 97 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 98 with params: {'learning_rate': 0.00035248979435431767, 'weight_decay': 0.008, 'warmup_steps': 3, 'lambda_param': 0.8, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:29, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.809300</td>\n",
       "      <td>0.680405</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.520226</td>\n",
       "      <td>0.510901</td>\n",
       "      <td>0.501498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.197600</td>\n",
       "      <td>0.646280</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.701316</td>\n",
       "      <td>0.629518</td>\n",
       "      <td>0.647402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.119900</td>\n",
       "      <td>0.658645</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.754513</td>\n",
       "      <td>0.676118</td>\n",
       "      <td>0.700567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.094600</td>\n",
       "      <td>0.651384</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.801740</td>\n",
       "      <td>0.703100</td>\n",
       "      <td>0.730740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.083900</td>\n",
       "      <td>0.665245</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.819994</td>\n",
       "      <td>0.714983</td>\n",
       "      <td>0.745652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.078300</td>\n",
       "      <td>0.674528</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.816913</td>\n",
       "      <td>0.716203</td>\n",
       "      <td>0.748292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.681591</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.821829</td>\n",
       "      <td>0.726697</td>\n",
       "      <td>0.755100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.675378</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.815177</td>\n",
       "      <td>0.725815</td>\n",
       "      <td>0.753486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>0.672871</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.815052</td>\n",
       "      <td>0.723309</td>\n",
       "      <td>0.749779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.068500</td>\n",
       "      <td>0.681863</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.806532</td>\n",
       "      <td>0.718075</td>\n",
       "      <td>0.742880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.067500</td>\n",
       "      <td>0.692720</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.709595</td>\n",
       "      <td>0.739906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.066600</td>\n",
       "      <td>0.668770</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.807316</td>\n",
       "      <td>0.714268</td>\n",
       "      <td>0.741890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.065800</td>\n",
       "      <td>0.670119</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.813224</td>\n",
       "      <td>0.713800</td>\n",
       "      <td>0.743192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.065300</td>\n",
       "      <td>0.673018</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.829932</td>\n",
       "      <td>0.707080</td>\n",
       "      <td>0.744129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>0.668938</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.806117</td>\n",
       "      <td>0.708546</td>\n",
       "      <td>0.738355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 02:59:24,582] Trial 98 finished with value: 0.7383546195551596 and parameters: {'learning_rate': 0.00035248979435431767, 'weight_decay': 0.008, 'warmup_steps': 3, 'lambda_param': 0.8, 'temperature': 3.0}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 99 with params: {'learning_rate': 1.6023858648203628e-05, 'weight_decay': 0.01, 'warmup_steps': 28, 'lambda_param': 0.30000000000000004, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:29 < 02:58, 29.33 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.180500</td>\n",
       "      <td>1.940521</td>\n",
       "      <td>0.407883</td>\n",
       "      <td>0.096859</td>\n",
       "      <td>0.092319</td>\n",
       "      <td>0.075278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.749300</td>\n",
       "      <td>1.603128</td>\n",
       "      <td>0.508708</td>\n",
       "      <td>0.181015</td>\n",
       "      <td>0.152079</td>\n",
       "      <td>0.130582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.451300</td>\n",
       "      <td>1.379294</td>\n",
       "      <td>0.582951</td>\n",
       "      <td>0.245538</td>\n",
       "      <td>0.209732</td>\n",
       "      <td>0.195184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.240600</td>\n",
       "      <td>1.219545</td>\n",
       "      <td>0.647113</td>\n",
       "      <td>0.279377</td>\n",
       "      <td>0.256934</td>\n",
       "      <td>0.244727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.082000</td>\n",
       "      <td>1.102283</td>\n",
       "      <td>0.679193</td>\n",
       "      <td>0.258792</td>\n",
       "      <td>0.281212</td>\n",
       "      <td>0.258976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 03:00:54,947] Trial 99 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 with params: {'learning_rate': 0.00013391379320794176, 'weight_decay': 0.005, 'warmup_steps': 18, 'lambda_param': 1.0, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:58 < 01:29, 29.42 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.276200</td>\n",
       "      <td>0.833310</td>\n",
       "      <td>0.730522</td>\n",
       "      <td>0.357170</td>\n",
       "      <td>0.357751</td>\n",
       "      <td>0.338465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.470400</td>\n",
       "      <td>0.684407</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.499149</td>\n",
       "      <td>0.480887</td>\n",
       "      <td>0.477827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.271300</td>\n",
       "      <td>0.644058</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.575245</td>\n",
       "      <td>0.538586</td>\n",
       "      <td>0.540886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>0.647863</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.671290</td>\n",
       "      <td>0.587206</td>\n",
       "      <td>0.608287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.144400</td>\n",
       "      <td>0.653186</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.715542</td>\n",
       "      <td>0.633561</td>\n",
       "      <td>0.655476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>0.642200</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.775596</td>\n",
       "      <td>0.661153</td>\n",
       "      <td>0.695629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.108700</td>\n",
       "      <td>0.640945</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.770956</td>\n",
       "      <td>0.668869</td>\n",
       "      <td>0.699255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.100200</td>\n",
       "      <td>0.645878</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.769258</td>\n",
       "      <td>0.675705</td>\n",
       "      <td>0.704759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.094200</td>\n",
       "      <td>0.645437</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.777974</td>\n",
       "      <td>0.681189</td>\n",
       "      <td>0.709279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.089300</td>\n",
       "      <td>0.659903</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.773353</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.709129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 03:03:54,406] Trial 100 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 101 with params: {'learning_rate': 0.00028131770461181036, 'weight_decay': 0.007, 'warmup_steps': 9, 'lambda_param': 0.7000000000000001, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:25, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.907700</td>\n",
       "      <td>0.701872</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.476645</td>\n",
       "      <td>0.468678</td>\n",
       "      <td>0.458016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.238700</td>\n",
       "      <td>0.647965</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.636002</td>\n",
       "      <td>0.587675</td>\n",
       "      <td>0.597456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.136600</td>\n",
       "      <td>0.655061</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.714658</td>\n",
       "      <td>0.645863</td>\n",
       "      <td>0.664491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.103900</td>\n",
       "      <td>0.669887</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.778535</td>\n",
       "      <td>0.675789</td>\n",
       "      <td>0.707233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.090500</td>\n",
       "      <td>0.654941</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.794282</td>\n",
       "      <td>0.693813</td>\n",
       "      <td>0.722851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.082600</td>\n",
       "      <td>0.651467</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.821579</td>\n",
       "      <td>0.721401</td>\n",
       "      <td>0.753611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.670100</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.812768</td>\n",
       "      <td>0.730779</td>\n",
       "      <td>0.756538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.663644</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.810070</td>\n",
       "      <td>0.726001</td>\n",
       "      <td>0.749858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.072800</td>\n",
       "      <td>0.673160</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.818078</td>\n",
       "      <td>0.721577</td>\n",
       "      <td>0.749117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.679983</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.823116</td>\n",
       "      <td>0.723893</td>\n",
       "      <td>0.752881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.069400</td>\n",
       "      <td>0.685807</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.805260</td>\n",
       "      <td>0.720627</td>\n",
       "      <td>0.743528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.671506</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.794739</td>\n",
       "      <td>0.719122</td>\n",
       "      <td>0.741307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.067700</td>\n",
       "      <td>0.675840</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.816801</td>\n",
       "      <td>0.721254</td>\n",
       "      <td>0.749165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.674042</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.814102</td>\n",
       "      <td>0.721209</td>\n",
       "      <td>0.749891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.673248</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.812503</td>\n",
       "      <td>0.720541</td>\n",
       "      <td>0.748912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 03:08:21,323] Trial 101 finished with value: 0.7489120683422849 and parameters: {'learning_rate': 0.00028131770461181036, 'weight_decay': 0.007, 'warmup_steps': 9, 'lambda_param': 0.7000000000000001, 'temperature': 7.0}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 102 with params: {'learning_rate': 0.00047300971399577313, 'weight_decay': 0.007, 'warmup_steps': 0, 'lambda_param': 0.9, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:27, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.697000</td>\n",
       "      <td>0.675313</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.586446</td>\n",
       "      <td>0.533091</td>\n",
       "      <td>0.541796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.158900</td>\n",
       "      <td>0.670600</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.695413</td>\n",
       "      <td>0.646768</td>\n",
       "      <td>0.655051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>0.690371</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.763506</td>\n",
       "      <td>0.728174</td>\n",
       "      <td>0.733515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.086100</td>\n",
       "      <td>0.700948</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.810593</td>\n",
       "      <td>0.715549</td>\n",
       "      <td>0.745403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.674470</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.805311</td>\n",
       "      <td>0.730469</td>\n",
       "      <td>0.752833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.706832</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.819981</td>\n",
       "      <td>0.723897</td>\n",
       "      <td>0.754216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.711244</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.817880</td>\n",
       "      <td>0.714338</td>\n",
       "      <td>0.743893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.069500</td>\n",
       "      <td>0.699236</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.803415</td>\n",
       "      <td>0.734250</td>\n",
       "      <td>0.752108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.734618</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.816174</td>\n",
       "      <td>0.710749</td>\n",
       "      <td>0.743087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066300</td>\n",
       "      <td>0.706773</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.802239</td>\n",
       "      <td>0.729899</td>\n",
       "      <td>0.752626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.066200</td>\n",
       "      <td>0.708914</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.724037</td>\n",
       "      <td>0.747275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.064900</td>\n",
       "      <td>0.706148</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.823347</td>\n",
       "      <td>0.735691</td>\n",
       "      <td>0.762928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.063900</td>\n",
       "      <td>0.705035</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.810494</td>\n",
       "      <td>0.728426</td>\n",
       "      <td>0.749939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.063600</td>\n",
       "      <td>0.706662</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.822088</td>\n",
       "      <td>0.732206</td>\n",
       "      <td>0.761490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.063400</td>\n",
       "      <td>0.699538</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.820526</td>\n",
       "      <td>0.735886</td>\n",
       "      <td>0.762600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 03:12:49,952] Trial 102 finished with value: 0.7626002475427971 and parameters: {'learning_rate': 0.00047300971399577313, 'weight_decay': 0.007, 'warmup_steps': 0, 'lambda_param': 0.9, 'temperature': 3.5}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 103 with params: {'learning_rate': 0.0004072826259549412, 'weight_decay': 0.008, 'warmup_steps': 4, 'lambda_param': 1.0, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:33, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.759200</td>\n",
       "      <td>0.675556</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.541831</td>\n",
       "      <td>0.514618</td>\n",
       "      <td>0.513500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.177700</td>\n",
       "      <td>0.660413</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.720068</td>\n",
       "      <td>0.659074</td>\n",
       "      <td>0.671099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.110300</td>\n",
       "      <td>0.685885</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.788918</td>\n",
       "      <td>0.697071</td>\n",
       "      <td>0.724164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.089800</td>\n",
       "      <td>0.666319</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.811217</td>\n",
       "      <td>0.707836</td>\n",
       "      <td>0.739227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.080200</td>\n",
       "      <td>0.668106</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.804437</td>\n",
       "      <td>0.712438</td>\n",
       "      <td>0.741053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.076400</td>\n",
       "      <td>0.698634</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.794114</td>\n",
       "      <td>0.711209</td>\n",
       "      <td>0.734905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072700</td>\n",
       "      <td>0.688051</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.805124</td>\n",
       "      <td>0.717026</td>\n",
       "      <td>0.740863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>0.680274</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.827457</td>\n",
       "      <td>0.724732</td>\n",
       "      <td>0.755426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.713561</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.810163</td>\n",
       "      <td>0.706916</td>\n",
       "      <td>0.737344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067300</td>\n",
       "      <td>0.682555</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.806858</td>\n",
       "      <td>0.725604</td>\n",
       "      <td>0.748414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.066600</td>\n",
       "      <td>0.669789</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.811951</td>\n",
       "      <td>0.714464</td>\n",
       "      <td>0.744526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>0.672905</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.822989</td>\n",
       "      <td>0.721534</td>\n",
       "      <td>0.752974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>0.685149</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.811373</td>\n",
       "      <td>0.723225</td>\n",
       "      <td>0.750230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>0.683913</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.812264</td>\n",
       "      <td>0.718869</td>\n",
       "      <td>0.747775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.064100</td>\n",
       "      <td>0.679373</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.812932</td>\n",
       "      <td>0.721981</td>\n",
       "      <td>0.750038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 03:17:25,319] Trial 103 finished with value: 0.7500379053298729 and parameters: {'learning_rate': 0.0004072826259549412, 'weight_decay': 0.008, 'warmup_steps': 4, 'lambda_param': 1.0, 'temperature': 3.5}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 104 with params: {'learning_rate': 0.00047794578608353563, 'weight_decay': 0.006, 'warmup_steps': 8, 'lambda_param': 0.9, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:39, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.712700</td>\n",
       "      <td>0.659104</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.544473</td>\n",
       "      <td>0.517515</td>\n",
       "      <td>0.517338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.160300</td>\n",
       "      <td>0.661395</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.738763</td>\n",
       "      <td>0.659988</td>\n",
       "      <td>0.681914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.104200</td>\n",
       "      <td>0.664964</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.767772</td>\n",
       "      <td>0.702551</td>\n",
       "      <td>0.716345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.086800</td>\n",
       "      <td>0.672805</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.811103</td>\n",
       "      <td>0.717716</td>\n",
       "      <td>0.745976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.079500</td>\n",
       "      <td>0.685794</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.824621</td>\n",
       "      <td>0.722759</td>\n",
       "      <td>0.756674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.074200</td>\n",
       "      <td>0.705250</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.813224</td>\n",
       "      <td>0.712014</td>\n",
       "      <td>0.746020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.071900</td>\n",
       "      <td>0.720934</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.813498</td>\n",
       "      <td>0.707721</td>\n",
       "      <td>0.738443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.069300</td>\n",
       "      <td>0.686725</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.800015</td>\n",
       "      <td>0.712388</td>\n",
       "      <td>0.735142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.709202</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.804077</td>\n",
       "      <td>0.717341</td>\n",
       "      <td>0.745278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066600</td>\n",
       "      <td>0.709706</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.814094</td>\n",
       "      <td>0.722854</td>\n",
       "      <td>0.750388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.695582</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.802835</td>\n",
       "      <td>0.725813</td>\n",
       "      <td>0.742375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>0.702362</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.800764</td>\n",
       "      <td>0.718712</td>\n",
       "      <td>0.743699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.690008</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.807461</td>\n",
       "      <td>0.730514</td>\n",
       "      <td>0.753568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.063800</td>\n",
       "      <td>0.692307</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.811201</td>\n",
       "      <td>0.711952</td>\n",
       "      <td>0.740789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.063600</td>\n",
       "      <td>0.689285</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.812081</td>\n",
       "      <td>0.721879</td>\n",
       "      <td>0.749147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jovyan/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--recall/11f90e583db35601050aed380d48e83202a896976b9608432fba9244fb447f24 (last modified on Fri Jan 10 23:14:00 2025) since it couldn't be found locally at evaluate-metric--recall, or remotely on the Hugging Face Hub.\n",
      "[I 2025-03-27 03:22:06,836] Trial 104 finished with value: 0.7491473951940438 and parameters: {'learning_rate': 0.00047794578608353563, 'weight_decay': 0.006, 'warmup_steps': 8, 'lambda_param': 0.9, 'temperature': 3.5}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 105 with params: {'learning_rate': 2.1347915500916424e-05, 'weight_decay': 0.003, 'warmup_steps': 15, 'lambda_param': 0.1, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:28 < 02:56, 29.72 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.101900</td>\n",
       "      <td>1.809544</td>\n",
       "      <td>0.465628</td>\n",
       "      <td>0.108182</td>\n",
       "      <td>0.125732</td>\n",
       "      <td>0.106419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.581200</td>\n",
       "      <td>1.430680</td>\n",
       "      <td>0.567369</td>\n",
       "      <td>0.220411</td>\n",
       "      <td>0.193408</td>\n",
       "      <td>0.179069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.251100</td>\n",
       "      <td>1.195626</td>\n",
       "      <td>0.661778</td>\n",
       "      <td>0.270725</td>\n",
       "      <td>0.270120</td>\n",
       "      <td>0.252915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.031600</td>\n",
       "      <td>1.042671</td>\n",
       "      <td>0.686526</td>\n",
       "      <td>0.265930</td>\n",
       "      <td>0.287290</td>\n",
       "      <td>0.264418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.877700</td>\n",
       "      <td>0.944250</td>\n",
       "      <td>0.704858</td>\n",
       "      <td>0.294217</td>\n",
       "      <td>0.308625</td>\n",
       "      <td>0.284020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 03:23:36,064] Trial 105 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 106 with params: {'learning_rate': 2.777716320805797e-05, 'weight_decay': 0.0, 'warmup_steps': 4, 'lambda_param': 0.30000000000000004, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 03:02 < 01:31, 28.75 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.013400</td>\n",
       "      <td>1.669433</td>\n",
       "      <td>0.496792</td>\n",
       "      <td>0.103141</td>\n",
       "      <td>0.140472</td>\n",
       "      <td>0.113931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.409400</td>\n",
       "      <td>1.264322</td>\n",
       "      <td>0.622365</td>\n",
       "      <td>0.277905</td>\n",
       "      <td>0.241054</td>\n",
       "      <td>0.229056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.062300</td>\n",
       "      <td>1.037101</td>\n",
       "      <td>0.695692</td>\n",
       "      <td>0.309059</td>\n",
       "      <td>0.295618</td>\n",
       "      <td>0.273493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.848600</td>\n",
       "      <td>0.911504</td>\n",
       "      <td>0.710357</td>\n",
       "      <td>0.307167</td>\n",
       "      <td>0.318445</td>\n",
       "      <td>0.291437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.709300</td>\n",
       "      <td>0.838673</td>\n",
       "      <td>0.726856</td>\n",
       "      <td>0.324861</td>\n",
       "      <td>0.340330</td>\n",
       "      <td>0.316068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.618200</td>\n",
       "      <td>0.793373</td>\n",
       "      <td>0.732356</td>\n",
       "      <td>0.397489</td>\n",
       "      <td>0.371021</td>\n",
       "      <td>0.357881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.549100</td>\n",
       "      <td>0.762523</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.410745</td>\n",
       "      <td>0.397336</td>\n",
       "      <td>0.385501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.502500</td>\n",
       "      <td>0.739663</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.443439</td>\n",
       "      <td>0.414118</td>\n",
       "      <td>0.406799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.466000</td>\n",
       "      <td>0.728072</td>\n",
       "      <td>0.755270</td>\n",
       "      <td>0.462219</td>\n",
       "      <td>0.429378</td>\n",
       "      <td>0.422281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.436000</td>\n",
       "      <td>0.717743</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.473863</td>\n",
       "      <td>0.445457</td>\n",
       "      <td>0.440432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jovyan/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--accuracy/f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14 (last modified on Sat Oct 12 13:56:14 2024) since it couldn't be found locally at evaluate-metric--accuracy, or remotely on the Hugging Face Hub.\n",
      "[I 2025-03-27 03:26:39,590] Trial 106 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 107 with params: {'learning_rate': 0.0002529175340539921, 'weight_decay': 0.01, 'warmup_steps': 2, 'lambda_param': 0.9, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:30, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.940400</td>\n",
       "      <td>0.705218</td>\n",
       "      <td>0.765353</td>\n",
       "      <td>0.458219</td>\n",
       "      <td>0.448645</td>\n",
       "      <td>0.434894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.262300</td>\n",
       "      <td>0.646172</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.641919</td>\n",
       "      <td>0.592038</td>\n",
       "      <td>0.602819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.147700</td>\n",
       "      <td>0.650747</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.718903</td>\n",
       "      <td>0.646869</td>\n",
       "      <td>0.667192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.109800</td>\n",
       "      <td>0.651221</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.762867</td>\n",
       "      <td>0.636538</td>\n",
       "      <td>0.675641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.094800</td>\n",
       "      <td>0.655592</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.815302</td>\n",
       "      <td>0.712452</td>\n",
       "      <td>0.746545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.085800</td>\n",
       "      <td>0.649882</td>\n",
       "      <td>0.805683</td>\n",
       "      <td>0.813681</td>\n",
       "      <td>0.725821</td>\n",
       "      <td>0.754529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.663240</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.804472</td>\n",
       "      <td>0.711116</td>\n",
       "      <td>0.738078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.076700</td>\n",
       "      <td>0.653073</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.812292</td>\n",
       "      <td>0.712362</td>\n",
       "      <td>0.742754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.074200</td>\n",
       "      <td>0.670246</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.808214</td>\n",
       "      <td>0.725683</td>\n",
       "      <td>0.747779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.071700</td>\n",
       "      <td>0.670397</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.829216</td>\n",
       "      <td>0.722653</td>\n",
       "      <td>0.756710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.670904</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.804400</td>\n",
       "      <td>0.726353</td>\n",
       "      <td>0.747284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.069400</td>\n",
       "      <td>0.666391</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.813352</td>\n",
       "      <td>0.725271</td>\n",
       "      <td>0.750793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.068500</td>\n",
       "      <td>0.667229</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.829929</td>\n",
       "      <td>0.726356</td>\n",
       "      <td>0.759170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.067900</td>\n",
       "      <td>0.665882</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.824854</td>\n",
       "      <td>0.721978</td>\n",
       "      <td>0.754090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.067700</td>\n",
       "      <td>0.667493</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.817515</td>\n",
       "      <td>0.723704</td>\n",
       "      <td>0.751572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 03:31:11,247] Trial 107 finished with value: 0.7515722024777713 and parameters: {'learning_rate': 0.0002529175340539921, 'weight_decay': 0.01, 'warmup_steps': 2, 'lambda_param': 0.9, 'temperature': 3.0}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 108 with params: {'learning_rate': 0.00045425283942045593, 'weight_decay': 0.009000000000000001, 'warmup_steps': 2, 'lambda_param': 1.0, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 03:00 < 01:30, 29.13 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.720300</td>\n",
       "      <td>0.673605</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.546894</td>\n",
       "      <td>0.514024</td>\n",
       "      <td>0.516486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.165100</td>\n",
       "      <td>0.658323</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.721064</td>\n",
       "      <td>0.659058</td>\n",
       "      <td>0.673010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.106100</td>\n",
       "      <td>0.697693</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.757993</td>\n",
       "      <td>0.682172</td>\n",
       "      <td>0.701860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.087400</td>\n",
       "      <td>0.707223</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.810564</td>\n",
       "      <td>0.709946</td>\n",
       "      <td>0.737792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.079800</td>\n",
       "      <td>0.698317</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.814059</td>\n",
       "      <td>0.732929</td>\n",
       "      <td>0.757520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>0.687327</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.795844</td>\n",
       "      <td>0.732958</td>\n",
       "      <td>0.749767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.071700</td>\n",
       "      <td>0.704606</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.803937</td>\n",
       "      <td>0.727373</td>\n",
       "      <td>0.747887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.069900</td>\n",
       "      <td>0.704511</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.804075</td>\n",
       "      <td>0.715755</td>\n",
       "      <td>0.740548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068700</td>\n",
       "      <td>0.708355</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.794752</td>\n",
       "      <td>0.723165</td>\n",
       "      <td>0.742784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>0.703828</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.780823</td>\n",
       "      <td>0.723977</td>\n",
       "      <td>0.738659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 03:34:12,384] Trial 108 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 109 with params: {'learning_rate': 0.00019347904213013904, 'weight_decay': 0.006, 'warmup_steps': 0, 'lambda_param': 0.7000000000000001, 'temperature': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:57 < 01:28, 29.57 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.060100</td>\n",
       "      <td>0.739061</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.431255</td>\n",
       "      <td>0.415326</td>\n",
       "      <td>0.405136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.336200</td>\n",
       "      <td>0.635913</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.580635</td>\n",
       "      <td>0.536655</td>\n",
       "      <td>0.542391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.185100</td>\n",
       "      <td>0.639360</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.684583</td>\n",
       "      <td>0.612151</td>\n",
       "      <td>0.630187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.131500</td>\n",
       "      <td>0.654138</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.739771</td>\n",
       "      <td>0.628138</td>\n",
       "      <td>0.662272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.109000</td>\n",
       "      <td>0.656346</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.727975</td>\n",
       "      <td>0.648840</td>\n",
       "      <td>0.671194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.096400</td>\n",
       "      <td>0.643390</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.795299</td>\n",
       "      <td>0.685595</td>\n",
       "      <td>0.721891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.642407</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.823913</td>\n",
       "      <td>0.715191</td>\n",
       "      <td>0.748730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.083800</td>\n",
       "      <td>0.648555</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.807297</td>\n",
       "      <td>0.723678</td>\n",
       "      <td>0.744351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.079800</td>\n",
       "      <td>0.648788</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.808215</td>\n",
       "      <td>0.724651</td>\n",
       "      <td>0.750496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.076900</td>\n",
       "      <td>0.669258</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.814066</td>\n",
       "      <td>0.703624</td>\n",
       "      <td>0.737772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 03:37:10,848] Trial 109 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 110 with params: {'learning_rate': 0.0004591624044512961, 'weight_decay': 0.006, 'warmup_steps': 21, 'lambda_param': 1.0, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:28, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.745500</td>\n",
       "      <td>0.681768</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.551307</td>\n",
       "      <td>0.518322</td>\n",
       "      <td>0.518773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.164200</td>\n",
       "      <td>0.679103</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.711194</td>\n",
       "      <td>0.645417</td>\n",
       "      <td>0.660991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.105600</td>\n",
       "      <td>0.675434</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.762388</td>\n",
       "      <td>0.693663</td>\n",
       "      <td>0.710300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.088100</td>\n",
       "      <td>0.697918</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.809267</td>\n",
       "      <td>0.709374</td>\n",
       "      <td>0.737568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.079500</td>\n",
       "      <td>0.697899</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.819864</td>\n",
       "      <td>0.710205</td>\n",
       "      <td>0.743386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.697197</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.822799</td>\n",
       "      <td>0.712722</td>\n",
       "      <td>0.747094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.071700</td>\n",
       "      <td>0.702821</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.801608</td>\n",
       "      <td>0.711261</td>\n",
       "      <td>0.735397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.720687</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.798488</td>\n",
       "      <td>0.709392</td>\n",
       "      <td>0.732759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068300</td>\n",
       "      <td>0.718364</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.800830</td>\n",
       "      <td>0.719598</td>\n",
       "      <td>0.740793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.715802</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.808785</td>\n",
       "      <td>0.713470</td>\n",
       "      <td>0.741726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.066300</td>\n",
       "      <td>0.700202</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.796079</td>\n",
       "      <td>0.710285</td>\n",
       "      <td>0.735849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.065200</td>\n",
       "      <td>0.704196</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.804742</td>\n",
       "      <td>0.720066</td>\n",
       "      <td>0.743157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.064600</td>\n",
       "      <td>0.693338</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.805836</td>\n",
       "      <td>0.722338</td>\n",
       "      <td>0.746396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.063800</td>\n",
       "      <td>0.697342</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.720774</td>\n",
       "      <td>0.743742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.063600</td>\n",
       "      <td>0.693695</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.802800</td>\n",
       "      <td>0.720331</td>\n",
       "      <td>0.743195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 03:41:40,692] Trial 110 finished with value: 0.743195261913703 and parameters: {'learning_rate': 0.0004591624044512961, 'weight_decay': 0.006, 'warmup_steps': 21, 'lambda_param': 1.0, 'temperature': 4.5}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 111 with params: {'learning_rate': 0.0004114403307727495, 'weight_decay': 0.003, 'warmup_steps': 26, 'lambda_param': 0.2, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:57 < 01:28, 29.61 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.789300</td>\n",
       "      <td>0.679818</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.552493</td>\n",
       "      <td>0.510032</td>\n",
       "      <td>0.506980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.175400</td>\n",
       "      <td>0.671367</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.690217</td>\n",
       "      <td>0.650106</td>\n",
       "      <td>0.653847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.109900</td>\n",
       "      <td>0.672750</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.781341</td>\n",
       "      <td>0.707284</td>\n",
       "      <td>0.723200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.669341</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.804766</td>\n",
       "      <td>0.716328</td>\n",
       "      <td>0.738928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.081400</td>\n",
       "      <td>0.691249</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.771188</td>\n",
       "      <td>0.706317</td>\n",
       "      <td>0.722302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.692472</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.716052</td>\n",
       "      <td>0.744429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072900</td>\n",
       "      <td>0.705797</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.812252</td>\n",
       "      <td>0.714444</td>\n",
       "      <td>0.743669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.678990</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.802218</td>\n",
       "      <td>0.721164</td>\n",
       "      <td>0.744428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.693706</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.805326</td>\n",
       "      <td>0.712075</td>\n",
       "      <td>0.741226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067400</td>\n",
       "      <td>0.683713</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.800987</td>\n",
       "      <td>0.710811</td>\n",
       "      <td>0.736550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 03:44:38,851] Trial 111 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 112 with params: {'learning_rate': 0.00020395568647362994, 'weight_decay': 0.01, 'warmup_steps': 3, 'lambda_param': 0.7000000000000001, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:25, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>0.732235</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.432332</td>\n",
       "      <td>0.432241</td>\n",
       "      <td>0.419967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.317100</td>\n",
       "      <td>0.647764</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.609537</td>\n",
       "      <td>0.558371</td>\n",
       "      <td>0.566077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.175300</td>\n",
       "      <td>0.646743</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.669664</td>\n",
       "      <td>0.611225</td>\n",
       "      <td>0.624066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.125700</td>\n",
       "      <td>0.650222</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.755162</td>\n",
       "      <td>0.634608</td>\n",
       "      <td>0.672013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.104600</td>\n",
       "      <td>0.651739</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.744586</td>\n",
       "      <td>0.673796</td>\n",
       "      <td>0.692071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.093200</td>\n",
       "      <td>0.643377</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.744919</td>\n",
       "      <td>0.664405</td>\n",
       "      <td>0.691002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.085900</td>\n",
       "      <td>0.650249</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.824160</td>\n",
       "      <td>0.724270</td>\n",
       "      <td>0.757456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.082100</td>\n",
       "      <td>0.652998</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.810569</td>\n",
       "      <td>0.714635</td>\n",
       "      <td>0.742430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.078600</td>\n",
       "      <td>0.661706</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.801408</td>\n",
       "      <td>0.726590</td>\n",
       "      <td>0.751106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.672429</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.808925</td>\n",
       "      <td>0.724424</td>\n",
       "      <td>0.750941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.074200</td>\n",
       "      <td>0.659935</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.816068</td>\n",
       "      <td>0.727928</td>\n",
       "      <td>0.753378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.072700</td>\n",
       "      <td>0.662732</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.802460</td>\n",
       "      <td>0.733757</td>\n",
       "      <td>0.754517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.071700</td>\n",
       "      <td>0.659914</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.799248</td>\n",
       "      <td>0.732817</td>\n",
       "      <td>0.752674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.661384</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.807905</td>\n",
       "      <td>0.733170</td>\n",
       "      <td>0.757158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.070600</td>\n",
       "      <td>0.661283</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.814620</td>\n",
       "      <td>0.724861</td>\n",
       "      <td>0.752281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 03:49:05,946] Trial 112 finished with value: 0.7522814226576898 and parameters: {'learning_rate': 0.00020395568647362994, 'weight_decay': 0.01, 'warmup_steps': 3, 'lambda_param': 0.7000000000000001, 'temperature': 7.0}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 113 with params: {'learning_rate': 0.0004258741317669566, 'weight_decay': 0.009000000000000001, 'warmup_steps': 4, 'lambda_param': 0.8, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:59 < 01:29, 29.18 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.743400</td>\n",
       "      <td>0.671482</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.566524</td>\n",
       "      <td>0.531261</td>\n",
       "      <td>0.533200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.172400</td>\n",
       "      <td>0.652242</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.704791</td>\n",
       "      <td>0.631130</td>\n",
       "      <td>0.651070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.107900</td>\n",
       "      <td>0.673231</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.737746</td>\n",
       "      <td>0.693584</td>\n",
       "      <td>0.699146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.088900</td>\n",
       "      <td>0.669778</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.787111</td>\n",
       "      <td>0.693326</td>\n",
       "      <td>0.719975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.662871</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.792242</td>\n",
       "      <td>0.696505</td>\n",
       "      <td>0.723549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075800</td>\n",
       "      <td>0.676868</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.799670</td>\n",
       "      <td>0.715924</td>\n",
       "      <td>0.741858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072300</td>\n",
       "      <td>0.676400</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.813906</td>\n",
       "      <td>0.718882</td>\n",
       "      <td>0.748453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.704492</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.808017</td>\n",
       "      <td>0.732368</td>\n",
       "      <td>0.754520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.705045</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.791011</td>\n",
       "      <td>0.722985</td>\n",
       "      <td>0.742326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.704106</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.795334</td>\n",
       "      <td>0.717326</td>\n",
       "      <td>0.741399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 03:52:06,891] Trial 113 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 114 with params: {'learning_rate': 0.00043145474647907273, 'weight_decay': 0.008, 'warmup_steps': 2, 'lambda_param': 0.8, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:27, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.736600</td>\n",
       "      <td>0.684470</td>\n",
       "      <td>0.777269</td>\n",
       "      <td>0.558541</td>\n",
       "      <td>0.521175</td>\n",
       "      <td>0.522087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.170400</td>\n",
       "      <td>0.654689</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.690564</td>\n",
       "      <td>0.641995</td>\n",
       "      <td>0.651389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.107900</td>\n",
       "      <td>0.674628</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.742671</td>\n",
       "      <td>0.685810</td>\n",
       "      <td>0.697748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>0.672651</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.783465</td>\n",
       "      <td>0.694500</td>\n",
       "      <td>0.719701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.080700</td>\n",
       "      <td>0.663600</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.806117</td>\n",
       "      <td>0.738970</td>\n",
       "      <td>0.758848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.670853</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.824293</td>\n",
       "      <td>0.733697</td>\n",
       "      <td>0.763393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072300</td>\n",
       "      <td>0.675679</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.823495</td>\n",
       "      <td>0.729407</td>\n",
       "      <td>0.758385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>0.685382</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.808962</td>\n",
       "      <td>0.730629</td>\n",
       "      <td>0.753051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.689623</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.800046</td>\n",
       "      <td>0.721420</td>\n",
       "      <td>0.745039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067700</td>\n",
       "      <td>0.697918</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.813345</td>\n",
       "      <td>0.730080</td>\n",
       "      <td>0.757422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>0.685701</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.804255</td>\n",
       "      <td>0.735667</td>\n",
       "      <td>0.755629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>0.684867</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.816253</td>\n",
       "      <td>0.733895</td>\n",
       "      <td>0.759724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.678432</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.807958</td>\n",
       "      <td>0.731796</td>\n",
       "      <td>0.754442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.677195</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.817800</td>\n",
       "      <td>0.742412</td>\n",
       "      <td>0.765813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>0.673393</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.817067</td>\n",
       "      <td>0.732476</td>\n",
       "      <td>0.758792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 03:56:36,049] Trial 114 finished with value: 0.7587922225683519 and parameters: {'learning_rate': 0.00043145474647907273, 'weight_decay': 0.008, 'warmup_steps': 2, 'lambda_param': 0.8, 'temperature': 4.0}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 115 with params: {'learning_rate': 0.00041717431487517826, 'weight_decay': 0.008, 'warmup_steps': 2, 'lambda_param': 0.8, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:29, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.748000</td>\n",
       "      <td>0.680802</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.562245</td>\n",
       "      <td>0.525002</td>\n",
       "      <td>0.526096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.174300</td>\n",
       "      <td>0.648615</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.748541</td>\n",
       "      <td>0.651939</td>\n",
       "      <td>0.678248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.109400</td>\n",
       "      <td>0.662473</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.751522</td>\n",
       "      <td>0.681040</td>\n",
       "      <td>0.699764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.089700</td>\n",
       "      <td>0.656836</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.806038</td>\n",
       "      <td>0.717202</td>\n",
       "      <td>0.740620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.080700</td>\n",
       "      <td>0.680267</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.710831</td>\n",
       "      <td>0.742188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.662255</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.812863</td>\n",
       "      <td>0.733369</td>\n",
       "      <td>0.755104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072900</td>\n",
       "      <td>0.681790</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.807061</td>\n",
       "      <td>0.719866</td>\n",
       "      <td>0.744921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.669947</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.809407</td>\n",
       "      <td>0.734639</td>\n",
       "      <td>0.755127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.069500</td>\n",
       "      <td>0.688775</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.790155</td>\n",
       "      <td>0.720105</td>\n",
       "      <td>0.738850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067700</td>\n",
       "      <td>0.693649</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.803197</td>\n",
       "      <td>0.728843</td>\n",
       "      <td>0.749596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>0.688475</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.803372</td>\n",
       "      <td>0.723598</td>\n",
       "      <td>0.746363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.678643</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.812486</td>\n",
       "      <td>0.725341</td>\n",
       "      <td>0.751930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>0.677838</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.807719</td>\n",
       "      <td>0.734249</td>\n",
       "      <td>0.753251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.064600</td>\n",
       "      <td>0.679523</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.810634</td>\n",
       "      <td>0.731045</td>\n",
       "      <td>0.753791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.678239</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.813265</td>\n",
       "      <td>0.733816</td>\n",
       "      <td>0.755367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 04:01:07,309] Trial 115 finished with value: 0.7553667764672197 and parameters: {'learning_rate': 0.00041717431487517826, 'weight_decay': 0.008, 'warmup_steps': 2, 'lambda_param': 0.8, 'temperature': 4.0}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 116 with params: {'learning_rate': 0.0004111487149533104, 'weight_decay': 0.009000000000000001, 'warmup_steps': 7, 'lambda_param': 0.7000000000000001, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:23, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.759000</td>\n",
       "      <td>0.667200</td>\n",
       "      <td>0.778185</td>\n",
       "      <td>0.518899</td>\n",
       "      <td>0.504773</td>\n",
       "      <td>0.497767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.176500</td>\n",
       "      <td>0.661695</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.682571</td>\n",
       "      <td>0.643498</td>\n",
       "      <td>0.647351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.109700</td>\n",
       "      <td>0.673141</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.740021</td>\n",
       "      <td>0.682974</td>\n",
       "      <td>0.697775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.089200</td>\n",
       "      <td>0.682676</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.813492</td>\n",
       "      <td>0.715567</td>\n",
       "      <td>0.743613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.081300</td>\n",
       "      <td>0.681412</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.816105</td>\n",
       "      <td>0.721898</td>\n",
       "      <td>0.748842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.076100</td>\n",
       "      <td>0.698729</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.812773</td>\n",
       "      <td>0.702750</td>\n",
       "      <td>0.735282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.073100</td>\n",
       "      <td>0.700840</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.791803</td>\n",
       "      <td>0.713206</td>\n",
       "      <td>0.735138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>0.694712</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.801384</td>\n",
       "      <td>0.722495</td>\n",
       "      <td>0.745219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.702429</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.794030</td>\n",
       "      <td>0.715079</td>\n",
       "      <td>0.736370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067700</td>\n",
       "      <td>0.707621</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.818433</td>\n",
       "      <td>0.713840</td>\n",
       "      <td>0.744589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.692876</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.800128</td>\n",
       "      <td>0.712646</td>\n",
       "      <td>0.737847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.686941</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.817034</td>\n",
       "      <td>0.718895</td>\n",
       "      <td>0.748918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.065200</td>\n",
       "      <td>0.691369</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.806674</td>\n",
       "      <td>0.717237</td>\n",
       "      <td>0.743568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.697778</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.807793</td>\n",
       "      <td>0.727140</td>\n",
       "      <td>0.751633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>0.694929</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.807838</td>\n",
       "      <td>0.721608</td>\n",
       "      <td>0.746107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 04:05:32,947] Trial 116 finished with value: 0.7461073696526364 and parameters: {'learning_rate': 0.0004111487149533104, 'weight_decay': 0.009000000000000001, 'warmup_steps': 7, 'lambda_param': 0.7000000000000001, 'temperature': 5.0}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 117 with params: {'learning_rate': 0.0003207579028760763, 'weight_decay': 0.003, 'warmup_steps': 27, 'lambda_param': 0.30000000000000004, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:55 < 01:27, 29.93 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.881700</td>\n",
       "      <td>0.691903</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.491335</td>\n",
       "      <td>0.485925</td>\n",
       "      <td>0.480069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.214200</td>\n",
       "      <td>0.639643</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.704463</td>\n",
       "      <td>0.615511</td>\n",
       "      <td>0.638649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.125300</td>\n",
       "      <td>0.662832</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.706077</td>\n",
       "      <td>0.642662</td>\n",
       "      <td>0.658740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.097900</td>\n",
       "      <td>0.673018</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.793710</td>\n",
       "      <td>0.681142</td>\n",
       "      <td>0.715735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.086300</td>\n",
       "      <td>0.660574</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.804418</td>\n",
       "      <td>0.706977</td>\n",
       "      <td>0.732762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>0.673011</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.807328</td>\n",
       "      <td>0.708283</td>\n",
       "      <td>0.737485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.677221</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.801466</td>\n",
       "      <td>0.702280</td>\n",
       "      <td>0.731081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>0.668368</td>\n",
       "      <td>0.804766</td>\n",
       "      <td>0.834718</td>\n",
       "      <td>0.720993</td>\n",
       "      <td>0.755796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.681766</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.816692</td>\n",
       "      <td>0.718527</td>\n",
       "      <td>0.747360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.691467</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.809846</td>\n",
       "      <td>0.718698</td>\n",
       "      <td>0.744185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 04:08:29,272] Trial 117 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 118 with params: {'learning_rate': 0.00037705707877799745, 'weight_decay': 0.007, 'warmup_steps': 3, 'lambda_param': 0.8, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:30, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.783500</td>\n",
       "      <td>0.677224</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.548018</td>\n",
       "      <td>0.510495</td>\n",
       "      <td>0.508539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.187100</td>\n",
       "      <td>0.661151</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.684582</td>\n",
       "      <td>0.631950</td>\n",
       "      <td>0.640196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.114700</td>\n",
       "      <td>0.663983</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.747773</td>\n",
       "      <td>0.676815</td>\n",
       "      <td>0.694230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.092100</td>\n",
       "      <td>0.653974</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.836186</td>\n",
       "      <td>0.724105</td>\n",
       "      <td>0.756118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.082700</td>\n",
       "      <td>0.676976</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.828318</td>\n",
       "      <td>0.715378</td>\n",
       "      <td>0.750930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.077500</td>\n",
       "      <td>0.676428</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.801341</td>\n",
       "      <td>0.720745</td>\n",
       "      <td>0.745578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.073700</td>\n",
       "      <td>0.668514</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.832725</td>\n",
       "      <td>0.721797</td>\n",
       "      <td>0.758978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.071400</td>\n",
       "      <td>0.681145</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.819886</td>\n",
       "      <td>0.724645</td>\n",
       "      <td>0.754826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.069700</td>\n",
       "      <td>0.691289</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.808354</td>\n",
       "      <td>0.715111</td>\n",
       "      <td>0.743150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067900</td>\n",
       "      <td>0.695829</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.821753</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.749995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.067100</td>\n",
       "      <td>0.692342</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.817354</td>\n",
       "      <td>0.716601</td>\n",
       "      <td>0.747241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.688150</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.815620</td>\n",
       "      <td>0.721838</td>\n",
       "      <td>0.749117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>0.687907</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.807212</td>\n",
       "      <td>0.712493</td>\n",
       "      <td>0.741261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.064900</td>\n",
       "      <td>0.686201</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.822472</td>\n",
       "      <td>0.711379</td>\n",
       "      <td>0.747015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.064600</td>\n",
       "      <td>0.683123</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.811699</td>\n",
       "      <td>0.711508</td>\n",
       "      <td>0.741657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 04:13:01,078] Trial 118 finished with value: 0.7416565460370578 and parameters: {'learning_rate': 0.00037705707877799745, 'weight_decay': 0.007, 'warmup_steps': 3, 'lambda_param': 0.8, 'temperature': 4.0}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 119 with params: {'learning_rate': 0.0004296747924955775, 'weight_decay': 0.006, 'warmup_steps': 3, 'lambda_param': 0.7000000000000001, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:30, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.738400</td>\n",
       "      <td>0.668390</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.542391</td>\n",
       "      <td>0.516567</td>\n",
       "      <td>0.512668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.170900</td>\n",
       "      <td>0.655871</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.701491</td>\n",
       "      <td>0.648258</td>\n",
       "      <td>0.661050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.108400</td>\n",
       "      <td>0.671512</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.769620</td>\n",
       "      <td>0.700111</td>\n",
       "      <td>0.718620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.089000</td>\n",
       "      <td>0.661373</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.821849</td>\n",
       "      <td>0.730123</td>\n",
       "      <td>0.755167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.673154</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.813750</td>\n",
       "      <td>0.723245</td>\n",
       "      <td>0.750330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.076100</td>\n",
       "      <td>0.695991</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.793539</td>\n",
       "      <td>0.725908</td>\n",
       "      <td>0.743549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.071700</td>\n",
       "      <td>0.711415</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.797408</td>\n",
       "      <td>0.711592</td>\n",
       "      <td>0.736713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.711967</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.793272</td>\n",
       "      <td>0.706423</td>\n",
       "      <td>0.728378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>0.721292</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.788160</td>\n",
       "      <td>0.722658</td>\n",
       "      <td>0.739051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067100</td>\n",
       "      <td>0.716624</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.801085</td>\n",
       "      <td>0.724542</td>\n",
       "      <td>0.747595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.705907</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.803576</td>\n",
       "      <td>0.733897</td>\n",
       "      <td>0.753624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.694287</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.807820</td>\n",
       "      <td>0.738257</td>\n",
       "      <td>0.756481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.701523</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.790709</td>\n",
       "      <td>0.721453</td>\n",
       "      <td>0.739101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>0.694139</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.810298</td>\n",
       "      <td>0.728455</td>\n",
       "      <td>0.752775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.063900</td>\n",
       "      <td>0.694454</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.815586</td>\n",
       "      <td>0.737502</td>\n",
       "      <td>0.760507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 04:17:32,959] Trial 119 finished with value: 0.7605065094388407 and parameters: {'learning_rate': 0.0004296747924955775, 'weight_decay': 0.006, 'warmup_steps': 3, 'lambda_param': 0.7000000000000001, 'temperature': 6.0}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 120 with params: {'learning_rate': 0.0003791496115871342, 'weight_decay': 0.008, 'warmup_steps': 9, 'lambda_param': 0.0, 'temperature': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:30, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.790200</td>\n",
       "      <td>0.681579</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.498762</td>\n",
       "      <td>0.497699</td>\n",
       "      <td>0.491648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.187100</td>\n",
       "      <td>0.660016</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.685598</td>\n",
       "      <td>0.623844</td>\n",
       "      <td>0.638952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.114700</td>\n",
       "      <td>0.660640</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.764969</td>\n",
       "      <td>0.676148</td>\n",
       "      <td>0.703912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.092600</td>\n",
       "      <td>0.669551</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.801695</td>\n",
       "      <td>0.699449</td>\n",
       "      <td>0.729908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.082300</td>\n",
       "      <td>0.672827</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.820848</td>\n",
       "      <td>0.715665</td>\n",
       "      <td>0.746883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.077300</td>\n",
       "      <td>0.665827</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.776525</td>\n",
       "      <td>0.709398</td>\n",
       "      <td>0.728636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>0.680638</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.808899</td>\n",
       "      <td>0.725819</td>\n",
       "      <td>0.751705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>0.669996</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.808751</td>\n",
       "      <td>0.722641</td>\n",
       "      <td>0.748659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.069900</td>\n",
       "      <td>0.679226</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.799509</td>\n",
       "      <td>0.717158</td>\n",
       "      <td>0.744130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.675415</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.825604</td>\n",
       "      <td>0.717615</td>\n",
       "      <td>0.753392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.682496</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.809354</td>\n",
       "      <td>0.721277</td>\n",
       "      <td>0.747161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.677834</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.805456</td>\n",
       "      <td>0.738511</td>\n",
       "      <td>0.757585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>0.672595</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.807995</td>\n",
       "      <td>0.725059</td>\n",
       "      <td>0.749442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.064800</td>\n",
       "      <td>0.676713</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.818629</td>\n",
       "      <td>0.724644</td>\n",
       "      <td>0.754630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.673009</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.816246</td>\n",
       "      <td>0.724325</td>\n",
       "      <td>0.753203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 04:22:05,331] Trial 120 finished with value: 0.7532031380207524 and parameters: {'learning_rate': 0.0003791496115871342, 'weight_decay': 0.008, 'warmup_steps': 9, 'lambda_param': 0.0, 'temperature': 2.5}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 121 with params: {'learning_rate': 1.5745418122329243e-05, 'weight_decay': 0.003, 'warmup_steps': 34, 'lambda_param': 1.0, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:57 < 01:28, 29.59 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.186800</td>\n",
       "      <td>1.949074</td>\n",
       "      <td>0.404216</td>\n",
       "      <td>0.097918</td>\n",
       "      <td>0.090901</td>\n",
       "      <td>0.073736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.759800</td>\n",
       "      <td>1.614061</td>\n",
       "      <td>0.505958</td>\n",
       "      <td>0.140948</td>\n",
       "      <td>0.149763</td>\n",
       "      <td>0.126652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.463700</td>\n",
       "      <td>1.390694</td>\n",
       "      <td>0.582035</td>\n",
       "      <td>0.231379</td>\n",
       "      <td>0.207771</td>\n",
       "      <td>0.192557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.253500</td>\n",
       "      <td>1.231010</td>\n",
       "      <td>0.641613</td>\n",
       "      <td>0.279433</td>\n",
       "      <td>0.253513</td>\n",
       "      <td>0.242128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.094900</td>\n",
       "      <td>1.113172</td>\n",
       "      <td>0.678277</td>\n",
       "      <td>0.259135</td>\n",
       "      <td>0.279413</td>\n",
       "      <td>0.257813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.978700</td>\n",
       "      <td>1.028422</td>\n",
       "      <td>0.688359</td>\n",
       "      <td>0.266274</td>\n",
       "      <td>0.291166</td>\n",
       "      <td>0.265212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.887700</td>\n",
       "      <td>0.966632</td>\n",
       "      <td>0.705775</td>\n",
       "      <td>0.293907</td>\n",
       "      <td>0.307582</td>\n",
       "      <td>0.283584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.822100</td>\n",
       "      <td>0.923631</td>\n",
       "      <td>0.711274</td>\n",
       "      <td>0.323652</td>\n",
       "      <td>0.317633</td>\n",
       "      <td>0.296265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.770300</td>\n",
       "      <td>0.890247</td>\n",
       "      <td>0.716774</td>\n",
       "      <td>0.318573</td>\n",
       "      <td>0.324863</td>\n",
       "      <td>0.301427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.728300</td>\n",
       "      <td>0.867275</td>\n",
       "      <td>0.721357</td>\n",
       "      <td>0.320998</td>\n",
       "      <td>0.331751</td>\n",
       "      <td>0.307245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 04:25:03,676] Trial 121 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 122 with params: {'learning_rate': 0.0004393550916036238, 'weight_decay': 0.004, 'warmup_steps': 1, 'lambda_param': 0.6000000000000001, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:26, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.727000</td>\n",
       "      <td>0.677960</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.560425</td>\n",
       "      <td>0.520101</td>\n",
       "      <td>0.520686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.169000</td>\n",
       "      <td>0.687645</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.706087</td>\n",
       "      <td>0.631077</td>\n",
       "      <td>0.649685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.108100</td>\n",
       "      <td>0.677044</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.768365</td>\n",
       "      <td>0.699230</td>\n",
       "      <td>0.718437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.088800</td>\n",
       "      <td>0.676439</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.796255</td>\n",
       "      <td>0.711658</td>\n",
       "      <td>0.737741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.680225</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.813172</td>\n",
       "      <td>0.730543</td>\n",
       "      <td>0.754560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>0.697251</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.824657</td>\n",
       "      <td>0.719610</td>\n",
       "      <td>0.751881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.701776</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.819303</td>\n",
       "      <td>0.726840</td>\n",
       "      <td>0.755051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.684328</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.802175</td>\n",
       "      <td>0.729320</td>\n",
       "      <td>0.749422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.718751</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.804465</td>\n",
       "      <td>0.716987</td>\n",
       "      <td>0.744278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067500</td>\n",
       "      <td>0.703505</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.814109</td>\n",
       "      <td>0.725186</td>\n",
       "      <td>0.752234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.066900</td>\n",
       "      <td>0.700344</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.809896</td>\n",
       "      <td>0.731063</td>\n",
       "      <td>0.753775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.065300</td>\n",
       "      <td>0.691372</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.817917</td>\n",
       "      <td>0.730121</td>\n",
       "      <td>0.757730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.064700</td>\n",
       "      <td>0.689390</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.814836</td>\n",
       "      <td>0.741473</td>\n",
       "      <td>0.764111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>0.689048</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.819972</td>\n",
       "      <td>0.735953</td>\n",
       "      <td>0.764240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.690762</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.818995</td>\n",
       "      <td>0.724187</td>\n",
       "      <td>0.755600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 04:29:32,207] Trial 122 finished with value: 0.755600047104299 and parameters: {'learning_rate': 0.0004393550916036238, 'weight_decay': 0.004, 'warmup_steps': 1, 'lambda_param': 0.6000000000000001, 'temperature': 7.0}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 123 with params: {'learning_rate': 0.0004503110805633973, 'weight_decay': 0.006, 'warmup_steps': 6, 'lambda_param': 0.6000000000000001, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:27, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.727300</td>\n",
       "      <td>0.663102</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.562538</td>\n",
       "      <td>0.520874</td>\n",
       "      <td>0.526769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.165600</td>\n",
       "      <td>0.674814</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.719635</td>\n",
       "      <td>0.654579</td>\n",
       "      <td>0.670846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.105400</td>\n",
       "      <td>0.679028</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.753325</td>\n",
       "      <td>0.699723</td>\n",
       "      <td>0.707248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.087600</td>\n",
       "      <td>0.683767</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.803525</td>\n",
       "      <td>0.714763</td>\n",
       "      <td>0.737549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.079800</td>\n",
       "      <td>0.678465</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.808615</td>\n",
       "      <td>0.715293</td>\n",
       "      <td>0.741866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>0.694025</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.799116</td>\n",
       "      <td>0.701973</td>\n",
       "      <td>0.729333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.692257</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.801563</td>\n",
       "      <td>0.708042</td>\n",
       "      <td>0.730355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.069800</td>\n",
       "      <td>0.693761</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.803686</td>\n",
       "      <td>0.716073</td>\n",
       "      <td>0.738716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068200</td>\n",
       "      <td>0.693843</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.790630</td>\n",
       "      <td>0.717278</td>\n",
       "      <td>0.730862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.683059</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.804521</td>\n",
       "      <td>0.735665</td>\n",
       "      <td>0.751482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.066100</td>\n",
       "      <td>0.682946</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.794476</td>\n",
       "      <td>0.727923</td>\n",
       "      <td>0.735844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>0.686293</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.826732</td>\n",
       "      <td>0.735395</td>\n",
       "      <td>0.763037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.064700</td>\n",
       "      <td>0.686313</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.809360</td>\n",
       "      <td>0.719887</td>\n",
       "      <td>0.742922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>0.682079</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.812594</td>\n",
       "      <td>0.735870</td>\n",
       "      <td>0.756449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.063900</td>\n",
       "      <td>0.680863</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.813763</td>\n",
       "      <td>0.726501</td>\n",
       "      <td>0.749134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 04:34:00,861] Trial 123 finished with value: 0.7491344130184907 and parameters: {'learning_rate': 0.0004503110805633973, 'weight_decay': 0.006, 'warmup_steps': 6, 'lambda_param': 0.6000000000000001, 'temperature': 5.5}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 124 with params: {'learning_rate': 0.0002248717943367038, 'weight_decay': 0.005, 'warmup_steps': 9, 'lambda_param': 0.8, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:27 < 02:55, 29.90 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.007100</td>\n",
       "      <td>0.720320</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.434543</td>\n",
       "      <td>0.438213</td>\n",
       "      <td>0.424100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.290200</td>\n",
       "      <td>0.648187</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.614156</td>\n",
       "      <td>0.573735</td>\n",
       "      <td>0.580161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.160900</td>\n",
       "      <td>0.651052</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.691486</td>\n",
       "      <td>0.626092</td>\n",
       "      <td>0.641324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.118100</td>\n",
       "      <td>0.657454</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.741788</td>\n",
       "      <td>0.638465</td>\n",
       "      <td>0.670724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.099700</td>\n",
       "      <td>0.657092</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.731447</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>0.685298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 04:35:29,604] Trial 124 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 125 with params: {'learning_rate': 0.00040325095799879554, 'weight_decay': 0.007, 'warmup_steps': 6, 'lambda_param': 1.0, 'temperature': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:24, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.764900</td>\n",
       "      <td>0.667342</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.543345</td>\n",
       "      <td>0.517809</td>\n",
       "      <td>0.513850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.178800</td>\n",
       "      <td>0.662636</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.699753</td>\n",
       "      <td>0.639028</td>\n",
       "      <td>0.653152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.111200</td>\n",
       "      <td>0.656867</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.748706</td>\n",
       "      <td>0.684661</td>\n",
       "      <td>0.699431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.090100</td>\n",
       "      <td>0.663611</td>\n",
       "      <td>0.804766</td>\n",
       "      <td>0.836000</td>\n",
       "      <td>0.716074</td>\n",
       "      <td>0.751909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.081700</td>\n",
       "      <td>0.660645</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.804511</td>\n",
       "      <td>0.718040</td>\n",
       "      <td>0.740928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.076200</td>\n",
       "      <td>0.696404</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.786904</td>\n",
       "      <td>0.712869</td>\n",
       "      <td>0.734168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072500</td>\n",
       "      <td>0.689136</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.820938</td>\n",
       "      <td>0.725576</td>\n",
       "      <td>0.757191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070600</td>\n",
       "      <td>0.678495</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.816264</td>\n",
       "      <td>0.723824</td>\n",
       "      <td>0.752001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.069200</td>\n",
       "      <td>0.680268</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.821121</td>\n",
       "      <td>0.726014</td>\n",
       "      <td>0.756363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067700</td>\n",
       "      <td>0.688070</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.806056</td>\n",
       "      <td>0.720186</td>\n",
       "      <td>0.744688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.066700</td>\n",
       "      <td>0.679594</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.787589</td>\n",
       "      <td>0.710886</td>\n",
       "      <td>0.731031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.661630</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.801082</td>\n",
       "      <td>0.732875</td>\n",
       "      <td>0.751955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.665605</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.800108</td>\n",
       "      <td>0.719772</td>\n",
       "      <td>0.742630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.670531</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.819151</td>\n",
       "      <td>0.726761</td>\n",
       "      <td>0.756142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>0.670793</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.814974</td>\n",
       "      <td>0.728548</td>\n",
       "      <td>0.754319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 04:39:55,764] Trial 125 finished with value: 0.7543191786921076 and parameters: {'learning_rate': 0.00040325095799879554, 'weight_decay': 0.007, 'warmup_steps': 6, 'lambda_param': 1.0, 'temperature': 2.0}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 126 with params: {'learning_rate': 0.00011704977597501867, 'weight_decay': 0.0, 'warmup_steps': 42, 'lambda_param': 0.0, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:27 < 02:55, 29.86 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.377700</td>\n",
       "      <td>0.880741</td>\n",
       "      <td>0.723190</td>\n",
       "      <td>0.333972</td>\n",
       "      <td>0.334897</td>\n",
       "      <td>0.311371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.530800</td>\n",
       "      <td>0.709580</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.493750</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.443655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.314900</td>\n",
       "      <td>0.659586</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.561641</td>\n",
       "      <td>0.521652</td>\n",
       "      <td>0.522781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.215700</td>\n",
       "      <td>0.651912</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.649728</td>\n",
       "      <td>0.561701</td>\n",
       "      <td>0.583045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.164700</td>\n",
       "      <td>0.648827</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.668180</td>\n",
       "      <td>0.616652</td>\n",
       "      <td>0.628096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 04:41:24,566] Trial 126 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 127 with params: {'learning_rate': 0.000426459691039338, 'weight_decay': 0.006, 'warmup_steps': 3, 'lambda_param': 0.8, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:32, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.741000</td>\n",
       "      <td>0.671336</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.568103</td>\n",
       "      <td>0.526050</td>\n",
       "      <td>0.527828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.171600</td>\n",
       "      <td>0.662013</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.703759</td>\n",
       "      <td>0.634753</td>\n",
       "      <td>0.646019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.108800</td>\n",
       "      <td>0.675304</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.766074</td>\n",
       "      <td>0.704425</td>\n",
       "      <td>0.719918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.089000</td>\n",
       "      <td>0.674606</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.791123</td>\n",
       "      <td>0.694793</td>\n",
       "      <td>0.719899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.080600</td>\n",
       "      <td>0.685527</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.801405</td>\n",
       "      <td>0.716503</td>\n",
       "      <td>0.740175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.697275</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.812546</td>\n",
       "      <td>0.722706</td>\n",
       "      <td>0.748034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.687244</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.812308</td>\n",
       "      <td>0.718400</td>\n",
       "      <td>0.746437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070600</td>\n",
       "      <td>0.698476</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.799873</td>\n",
       "      <td>0.726542</td>\n",
       "      <td>0.747166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.700189</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.812574</td>\n",
       "      <td>0.714810</td>\n",
       "      <td>0.743534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.689363</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.813451</td>\n",
       "      <td>0.721686</td>\n",
       "      <td>0.749137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.066300</td>\n",
       "      <td>0.709246</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.817354</td>\n",
       "      <td>0.729830</td>\n",
       "      <td>0.755851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>0.696290</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.815348</td>\n",
       "      <td>0.739369</td>\n",
       "      <td>0.761984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.064900</td>\n",
       "      <td>0.694354</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.813255</td>\n",
       "      <td>0.732057</td>\n",
       "      <td>0.754905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>0.690790</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.835888</td>\n",
       "      <td>0.739411</td>\n",
       "      <td>0.768755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.064100</td>\n",
       "      <td>0.687736</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.817435</td>\n",
       "      <td>0.742134</td>\n",
       "      <td>0.762068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 04:45:58,684] Trial 127 finished with value: 0.7620678718863323 and parameters: {'learning_rate': 0.000426459691039338, 'weight_decay': 0.006, 'warmup_steps': 3, 'lambda_param': 0.8, 'temperature': 6.0}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 128 with params: {'learning_rate': 0.0003385556098094082, 'weight_decay': 0.004, 'warmup_steps': 4, 'lambda_param': 0.9, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:30, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.824800</td>\n",
       "      <td>0.679432</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.509783</td>\n",
       "      <td>0.505475</td>\n",
       "      <td>0.496461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.203400</td>\n",
       "      <td>0.637909</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.718314</td>\n",
       "      <td>0.629550</td>\n",
       "      <td>0.652312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.122100</td>\n",
       "      <td>0.666616</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.725449</td>\n",
       "      <td>0.652560</td>\n",
       "      <td>0.671844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.095900</td>\n",
       "      <td>0.666399</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.791701</td>\n",
       "      <td>0.689015</td>\n",
       "      <td>0.718747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.085200</td>\n",
       "      <td>0.669470</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.818535</td>\n",
       "      <td>0.690648</td>\n",
       "      <td>0.730787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.078400</td>\n",
       "      <td>0.676760</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.814253</td>\n",
       "      <td>0.723991</td>\n",
       "      <td>0.753061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>0.684404</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.804476</td>\n",
       "      <td>0.715194</td>\n",
       "      <td>0.740987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.072800</td>\n",
       "      <td>0.683049</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.813109</td>\n",
       "      <td>0.719597</td>\n",
       "      <td>0.749776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.697787</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.811870</td>\n",
       "      <td>0.713079</td>\n",
       "      <td>0.740002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.684767</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.814838</td>\n",
       "      <td>0.724695</td>\n",
       "      <td>0.753343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.682752</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.809329</td>\n",
       "      <td>0.723754</td>\n",
       "      <td>0.749163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.687452</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.797392</td>\n",
       "      <td>0.725447</td>\n",
       "      <td>0.747673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.674065</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.815168</td>\n",
       "      <td>0.711211</td>\n",
       "      <td>0.744538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.681528</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.803142</td>\n",
       "      <td>0.706487</td>\n",
       "      <td>0.736160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>0.676989</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.794467</td>\n",
       "      <td>0.699625</td>\n",
       "      <td>0.729160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 04:50:30,217] Trial 128 finished with value: 0.7291603920049852 and parameters: {'learning_rate': 0.0003385556098094082, 'weight_decay': 0.004, 'warmup_steps': 4, 'lambda_param': 0.9, 'temperature': 6.0}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 129 with params: {'learning_rate': 6.728117982290995e-05, 'weight_decay': 0.008, 'warmup_steps': 2, 'lambda_param': 1.0, 'temperature': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:27 < 02:54, 30.10 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.625100</td>\n",
       "      <td>1.142155</td>\n",
       "      <td>0.667278</td>\n",
       "      <td>0.285865</td>\n",
       "      <td>0.273121</td>\n",
       "      <td>0.259587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.812800</td>\n",
       "      <td>0.822709</td>\n",
       "      <td>0.729606</td>\n",
       "      <td>0.360197</td>\n",
       "      <td>0.356511</td>\n",
       "      <td>0.339318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.531700</td>\n",
       "      <td>0.733211</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.461016</td>\n",
       "      <td>0.433080</td>\n",
       "      <td>0.424296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.395200</td>\n",
       "      <td>0.690064</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.506347</td>\n",
       "      <td>0.480202</td>\n",
       "      <td>0.477220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.306300</td>\n",
       "      <td>0.658163</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.551302</td>\n",
       "      <td>0.509224</td>\n",
       "      <td>0.510291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 04:51:58,298] Trial 129 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 130 with params: {'learning_rate': 0.0003518988602880114, 'weight_decay': 0.007, 'warmup_steps': 3, 'lambda_param': 0.8, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:58 < 01:29, 29.37 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.809900</td>\n",
       "      <td>0.680767</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.522899</td>\n",
       "      <td>0.510901</td>\n",
       "      <td>0.502926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.198000</td>\n",
       "      <td>0.646583</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.698331</td>\n",
       "      <td>0.627064</td>\n",
       "      <td>0.644392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.663717</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.746779</td>\n",
       "      <td>0.681913</td>\n",
       "      <td>0.699394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.094300</td>\n",
       "      <td>0.658774</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.795248</td>\n",
       "      <td>0.707589</td>\n",
       "      <td>0.730727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.083600</td>\n",
       "      <td>0.667331</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.816999</td>\n",
       "      <td>0.697244</td>\n",
       "      <td>0.734370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.078400</td>\n",
       "      <td>0.673673</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.806691</td>\n",
       "      <td>0.711505</td>\n",
       "      <td>0.739551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.074300</td>\n",
       "      <td>0.681169</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.814015</td>\n",
       "      <td>0.708179</td>\n",
       "      <td>0.740952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.071900</td>\n",
       "      <td>0.670998</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.801686</td>\n",
       "      <td>0.721016</td>\n",
       "      <td>0.744057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>0.679965</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.811251</td>\n",
       "      <td>0.713059</td>\n",
       "      <td>0.741952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.068500</td>\n",
       "      <td>0.688622</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.815359</td>\n",
       "      <td>0.713573</td>\n",
       "      <td>0.744670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 04:54:57,989] Trial 130 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 131 with params: {'learning_rate': 0.00046898598700731013, 'weight_decay': 0.006, 'warmup_steps': 18, 'lambda_param': 0.8, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:25, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.733500</td>\n",
       "      <td>0.674208</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.582369</td>\n",
       "      <td>0.523778</td>\n",
       "      <td>0.530873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.162600</td>\n",
       "      <td>0.690974</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.672874</td>\n",
       "      <td>0.653694</td>\n",
       "      <td>0.652140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>0.671444</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.771376</td>\n",
       "      <td>0.703098</td>\n",
       "      <td>0.721618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.659777</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.809313</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.739552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.078600</td>\n",
       "      <td>0.672951</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.806743</td>\n",
       "      <td>0.732496</td>\n",
       "      <td>0.756438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.074700</td>\n",
       "      <td>0.668317</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.797003</td>\n",
       "      <td>0.739326</td>\n",
       "      <td>0.755832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.071700</td>\n",
       "      <td>0.683294</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.811728</td>\n",
       "      <td>0.713662</td>\n",
       "      <td>0.745585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.687365</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.808893</td>\n",
       "      <td>0.714050</td>\n",
       "      <td>0.743145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.067700</td>\n",
       "      <td>0.676325</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.807563</td>\n",
       "      <td>0.714765</td>\n",
       "      <td>0.739856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.664262</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.792929</td>\n",
       "      <td>0.722719</td>\n",
       "      <td>0.742225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.681857</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.801035</td>\n",
       "      <td>0.732727</td>\n",
       "      <td>0.749957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.064900</td>\n",
       "      <td>0.666797</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.797948</td>\n",
       "      <td>0.737411</td>\n",
       "      <td>0.753033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>0.664104</td>\n",
       "      <td>0.802933</td>\n",
       "      <td>0.800019</td>\n",
       "      <td>0.745341</td>\n",
       "      <td>0.760843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.063700</td>\n",
       "      <td>0.665542</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.817290</td>\n",
       "      <td>0.739957</td>\n",
       "      <td>0.763447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.063400</td>\n",
       "      <td>0.663653</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.810199</td>\n",
       "      <td>0.736210</td>\n",
       "      <td>0.756178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 04:59:24,971] Trial 131 finished with value: 0.7561777696498254 and parameters: {'learning_rate': 0.00046898598700731013, 'weight_decay': 0.006, 'warmup_steps': 18, 'lambda_param': 0.8, 'temperature': 6.5}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 132 with params: {'learning_rate': 0.00048071045176241575, 'weight_decay': 0.005, 'warmup_steps': 18, 'lambda_param': 0.9, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:56 < 01:28, 29.66 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.658171</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.578810</td>\n",
       "      <td>0.517548</td>\n",
       "      <td>0.524310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.161000</td>\n",
       "      <td>0.675098</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.695907</td>\n",
       "      <td>0.648214</td>\n",
       "      <td>0.660699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.103900</td>\n",
       "      <td>0.657342</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.774585</td>\n",
       "      <td>0.711926</td>\n",
       "      <td>0.729176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.086900</td>\n",
       "      <td>0.670550</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.831291</td>\n",
       "      <td>0.731574</td>\n",
       "      <td>0.762547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>0.678695</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.812058</td>\n",
       "      <td>0.713659</td>\n",
       "      <td>0.743517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.679737</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.827336</td>\n",
       "      <td>0.729546</td>\n",
       "      <td>0.760813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.071600</td>\n",
       "      <td>0.709448</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.791097</td>\n",
       "      <td>0.718148</td>\n",
       "      <td>0.740020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.069500</td>\n",
       "      <td>0.692248</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.793808</td>\n",
       "      <td>0.712133</td>\n",
       "      <td>0.734342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068100</td>\n",
       "      <td>0.707029</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.800933</td>\n",
       "      <td>0.717721</td>\n",
       "      <td>0.742891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067100</td>\n",
       "      <td>0.692441</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.799525</td>\n",
       "      <td>0.708482</td>\n",
       "      <td>0.736386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 05:02:22,877] Trial 132 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 133 with params: {'learning_rate': 0.00022248107699699603, 'weight_decay': 0.005, 'warmup_steps': 12, 'lambda_param': 0.7000000000000001, 'temperature': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:58 < 01:29, 29.44 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.017500</td>\n",
       "      <td>0.720631</td>\n",
       "      <td>0.762603</td>\n",
       "      <td>0.413796</td>\n",
       "      <td>0.432364</td>\n",
       "      <td>0.413880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.294800</td>\n",
       "      <td>0.647829</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.615273</td>\n",
       "      <td>0.574647</td>\n",
       "      <td>0.581192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.162600</td>\n",
       "      <td>0.655747</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.705405</td>\n",
       "      <td>0.637438</td>\n",
       "      <td>0.654983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.118600</td>\n",
       "      <td>0.659527</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.748180</td>\n",
       "      <td>0.633508</td>\n",
       "      <td>0.668823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.666655</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.780101</td>\n",
       "      <td>0.683709</td>\n",
       "      <td>0.713111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.090200</td>\n",
       "      <td>0.660746</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.793586</td>\n",
       "      <td>0.683453</td>\n",
       "      <td>0.715987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.083200</td>\n",
       "      <td>0.669181</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.808514</td>\n",
       "      <td>0.702480</td>\n",
       "      <td>0.733507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.079800</td>\n",
       "      <td>0.668766</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.816861</td>\n",
       "      <td>0.709174</td>\n",
       "      <td>0.739667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.076800</td>\n",
       "      <td>0.667022</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.807386</td>\n",
       "      <td>0.706108</td>\n",
       "      <td>0.735173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.074100</td>\n",
       "      <td>0.682140</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.811601</td>\n",
       "      <td>0.704679</td>\n",
       "      <td>0.736616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jovyan/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--precision/155d3220d6cd4a6553f12da68eeb3d1f97cf431206304a4bc6e2d564c29502e9 (last modified on Fri Jan 10 23:13:59 2025) since it couldn't be found locally at evaluate-metric--precision, or remotely on the Hugging Face Hub.\n",
      "[I 2025-03-27 05:05:22,203] Trial 133 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 134 with params: {'learning_rate': 0.0004669695806329286, 'weight_decay': 0.006, 'warmup_steps': 0, 'lambda_param': 0.7000000000000001, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:58 < 01:29, 29.35 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.700800</td>\n",
       "      <td>0.683615</td>\n",
       "      <td>0.779102</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.523896</td>\n",
       "      <td>0.530238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.691842</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.693494</td>\n",
       "      <td>0.635771</td>\n",
       "      <td>0.646608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.103500</td>\n",
       "      <td>0.689630</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.783104</td>\n",
       "      <td>0.706771</td>\n",
       "      <td>0.728036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.086400</td>\n",
       "      <td>0.697065</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.816214</td>\n",
       "      <td>0.707273</td>\n",
       "      <td>0.739200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.078700</td>\n",
       "      <td>0.707210</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.804847</td>\n",
       "      <td>0.711126</td>\n",
       "      <td>0.739359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.074200</td>\n",
       "      <td>0.695231</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.811903</td>\n",
       "      <td>0.715632</td>\n",
       "      <td>0.743822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.724609</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.799093</td>\n",
       "      <td>0.708109</td>\n",
       "      <td>0.732649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.069400</td>\n",
       "      <td>0.709801</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.811243</td>\n",
       "      <td>0.730325</td>\n",
       "      <td>0.752167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068100</td>\n",
       "      <td>0.706258</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.804299</td>\n",
       "      <td>0.705696</td>\n",
       "      <td>0.733382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.719765</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.812933</td>\n",
       "      <td>0.708745</td>\n",
       "      <td>0.739656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 05:08:22,044] Trial 134 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 135 with params: {'learning_rate': 0.0004991644632130081, 'weight_decay': 0.007, 'warmup_steps': 7, 'lambda_param': 0.9, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:28, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.696400</td>\n",
       "      <td>0.648397</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.582876</td>\n",
       "      <td>0.539857</td>\n",
       "      <td>0.540773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.155200</td>\n",
       "      <td>0.674511</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.749908</td>\n",
       "      <td>0.659002</td>\n",
       "      <td>0.680173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.101200</td>\n",
       "      <td>0.660817</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.795860</td>\n",
       "      <td>0.734181</td>\n",
       "      <td>0.750313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.086300</td>\n",
       "      <td>0.699551</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.786591</td>\n",
       "      <td>0.733907</td>\n",
       "      <td>0.744225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.078400</td>\n",
       "      <td>0.691592</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.795787</td>\n",
       "      <td>0.717779</td>\n",
       "      <td>0.737683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.074200</td>\n",
       "      <td>0.706065</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.823112</td>\n",
       "      <td>0.722519</td>\n",
       "      <td>0.752762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>0.710445</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.800998</td>\n",
       "      <td>0.719146</td>\n",
       "      <td>0.745089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.069200</td>\n",
       "      <td>0.718559</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.815072</td>\n",
       "      <td>0.724271</td>\n",
       "      <td>0.749965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.067900</td>\n",
       "      <td>0.694260</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.815425</td>\n",
       "      <td>0.708567</td>\n",
       "      <td>0.742108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.713184</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.787807</td>\n",
       "      <td>0.727137</td>\n",
       "      <td>0.743574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.065800</td>\n",
       "      <td>0.723139</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>0.794514</td>\n",
       "      <td>0.716792</td>\n",
       "      <td>0.739230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.064800</td>\n",
       "      <td>0.702875</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.795473</td>\n",
       "      <td>0.725546</td>\n",
       "      <td>0.746684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.064100</td>\n",
       "      <td>0.699138</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.809051</td>\n",
       "      <td>0.726916</td>\n",
       "      <td>0.752713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.063600</td>\n",
       "      <td>0.706636</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.721924</td>\n",
       "      <td>0.744848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.063400</td>\n",
       "      <td>0.704628</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.796978</td>\n",
       "      <td>0.723375</td>\n",
       "      <td>0.744604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 05:12:52,047] Trial 135 finished with value: 0.7446037996563569 and parameters: {'learning_rate': 0.0004991644632130081, 'weight_decay': 0.007, 'warmup_steps': 7, 'lambda_param': 0.9, 'temperature': 6.0}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 136 with params: {'learning_rate': 0.00031300780411857334, 'weight_decay': 0.006, 'warmup_steps': 19, 'lambda_param': 1.0, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:58 < 01:29, 29.37 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.880600</td>\n",
       "      <td>0.699391</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.492259</td>\n",
       "      <td>0.487974</td>\n",
       "      <td>0.479773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.217000</td>\n",
       "      <td>0.655214</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.691679</td>\n",
       "      <td>0.617213</td>\n",
       "      <td>0.634027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.126600</td>\n",
       "      <td>0.663251</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.736029</td>\n",
       "      <td>0.649815</td>\n",
       "      <td>0.673798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.099000</td>\n",
       "      <td>0.659755</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.770718</td>\n",
       "      <td>0.681214</td>\n",
       "      <td>0.707508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.086400</td>\n",
       "      <td>0.670775</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.819610</td>\n",
       "      <td>0.719775</td>\n",
       "      <td>0.750710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>0.673739</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.817410</td>\n",
       "      <td>0.719658</td>\n",
       "      <td>0.745145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>0.680874</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.802356</td>\n",
       "      <td>0.701786</td>\n",
       "      <td>0.730920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.073200</td>\n",
       "      <td>0.684463</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.808305</td>\n",
       "      <td>0.710508</td>\n",
       "      <td>0.739374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>0.694073</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.815165</td>\n",
       "      <td>0.713020</td>\n",
       "      <td>0.742457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.069500</td>\n",
       "      <td>0.695688</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.811196</td>\n",
       "      <td>0.708819</td>\n",
       "      <td>0.740226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 05:15:51,688] Trial 136 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 137 with params: {'learning_rate': 0.0002762423005400957, 'weight_decay': 0.001, 'warmup_steps': 9, 'lambda_param': 0.5, 'temperature': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:28, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.915400</td>\n",
       "      <td>0.704378</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.473267</td>\n",
       "      <td>0.458734</td>\n",
       "      <td>0.445362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.241900</td>\n",
       "      <td>0.646660</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.642803</td>\n",
       "      <td>0.588950</td>\n",
       "      <td>0.601796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.138300</td>\n",
       "      <td>0.652854</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.714447</td>\n",
       "      <td>0.646089</td>\n",
       "      <td>0.664067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.104800</td>\n",
       "      <td>0.662442</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.780575</td>\n",
       "      <td>0.675436</td>\n",
       "      <td>0.707949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.091200</td>\n",
       "      <td>0.651604</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.797777</td>\n",
       "      <td>0.697623</td>\n",
       "      <td>0.728779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.083100</td>\n",
       "      <td>0.657330</td>\n",
       "      <td>0.805683</td>\n",
       "      <td>0.831649</td>\n",
       "      <td>0.724056</td>\n",
       "      <td>0.759078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.078200</td>\n",
       "      <td>0.671288</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.807785</td>\n",
       "      <td>0.727617</td>\n",
       "      <td>0.752317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>0.662457</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.813801</td>\n",
       "      <td>0.734523</td>\n",
       "      <td>0.759165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.073200</td>\n",
       "      <td>0.675650</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.821147</td>\n",
       "      <td>0.723026</td>\n",
       "      <td>0.752020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.680197</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.826883</td>\n",
       "      <td>0.717506</td>\n",
       "      <td>0.748723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.069800</td>\n",
       "      <td>0.685620</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.805303</td>\n",
       "      <td>0.721862</td>\n",
       "      <td>0.745463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.068700</td>\n",
       "      <td>0.675720</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.798265</td>\n",
       "      <td>0.719645</td>\n",
       "      <td>0.744199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.670609</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.805206</td>\n",
       "      <td>0.720427</td>\n",
       "      <td>0.746196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.670804</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.817822</td>\n",
       "      <td>0.720285</td>\n",
       "      <td>0.749128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.672038</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.815063</td>\n",
       "      <td>0.720356</td>\n",
       "      <td>0.747673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 05:20:21,548] Trial 137 finished with value: 0.7476729521364613 and parameters: {'learning_rate': 0.0002762423005400957, 'weight_decay': 0.001, 'warmup_steps': 9, 'lambda_param': 0.5, 'temperature': 5.0}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 138 with params: {'learning_rate': 0.0002882384993712165, 'weight_decay': 0.006, 'warmup_steps': 11, 'lambda_param': 0.5, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:25, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.902200</td>\n",
       "      <td>0.703108</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.476556</td>\n",
       "      <td>0.467644</td>\n",
       "      <td>0.456326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.233600</td>\n",
       "      <td>0.641633</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.640883</td>\n",
       "      <td>0.589988</td>\n",
       "      <td>0.603645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.134300</td>\n",
       "      <td>0.655620</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.733375</td>\n",
       "      <td>0.646926</td>\n",
       "      <td>0.671889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.102700</td>\n",
       "      <td>0.670551</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.758022</td>\n",
       "      <td>0.647676</td>\n",
       "      <td>0.679944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.090200</td>\n",
       "      <td>0.656036</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.818965</td>\n",
       "      <td>0.712631</td>\n",
       "      <td>0.744925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.082100</td>\n",
       "      <td>0.649719</td>\n",
       "      <td>0.808433</td>\n",
       "      <td>0.830966</td>\n",
       "      <td>0.733511</td>\n",
       "      <td>0.766975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.077400</td>\n",
       "      <td>0.670008</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.805702</td>\n",
       "      <td>0.721392</td>\n",
       "      <td>0.745351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.665995</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.807862</td>\n",
       "      <td>0.711622</td>\n",
       "      <td>0.740508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.072500</td>\n",
       "      <td>0.674163</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.812485</td>\n",
       "      <td>0.719602</td>\n",
       "      <td>0.745889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.672495</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.819091</td>\n",
       "      <td>0.726306</td>\n",
       "      <td>0.753844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.681462</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.810048</td>\n",
       "      <td>0.720350</td>\n",
       "      <td>0.745857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.068200</td>\n",
       "      <td>0.668880</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.811200</td>\n",
       "      <td>0.723058</td>\n",
       "      <td>0.747949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.067300</td>\n",
       "      <td>0.667946</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.795184</td>\n",
       "      <td>0.711955</td>\n",
       "      <td>0.737074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.066700</td>\n",
       "      <td>0.667666</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.802656</td>\n",
       "      <td>0.721933</td>\n",
       "      <td>0.746786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.066600</td>\n",
       "      <td>0.666288</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.803183</td>\n",
       "      <td>0.721933</td>\n",
       "      <td>0.747018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 05:24:49,085] Trial 138 finished with value: 0.7470175429323399 and parameters: {'learning_rate': 0.0002882384993712165, 'weight_decay': 0.006, 'warmup_steps': 11, 'lambda_param': 0.5, 'temperature': 6.0}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 139 with params: {'learning_rate': 0.0002913900631482027, 'weight_decay': 0.007, 'warmup_steps': 22, 'lambda_param': 0.7000000000000001, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:57 < 01:28, 29.63 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.913200</td>\n",
       "      <td>0.705058</td>\n",
       "      <td>0.774519</td>\n",
       "      <td>0.501685</td>\n",
       "      <td>0.477500</td>\n",
       "      <td>0.472504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.231000</td>\n",
       "      <td>0.655439</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.680165</td>\n",
       "      <td>0.607913</td>\n",
       "      <td>0.624706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.132400</td>\n",
       "      <td>0.653322</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.714733</td>\n",
       "      <td>0.644698</td>\n",
       "      <td>0.665059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>0.669470</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.779779</td>\n",
       "      <td>0.668163</td>\n",
       "      <td>0.702192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.089200</td>\n",
       "      <td>0.668575</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.797671</td>\n",
       "      <td>0.698017</td>\n",
       "      <td>0.730282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.081700</td>\n",
       "      <td>0.665626</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.823047</td>\n",
       "      <td>0.710341</td>\n",
       "      <td>0.747951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.076900</td>\n",
       "      <td>0.677979</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.818198</td>\n",
       "      <td>0.711352</td>\n",
       "      <td>0.745712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.074200</td>\n",
       "      <td>0.674260</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.798009</td>\n",
       "      <td>0.711801</td>\n",
       "      <td>0.739188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.673151</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.831122</td>\n",
       "      <td>0.712316</td>\n",
       "      <td>0.747770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>0.689195</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.808086</td>\n",
       "      <td>0.710147</td>\n",
       "      <td>0.741151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 05:27:47,120] Trial 139 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 140 with params: {'learning_rate': 0.0004959453867214615, 'weight_decay': 0.007, 'warmup_steps': 0, 'lambda_param': 1.0, 'temperature': 3.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:56 < 01:28, 29.69 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.682400</td>\n",
       "      <td>0.667205</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.555770</td>\n",
       "      <td>0.525047</td>\n",
       "      <td>0.529079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.153200</td>\n",
       "      <td>0.677779</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.714461</td>\n",
       "      <td>0.664088</td>\n",
       "      <td>0.671594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.101700</td>\n",
       "      <td>0.678146</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.776178</td>\n",
       "      <td>0.722293</td>\n",
       "      <td>0.733236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.085900</td>\n",
       "      <td>0.723360</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.799098</td>\n",
       "      <td>0.715436</td>\n",
       "      <td>0.735343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.078200</td>\n",
       "      <td>0.724903</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.787024</td>\n",
       "      <td>0.712660</td>\n",
       "      <td>0.731394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.073600</td>\n",
       "      <td>0.711444</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.800524</td>\n",
       "      <td>0.720964</td>\n",
       "      <td>0.742143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>0.739619</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.800036</td>\n",
       "      <td>0.710489</td>\n",
       "      <td>0.733716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.069200</td>\n",
       "      <td>0.737539</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.781487</td>\n",
       "      <td>0.714453</td>\n",
       "      <td>0.733203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.067400</td>\n",
       "      <td>0.735620</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.789907</td>\n",
       "      <td>0.707691</td>\n",
       "      <td>0.733088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.737741</td>\n",
       "      <td>0.778185</td>\n",
       "      <td>0.782767</td>\n",
       "      <td>0.707393</td>\n",
       "      <td>0.729854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 05:30:44,944] Trial 140 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 141 with params: {'learning_rate': 0.0003962280767843101, 'weight_decay': 0.003, 'warmup_steps': 37, 'lambda_param': 1.0, 'temperature': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:25, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.816200</td>\n",
       "      <td>0.667307</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.497187</td>\n",
       "      <td>0.496975</td>\n",
       "      <td>0.489224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.183100</td>\n",
       "      <td>0.672703</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.669870</td>\n",
       "      <td>0.607954</td>\n",
       "      <td>0.618113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.111900</td>\n",
       "      <td>0.678892</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.779835</td>\n",
       "      <td>0.701083</td>\n",
       "      <td>0.724147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.090400</td>\n",
       "      <td>0.684224</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.809086</td>\n",
       "      <td>0.717794</td>\n",
       "      <td>0.742822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.081600</td>\n",
       "      <td>0.688290</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.812775</td>\n",
       "      <td>0.704264</td>\n",
       "      <td>0.737623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.684266</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.809389</td>\n",
       "      <td>0.720146</td>\n",
       "      <td>0.747290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072900</td>\n",
       "      <td>0.688880</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.820727</td>\n",
       "      <td>0.713254</td>\n",
       "      <td>0.744013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070700</td>\n",
       "      <td>0.680816</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.837108</td>\n",
       "      <td>0.721361</td>\n",
       "      <td>0.755512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.699783</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.825966</td>\n",
       "      <td>0.725710</td>\n",
       "      <td>0.756962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067400</td>\n",
       "      <td>0.698533</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.816434</td>\n",
       "      <td>0.715614</td>\n",
       "      <td>0.745607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>0.699489</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.810211</td>\n",
       "      <td>0.715772</td>\n",
       "      <td>0.743496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.673409</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.821762</td>\n",
       "      <td>0.717362</td>\n",
       "      <td>0.748946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.065300</td>\n",
       "      <td>0.667996</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.818861</td>\n",
       "      <td>0.707115</td>\n",
       "      <td>0.741041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.670555</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.822976</td>\n",
       "      <td>0.715859</td>\n",
       "      <td>0.748893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.671152</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.819780</td>\n",
       "      <td>0.715093</td>\n",
       "      <td>0.746854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 05:35:12,651] Trial 141 finished with value: 0.7468542399219683 and parameters: {'learning_rate': 0.0003962280767843101, 'weight_decay': 0.003, 'warmup_steps': 37, 'lambda_param': 1.0, 'temperature': 6.0}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 142 with params: {'learning_rate': 0.00011048239252562487, 'weight_decay': 0.008, 'warmup_steps': 10, 'lambda_param': 0.9, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:55 < 01:27, 29.93 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.366900</td>\n",
       "      <td>0.892749</td>\n",
       "      <td>0.724106</td>\n",
       "      <td>0.334530</td>\n",
       "      <td>0.336109</td>\n",
       "      <td>0.311875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.719244</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.452993</td>\n",
       "      <td>0.438935</td>\n",
       "      <td>0.429191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.331600</td>\n",
       "      <td>0.662811</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.560752</td>\n",
       "      <td>0.514923</td>\n",
       "      <td>0.513659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.227400</td>\n",
       "      <td>0.649654</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.634467</td>\n",
       "      <td>0.553760</td>\n",
       "      <td>0.571118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.173200</td>\n",
       "      <td>0.645672</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.663803</td>\n",
       "      <td>0.615019</td>\n",
       "      <td>0.622625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.143800</td>\n",
       "      <td>0.640806</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.707607</td>\n",
       "      <td>0.627286</td>\n",
       "      <td>0.649707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.125600</td>\n",
       "      <td>0.637575</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.726938</td>\n",
       "      <td>0.642811</td>\n",
       "      <td>0.665121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.114400</td>\n",
       "      <td>0.637373</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.734934</td>\n",
       "      <td>0.652305</td>\n",
       "      <td>0.674192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.106200</td>\n",
       "      <td>0.645186</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.765465</td>\n",
       "      <td>0.670573</td>\n",
       "      <td>0.698236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.099800</td>\n",
       "      <td>0.654116</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.747779</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.695417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 05:38:08,941] Trial 142 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 143 with params: {'learning_rate': 0.00028608073093940457, 'weight_decay': 0.01, 'warmup_steps': 12, 'lambda_param': 0.9, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:25, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.907400</td>\n",
       "      <td>0.705306</td>\n",
       "      <td>0.768103</td>\n",
       "      <td>0.470487</td>\n",
       "      <td>0.461237</td>\n",
       "      <td>0.449784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.235000</td>\n",
       "      <td>0.638689</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.644549</td>\n",
       "      <td>0.591595</td>\n",
       "      <td>0.604152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.134600</td>\n",
       "      <td>0.656597</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.723944</td>\n",
       "      <td>0.645436</td>\n",
       "      <td>0.666543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>0.673788</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.741409</td>\n",
       "      <td>0.643633</td>\n",
       "      <td>0.671856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.090200</td>\n",
       "      <td>0.666345</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.789101</td>\n",
       "      <td>0.702006</td>\n",
       "      <td>0.729235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.082100</td>\n",
       "      <td>0.657252</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.820265</td>\n",
       "      <td>0.715670</td>\n",
       "      <td>0.750886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.077400</td>\n",
       "      <td>0.677089</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.815399</td>\n",
       "      <td>0.723887</td>\n",
       "      <td>0.752633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>0.668327</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.818075</td>\n",
       "      <td>0.715465</td>\n",
       "      <td>0.745100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.072700</td>\n",
       "      <td>0.673960</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.814962</td>\n",
       "      <td>0.723264</td>\n",
       "      <td>0.748321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.070600</td>\n",
       "      <td>0.673747</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.823678</td>\n",
       "      <td>0.729630</td>\n",
       "      <td>0.759044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.069500</td>\n",
       "      <td>0.681684</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.799036</td>\n",
       "      <td>0.716471</td>\n",
       "      <td>0.737989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.068200</td>\n",
       "      <td>0.661308</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.810523</td>\n",
       "      <td>0.723604</td>\n",
       "      <td>0.747584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.067500</td>\n",
       "      <td>0.666247</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.807244</td>\n",
       "      <td>0.723340</td>\n",
       "      <td>0.748768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.066700</td>\n",
       "      <td>0.664326</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.808618</td>\n",
       "      <td>0.724673</td>\n",
       "      <td>0.750047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.066600</td>\n",
       "      <td>0.665655</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.812810</td>\n",
       "      <td>0.724643</td>\n",
       "      <td>0.751761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 05:42:36,377] Trial 143 finished with value: 0.7517614008331276 and parameters: {'learning_rate': 0.00028608073093940457, 'weight_decay': 0.01, 'warmup_steps': 12, 'lambda_param': 0.9, 'temperature': 7.0}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 144 with params: {'learning_rate': 0.0004987574800305614, 'weight_decay': 0.008, 'warmup_steps': 10, 'lambda_param': 1.0, 'temperature': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:58 < 01:29, 29.34 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.699100</td>\n",
       "      <td>0.664259</td>\n",
       "      <td>0.779102</td>\n",
       "      <td>0.556716</td>\n",
       "      <td>0.526868</td>\n",
       "      <td>0.525338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>0.674133</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.741276</td>\n",
       "      <td>0.646871</td>\n",
       "      <td>0.675560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.101700</td>\n",
       "      <td>0.671532</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.788122</td>\n",
       "      <td>0.713488</td>\n",
       "      <td>0.734971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.085500</td>\n",
       "      <td>0.693324</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.803398</td>\n",
       "      <td>0.707082</td>\n",
       "      <td>0.736602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.077900</td>\n",
       "      <td>0.692474</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.809943</td>\n",
       "      <td>0.724833</td>\n",
       "      <td>0.750528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.074300</td>\n",
       "      <td>0.673189</td>\n",
       "      <td>0.804766</td>\n",
       "      <td>0.823282</td>\n",
       "      <td>0.726921</td>\n",
       "      <td>0.755698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.070700</td>\n",
       "      <td>0.724129</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.818236</td>\n",
       "      <td>0.711537</td>\n",
       "      <td>0.746540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.069500</td>\n",
       "      <td>0.712846</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.805077</td>\n",
       "      <td>0.717917</td>\n",
       "      <td>0.743753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.067600</td>\n",
       "      <td>0.711119</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.814756</td>\n",
       "      <td>0.724119</td>\n",
       "      <td>0.751746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066600</td>\n",
       "      <td>0.717041</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.796309</td>\n",
       "      <td>0.713701</td>\n",
       "      <td>0.738529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 05:45:36,204] Trial 144 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 145 with params: {'learning_rate': 0.0004424758983506504, 'weight_decay': 0.007, 'warmup_steps': 34, 'lambda_param': 0.7000000000000001, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:57 < 01:29, 29.49 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.775100</td>\n",
       "      <td>0.674487</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.539348</td>\n",
       "      <td>0.510688</td>\n",
       "      <td>0.506158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.167100</td>\n",
       "      <td>0.680328</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.722546</td>\n",
       "      <td>0.652610</td>\n",
       "      <td>0.669387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.106400</td>\n",
       "      <td>0.685562</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.780791</td>\n",
       "      <td>0.717435</td>\n",
       "      <td>0.732471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.088800</td>\n",
       "      <td>0.674118</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.814195</td>\n",
       "      <td>0.718953</td>\n",
       "      <td>0.744010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.079800</td>\n",
       "      <td>0.688017</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.807325</td>\n",
       "      <td>0.699463</td>\n",
       "      <td>0.725010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075600</td>\n",
       "      <td>0.688909</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.810104</td>\n",
       "      <td>0.725177</td>\n",
       "      <td>0.749213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.689412</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.803397</td>\n",
       "      <td>0.727763</td>\n",
       "      <td>0.748452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.695088</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.801995</td>\n",
       "      <td>0.721927</td>\n",
       "      <td>0.740727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068700</td>\n",
       "      <td>0.692046</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.799017</td>\n",
       "      <td>0.716339</td>\n",
       "      <td>0.737807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>0.714496</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.799485</td>\n",
       "      <td>0.710738</td>\n",
       "      <td>0.734630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 05:48:35,197] Trial 145 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 146 with params: {'learning_rate': 0.00019515656490385515, 'weight_decay': 0.003, 'warmup_steps': 21, 'lambda_param': 0.6000000000000001, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7875' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7875/7875 04:27, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.090700</td>\n",
       "      <td>0.741017</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.451866</td>\n",
       "      <td>0.422822</td>\n",
       "      <td>0.415471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.335500</td>\n",
       "      <td>0.648257</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.596087</td>\n",
       "      <td>0.546887</td>\n",
       "      <td>0.552770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.184400</td>\n",
       "      <td>0.651432</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.697528</td>\n",
       "      <td>0.623010</td>\n",
       "      <td>0.639114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.131000</td>\n",
       "      <td>0.657454</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.728878</td>\n",
       "      <td>0.621228</td>\n",
       "      <td>0.652568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.108300</td>\n",
       "      <td>0.666512</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.754774</td>\n",
       "      <td>0.659526</td>\n",
       "      <td>0.686451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.095700</td>\n",
       "      <td>0.648594</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.770180</td>\n",
       "      <td>0.658160</td>\n",
       "      <td>0.692209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.087300</td>\n",
       "      <td>0.661418</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.805294</td>\n",
       "      <td>0.708067</td>\n",
       "      <td>0.736636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.083400</td>\n",
       "      <td>0.655718</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.802761</td>\n",
       "      <td>0.716344</td>\n",
       "      <td>0.741559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>0.663999</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.806275</td>\n",
       "      <td>0.715717</td>\n",
       "      <td>0.740688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.076600</td>\n",
       "      <td>0.674625</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.801277</td>\n",
       "      <td>0.721926</td>\n",
       "      <td>0.743700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.666040</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.802084</td>\n",
       "      <td>0.724973</td>\n",
       "      <td>0.747242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.073700</td>\n",
       "      <td>0.665562</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.800208</td>\n",
       "      <td>0.726188</td>\n",
       "      <td>0.747651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.072300</td>\n",
       "      <td>0.664483</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.806969</td>\n",
       "      <td>0.728930</td>\n",
       "      <td>0.751886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.662063</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.814896</td>\n",
       "      <td>0.727163</td>\n",
       "      <td>0.753479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.071300</td>\n",
       "      <td>0.663261</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.813402</td>\n",
       "      <td>0.726948</td>\n",
       "      <td>0.753249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 05:53:03,809] Trial 146 finished with value: 0.7532487916985212 and parameters: {'learning_rate': 0.00019515656490385515, 'weight_decay': 0.003, 'warmup_steps': 21, 'lambda_param': 0.6000000000000001, 'temperature': 5.5}. Best is trial 92 with value: 0.7644517643387146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 147 with params: {'learning_rate': 8.5277304406668e-05, 'weight_decay': 0.01, 'warmup_steps': 5, 'lambda_param': 0.9, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:27 < 02:54, 30.04 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.503000</td>\n",
       "      <td>1.010337</td>\n",
       "      <td>0.693859</td>\n",
       "      <td>0.304206</td>\n",
       "      <td>0.297285</td>\n",
       "      <td>0.276174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.678200</td>\n",
       "      <td>0.760640</td>\n",
       "      <td>0.746104</td>\n",
       "      <td>0.418433</td>\n",
       "      <td>0.405416</td>\n",
       "      <td>0.394008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.430500</td>\n",
       "      <td>0.693484</td>\n",
       "      <td>0.773602</td>\n",
       "      <td>0.506555</td>\n",
       "      <td>0.481427</td>\n",
       "      <td>0.478444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.305700</td>\n",
       "      <td>0.663284</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.586799</td>\n",
       "      <td>0.520515</td>\n",
       "      <td>0.529181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.231200</td>\n",
       "      <td>0.643818</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.633259</td>\n",
       "      <td>0.560318</td>\n",
       "      <td>0.572337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 05:54:32,107] Trial 147 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 148 with params: {'learning_rate': 0.00042273047075564943, 'weight_decay': 0.005, 'warmup_steps': 15, 'lambda_param': 0.7000000000000001, 'temperature': 5.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/7875 01:27 < 02:55, 29.98 it/s, Epoch 5/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.763700</td>\n",
       "      <td>0.673012</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>0.508232</td>\n",
       "      <td>0.501519</td>\n",
       "      <td>0.496941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.173000</td>\n",
       "      <td>0.670573</td>\n",
       "      <td>0.787351</td>\n",
       "      <td>0.710229</td>\n",
       "      <td>0.653977</td>\n",
       "      <td>0.665853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.108500</td>\n",
       "      <td>0.652390</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.734206</td>\n",
       "      <td>0.666877</td>\n",
       "      <td>0.683988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.090100</td>\n",
       "      <td>0.699853</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>0.781749</td>\n",
       "      <td>0.704871</td>\n",
       "      <td>0.723697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.081100</td>\n",
       "      <td>0.675038</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.784465</td>\n",
       "      <td>0.696817</td>\n",
       "      <td>0.722463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 05:56:00,613] Trial 148 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 149 with params: {'learning_rate': 0.00012239133611176964, 'weight_decay': 0.005, 'warmup_steps': 7, 'lambda_param': 1.0, 'temperature': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='7875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/7875 02:56 < 01:28, 29.70 it/s, Epoch 10/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.308800</td>\n",
       "      <td>0.859274</td>\n",
       "      <td>0.726856</td>\n",
       "      <td>0.342461</td>\n",
       "      <td>0.343372</td>\n",
       "      <td>0.319868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.505900</td>\n",
       "      <td>0.697547</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.488707</td>\n",
       "      <td>0.457179</td>\n",
       "      <td>0.454539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.297800</td>\n",
       "      <td>0.650554</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.580677</td>\n",
       "      <td>0.538162</td>\n",
       "      <td>0.540940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.203500</td>\n",
       "      <td>0.646560</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.648662</td>\n",
       "      <td>0.562095</td>\n",
       "      <td>0.582950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.156800</td>\n",
       "      <td>0.648908</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.684762</td>\n",
       "      <td>0.628207</td>\n",
       "      <td>0.641011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.131700</td>\n",
       "      <td>0.639798</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.752715</td>\n",
       "      <td>0.643859</td>\n",
       "      <td>0.675339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.115800</td>\n",
       "      <td>0.636609</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.762955</td>\n",
       "      <td>0.676112</td>\n",
       "      <td>0.701476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.106300</td>\n",
       "      <td>0.638701</td>\n",
       "      <td>0.800183</td>\n",
       "      <td>0.770711</td>\n",
       "      <td>0.677244</td>\n",
       "      <td>0.705169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.099400</td>\n",
       "      <td>0.644222</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.759820</td>\n",
       "      <td>0.669010</td>\n",
       "      <td>0.694522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.093800</td>\n",
       "      <td>0.654706</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.752660</td>\n",
       "      <td>0.673049</td>\n",
       "      <td>0.696033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 05:58:58,291] Trial 149 pruned. \n"
     ]
    }
   ],
   "source": [
    "best_trial_distill_aug = trainer.hyperparameter_search(\n",
    "    direction=\"maximize\",\n",
    "    backend=\"optuna\",\n",
    "    hp_space=hp_space,\n",
    "    compute_objective=lambda metrics: metrics[\"eval_f1\"],\n",
    "    pruner=pruner,\n",
    "    sampler=sampler,\n",
    "    study_name=\"Test-Distill-aug\",\n",
    "    n_trials=150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "896e187f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BestRun(run_id='92', objective=0.7644517643387146, hyperparameters={'learning_rate': 0.0004922578519032032, 'weight_decay': 0.008, 'warmup_steps': 6, 'lambda_param': 1.0, 'temperature': 4.0}, run_summary=None)\n"
     ]
    }
   ],
   "source": [
    "print(best_trial_distill_aug)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
