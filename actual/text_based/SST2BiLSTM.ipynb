{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets, load_from_disk\n",
    "from transformers import BasicTokenizer, Trainer, EarlyStoppingCallback\n",
    "from torch.utils.data import DataLoader\n",
    "import kagglehub\n",
    "import torch\n",
    "import base\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.cache/kagglehub/datasets/thanakomsn/glove6b300dtxt/versions/1\n"
     ]
    }
   ],
   "source": [
    "my_glove = kagglehub.dataset_download(\"thanakomsn/glove6b300dtxt\")\n",
    "print(my_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_FILE = f\"{my_glove}/glove.6B.300d.txt\"\n",
    "DATASET = \"sst2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_from_disk(f\"~/data/{DATASET}/train-logits\")\n",
    "eval_data = load_from_disk(f\"~/data/{DATASET}/eval-logits\")\n",
    "test_data = load_from_disk(f\"~/data/{DATASET}/test-logits\")\n",
    "\n",
    "all_train_data = load_from_disk(f\"~/data/{DATASET}/train-logits-augmented\")\n",
    "test_blank_data = load_from_disk(f\"~/data/{DATASET}/test-blank-logits\")\n",
    "\n",
    "all_data = concatenate_datasets([load_from_disk(file) for file in [f\"~/data/{DATASET}/eval-logits\", f\"~/data/{DATASET}/test-logits\", f\"~/data/{DATASET}/train-logits-augmented\", f\"~/data/{DATASET}/test-blank-logits\"]])\n",
    "tokenizer = BasicTokenizer(do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and will be used: NVIDIA A100 80GB PCIe MIG 2g.20gb\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and will be used:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_tokens = list(map(lambda e: tokenizer.tokenize(e[\"sentence\"]), train_data))\n",
    "eval_data_tokens = list(map(lambda e: tokenizer.tokenize(e[\"sentence\"]), eval_data))\n",
    "test_data_tokens = list(map(lambda e: tokenizer.tokenize(e[\"sentence\"]), test_data))\n",
    "\n",
    "all_train_data_tokens = list(map(lambda e: tokenizer.tokenize(e[\"sentence\"]), all_train_data))\n",
    "test_data_blank_tokens = list(map(lambda e: tokenizer.tokenize(e[\"sentence\"]), test_blank_data))\n",
    "\n",
    "all_data_tokens = list(map(lambda e: tokenizer.tokenize(e[\"sentence\"]), all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = base.get_vocab(all_data_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = dict(zip(vocab, range(len(vocab))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = base.get_embeddings_indeces(GLOVE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16152\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))\n",
    "num_tokens = len(vocab) + 2\n",
    "embedding_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 15775 words (377) misses\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = base.get_embedding_matrix(num_tokens, embedding_dim, word_index, embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_index = list(map(lambda x: list(map(lambda y: word_index[y], x)),train_data_tokens))\n",
    "eval_data_index = list(map(lambda x: list(map(lambda y: word_index[y], x)),eval_data_tokens))\n",
    "test_data_index = list(map(lambda x: list(map(lambda y: word_index[y], x)),test_data_tokens))\n",
    "\n",
    "all_train_data_index = list(map(lambda x: list(map(lambda y: word_index[y], x)),all_train_data_tokens))\n",
    "test_data_blank_index = list(map(lambda x: list(map(lambda y: word_index[y], x)),test_data_blank_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded_data = list(map(lambda x: base.padd(x,60), train_data_index))\n",
    "eval_padded_data = list(map(lambda x: base.padd(x,60), eval_data_index))\n",
    "test_padded_data = list(map(lambda x: base.padd(x,60), test_data_index))\n",
    "\n",
    "all_train_padded_data = list(map(lambda x: base.padd(x,60), all_train_data_index))\n",
    "test_blank_padded_data = list(map(lambda x: base.padd(x,60), test_data_blank_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.add_column(\"input_ids\", train_padded_data)\n",
    "eval_data = eval_data.add_column(\"input_ids\", eval_padded_data)\n",
    "test_data = test_data.add_column(\"input_ids\", test_padded_data)\n",
    "\n",
    "all_train_data = all_train_data.add_column(\"input_ids\", all_train_padded_data)\n",
    "test_blank_data = test_blank_data.add_column(\"input_ids\", test_blank_padded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = base.BiLSTMClassifier(embedding_matrix=embedding_matrix, embedding_dim=embedding_dim, fc_dim=400, hidden_dim=300, output_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTMClassifier(\n",
      "  (embedding): Embedding(16154, 300)\n",
      "  (lstm): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
      "  (fc1): Linear(in_features=600, out_features=400, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc2): Linear(in_features=400, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bilstm-base\", logging_dir=f\"~/logs/{DATASET}/bilstm-base\", lr=.001,  epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3789' max='4210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3789/4210 03:43 < 00:24, 16.97 it/s, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.378700</td>\n",
       "      <td>0.428864</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.798149</td>\n",
       "      <td>0.790562</td>\n",
       "      <td>0.787919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.405656</td>\n",
       "      <td>0.841743</td>\n",
       "      <td>0.844052</td>\n",
       "      <td>0.840974</td>\n",
       "      <td>0.841221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.224000</td>\n",
       "      <td>0.421950</td>\n",
       "      <td>0.830275</td>\n",
       "      <td>0.835364</td>\n",
       "      <td>0.829124</td>\n",
       "      <td>0.829237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.171700</td>\n",
       "      <td>0.510579</td>\n",
       "      <td>0.823394</td>\n",
       "      <td>0.830903</td>\n",
       "      <td>0.821988</td>\n",
       "      <td>0.821895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.126700</td>\n",
       "      <td>0.519346</td>\n",
       "      <td>0.846330</td>\n",
       "      <td>0.846330</td>\n",
       "      <td>0.846447</td>\n",
       "      <td>0.846317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>0.584370</td>\n",
       "      <td>0.855505</td>\n",
       "      <td>0.856079</td>\n",
       "      <td>0.855119</td>\n",
       "      <td>0.855310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.065600</td>\n",
       "      <td>0.523298</td>\n",
       "      <td>0.853211</td>\n",
       "      <td>0.853534</td>\n",
       "      <td>0.852909</td>\n",
       "      <td>0.853060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.044600</td>\n",
       "      <td>0.625059</td>\n",
       "      <td>0.854358</td>\n",
       "      <td>0.855320</td>\n",
       "      <td>0.853867</td>\n",
       "      <td>0.854095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.029700</td>\n",
       "      <td>0.734544</td>\n",
       "      <td>0.854358</td>\n",
       "      <td>0.854438</td>\n",
       "      <td>0.854540</td>\n",
       "      <td>0.854353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3789, training_loss=0.15810505133815353, metrics={'train_runtime': 225.113, 'train_samples_per_second': 2393.42, 'train_steps_per_second': 18.702, 'total_flos': 0.0, 'train_loss': 0.15810505133815353, 'epoch': 9.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMClassifier(\n",
       "  (embedding): Embedding(16154, 300)\n",
       "  (lstm): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=600, out_features=400, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=400, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='106' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/106 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.23646903038024902,\n",
       " 'eval_accuracy': 0.9288789903489235,\n",
       " 'eval_precision': 0.9271139731044955,\n",
       " 'eval_recall': 0.9294811985614317,\n",
       " 'eval_f1': 0.9281267956799594,\n",
       " 'eval_runtime': 6.1311,\n",
       " 'eval_samples_per_second': 2197.002,\n",
       " 'eval_steps_per_second': 17.289,\n",
       " 'epoch': 9.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bilstm-base.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a08211654de04fc89d7ab986a873885e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating logits for given dataset:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_blank_data.set_format(type=\"torch\", columns=[\"input_ids\"], device=\"cuda\")\n",
    "test_blank_dataloader = DataLoader(test_blank_data, batch_size=128, shuffle=False)\n",
    "test_blank_logits = base.generate_logits(test_blank_dataloader, model, images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created output file named: /home/jovyan/data/sst2/bilstm-base-test.tsv upload it to GLUE benchmark to obtain results!\n"
     ]
    }
   ],
   "source": [
    "base.generate_real_test_file_sst2(test_blank_logits, f\"{os.path.expanduser('~')}/data/{DATASET}/bilstm-base-test.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reálné skóre na pravé test části datasetu\n",
    "\n",
    "![Real test score (GLUE Benchmark)](../imgs/sst2_BiLSTM_base_score.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = base.BiLSTMClassifier(embedding_matrix=embedding_matrix, embedding_dim=embedding_dim, fc_dim=400, hidden_dim=300, output_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bilstm-distill\", remove_unused_columns=False, logging_dir=f\"~/logs/{DATASET}/bilstm-distill\", lr=.001,  epochs=10, batch_size=128, lambda_param=.75, temp=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainer(\n",
    "    student_model=student_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='4210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/4210 04:41, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.201700</td>\n",
       "      <td>1.776676</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.805656</td>\n",
       "      <td>0.805443</td>\n",
       "      <td>0.805037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.442900</td>\n",
       "      <td>1.665758</td>\n",
       "      <td>0.839450</td>\n",
       "      <td>0.842292</td>\n",
       "      <td>0.838596</td>\n",
       "      <td>0.838831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.999800</td>\n",
       "      <td>1.760082</td>\n",
       "      <td>0.841743</td>\n",
       "      <td>0.847053</td>\n",
       "      <td>0.840595</td>\n",
       "      <td>0.840775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.714800</td>\n",
       "      <td>1.644500</td>\n",
       "      <td>0.840596</td>\n",
       "      <td>0.842765</td>\n",
       "      <td>0.839848</td>\n",
       "      <td>0.840091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.535300</td>\n",
       "      <td>1.492927</td>\n",
       "      <td>0.848624</td>\n",
       "      <td>0.848757</td>\n",
       "      <td>0.848404</td>\n",
       "      <td>0.848509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.397000</td>\n",
       "      <td>1.638747</td>\n",
       "      <td>0.855505</td>\n",
       "      <td>0.855732</td>\n",
       "      <td>0.855245</td>\n",
       "      <td>0.855376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.312100</td>\n",
       "      <td>1.508142</td>\n",
       "      <td>0.853211</td>\n",
       "      <td>0.853534</td>\n",
       "      <td>0.852909</td>\n",
       "      <td>0.853060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.243000</td>\n",
       "      <td>1.597368</td>\n",
       "      <td>0.857798</td>\n",
       "      <td>0.859267</td>\n",
       "      <td>0.857203</td>\n",
       "      <td>0.857468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.196200</td>\n",
       "      <td>1.480608</td>\n",
       "      <td>0.863532</td>\n",
       "      <td>0.863498</td>\n",
       "      <td>0.863465</td>\n",
       "      <td>0.863480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.164600</td>\n",
       "      <td>1.497354</td>\n",
       "      <td>0.865826</td>\n",
       "      <td>0.866024</td>\n",
       "      <td>0.865591</td>\n",
       "      <td>0.865715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jovyan/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--accuracy/f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14 (last modified on Sat Oct 12 13:56:14 2024) since it couldn't be found locally at evaluate-metric--accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4210, training_loss=0.7207459438441768, metrics={'train_runtime': 281.9936, 'train_samples_per_second': 1910.646, 'train_steps_per_second': 14.929, 'total_flos': 0.0, 'train_loss': 0.7207459438441768, 'epoch': 10.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMClassifier(\n",
       "  (embedding): Embedding(16154, 300)\n",
       "  (lstm): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=600, out_features=400, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=400, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='106' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/106 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5973865985870361,\n",
       " 'eval_accuracy': 0.9455827765404603,\n",
       " 'eval_precision': 0.9444359599914218,\n",
       " 'eval_recall': 0.945428015007759,\n",
       " 'eval_f1': 0.9449077661189482,\n",
       " 'eval_runtime': 6.1664,\n",
       " 'eval_samples_per_second': 2184.408,\n",
       " 'eval_steps_per_second': 17.19,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student_model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bilstm-distill.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3490ec6870d4b9ba77a01362496d85b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating logits for given dataset:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created output file named: /home/jovyan/data/sst2/bilstm-distill-test.tsv upload it to GLUE benchmark to obtain results!\n"
     ]
    }
   ],
   "source": [
    "test_blank_logits = base.generate_logits(test_blank_dataloader, student_model, images=False)\n",
    "base.generate_real_test_file_sst2(test_blank_logits, f\"{os.path.expanduser('~')}/data/{DATASET}/bilstm-distill-test.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reálné skóre na pravé test části datasetu\n",
    "\n",
    "![Real test score (GLUE Benchmark)](../imgs/sst2_BiLSTM_distill_score.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = base.BiLSTMClassifier(embedding_matrix=embedding_matrix, embedding_dim=embedding_dim, fc_dim=400, hidden_dim=300, output_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bilstm-base-aug\", logging_dir=f\"~/logs/{DATASET}/bilstm-base-aug\", lr=.001,  epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=all_train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 4)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11802' max='41690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11802/41690 10:27 < 26:30, 18.79 it/s, Epoch 2.83/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.209100</td>\n",
       "      <td>0.419615</td>\n",
       "      <td>0.860092</td>\n",
       "      <td>0.860547</td>\n",
       "      <td>0.859750</td>\n",
       "      <td>0.859926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.073300</td>\n",
       "      <td>0.556338</td>\n",
       "      <td>0.858945</td>\n",
       "      <td>0.860657</td>\n",
       "      <td>0.859592</td>\n",
       "      <td>0.858891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2550\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2547\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2548\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[0;32m-> 2550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2551\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2552\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2553\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2554\u001b[0m ):\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2556\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2557\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMClassifier(\n",
       "  (embedding): Embedding(16154, 300)\n",
       "  (lstm): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=600, out_features=400, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=400, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='106' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/106 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.20508646965026855,\n",
       " 'eval_accuracy': 0.9359317000742391,\n",
       " 'eval_precision': 0.9343437073392804,\n",
       " 'eval_recall': 0.9363075203430427,\n",
       " 'eval_f1': 0.9352168087509563,\n",
       " 'eval_runtime': 5.7357,\n",
       " 'eval_samples_per_second': 2348.437,\n",
       " 'eval_steps_per_second': 18.481,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bilstm-base-aug.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eacbde4e0d784738805515122d0e2685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating logits for given dataset:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created output file named: /home/jovyan/data/sst2/bilstm-base-aug-test.tsv upload it to GLUE benchmark to obtain results!\n"
     ]
    }
   ],
   "source": [
    "test_blank_logits = base.generate_logits(test_blank_dataloader, model, images=False)\n",
    "base.generate_real_test_file_sst2(test_blank_logits, f\"{os.path.expanduser('~')}/data/{DATASET}/bilstm-base-aug-test.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reálné skóre na pravé test části datasetu\n",
    "\n",
    "![Real test score (GLUE Benchmark)](../imgs/sst2_BiLSTM_base_aug_score.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = base.BiLSTMClassifier(embedding_matrix=embedding_matrix, embedding_dim=embedding_dim, fc_dim=400, hidden_dim=300, output_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bilstm-distill-aug\", remove_unused_columns=False, logging_dir=f\"~/logs/{DATASET}/bilstm-distill-aug\", lr=.001,  epochs=10, batch_size=128, lambda_param=.75, temp=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainer(\n",
    "    student_model=student_model,\n",
    "    args=training_args,\n",
    "    train_dataset=all_train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 4)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29929' max='41690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29929/41690 15:04 < 05:55, 33.09 it/s, Epoch 7.18/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.849900</td>\n",
       "      <td>1.286510</td>\n",
       "      <td>0.860092</td>\n",
       "      <td>0.862042</td>\n",
       "      <td>0.859413</td>\n",
       "      <td>0.859701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.259900</td>\n",
       "      <td>1.146900</td>\n",
       "      <td>0.860092</td>\n",
       "      <td>0.860240</td>\n",
       "      <td>0.859876</td>\n",
       "      <td>0.859986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>1.138879</td>\n",
       "      <td>0.872706</td>\n",
       "      <td>0.873945</td>\n",
       "      <td>0.872179</td>\n",
       "      <td>0.872451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.115200</td>\n",
       "      <td>1.102087</td>\n",
       "      <td>0.870413</td>\n",
       "      <td>0.870367</td>\n",
       "      <td>0.870474</td>\n",
       "      <td>0.870392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.093000</td>\n",
       "      <td>1.083817</td>\n",
       "      <td>0.872706</td>\n",
       "      <td>0.873175</td>\n",
       "      <td>0.873063</td>\n",
       "      <td>0.872705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.077500</td>\n",
       "      <td>1.066516</td>\n",
       "      <td>0.861239</td>\n",
       "      <td>0.861219</td>\n",
       "      <td>0.861339</td>\n",
       "      <td>0.861224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.066200</td>\n",
       "      <td>0.976038</td>\n",
       "      <td>0.872706</td>\n",
       "      <td>0.872729</td>\n",
       "      <td>0.872853</td>\n",
       "      <td>0.872698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2500\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2498\u001b[0m update_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2499\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step \u001b[38;5;241m!=\u001b[39m (total_updates \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[0;32m-> 2500\u001b[0m batch_samples, num_items_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2501\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_samples):\n\u001b[1;32m   2502\u001b[0m     step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:5195\u001b[0m, in \u001b[0;36mTrainer.get_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches)\u001b[0m\n\u001b[1;32m   5192\u001b[0m     num_items_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather(num_items_in_batch)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m   5194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(num_items_in_batch):\n\u001b[0;32m-> 5195\u001b[0m     num_items_in_batch \u001b[38;5;241m=\u001b[39m \u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch_samples, num_items_in_batch\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMClassifier(\n",
       "  (embedding): Embedding(16154, 300)\n",
       "  (lstm): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=600, out_features=400, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=400, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='106' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/106 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.33813270926475525,\n",
       " 'eval_accuracy': 0.9596139569413511,\n",
       " 'eval_precision': 0.9584960659013655,\n",
       " 'eval_recall': 0.9598496283543609,\n",
       " 'eval_f1': 0.9591285149534032,\n",
       " 'eval_runtime': 3.6436,\n",
       " 'eval_samples_per_second': 3696.876,\n",
       " 'eval_steps_per_second': 29.092,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bilstm-distill-aug.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c974d1db5f46bc939f9802ae962912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating logits for given dataset:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created output file named: ./data/sst2/bilstm-distill-aug-test.tsv upload it to GLUE benchmark to obtain results!\n"
     ]
    }
   ],
   "source": [
    "test_blank_logits = base.generate_logits(test_blank_dataloader, student_model, images=False)\n",
    "base.generate_real_test_file_sst2(test_blank_logits, f\"{os.path.expanduser('~')}/data/{DATASET}/bilstm-distill-aug-test.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reálné skóre na pravé test části datasetu\n",
    "\n",
    "![Real test score (GLUE Benchmark)](../imgs/sst2_BiLSTM_distill_aug_score.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skóre učitelského modelu na reálné test části datasetu\n",
    "\n",
    "![SST2 test score for best BERT model](../imgs/sst2_BERT_test_score.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
