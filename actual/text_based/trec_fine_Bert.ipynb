{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Torchtext není k dispozici pro poslední verzi pytorch, budeme tedy využuívat něco jiného ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, BertForSequenceClassification, BertTokenizer, EarlyStoppingCallback\n",
    "from datasets import load_from_disk\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import base\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"trec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and will be used: NVIDIA H100 PCIe\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and will be used:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_from_disk(f\"~/data/{DATASET}/train-logits_fine\")\n",
    "eval = load_from_disk(f\"~/data/{DATASET}/eval-logits_fine\")\n",
    "test = load_from_disk(f\"~/data/{DATASET}/test-logits_fine\")\n",
    "\n",
    "train_aug = load_from_disk(f\"~/data/{DATASET}/train-logits-augmented_fine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"ndavid/autotrain-trec-fine-bert-739422530\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f87e5d83335474b89abbe1f245f07ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the train dataset:   0%|          | 0/4361 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "811fc86e3b8c47cba302a8d17cba2aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the eval dataset:   0%|          | 0/1091 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef014110b094551ada6be00e7eb2e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the test dataset:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9dada877f8b4daf9b4e9e64003c75a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the augmented dataset:   0%|          | 0/66864 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = train.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the train dataset\")\n",
    "eval = eval.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the eval dataset\")\n",
    "test = test.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the test dataset\")\n",
    "\n",
    "train_aug = train_aug.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the augmented dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\", num_labels=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bert-base_fine\", logging_dir=f\"~/logs/{DATASET}/bert-base_fine\", lr=0.0005, weight_decay=.01, warmup_steps=4, batch_size=128, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [700/700 01:44, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.387000</td>\n",
       "      <td>2.840134</td>\n",
       "      <td>0.432631</td>\n",
       "      <td>0.064656</td>\n",
       "      <td>0.103830</td>\n",
       "      <td>0.076528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.490700</td>\n",
       "      <td>2.123035</td>\n",
       "      <td>0.571952</td>\n",
       "      <td>0.225552</td>\n",
       "      <td>0.207389</td>\n",
       "      <td>0.188044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.844300</td>\n",
       "      <td>1.671466</td>\n",
       "      <td>0.667278</td>\n",
       "      <td>0.320821</td>\n",
       "      <td>0.306982</td>\n",
       "      <td>0.289364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.406600</td>\n",
       "      <td>1.416176</td>\n",
       "      <td>0.725940</td>\n",
       "      <td>0.390650</td>\n",
       "      <td>0.378789</td>\n",
       "      <td>0.359673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.105900</td>\n",
       "      <td>1.262823</td>\n",
       "      <td>0.742438</td>\n",
       "      <td>0.385176</td>\n",
       "      <td>0.390920</td>\n",
       "      <td>0.370337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.874700</td>\n",
       "      <td>1.166682</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.418634</td>\n",
       "      <td>0.405066</td>\n",
       "      <td>0.389456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.717000</td>\n",
       "      <td>1.122182</td>\n",
       "      <td>0.740605</td>\n",
       "      <td>0.436371</td>\n",
       "      <td>0.409665</td>\n",
       "      <td>0.404332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.607900</td>\n",
       "      <td>1.078695</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.460445</td>\n",
       "      <td>0.443123</td>\n",
       "      <td>0.433565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.500900</td>\n",
       "      <td>1.034985</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.517015</td>\n",
       "      <td>0.464773</td>\n",
       "      <td>0.466777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.421600</td>\n",
       "      <td>1.028733</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.480723</td>\n",
       "      <td>0.481258</td>\n",
       "      <td>0.472726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.364400</td>\n",
       "      <td>1.007080</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.496029</td>\n",
       "      <td>0.466823</td>\n",
       "      <td>0.466735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.315900</td>\n",
       "      <td>0.993210</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>0.539328</td>\n",
       "      <td>0.510245</td>\n",
       "      <td>0.514486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.273300</td>\n",
       "      <td>0.995696</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.572748</td>\n",
       "      <td>0.533880</td>\n",
       "      <td>0.536077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.232800</td>\n",
       "      <td>1.003556</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.554138</td>\n",
       "      <td>0.539661</td>\n",
       "      <td>0.535609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.212300</td>\n",
       "      <td>1.000657</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.620142</td>\n",
       "      <td>0.575087</td>\n",
       "      <td>0.583545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.196200</td>\n",
       "      <td>1.007416</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.613505</td>\n",
       "      <td>0.577605</td>\n",
       "      <td>0.580498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.182100</td>\n",
       "      <td>1.004870</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.631156</td>\n",
       "      <td>0.579407</td>\n",
       "      <td>0.587993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.168100</td>\n",
       "      <td>0.998991</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.651794</td>\n",
       "      <td>0.590158</td>\n",
       "      <td>0.602041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.164200</td>\n",
       "      <td>1.005455</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.686656</td>\n",
       "      <td>0.601301</td>\n",
       "      <td>0.622629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.163100</td>\n",
       "      <td>1.006463</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.682700</td>\n",
       "      <td>0.606293</td>\n",
       "      <td>0.623973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=700, training_loss=0.7814531803131104, metrics={'train_runtime': 105.6302, 'train_samples_per_second': 825.71, 'train_steps_per_second': 6.627, 'total_flos': 65900954952000.0, 'train_loss': 0.7814531803131104, 'epoch': 20.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-1): 2 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=128, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0739054679870605,\n",
       " 'eval_accuracy': 0.75,\n",
       " 'eval_precision': 0.5956436960292529,\n",
       " 'eval_recall': 0.6108920151191847,\n",
       " 'eval_f1': 0.5633155299167988,\n",
       " 'eval_runtime': 25.5307,\n",
       " 'eval_samples_per_second': 19.584,\n",
       " 'eval_steps_per_second': 0.157,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bert_fine.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "student_model = BertForSequenceClassification.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\", num_labels=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bert-distill_fine\", logging_dir=f\"~/logs/{DATASET}/bert-distill_fine\", remove_unused_columns=False, lr=0.0005, weight_decay=.003, warmup_steps=4, batch_size=128, epochs=20, temp=6, lambda_param=.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainer(\n",
    "    student_model=student_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [700/700 01:39, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.388000</td>\n",
       "      <td>2.022393</td>\n",
       "      <td>0.439963</td>\n",
       "      <td>0.082278</td>\n",
       "      <td>0.111877</td>\n",
       "      <td>0.082839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.774600</td>\n",
       "      <td>1.518177</td>\n",
       "      <td>0.581118</td>\n",
       "      <td>0.242029</td>\n",
       "      <td>0.216172</td>\n",
       "      <td>0.195616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.326200</td>\n",
       "      <td>1.214127</td>\n",
       "      <td>0.678277</td>\n",
       "      <td>0.284868</td>\n",
       "      <td>0.298381</td>\n",
       "      <td>0.276712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.040700</td>\n",
       "      <td>1.040531</td>\n",
       "      <td>0.725940</td>\n",
       "      <td>0.319425</td>\n",
       "      <td>0.341143</td>\n",
       "      <td>0.320662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.851200</td>\n",
       "      <td>0.942741</td>\n",
       "      <td>0.734189</td>\n",
       "      <td>0.321513</td>\n",
       "      <td>0.349247</td>\n",
       "      <td>0.326995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.699500</td>\n",
       "      <td>0.880714</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.375358</td>\n",
       "      <td>0.381842</td>\n",
       "      <td>0.363885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.591500</td>\n",
       "      <td>0.842096</td>\n",
       "      <td>0.745188</td>\n",
       "      <td>0.350238</td>\n",
       "      <td>0.368303</td>\n",
       "      <td>0.351581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.517700</td>\n",
       "      <td>0.809350</td>\n",
       "      <td>0.763520</td>\n",
       "      <td>0.437652</td>\n",
       "      <td>0.415115</td>\n",
       "      <td>0.409491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.450400</td>\n",
       "      <td>0.794824</td>\n",
       "      <td>0.764436</td>\n",
       "      <td>0.480924</td>\n",
       "      <td>0.425622</td>\n",
       "      <td>0.430564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.395000</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.491696</td>\n",
       "      <td>0.447030</td>\n",
       "      <td>0.446788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.358300</td>\n",
       "      <td>0.769565</td>\n",
       "      <td>0.771769</td>\n",
       "      <td>0.532866</td>\n",
       "      <td>0.465928</td>\n",
       "      <td>0.471892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.320400</td>\n",
       "      <td>0.748340</td>\n",
       "      <td>0.779102</td>\n",
       "      <td>0.574010</td>\n",
       "      <td>0.480881</td>\n",
       "      <td>0.499813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.295300</td>\n",
       "      <td>0.748111</td>\n",
       "      <td>0.779102</td>\n",
       "      <td>0.568008</td>\n",
       "      <td>0.496603</td>\n",
       "      <td>0.512363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.265800</td>\n",
       "      <td>0.748311</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.566944</td>\n",
       "      <td>0.513451</td>\n",
       "      <td>0.524647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.253600</td>\n",
       "      <td>0.747917</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.567561</td>\n",
       "      <td>0.525384</td>\n",
       "      <td>0.533387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.240200</td>\n",
       "      <td>0.750978</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.566190</td>\n",
       "      <td>0.518309</td>\n",
       "      <td>0.528333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.228700</td>\n",
       "      <td>0.742981</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.567096</td>\n",
       "      <td>0.518063</td>\n",
       "      <td>0.527972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.221800</td>\n",
       "      <td>0.732937</td>\n",
       "      <td>0.795600</td>\n",
       "      <td>0.581677</td>\n",
       "      <td>0.530133</td>\n",
       "      <td>0.540571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.218600</td>\n",
       "      <td>0.734380</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.580314</td>\n",
       "      <td>0.528121</td>\n",
       "      <td>0.538632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.217600</td>\n",
       "      <td>0.735637</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.582921</td>\n",
       "      <td>0.528121</td>\n",
       "      <td>0.539459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=700, training_loss=0.6327556821278163, metrics={'train_runtime': 99.3637, 'train_samples_per_second': 877.785, 'train_steps_per_second': 7.045, 'total_flos': 65900954952000.0, 'train_loss': 0.6327556821278163, 'epoch': 20.0})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-1): 2 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=128, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7448195219039917,\n",
       " 'eval_accuracy': 0.772,\n",
       " 'eval_precision': 0.5266354326636652,\n",
       " 'eval_recall': 0.5743078647261858,\n",
       " 'eval_f1': 0.5201327909952986,\n",
       " 'eval_runtime': 3.6785,\n",
       " 'eval_samples_per_second': 135.924,\n",
       " 'eval_steps_per_second': 1.087,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student_model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bert-distil_fine.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\", num_labels=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bert-base-aug_fine\", logging_dir=f\"~/logs/{DATASET}/bert-base-aug_fine\", lr=0.0002, warmup_steps=20, batch_size=128, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_aug,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4707' max='10460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 4707/10460 01:56 < 02:22, 40.26 it/s, Epoch 9/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.657000</td>\n",
       "      <td>1.124339</td>\n",
       "      <td>0.752521</td>\n",
       "      <td>0.440498</td>\n",
       "      <td>0.447612</td>\n",
       "      <td>0.431779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.392200</td>\n",
       "      <td>0.991754</td>\n",
       "      <td>0.780935</td>\n",
       "      <td>0.595150</td>\n",
       "      <td>0.552515</td>\n",
       "      <td>0.552570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.150200</td>\n",
       "      <td>1.024132</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.709125</td>\n",
       "      <td>0.667845</td>\n",
       "      <td>0.667761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>1.067830</td>\n",
       "      <td>0.806599</td>\n",
       "      <td>0.816312</td>\n",
       "      <td>0.725097</td>\n",
       "      <td>0.749853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.043800</td>\n",
       "      <td>1.141872</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.796053</td>\n",
       "      <td>0.726970</td>\n",
       "      <td>0.740722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>1.184395</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.803258</td>\n",
       "      <td>0.734878</td>\n",
       "      <td>0.751566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>1.246228</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.799595</td>\n",
       "      <td>0.738313</td>\n",
       "      <td>0.749569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>1.296766</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.789797</td>\n",
       "      <td>0.737691</td>\n",
       "      <td>0.746359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>1.344361</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.790948</td>\n",
       "      <td>0.742190</td>\n",
       "      <td>0.748242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4707, training_loss=0.2667730106323774, metrics={'train_runtime': 117.5222, 'train_samples_per_second': 11378.952, 'train_steps_per_second': 89.004, 'total_flos': 454684855161600.0, 'train_loss': 0.2667730106323774, 'epoch': 9.0})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-1): 2 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=128, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.112660527229309,\n",
       " 'eval_accuracy': 0.802,\n",
       " 'eval_precision': 0.7059030232013304,\n",
       " 'eval_recall': 0.6940250900545852,\n",
       " 'eval_f1': 0.6775414956968477,\n",
       " 'eval_runtime': 3.1838,\n",
       " 'eval_samples_per_second': 157.046,\n",
       " 'eval_steps_per_second': 1.256,\n",
       " 'epoch': 9.0}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bert-base-aug_fine.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "student_model = BertForSequenceClassification.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\", num_labels=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bert-distill-aug_fine\", logging_dir=f\"~/logs/{DATASET}/bert-distill-aug_fine\", remove_unused_columns=False, lr=0.0005, batch_size=128, weight_decay=.008, warmup_steps=6, epochs=20, temp=4, lambda_param=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainer(\n",
    "    student_model=student_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_aug,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8368' max='10460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8368/10460 03:53 < 00:58, 35.76 it/s, Epoch 16/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.579800</td>\n",
       "      <td>0.544874</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>0.562526</td>\n",
       "      <td>0.506004</td>\n",
       "      <td>0.510333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.128900</td>\n",
       "      <td>0.543075</td>\n",
       "      <td>0.783685</td>\n",
       "      <td>0.676358</td>\n",
       "      <td>0.590180</td>\n",
       "      <td>0.616199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.089700</td>\n",
       "      <td>0.529881</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.726190</td>\n",
       "      <td>0.655666</td>\n",
       "      <td>0.671212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.078600</td>\n",
       "      <td>0.522756</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.773533</td>\n",
       "      <td>0.681308</td>\n",
       "      <td>0.709115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.073200</td>\n",
       "      <td>0.552171</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.805312</td>\n",
       "      <td>0.702308</td>\n",
       "      <td>0.735302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.069300</td>\n",
       "      <td>0.561877</td>\n",
       "      <td>0.790101</td>\n",
       "      <td>0.827488</td>\n",
       "      <td>0.723885</td>\n",
       "      <td>0.755998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.067600</td>\n",
       "      <td>0.537938</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.820343</td>\n",
       "      <td>0.725125</td>\n",
       "      <td>0.752319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.521953</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.824642</td>\n",
       "      <td>0.730822</td>\n",
       "      <td>0.757816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.552106</td>\n",
       "      <td>0.791017</td>\n",
       "      <td>0.835892</td>\n",
       "      <td>0.721802</td>\n",
       "      <td>0.754901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.063200</td>\n",
       "      <td>0.532560</td>\n",
       "      <td>0.804766</td>\n",
       "      <td>0.842718</td>\n",
       "      <td>0.722607</td>\n",
       "      <td>0.759278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.555660</td>\n",
       "      <td>0.789184</td>\n",
       "      <td>0.823945</td>\n",
       "      <td>0.722487</td>\n",
       "      <td>0.749818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.536541</td>\n",
       "      <td>0.798350</td>\n",
       "      <td>0.831350</td>\n",
       "      <td>0.724575</td>\n",
       "      <td>0.755665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.061200</td>\n",
       "      <td>0.532382</td>\n",
       "      <td>0.803850</td>\n",
       "      <td>0.841480</td>\n",
       "      <td>0.736235</td>\n",
       "      <td>0.765994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.060100</td>\n",
       "      <td>0.540972</td>\n",
       "      <td>0.799267</td>\n",
       "      <td>0.831340</td>\n",
       "      <td>0.734783</td>\n",
       "      <td>0.760795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.060100</td>\n",
       "      <td>0.532940</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.842911</td>\n",
       "      <td>0.727390</td>\n",
       "      <td>0.762355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.059500</td>\n",
       "      <td>0.544438</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.833541</td>\n",
       "      <td>0.723635</td>\n",
       "      <td>0.755928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8368, training_loss=0.1028169580445007, metrics={'train_runtime': 234.3124, 'train_samples_per_second': 5707.251, 'train_steps_per_second': 44.641, 'total_flos': 808328631398400.0, 'train_loss': 0.1028169580445007, 'epoch': 16.0})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-1): 2 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=128, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.44254034757614136,\n",
       " 'eval_accuracy': 0.812,\n",
       " 'eval_precision': 0.7194187710473471,\n",
       " 'eval_recall': 0.6992282075148261,\n",
       " 'eval_f1': 0.6826634614101706,\n",
       " 'eval_runtime': 3.7661,\n",
       " 'eval_samples_per_second': 132.763,\n",
       " 'eval_steps_per_second': 1.062,\n",
       " 'epoch': 16.0}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student_model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bert-distil-aug_fine.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
