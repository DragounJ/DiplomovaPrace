{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets, load_from_disk\n",
    "from transformers import BasicTokenizer, BertForSequenceClassification, BertTokenizer\n",
    "import kagglehub\n",
    "import torch\n",
    "import base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.10), please consider upgrading to the latest version (0.3.11).\n",
      "/home/jovyan/.cache/kagglehub/datasets/thanakomsn/glove6b300dtxt/versions/1\n"
     ]
    }
   ],
   "source": [
    "my_glove = kagglehub.dataset_download(\"thanakomsn/glove6b300dtxt\")\n",
    "print(my_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_FILE = f\"{my_glove}/glove.6B.300d.txt\"\n",
    "DATASET = \"dbpedia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_from_disk(f\"~/data/{DATASET}/train-logits\")\n",
    "eval_data = load_from_disk(f\"~/data/{DATASET}/eval-logits\")\n",
    "test_data = load_from_disk(f\"~/data/{DATASET}/test-logits\")\n",
    "\n",
    "all_train_data = load_from_disk(f\"~/data/{DATASET}/train-logits-augmented\")\n",
    "\n",
    "all_data = concatenate_datasets([load_from_disk(file) for file in [f\"~/data/{DATASET}/eval-logits\", f\"~/data/{DATASET}/test-logits\", f\"~/data/{DATASET}/train-logits-augmented\"]])\n",
    "tokenizer = BasicTokenizer(do_lower_case=True)\n",
    "teacher_tokenizer = BertTokenizer.from_pretrained(\"fabriceyhc/bert-base-uncased-dbpedia_14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and will be used: NVIDIA A100 80GB PCIe MIG 2g.20gb\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and will be used:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_tokens = list(map(lambda e: tokenizer.tokenize(e[\"sentence\"]), train_data))\n",
    "eval_data_tokens = list(map(lambda e: tokenizer.tokenize(e[\"sentence\"]), eval_data))\n",
    "test_data_tokens = list(map(lambda e: tokenizer.tokenize(e[\"sentence\"]), test_data))\n",
    "\n",
    "all_train_data_tokens = list(map(lambda e: tokenizer.tokenize(e[\"sentence\"]), all_train_data))\n",
    "\n",
    "all_data_tokens = list(map(lambda e: tokenizer.tokenize(e[\"sentence\"]), all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = base.get_vocab(all_data_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = dict(zip(vocab, range(len(vocab))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = base.get_embeddings_indeces(GLOVE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691158\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))\n",
    "num_tokens = len(vocab) + 2\n",
    "embedding_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 212978 words (478180) misses\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = base.get_embedding_matrix(num_tokens, embedding_dim, word_index, embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_index = list(map(lambda x: list(map(lambda y: word_index[y], x)),train_data_tokens))\n",
    "eval_data_index = list(map(lambda x: list(map(lambda y: word_index[y], x)),eval_data_tokens))\n",
    "test_data_index = list(map(lambda x: list(map(lambda y: word_index[y], x)),test_data_tokens))\n",
    "\n",
    "all_train_data_index = list(map(lambda x: list(map(lambda y: word_index[y], x)),all_train_data_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded_data = list(map(lambda x: base.padd(x,60), train_data_index))\n",
    "eval_padded_data = list(map(lambda x: base.padd(x,60), eval_data_index))\n",
    "test_padded_data = list(map(lambda x: base.padd(x,60), test_data_index))\n",
    "\n",
    "all_train_padded_data = list(map(lambda x: base.padd(x,60), all_train_data_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e0265154be494a936b2658a7911670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the provided dataset:   0%|          | 0/448000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0fa0117541476f8a29b176b423eb65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the provided dataset:   0%|          | 0/112000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90115f8eabf7477491e35af245e931cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the provided dataset:   0%|          | 0/70000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e1c9fb42f643cc97223a5c2a3e335e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the provided dataset:   0%|          | 0/879371 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_teacher_data = base.prepare_dataset_teacher(train_data, teacher_tokenizer)\n",
    "eval_teacher_data = base.prepare_dataset_teacher(eval_data, teacher_tokenizer)\n",
    "test_teacher_data = base.prepare_dataset_teacher(test_data, teacher_tokenizer)\n",
    "\n",
    "all_train_teacher_data = base.prepare_dataset_teacher(all_train_data, teacher_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.add_column(\"input_ids\", train_padded_data)\n",
    "train_data = train_data.add_column(\"teacher_ids\", train_teacher_data[0])\n",
    "train_data = train_data.add_column(\"teacher_attention\", train_teacher_data[1])\n",
    "\n",
    "eval_data = eval_data.add_column(\"input_ids\", eval_padded_data)\n",
    "eval_data = eval_data.add_column(\"teacher_ids\", eval_teacher_data[0])\n",
    "eval_data = eval_data.add_column(\"teacher_attention\", eval_teacher_data[1])\n",
    "\n",
    "test_data = test_data.add_column(\"input_ids\", test_padded_data)\n",
    "test_data = test_data.add_column(\"teacher_ids\", test_teacher_data[0])\n",
    "test_data = test_data.add_column(\"teacher_attention\", test_teacher_data[1])\n",
    "\n",
    "all_train_data = all_train_data.add_column(\"input_ids\", all_train_padded_data)\n",
    "all_train_data = all_train_data.add_column(\"teacher_ids\", all_train_teacher_data[0])\n",
    "all_train_data = all_train_data.add_column(\"teacher_attention\", all_train_teacher_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = base.BiLSTMClassifier(embedding_matrix=embedding_matrix, embedding_dim=embedding_dim, fc_dim=400, hidden_dim=300, output_dim=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bilstm-distill_fine\", remove_unused_columns=False, logging_dir=f\"~/logs/{DATASET}/bilstm-distill_fine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.set_format(type=\"torch\", columns=[\"input_ids\", \"logits\", \"labels\"], device=\"cpu\")\n",
    "eval_data.set_format(type=\"torch\", columns=[\"input_ids\", \"logits\", \"labels\"], device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainer(\n",
    "    student_model=student_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    compute_metrics=base.compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17500' max='17500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17500/17500 04:51, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.169500</td>\n",
       "      <td>0.214040</td>\n",
       "      <td>0.974527</td>\n",
       "      <td>0.974705</td>\n",
       "      <td>0.974527</td>\n",
       "      <td>0.974542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.217200</td>\n",
       "      <td>0.150281</td>\n",
       "      <td>0.980589</td>\n",
       "      <td>0.980584</td>\n",
       "      <td>0.980589</td>\n",
       "      <td>0.980559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.173300</td>\n",
       "      <td>0.130726</td>\n",
       "      <td>0.982509</td>\n",
       "      <td>0.982523</td>\n",
       "      <td>0.982509</td>\n",
       "      <td>0.982496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.151200</td>\n",
       "      <td>0.116111</td>\n",
       "      <td>0.983812</td>\n",
       "      <td>0.983797</td>\n",
       "      <td>0.983812</td>\n",
       "      <td>0.983800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.111401</td>\n",
       "      <td>0.984241</td>\n",
       "      <td>0.984229</td>\n",
       "      <td>0.984241</td>\n",
       "      <td>0.984229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=17500, training_loss=0.3700160487583705, metrics={'train_runtime': 293.9027, 'train_samples_per_second': 7621.57, 'train_steps_per_second': 59.544, 'total_flos': 0.0, 'train_loss': 0.3700160487583705, 'epoch': 5.0})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model = base.BiLSTMClassifier(embedding_matrix=embedding_matrix, embedding_dim=embedding_dim, fc_dim=400, hidden_dim=300, output_dim=14)\n",
    "teacher_model = BertForSequenceClassification.from_pretrained(\"fabriceyhc/bert-base-uncased-dbpedia_14\", num_labels=14)\n",
    "teacher_model.to(device)\n",
    "teacher_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bilstm-distill_fine_infer\", remove_unused_columns=False, logging_dir=f\"~/logs/{DATASET}/bilstm-distill_fine_infer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.reset_format()\n",
    "eval_data.reset_format()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainerInferText(\n",
    "    student_model=student_model,\n",
    "    teacher_model=teacher_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    compute_metrics=base.compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17500' max='17500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17500/17500 25:56, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.107600</td>\n",
       "      <td>0.236866</td>\n",
       "      <td>0.973000</td>\n",
       "      <td>0.973454</td>\n",
       "      <td>0.973000</td>\n",
       "      <td>0.973019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.217000</td>\n",
       "      <td>0.155023</td>\n",
       "      <td>0.979732</td>\n",
       "      <td>0.979809</td>\n",
       "      <td>0.979732</td>\n",
       "      <td>0.979715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.172100</td>\n",
       "      <td>0.133987</td>\n",
       "      <td>0.981812</td>\n",
       "      <td>0.981825</td>\n",
       "      <td>0.981813</td>\n",
       "      <td>0.981790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.150800</td>\n",
       "      <td>0.116564</td>\n",
       "      <td>0.983429</td>\n",
       "      <td>0.983411</td>\n",
       "      <td>0.983429</td>\n",
       "      <td>0.983401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.138400</td>\n",
       "      <td>0.111180</td>\n",
       "      <td>0.984071</td>\n",
       "      <td>0.984061</td>\n",
       "      <td>0.984071</td>\n",
       "      <td>0.984059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=17500, training_loss=0.35717176339285717, metrics={'train_runtime': 1559.0717, 'train_samples_per_second': 1436.752, 'train_steps_per_second': 11.225, 'total_flos': 0.0, 'train_loss': 0.35717176339285717, 'epoch': 5.0})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = base.BiLSTMClassifier(embedding_matrix=embedding_matrix, embedding_dim=embedding_dim, fc_dim=400, hidden_dim=300, output_dim=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bilstm-distill_fine\", remove_unused_columns=False, logging_dir=f\"~/logs/{DATASET}/bilstm-distill_fine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data.set_format(type=\"torch\", columns=[\"input_ids\", \"logits\", \"labels\"], device=\"cpu\")\n",
    "eval_data.set_format(type=\"torch\", columns=[\"input_ids\", \"logits\", \"labels\"], device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainer(\n",
    "    student_model=student_model,\n",
    "    args=training_args,\n",
    "    train_dataset= all_train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    compute_metrics=base.compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34355' max='34355' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34355/34355 07:36, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.921300</td>\n",
       "      <td>0.177431</td>\n",
       "      <td>0.977866</td>\n",
       "      <td>0.977863</td>\n",
       "      <td>0.977866</td>\n",
       "      <td>0.977817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.251300</td>\n",
       "      <td>0.127120</td>\n",
       "      <td>0.983143</td>\n",
       "      <td>0.983132</td>\n",
       "      <td>0.983143</td>\n",
       "      <td>0.983130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.202700</td>\n",
       "      <td>0.111748</td>\n",
       "      <td>0.984464</td>\n",
       "      <td>0.984477</td>\n",
       "      <td>0.984464</td>\n",
       "      <td>0.984461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.178700</td>\n",
       "      <td>0.104118</td>\n",
       "      <td>0.985384</td>\n",
       "      <td>0.985384</td>\n",
       "      <td>0.985384</td>\n",
       "      <td>0.985381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.164600</td>\n",
       "      <td>0.100004</td>\n",
       "      <td>0.985580</td>\n",
       "      <td>0.985561</td>\n",
       "      <td>0.985580</td>\n",
       "      <td>0.985566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=34355, training_loss=0.3437155339242832, metrics={'train_runtime': 458.1501, 'train_samples_per_second': 9596.976, 'train_steps_per_second': 74.986, 'total_flos': 0.0, 'train_loss': 0.3437155339242832, 'epoch': 5.0})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = base.BiLSTMClassifier(embedding_matrix=embedding_matrix, embedding_dim=embedding_dim, fc_dim=400, hidden_dim=300, output_dim=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bilstm-distill_fine_infer\", remove_unused_columns=False, logging_dir=f\"~/logs/{DATASET}/bilstm-distill_fine_infer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data.reset_format()\n",
    "eval_data.reset_format()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainerInferText(\n",
    "    student_model=student_model,\n",
    "    teacher_model=teacher_model,\n",
    "    args=training_args,\n",
    "    train_dataset=all_train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    compute_metrics=base.compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34355' max='34355' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34355/34355 44:59, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.921300</td>\n",
       "      <td>0.177431</td>\n",
       "      <td>0.977866</td>\n",
       "      <td>0.977863</td>\n",
       "      <td>0.977866</td>\n",
       "      <td>0.977817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.251500</td>\n",
       "      <td>0.126002</td>\n",
       "      <td>0.983134</td>\n",
       "      <td>0.983116</td>\n",
       "      <td>0.983134</td>\n",
       "      <td>0.983116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.202400</td>\n",
       "      <td>0.111495</td>\n",
       "      <td>0.984509</td>\n",
       "      <td>0.984514</td>\n",
       "      <td>0.984509</td>\n",
       "      <td>0.984501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.178600</td>\n",
       "      <td>0.104205</td>\n",
       "      <td>0.985295</td>\n",
       "      <td>0.985294</td>\n",
       "      <td>0.985295</td>\n",
       "      <td>0.985291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.164600</td>\n",
       "      <td>0.099913</td>\n",
       "      <td>0.985580</td>\n",
       "      <td>0.985563</td>\n",
       "      <td>0.985580</td>\n",
       "      <td>0.985567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=34355, training_loss=0.3436608607792261, metrics={'train_runtime': 2700.8682, 'train_samples_per_second': 1627.941, 'train_steps_per_second': 12.72, 'total_flos': 0.0, 'train_loss': 0.3436608607792261, 'epoch': 5.0})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "student_model = BertForSequenceClassification.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\", num_labels=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bilstm-distill_fine\", remove_unused_columns=False, logging_dir=f\"~/logs/{DATASET}/bilstm-distill_fine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.remove_columns([\"input_ids\"])\n",
    "train_data = train_data.rename_column(\"teacher_attention\", \"attention_mask\")\n",
    "train_data = train_data.rename_column(\"teacher_ids\", \"input_ids\")\n",
    "\n",
    "eval_data = eval_data.remove_columns([\"input_ids\"])\n",
    "eval_data = eval_data.rename_column(\"teacher_attention\", \"attention_mask\")\n",
    "eval_data = eval_data.rename_column(\"teacher_ids\", \"input_ids\")\n",
    "\n",
    "train_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"logits\", \"labels\"], device=\"cpu\")\n",
    "eval_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"logits\", \"labels\"], device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainer(\n",
    "    student_model=student_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    compute_metrics=base.compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17500' max='17500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17500/17500 04:57, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.382600</td>\n",
       "      <td>0.121406</td>\n",
       "      <td>0.984563</td>\n",
       "      <td>0.984585</td>\n",
       "      <td>0.984563</td>\n",
       "      <td>0.984566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.122000</td>\n",
       "      <td>0.083456</td>\n",
       "      <td>0.985964</td>\n",
       "      <td>0.985951</td>\n",
       "      <td>0.985964</td>\n",
       "      <td>0.985950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.097900</td>\n",
       "      <td>0.074269</td>\n",
       "      <td>0.986875</td>\n",
       "      <td>0.986876</td>\n",
       "      <td>0.986875</td>\n",
       "      <td>0.986872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.087900</td>\n",
       "      <td>0.070338</td>\n",
       "      <td>0.987125</td>\n",
       "      <td>0.987126</td>\n",
       "      <td>0.987125</td>\n",
       "      <td>0.987122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.069853</td>\n",
       "      <td>0.987384</td>\n",
       "      <td>0.987385</td>\n",
       "      <td>0.987384</td>\n",
       "      <td>0.987379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=17500, training_loss=0.35451332135881697, metrics={'train_runtime': 299.2541, 'train_samples_per_second': 7485.278, 'train_steps_per_second': 58.479, 'total_flos': 334751155200000.0, 'train_loss': 0.35451332135881697, 'epoch': 5.0})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "student_model = BertForSequenceClassification.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\", num_labels=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bilstm-distill_fine_infer\", remove_unused_columns=False, logging_dir=f\"~/logs/{DATASET}/bilstm-distill_fine_infer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainerInfer(\n",
    "    student_model=student_model,\n",
    "    teacher_model=teacher_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    compute_metrics=base.compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17500' max='17500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17500/17500 25:25, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.359800</td>\n",
       "      <td>0.119925</td>\n",
       "      <td>0.984321</td>\n",
       "      <td>0.984337</td>\n",
       "      <td>0.984321</td>\n",
       "      <td>0.984316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.121500</td>\n",
       "      <td>0.081011</td>\n",
       "      <td>0.986214</td>\n",
       "      <td>0.986202</td>\n",
       "      <td>0.986214</td>\n",
       "      <td>0.986205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.074563</td>\n",
       "      <td>0.986563</td>\n",
       "      <td>0.986559</td>\n",
       "      <td>0.986563</td>\n",
       "      <td>0.986556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.087600</td>\n",
       "      <td>0.070689</td>\n",
       "      <td>0.986938</td>\n",
       "      <td>0.986931</td>\n",
       "      <td>0.986937</td>\n",
       "      <td>0.986933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.082700</td>\n",
       "      <td>0.069735</td>\n",
       "      <td>0.987054</td>\n",
       "      <td>0.987052</td>\n",
       "      <td>0.987054</td>\n",
       "      <td>0.987050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=17500, training_loss=0.3499100428989955, metrics={'train_runtime': 1528.1119, 'train_samples_per_second': 1465.861, 'train_steps_per_second': 11.452, 'total_flos': 334751155200000.0, 'train_loss': 0.3499100428989955, 'epoch': 5.0})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "student_model = BertForSequenceClassification.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\", num_labels=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bilstm-distill_fine\", remove_unused_columns=False, logging_dir=f\"~/logs/{DATASET}/bilstm-distill_fine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data = all_train_data.remove_columns([\"input_ids\"])\n",
    "all_train_data = all_train_data.rename_column(\"teacher_attention\", \"attention_mask\")\n",
    "all_train_data = all_train_data.rename_column(\"teacher_ids\", \"input_ids\")\n",
    "\n",
    "all_train_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"logits\", \"labels\"], device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainer(\n",
    "    student_model=student_model,\n",
    "    args=training_args,\n",
    "    train_dataset=all_train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    compute_metrics=base.compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34355' max='34355' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34355/34355 08:09, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.830100</td>\n",
       "      <td>0.081244</td>\n",
       "      <td>0.986161</td>\n",
       "      <td>0.986155</td>\n",
       "      <td>0.986161</td>\n",
       "      <td>0.986148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.069424</td>\n",
       "      <td>0.986955</td>\n",
       "      <td>0.986953</td>\n",
       "      <td>0.986955</td>\n",
       "      <td>0.986946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.065170</td>\n",
       "      <td>0.987554</td>\n",
       "      <td>0.987547</td>\n",
       "      <td>0.987554</td>\n",
       "      <td>0.987546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.098700</td>\n",
       "      <td>0.062519</td>\n",
       "      <td>0.987946</td>\n",
       "      <td>0.987944</td>\n",
       "      <td>0.987946</td>\n",
       "      <td>0.987941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.092900</td>\n",
       "      <td>0.062191</td>\n",
       "      <td>0.987830</td>\n",
       "      <td>0.987830</td>\n",
       "      <td>0.987830</td>\n",
       "      <td>0.987825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=34355, training_loss=0.25274641503067696, metrics={'train_runtime': 491.0509, 'train_samples_per_second': 8953.97, 'train_steps_per_second': 69.962, 'total_flos': 657076915400400.0, 'train_loss': 0.25274641503067696, 'epoch': 5.0})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "student_model = BertForSequenceClassification.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\", num_labels=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bilstm-distill_fine_infer\", remove_unused_columns=False, logging_dir=f\"~/logs/{DATASET}/bilstm-distill_fine_infer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainerInfer(\n",
    "    student_model=student_model,\n",
    "    teacher_model=teacher_model,\n",
    "    args=training_args,\n",
    "    train_dataset=all_train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    compute_metrics=base.compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34355' max='34355' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34355/34355 44:13, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.813600</td>\n",
       "      <td>0.081995</td>\n",
       "      <td>0.986125</td>\n",
       "      <td>0.986117</td>\n",
       "      <td>0.986125</td>\n",
       "      <td>0.986115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.131500</td>\n",
       "      <td>0.069635</td>\n",
       "      <td>0.987268</td>\n",
       "      <td>0.987268</td>\n",
       "      <td>0.987268</td>\n",
       "      <td>0.987261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.109400</td>\n",
       "      <td>0.066111</td>\n",
       "      <td>0.987616</td>\n",
       "      <td>0.987614</td>\n",
       "      <td>0.987616</td>\n",
       "      <td>0.987609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.098800</td>\n",
       "      <td>0.063145</td>\n",
       "      <td>0.987902</td>\n",
       "      <td>0.987906</td>\n",
       "      <td>0.987902</td>\n",
       "      <td>0.987900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.093200</td>\n",
       "      <td>0.062660</td>\n",
       "      <td>0.987839</td>\n",
       "      <td>0.987839</td>\n",
       "      <td>0.987839</td>\n",
       "      <td>0.987835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=34355, training_loss=0.2493221464505485, metrics={'train_runtime': 2655.1507, 'train_samples_per_second': 1655.972, 'train_steps_per_second': 12.939, 'total_flos': 657076915400400.0, 'train_loss': 0.2493221464505485, 'epoch': 5.0})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
