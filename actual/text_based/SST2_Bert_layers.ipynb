{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trénink s destilací vnitřních stavů nad datasetem SST2 s modelem BERT TINY\n",
    "V tomto notebooku je trénován BERT TINY nad původním i augmentovaným datasetem SST2, jako učitelský model je využíván finetunued BERT nad stejným datasetem. Prováděna je destilace vnitřních stavů. \n",
    "\n",
    "Konfigurace hyperparametrů vychází z poznatků získaných napříč notebooky s tímto modelem a datasetem. Pro destilaci vnitřních stavů není k dispozici prohledávání parametrů a to především s ohledem na dobu tréninku. \n",
    "\n",
    "Při tréninku je využito EarlyStoppingu pro zmenšení přeučení a jsou získány výkonnostní metriky nad umělou i oficiální testovací částí datasetu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import knihoven a základní nastavení"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer, EarlyStoppingCallback\n",
    "from datasets import load_from_disk\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import base\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resetování náhodného seedu pro replikovatelnost výsledků."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ověření dostupnosti GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and will be used: NVIDIA A100 80GB PCIe MIG 2g.20gb\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and will be used:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"sst2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Načtení datasetu a jeho základní předzpracování.\n",
    "\n",
    "Pracováno je jak s oficiální tak umělou testovací částí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_from_disk(f\"~/data/{DATASET}/train-logits\")\n",
    "eval = load_from_disk(f\"~/data/{DATASET}/eval-logits\")\n",
    "test = load_from_disk(f\"~/data/{DATASET}/test-logits\")\n",
    "\n",
    "train_aug = load_from_disk(f\"~/data/{DATASET}/train-logits-augmented\")\n",
    "test_blank= load_from_disk(f\"~/data/{DATASET}/test-blank-logits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"gchhablani/bert-base-cased-finetuned-sst2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizace, padding a převod na IDčka skrze tokenizer učitele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the train dataset\")\n",
    "eval = eval.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the eval dataset\")\n",
    "test = test.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the test dataset\")\n",
    "\n",
    "train_aug = train_aug.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the augmented dataset\")\n",
    "test_blank = test_blank.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=300), batched=True, desc=\"Tokenizing the blank test dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Příprava dataloaderů pro finální ověření rychlosti inference. Testování probíhá pouze nad jedním záznamem z trénovací části."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gpu = copy.deepcopy(train)\n",
    "train_data_gpu.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"], device=\"cuda\")\n",
    "gpu_data_loader = DataLoader(train_data_gpu, batch_size=1, shuffle=False)\n",
    "\n",
    "train_data_cpu = copy.deepcopy(train)\n",
    "train_data_cpu.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"], device=\"cpu\")\n",
    "cpu_data_loader = DataLoader(train_data_cpu, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trénink s destilací vnitřních stavů s původním datasetem\n",
    "\n",
    "Získání učitelského modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_model = BertForSequenceClassification.from_pretrained(\"gchhablani/bert-base-cased-finetuned-sst2\", num_labels=2)\n",
    "teacher_model.to(device)\n",
    "teacher_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Získání předtrénovaného studentského modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "student_model = BertForSequenceClassification.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\", num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konfigurace destilačního tréninku, parametry jsou rozšířeny o alpha pro stanovení poměru destilace vnitřních stavů s ostatními ztrátovými funkcemi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bert-distill-inner\", logging_dir=f\"~/logs/{DATASET}/bert-distill-inner\", remove_unused_columns=False, lr=0.000047, weight_decay=0.07, epochs=20, temp=6, lambda_param=0.2, alpha_param=.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konfigurace destilačního trenéra s trpělivostí 3 epoch. Tato varianta trenéra pracuje i s vnitřními stavy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainerInner(\n",
    "    student_model=student_model,\n",
    "    teacher_model=teacher_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spuštění tréninku s destilací, výstupy nad validační částí datasetu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5052' max='8420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5052/8420 34:55 < 23:17, 2.41 it/s, Epoch 12/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.464900</td>\n",
       "      <td>0.549621</td>\n",
       "      <td>0.737385</td>\n",
       "      <td>0.739053</td>\n",
       "      <td>0.738076</td>\n",
       "      <td>0.737233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.337900</td>\n",
       "      <td>0.590379</td>\n",
       "      <td>0.779817</td>\n",
       "      <td>0.779864</td>\n",
       "      <td>0.779953</td>\n",
       "      <td>0.779806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.263700</td>\n",
       "      <td>0.614781</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.799292</td>\n",
       "      <td>0.799392</td>\n",
       "      <td>0.799291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.224300</td>\n",
       "      <td>0.721653</td>\n",
       "      <td>0.794725</td>\n",
       "      <td>0.797189</td>\n",
       "      <td>0.793835</td>\n",
       "      <td>0.793905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.198400</td>\n",
       "      <td>0.700087</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.800451</td>\n",
       "      <td>0.799855</td>\n",
       "      <td>0.799267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.182900</td>\n",
       "      <td>0.736698</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812037</td>\n",
       "      <td>0.812116</td>\n",
       "      <td>0.811923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.170600</td>\n",
       "      <td>0.807443</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.808467</td>\n",
       "      <td>0.808569</td>\n",
       "      <td>0.808466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.162900</td>\n",
       "      <td>0.788713</td>\n",
       "      <td>0.811927</td>\n",
       "      <td>0.812839</td>\n",
       "      <td>0.812411</td>\n",
       "      <td>0.811902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.154600</td>\n",
       "      <td>0.820029</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.813396</td>\n",
       "      <td>0.813368</td>\n",
       "      <td>0.813073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.147900</td>\n",
       "      <td>0.858203</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.804827</td>\n",
       "      <td>0.803486</td>\n",
       "      <td>0.802627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.143700</td>\n",
       "      <td>0.883048</td>\n",
       "      <td>0.795872</td>\n",
       "      <td>0.796264</td>\n",
       "      <td>0.795466</td>\n",
       "      <td>0.795596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.139100</td>\n",
       "      <td>0.886524</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.802936</td>\n",
       "      <td>0.802981</td>\n",
       "      <td>0.802751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5052, training_loss=0.21590178709415245, metrics={'train_runtime': 2096.564, 'train_samples_per_second': 513.974, 'train_steps_per_second': 4.016, 'total_flos': 481307141448000.0, 'train_loss': 0.21590178709415245, 'epoch': 12.0})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Přepnutí studenta do evaluačního režimu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-1): 2 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Otestování modelu nad umělou testovací částí datasetu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='106' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/106 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.35776326060295105,\n",
       " 'eval_accuracy': 0.9060876020786934,\n",
       " 'eval_precision': 0.904093922577215,\n",
       " 'eval_recall': 0.9065983479595644,\n",
       " 'eval_f1': 0.90513043598376,\n",
       " 'eval_runtime': 5.3204,\n",
       " 'eval_samples_per_second': 2531.757,\n",
       " 'eval_steps_per_second': 19.923,\n",
       " 'epoch': 12.0}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uložení studentského modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student_model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bert-distill-inner.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vygenerování predikcí nad oficiální testovací částí a jejich export pro nahrání na GLUE Benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf1015a2ff5416ab1adef15e24573ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating logits for given dataset:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created output file named: /home/jovyan/data/sst2/tiny-bert-distill-inner-test.tsv upload it to GLUE benchmark to obtain results!\n"
     ]
    }
   ],
   "source": [
    "test_blank.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"], device=\"cuda\")\n",
    "test_blank_dataloader = DataLoader(test_blank, batch_size=128, shuffle=False)\n",
    "test_blank_logits = base.generate_logits(test_blank_dataloader, student_model)\n",
    "base.generate_real_test_file_sst2(test_blank_logits, f\"{os.path.expanduser('~')}/data/{DATASET}/tiny-bert-distill-inner-test.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trénink s destilací vnitřních stavů s augmentovaným datasetem\n",
    "\n",
    "Získání předtrénovaného studentského modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "student_model = BertForSequenceClassification.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\", num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konfigurace destilačního tréninku, parametry jsou rozšířeny o alpha pro stanovení poměru destilace vnitřních stavů s ostatními ztrátovými funkcemi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/bert-distill-inner-aug\", logging_dir=f\"~/logs/{DATASET}/bert-distill-inner-aug\", remove_unused_columns=False, lr=0.00005, weight_decay=0.08, epochs=20, temp=7, lambda_param=0, alpha_param=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konfigurace destilačního trenéra s trpělivostí 3 epoch. Tato varianta trenéra pracuje i s vnitřními stavy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainerInner(\n",
    "    student_model=student_model,\n",
    "    teacher_model=teacher_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_aug,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spuštění tréninku s destilací, výstupy nad validační částí datasetu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9180' max='45900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 9180/45900 1:01:52 < 4:07:33, 2.47 it/s, Epoch 4/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.210800</td>\n",
       "      <td>0.463851</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.801924</td>\n",
       "      <td>0.801897</td>\n",
       "      <td>0.801605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.128300</td>\n",
       "      <td>0.523375</td>\n",
       "      <td>0.801606</td>\n",
       "      <td>0.801566</td>\n",
       "      <td>0.801476</td>\n",
       "      <td>0.801511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.106800</td>\n",
       "      <td>0.581596</td>\n",
       "      <td>0.799312</td>\n",
       "      <td>0.799304</td>\n",
       "      <td>0.799139</td>\n",
       "      <td>0.799195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.092900</td>\n",
       "      <td>0.614697</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.789363</td>\n",
       "      <td>0.788583</td>\n",
       "      <td>0.788706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9180, training_loss=0.13469865753240315, metrics={'train_runtime': 3714.66, 'train_samples_per_second': 1580.958, 'train_steps_per_second': 12.356, 'total_flos': 874361091744000.0, 'train_loss': 0.13469865753240315, 'epoch': 4.0})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Přepnutí studenta do evaluačního režimu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-1): 2 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otestování studenta nad umělou testovací částí datasetu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='106' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [106/106 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.27749595046043396,\n",
       " 'eval_accuracy': 0.8929472902746844,\n",
       " 'eval_precision': 0.8912168610225423,\n",
       " 'eval_recall': 0.8920526992997893,\n",
       " 'eval_f1': 0.8916139549882979,\n",
       " 'eval_runtime': 5.1127,\n",
       " 'eval_samples_per_second': 2634.639,\n",
       " 'eval_steps_per_second': 20.733,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uložení studentského modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student_model.state_dict(), f\"{os.path.expanduser('~')}/models/{DATASET}/bert-distill-inner-aug.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vygenerování predikcí nad oficiální testovací částí a jejich export pro nahrání na GLUE Benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1576adb6d1cd437abc9ff5d62ca199fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating logits for given dataset:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created output file named: /home/jovyan/data/sst2/tiny-bert-base-inner-aug-test.tsv upload it to GLUE benchmark to obtain results!\n"
     ]
    }
   ],
   "source": [
    "test_blank_logits = base.generate_logits(test_blank_dataloader, student_model)\n",
    "base.generate_real_test_file_sst2(test_blank_logits, f\"{os.path.expanduser('~')}/data/{DATASET}/tiny-bert-base-inner-aug-test.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Získání počtu trénovatelných parametrů v modelu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 16.740MB.\n",
      "Total Trainable Params: 4386178.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Modules</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert.embeddings.word_embeddings.weight</td>\n",
       "      <td>3906816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert.embeddings.position_embeddings.weight</td>\n",
       "      <td>65536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert.embeddings.token_type_embeddings.weight</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert.embeddings.LayerNorm.weight</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bert.embeddings.LayerNorm.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bert.encoder.layer.0.attention.self.query.weight</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bert.encoder.layer.0.attention.self.query.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bert.encoder.layer.0.attention.self.key.weight</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bert.encoder.layer.0.attention.self.key.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bert.encoder.layer.0.attention.self.value.weight</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bert.encoder.layer.0.attention.self.value.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bert.encoder.layer.0.attention.output.dense.we...</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bert.encoder.layer.0.attention.output.dense.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bert.encoder.layer.0.attention.output.LayerNor...</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bert.encoder.layer.0.attention.output.LayerNor...</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bert.encoder.layer.0.intermediate.dense.weight</td>\n",
       "      <td>65536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bert.encoder.layer.0.intermediate.dense.bias</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bert.encoder.layer.0.output.dense.weight</td>\n",
       "      <td>65536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bert.encoder.layer.0.output.dense.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bert.encoder.layer.0.output.LayerNorm.weight</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bert.encoder.layer.0.output.LayerNorm.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bert.encoder.layer.1.attention.self.query.weight</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bert.encoder.layer.1.attention.self.query.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bert.encoder.layer.1.attention.self.key.weight</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bert.encoder.layer.1.attention.self.key.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bert.encoder.layer.1.attention.self.value.weight</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bert.encoder.layer.1.attention.self.value.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bert.encoder.layer.1.attention.output.dense.we...</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bert.encoder.layer.1.attention.output.dense.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bert.encoder.layer.1.attention.output.LayerNor...</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>bert.encoder.layer.1.attention.output.LayerNor...</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>bert.encoder.layer.1.intermediate.dense.weight</td>\n",
       "      <td>65536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>bert.encoder.layer.1.intermediate.dense.bias</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>bert.encoder.layer.1.output.dense.weight</td>\n",
       "      <td>65536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>bert.encoder.layer.1.output.dense.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>bert.encoder.layer.1.output.LayerNorm.weight</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>bert.encoder.layer.1.output.LayerNorm.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>bert.pooler.dense.weight</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>bert.pooler.dense.bias</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>classifier.weight</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>classifier.bias</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Modules Parameters\n",
       "0              bert.embeddings.word_embeddings.weight    3906816\n",
       "1          bert.embeddings.position_embeddings.weight      65536\n",
       "2        bert.embeddings.token_type_embeddings.weight        256\n",
       "3                    bert.embeddings.LayerNorm.weight        128\n",
       "4                      bert.embeddings.LayerNorm.bias        128\n",
       "5    bert.encoder.layer.0.attention.self.query.weight      16384\n",
       "6      bert.encoder.layer.0.attention.self.query.bias        128\n",
       "7      bert.encoder.layer.0.attention.self.key.weight      16384\n",
       "8        bert.encoder.layer.0.attention.self.key.bias        128\n",
       "9    bert.encoder.layer.0.attention.self.value.weight      16384\n",
       "10     bert.encoder.layer.0.attention.self.value.bias        128\n",
       "11  bert.encoder.layer.0.attention.output.dense.we...      16384\n",
       "12   bert.encoder.layer.0.attention.output.dense.bias        128\n",
       "13  bert.encoder.layer.0.attention.output.LayerNor...        128\n",
       "14  bert.encoder.layer.0.attention.output.LayerNor...        128\n",
       "15     bert.encoder.layer.0.intermediate.dense.weight      65536\n",
       "16       bert.encoder.layer.0.intermediate.dense.bias        512\n",
       "17           bert.encoder.layer.0.output.dense.weight      65536\n",
       "18             bert.encoder.layer.0.output.dense.bias        128\n",
       "19       bert.encoder.layer.0.output.LayerNorm.weight        128\n",
       "20         bert.encoder.layer.0.output.LayerNorm.bias        128\n",
       "21   bert.encoder.layer.1.attention.self.query.weight      16384\n",
       "22     bert.encoder.layer.1.attention.self.query.bias        128\n",
       "23     bert.encoder.layer.1.attention.self.key.weight      16384\n",
       "24       bert.encoder.layer.1.attention.self.key.bias        128\n",
       "25   bert.encoder.layer.1.attention.self.value.weight      16384\n",
       "26     bert.encoder.layer.1.attention.self.value.bias        128\n",
       "27  bert.encoder.layer.1.attention.output.dense.we...      16384\n",
       "28   bert.encoder.layer.1.attention.output.dense.bias        128\n",
       "29  bert.encoder.layer.1.attention.output.LayerNor...        128\n",
       "30  bert.encoder.layer.1.attention.output.LayerNor...        128\n",
       "31     bert.encoder.layer.1.intermediate.dense.weight      65536\n",
       "32       bert.encoder.layer.1.intermediate.dense.bias        512\n",
       "33           bert.encoder.layer.1.output.dense.weight      65536\n",
       "34             bert.encoder.layer.1.output.dense.bias        128\n",
       "35       bert.encoder.layer.1.output.LayerNorm.weight        128\n",
       "36         bert.encoder.layer.1.output.LayerNorm.bias        128\n",
       "37                           bert.pooler.dense.weight      16384\n",
       "38                             bert.pooler.dense.bias        128\n",
       "39                                  classifier.weight        256\n",
       "40                                    classifier.bias          2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.count_parameters(student_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Změření rychlosti inference při použití CPU, 1000 pokusů s jedním záznamem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x74156e73b940>\n",
      "self.infer_speed_comp()\n",
      "  3.66 ms\n",
      "  1 measurement, 1000 runs , 4 threads\n"
     ]
    }
   ],
   "source": [
    "cpu_benchmark = base.BenchMarkRunner(student_model, cpu_data_loader, \"cpu\", 1000)\n",
    "print(cpu_benchmark.run_benchmark())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Změření rychlosti inference při použití GPU, 1000 pokusů s jedním záznamem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7416d9d10550>\n",
      "self.infer_speed_comp()\n",
      "  2.30 ms\n",
      "  1 measurement, 1000 runs , 4 threads\n"
     ]
    }
   ],
   "source": [
    "gpu_benchmark = base.BenchMarkRunner(student_model, gpu_data_loader, \"cuda\", 1000)\n",
    "print(gpu_benchmark.run_benchmark())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
