{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b80e8fe1",
   "metadata": {},
   "source": [
    "# Notebook pro trénink s destilací nad datasetem CIFAR10\n",
    "V tomto notebooku je trénován MobileNetV2 nad datasetem CIFAR10, jako učitelsý model je využíván finetunued ViT nad stejným datasetem. \n",
    "\n",
    "MobileNetV2 je používán s náhodnou inicializací, tréninkem pouze klasifikační hlavy inicializovaného (předtrénovaného nad ImageNetem) MobileNetuV2 a trénink celého modelu, taktéž inicializovaného. Tyto tři úlohy jsou trénovány bězným způsobem a také s pomocí destilace výše zmíněného modelu.  \n",
    "\n",
    "Při destilaci je využíváno předpočítaných logitů ze sešitu precompute_logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efcfa7e-c869-43c9-955f-0678e717c4cf",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.27.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0a0)\n",
      "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.48.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.5)\n",
      "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.5.0a0+e000cf0ad9.nv24.10)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.2.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->transformers[torch]) (6.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0->transformers[torch]) (2.1.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers[torch] huggingface_hub datasets evaluate torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d1c726",
   "metadata": {},
   "source": [
    "## Import knihoven a definice metod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7e7a26f-aa1f-4645-b3b3-4643ca8be2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, MobileNetV2Config, MobileNetV2ForImageClassification, EarlyStoppingCallback\n",
    "from torchvision.transforms import v2 as transformsv2\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import random\n",
    "import pickle\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ce29a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_part = Enum('dataset_part', [('TRAIN', 1), ('TEST', 2), ('EVAL', 3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf6897a",
   "metadata": {},
   "source": [
    "Resetování náhodného seedu pro replikovatelnost výsledků.\n",
    "Zřejmě je možné části odebrat.\n",
    "\n",
    "TODO: Odebrat zbytečná nastavení."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd53a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964a9fbe",
   "metadata": {},
   "source": [
    "Nový wrapper, který pracuje přímo se soubory staženého a upraveného datasetu CIFAR10.\n",
    "Využití načtení pomocí metody jako dříve není možné kvůli jiné checksum. \n",
    "\n",
    "Zároveň se již dotahují logity přímo z datasetu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "947263ba-fa42-4861-9f45-9fa1a89b2795",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCIFAR10(Dataset):\n",
    "    def __init__(self, root, dataset_part = dataset_part.TRAIN, transform=None):\n",
    "        self.root = root\n",
    "        self.dataset_part = dataset_part\n",
    "        self.transform = transform\n",
    "\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "        self.logits = []\n",
    "        \n",
    "        if self.dataset_part == dataset_part.TRAIN:\n",
    "             for i in range(1, 5):\n",
    "                 data_file = os.path.join(self.root, 'cifar-10-batches-py', f'data_batch_{i}')\n",
    "                 with open(data_file, 'rb') as fo:\n",
    "                     dict = pickle.load(fo, encoding='bytes')\n",
    "                     self.data.append(dict[b'data'])\n",
    "                     self.targets.extend(dict[b'labels'])\n",
    "                     self.logits.extend(dict[b'logits'])  \n",
    "        elif self.dataset_part == dataset_part.TEST:\n",
    "            data_file = os.path.join(self.root, 'cifar-10-batches-py', 'test_batch')\n",
    "            with open(data_file, 'rb') as fo:\n",
    "                dict = pickle.load(fo, encoding='bytes')\n",
    "                self.data.append(dict[b'data'])\n",
    "                self.targets.extend(dict[b'labels'])\n",
    "                self.logits.extend(dict[b'logits'])\n",
    "        else:\n",
    "            data_file = os.path.join(self.root, 'cifar-10-batches-py', 'data_batch_5')\n",
    "            with open(data_file, \"rb\") as fo:\n",
    "                dict = pickle.load(fo, encoding='bytes')\n",
    "                self.data.append(dict[b'data'])\n",
    "                self.targets.extend(dict[b'labels'])\n",
    "                self.logits.extend(dict[b'logits'])  \n",
    "\n",
    "        self.data = np.concatenate(self.data, axis=0)\n",
    "        self.targets = np.array(self.targets)\n",
    "        self.logits = np.array(self.logits)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.data[index].reshape(3, 32, 32).transpose(1, 2, 0)\n",
    "        label = self.targets[index]\n",
    "        logit = self.logits[index]\n",
    "        \n",
    "        image = Image.fromarray(image.astype('uint8'), 'RGB')\n",
    "        logit = torch.tensor(logit, dtype=torch.float)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return {\n",
    "            'pixel_values': image,\n",
    "            'labels': label,\n",
    "            'logits': logit\n",
    "        }\n",
    "    \n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self.targets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05df404b",
   "metadata": {},
   "source": [
    "Definice accuracy metriky pro trénování modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d06b726",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "precision_metric = evaluate.load(\"precision\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    pred, labels = eval_pred\n",
    "    predictions = np.argmax(pred, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    precision = precision_metric.compute(predictions=predictions, references=labels, average='macro', zero_division = 0)\n",
    "    recall = recall_metric.compute(predictions=predictions, references=labels, average='macro', zero_division = 0)\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average='macro')\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy[\"accuracy\"],\n",
    "        \"precision\": precision[\"precision\"],\n",
    "        \"recall\": recall[\"recall\"],\n",
    "        \"f1\": f1[\"f1\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a279ff0b",
   "metadata": {},
   "source": [
    "Trénovací argumenty pro trainer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e698937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_training_args(TrainingArguments):\n",
    "    def __init__(self, lambda_param, temperature, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)    \n",
    "        self.lambda_param = lambda_param\n",
    "        self.temperature = temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90a40292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_args(output_dir, logging_dir, remove_unused_columns=True, lr=5e-5, epochs=5, weight_decay=0, lambda_param=.5, temp=5):\n",
    "    return (\n",
    "        Custom_training_args(\n",
    "        output_dir=output_dir,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        learning_rate=lr, #Defaultní hodnota \n",
    "        per_device_train_batch_size=128,\n",
    "        per_device_eval_batch_size=128,\n",
    "        num_train_epochs=epochs,\n",
    "        weight_decay=weight_decay,\n",
    "        seed = 42,  #Defaultní hodnota \n",
    "        metric_for_best_model=\"f1\",\n",
    "        load_best_model_at_end = True,\n",
    "        fp16=True, \n",
    "        logging_dir=logging_dir,\n",
    "        remove_unused_columns=remove_unused_columns,\n",
    "        lambda_param = lambda_param, \n",
    "        temperature = temp\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1451b922",
   "metadata": {},
   "source": [
    "Náhodně inicializovaný MobileNetV2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf11f33f-4501-48ac-a926-80839c32080f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_init_mobilenet():\n",
    "    reset_seed(42)\n",
    "    student_config = MobileNetV2Config()\n",
    "    student_config.num_labels = 10\n",
    "    return MobileNetV2ForImageClassification(student_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03a5883",
   "metadata": {},
   "source": [
    "Zamražení modelu a trénink pouze klasifikační hlavy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23385ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921fc223",
   "metadata": {},
   "source": [
    "Inicializovaný MobileNetV2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d820523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mobilenet():\n",
    "    model_pretrained = MobileNetV2ForImageClassification.from_pretrained(\"google/mobilenet_v2_1.0_224\")\n",
    "    in_features = model_pretrained.classifier.in_features\n",
    "\n",
    "    model_pretrained.classifier = nn.Linear(in_features,10) #Úprava klasifikační hlavy\n",
    "    model_pretrained.num_labels = 10\n",
    "    model_pretrained.config.num_labels = 10\n",
    "\n",
    "    return model_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad6208b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29b9ceef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and will be used: NVIDIA A100 80GB PCIe MIG 1g.10gb\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and will be used:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eb90dc",
   "metadata": {},
   "source": [
    "Provedení transformací nad datasetem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b74ce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transformsv2.Compose([\n",
    "    transformsv2.Resize((224, 224)), \n",
    "    transformsv2.ToImage(),\n",
    "    transformsv2.ToDtype(torch.float32, scale=True),\n",
    "    transformsv2.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "#Poslední train batch použijeme jako eval část...\n",
    "test = CustomCIFAR10(root='./data/10-logits', dataset_part=dataset_part.TEST, transform=transform)\n",
    "train = CustomCIFAR10(root='./data/10-logits', dataset_part=dataset_part.TRAIN, transform=transform)\n",
    "eval = CustomCIFAR10(root='./data/10-logits', dataset_part=dataset_part.EVAL, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b36ab156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5    1025\n",
      "9    1022\n",
      "3    1016\n",
      "0    1014\n",
      "1    1014\n",
      "8    1003\n",
      "4     997\n",
      "6     980\n",
      "7     977\n",
      "2     952\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Test rozložení --> Good Enough\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(eval.labels)\n",
    "print(df.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a85914",
   "metadata": {},
   "source": [
    "### Standardní trénink náhodně inicializovaného modelu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15c07c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = get_training_args(output_dir=\"./results/cifar10-random\", logging_dir='./logs/cifar10-random', lr=0.0005, weight_decay=0.008, epochs=20)\n",
    "model = get_random_init_mobilenet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc752b97-d843-4919-a0fc-066d192e037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 4)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97855619-93d5-4fc2-93d2-fee24c61b8ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "EarlyStoppingCallback requires load_best_model_at_end = True",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2171\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2172\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2437\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2435\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m   2436\u001b[0m grad_norm: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2437\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallback_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39meval_on_start:\n\u001b[1;32m   2440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate(trial, ignore_keys_for_eval, skip_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_callback.py:469\u001b[0m, in \u001b[0;36mCallbackHandler.on_train_begin\u001b[0;34m(self, args, state, control)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_begin\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: TrainingArguments, state: TrainerState, control: TrainerControl):\n\u001b[1;32m    468\u001b[0m     control\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 469\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_event\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_train_begin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_callback.py:519\u001b[0m, in \u001b[0;36mCallbackHandler.call_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_event\u001b[39m(\u001b[38;5;28mself\u001b[39m, event, args, state, control, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 519\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprocessing_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessing_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m         \u001b[38;5;66;03m# A Callback can skip the return of `control` if it doesn't change it.\u001b[39;00m\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_callback.py:710\u001b[0m, in \u001b[0;36mEarlyStoppingCallback.on_train_begin\u001b[0;34m(self, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_begin\u001b[39m(\u001b[38;5;28mself\u001b[39m, args, state, control, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 710\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m args\u001b[38;5;241m.\u001b[39mload_best_model_at_end, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEarlyStoppingCallback requires load_best_model_at_end = True\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    712\u001b[0m         args\u001b[38;5;241m.\u001b[39mmetric_for_best_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEarlyStoppingCallback requires metric_for_best_model is defined\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    715\u001b[0m         args\u001b[38;5;241m.\u001b[39meval_strategy \u001b[38;5;241m!=\u001b[39m IntervalStrategy\u001b[38;5;241m.\u001b[39mNO\n\u001b[1;32m    716\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEarlyStoppingCallback requires IntervalStrategy of steps or epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: EarlyStoppingCallback requires load_best_model_at_end = True"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882ec503-b58f-418c-bc31-58a9efce7dbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2ForImageClassification(\n",
       "  (mobilenet_v2): MobileNetV2Model(\n",
       "    (conv_stem): MobileNetV2Stem(\n",
       "      (first_conv): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (conv_3x3): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
       "        (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (reduce_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(16, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer): ModuleList(\n",
       "      (0): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3-4): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(64, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6-8): 3 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(64, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (9): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (10-11): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (12): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), groups=576, bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(160, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (13-14): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(160, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (15): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(320, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_1x1): MobileNetV2ConvLayer(\n",
       "      (convolution): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (normalization): BatchNorm2d(1280, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU6()\n",
       "    )\n",
       "    (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.8, inplace=True)\n",
       "  (classifier): Linear(in_features=1280, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b651751f-7022-4677-8059-11380670b185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0413583517074585,\n",
       " 'eval_accuracy': 0.6297,\n",
       " 'eval_precision': 0.6376551865860559,\n",
       " 'eval_recall': 0.6297,\n",
       " 'eval_f1': 0.6264225488074469}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87594fbb",
   "metadata": {},
   "source": [
    "## Definice destilačního tréninku\n",
    "\n",
    "Třída, která upravuje hugging face trenéra pro destilaci znalostí. Nově pracuje s logity uloženými v datasetu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc8c9348-c31e-49af-b26c-f9e2ab599bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDistilTrainer(Trainer):\n",
    "    def __init__(self, student_model=None, *args, **kwargs):\n",
    "        super().__init__(model=student_model, *args, **kwargs)\n",
    "        self.student = student_model\n",
    "        self.loss_function = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "        self.temperature = self.args.temperature\n",
    "        self.lambda_param = self.args.lambda_param\n",
    "\n",
    "\n",
    "\n",
    "    def compute_loss(self, student, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        logits = inputs.pop(\"logits\")\n",
    "\n",
    "        student_output = student(**inputs)\n",
    "\n",
    "        soft_teacher = F.softmax(logits / self.temperature, dim=-1)\n",
    "        soft_student = F.log_softmax(student_output.logits / self.temperature, dim=-1)\n",
    "\n",
    "\n",
    "        distillation_loss = self.loss_function(soft_student, soft_teacher) * (self.temperature ** 2)\n",
    "\n",
    "\n",
    "        student_target_loss = student_output.loss\n",
    "\n",
    "        loss = ((1. - self.lambda_param) * student_target_loss + self.lambda_param * distillation_loss)\n",
    "        return (loss, student_output) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd84cda",
   "metadata": {},
   "source": [
    "### Trénink náhodně inicializovaného modelu s pomocí destilace znalostí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24f990e8-d259-44c7-b85b-cca2f4f97a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8360e003-3a19-4bb3-8ce8-b40df5b2115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = get_random_init_mobilenet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aad7fa0f-f432-4e99-bb07-31951b7858f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = get_training_args(output_dir=\"./results/cifar10-random-KD\", logging_dir='./logs/cifar10-random-KD', remove_unused_columns=False, epochs=20, lr=0.00045, lambda_param=1, temp=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "43af926a-dba5-468f-9a48-c4c581e97893",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ImageDistilTrainer(\n",
    "    student_model=student_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 4)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22a2fa47-1cf3-465c-aa7f-9b41b66846d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='320' max='6260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 320/6260 02:48 < 52:27, 1.89 it/s, Epoch 1.02/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.732000</td>\n",
       "      <td>1.098484</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.438522</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.394528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2171\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2172\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2480\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2478\u001b[0m update_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2479\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step \u001b[38;5;241m!=\u001b[39m (total_updates \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[0;32m-> 2480\u001b[0m batch_samples, num_items_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2481\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_samples):\n\u001b[1;32m   2482\u001b[0m     step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:5156\u001b[0m, in \u001b[0;36mTrainer.get_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches)\u001b[0m\n\u001b[1;32m   5154\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[1;32m   5155\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5156\u001b[0m         batch_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m   5157\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   5158\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/data_loader.py:563\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    561\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m send_to_device(current_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_blocking)\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_state_dict()\n\u001b[0;32m--> 563\u001b[0m next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_batches:\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m current_batch\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[5], line 50\u001b[0m, in \u001b[0;36mCustomCIFAR10.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     48\u001b[0m logit \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(logit, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[0;32m---> 50\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpixel_values\u001b[39m\u001b[38;5;124m'\u001b[39m: image,\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m: label,\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m'\u001b[39m: logit\n\u001b[1;32m     56\u001b[0m }\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1741\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1740\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1741\u001b[0m     forward_call \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward)\n\u001b[1;32m   1742\u001b[0m     \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m             \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m             \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdb542b-ab09-419d-9094-9b2385e68d19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2ForImageClassification(\n",
       "  (mobilenet_v2): MobileNetV2Model(\n",
       "    (conv_stem): MobileNetV2Stem(\n",
       "      (first_conv): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (conv_3x3): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
       "        (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (reduce_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(16, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer): ModuleList(\n",
       "      (0): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3-4): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(64, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6-8): 3 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(64, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (9): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (10-11): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (12): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), groups=576, bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(160, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (13-14): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(160, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (15): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(320, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_1x1): MobileNetV2ConvLayer(\n",
       "      (convolution): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (normalization): BatchNorm2d(1280, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU6()\n",
       "    )\n",
       "    (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.8, inplace=True)\n",
       "  (classifier): Linear(in_features=1280, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9356e120-e435-44ff-91a1-2cac9facae31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0984840393066406,\n",
       " 'eval_accuracy': 0.4264,\n",
       " 'eval_precision': 0.4385223237761998,\n",
       " 'eval_recall': 0.42639999999999995,\n",
       " 'eval_f1': 0.3945276383308019}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b5de5a",
   "metadata": {},
   "source": [
    "## Získání inicializovaného MobileNetV2 modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0b010c5-c092-4b29-b948-4b2497639caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61abe4ec-2ae2-48ce-8923-92890fe8dbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pretrained = get_mobilenet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d1fc942-761f-479a-b5ce-87429bf61220",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2ForImageClassification(\n",
      "  (mobilenet_v2): MobileNetV2Model(\n",
      "    (conv_stem): MobileNetV2Stem(\n",
      "      (first_conv): MobileNetV2ConvLayer(\n",
      "        (convolution): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU6()\n",
      "      )\n",
      "      (conv_3x3): MobileNetV2ConvLayer(\n",
      "        (convolution): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
      "        (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU6()\n",
      "      )\n",
      "      (reduce_1x1): MobileNetV2ConvLayer(\n",
      "        (convolution): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (normalization): BatchNorm2d(16, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer): ModuleList(\n",
      "      (0): MobileNetV2InvertedResidual(\n",
      "        (expand_1x1): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU6()\n",
      "        )\n",
      "        (conv_3x3): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
      "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU6()\n",
      "        )\n",
      "        (reduce_1x1): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): MobileNetV2InvertedResidual(\n",
      "        (expand_1x1): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU6()\n",
      "        )\n",
      "        (conv_3x3): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
      "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU6()\n",
      "        )\n",
      "        (reduce_1x1): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): MobileNetV2InvertedResidual(\n",
      "        (expand_1x1): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU6()\n",
      "        )\n",
      "        (conv_3x3): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
      "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU6()\n",
      "        )\n",
      "        (reduce_1x1): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (3-4): 2 x MobileNetV2InvertedResidual(\n",
      "        (expand_1x1): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU6()\n",
      "        )\n",
      "        (conv_3x3): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
      "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU6()\n",
      "        )\n",
      "        (reduce_1x1): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (5): MobileNetV2InvertedResidual(\n",
      "        (expand_1x1): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU6()\n",
      "        )\n",
      "        (conv_3x3): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
      "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU6()\n",
      "        )\n",
      "        (reduce_1x1): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(64, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (6-8): 3 x MobileNetV2InvertedResidual(\n",
      "        (expand_1x1): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU6()\n",
      "        )\n",
      "        (conv_3x3): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
      "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU6()\n",
      "        )\n",
      "        (reduce_1x1): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(64, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (9): MobileNetV2InvertedResidual(\n",
      "        (expand_1x1): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU6()\n",
      "        )\n",
      "        (conv_3x3): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
      "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU6()\n",
      "        )\n",
      "        (reduce_1x1): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (10-11): 2 x MobileNetV2InvertedResidual(\n",
      "        (expand_1x1): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU6()\n",
      "        )\n",
      "        (conv_3x3): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
      "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU6()\n",
      "        )\n",
      "        (reduce_1x1): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (12): MobileNetV2InvertedResidual(\n",
      "        (expand_1x1): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU6()\n",
      "        )\n",
      "        (conv_3x3): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), groups=576, bias=False)\n",
      "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU6()\n",
      "        )\n",
      "        (reduce_1x1): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(160, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (13-14): 2 x MobileNetV2InvertedResidual(\n",
      "        (expand_1x1): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU6()\n",
      "        )\n",
      "        (conv_3x3): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
      "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU6()\n",
      "        )\n",
      "        (reduce_1x1): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(160, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (15): MobileNetV2InvertedResidual(\n",
      "        (expand_1x1): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU6()\n",
      "        )\n",
      "        (conv_3x3): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
      "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU6()\n",
      "        )\n",
      "        (reduce_1x1): MobileNetV2ConvLayer(\n",
      "          (convolution): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): BatchNorm2d(320, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv_1x1): MobileNetV2ConvLayer(\n",
      "      (convolution): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (normalization): BatchNorm2d(1280, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU6()\n",
      "    )\n",
      "    (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=True)\n",
      "  (classifier): Linear(in_features=1280, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba1bf1b9-e6ce-48b7-be37-a2f74205ee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_model(model_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22f38574-0e0a-47c5-bd28-1eb82f39755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = get_training_args(output_dir=\"./results/cifar10-pretrained-head\", logging_dir='./logs/cifar10-pretrained-head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14e9db4a-0b22-49ec-aac4-c2388c10cac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model_pretrained,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46d0803a-7592-4f36-906c-5dee715603f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15640' max='15640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15640/15640 1:00:35, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.890400</td>\n",
       "      <td>1.359444</td>\n",
       "      <td>0.630800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.122600</td>\n",
       "      <td>1.207275</td>\n",
       "      <td>0.624100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.016800</td>\n",
       "      <td>0.971210</td>\n",
       "      <td>0.709600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.904100</td>\n",
       "      <td>0.907923</td>\n",
       "      <td>0.714900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.876800</td>\n",
       "      <td>0.984846</td>\n",
       "      <td>0.680700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.832400</td>\n",
       "      <td>0.870077</td>\n",
       "      <td>0.721900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.827400</td>\n",
       "      <td>1.021028</td>\n",
       "      <td>0.655200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.802100</td>\n",
       "      <td>1.105069</td>\n",
       "      <td>0.629400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.791900</td>\n",
       "      <td>0.866780</td>\n",
       "      <td>0.706900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.785000</td>\n",
       "      <td>0.874822</td>\n",
       "      <td>0.712600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.780100</td>\n",
       "      <td>0.874086</td>\n",
       "      <td>0.711200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.774900</td>\n",
       "      <td>0.870484</td>\n",
       "      <td>0.709900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.772100</td>\n",
       "      <td>0.891623</td>\n",
       "      <td>0.701800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.764300</td>\n",
       "      <td>0.886542</td>\n",
       "      <td>0.700200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.755500</td>\n",
       "      <td>0.841449</td>\n",
       "      <td>0.717300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.752400</td>\n",
       "      <td>0.899128</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.753900</td>\n",
       "      <td>0.799339</td>\n",
       "      <td>0.735600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.754300</td>\n",
       "      <td>0.833219</td>\n",
       "      <td>0.721800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.751200</td>\n",
       "      <td>0.803156</td>\n",
       "      <td>0.729100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.812152</td>\n",
       "      <td>0.723900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15640, training_loss=0.8626149301943572, metrics={'train_runtime': 3635.8498, 'train_samples_per_second': 275.039, 'train_steps_per_second': 4.302, 'total_flos': 2.020099608576e+18, 'train_loss': 0.8626149301943572, 'epoch': 20.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64ccb6b2-be37-4793-99e2-7dc3b1461152",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2ForImageClassification(\n",
       "  (mobilenet_v2): MobileNetV2Model(\n",
       "    (conv_stem): MobileNetV2Stem(\n",
       "      (first_conv): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (conv_3x3): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
       "        (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (reduce_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(16, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer): ModuleList(\n",
       "      (0): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3-4): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(64, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6-8): 3 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(64, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (9): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (10-11): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (12): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), groups=576, bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(160, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (13-14): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(160, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (15): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(320, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_1x1): MobileNetV2ConvLayer(\n",
       "      (convolution): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (normalization): BatchNorm2d(1280, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU6()\n",
       "    )\n",
       "    (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=True)\n",
       "  (classifier): Linear(in_features=1280, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pretrained.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a75846b-507e-4336-a3b1-8234249f509d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='157' max='157' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [157/157 00:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7993389368057251,\n",
       " 'eval_accuracy': 0.7356,\n",
       " 'eval_runtime': 27.842,\n",
       " 'eval_samples_per_second': 359.17,\n",
       " 'eval_steps_per_second': 5.639,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fac8164",
   "metadata": {},
   "source": [
    "### Trénink inicializovaného MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "447b2059-053c-472d-a505-05d444c65567",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98a4006c-9885-4cb8-a73c-6b593208012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pretrained_whole = get_mobilenet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5507a023-e29b-4ede-b4b9-55a61fbfa3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = get_training_args(output_dir=\"./results/cifar10-pretrained\", logging_dir='./logs/cifar10-pretrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce019dd3-eaab-41b6-b419-0974865ee6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model_pretrained_whole,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9ef60e8e-bab6-48f3-832d-967acf66da05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15640' max='15640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15640/15640 1:30:04, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.667800</td>\n",
       "      <td>0.352117</td>\n",
       "      <td>0.881500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.182900</td>\n",
       "      <td>0.473985</td>\n",
       "      <td>0.855200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.109900</td>\n",
       "      <td>0.307834</td>\n",
       "      <td>0.908600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.306266</td>\n",
       "      <td>0.913600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.035600</td>\n",
       "      <td>0.562306</td>\n",
       "      <td>0.874200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.446769</td>\n",
       "      <td>0.906100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.618080</td>\n",
       "      <td>0.873600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.747778</td>\n",
       "      <td>0.854000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.461412</td>\n",
       "      <td>0.911700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.434470</td>\n",
       "      <td>0.919800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.530582</td>\n",
       "      <td>0.899000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.453351</td>\n",
       "      <td>0.924300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.501860</td>\n",
       "      <td>0.914300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.460102</td>\n",
       "      <td>0.920100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.546194</td>\n",
       "      <td>0.909200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.599153</td>\n",
       "      <td>0.901100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.480319</td>\n",
       "      <td>0.924100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.509955</td>\n",
       "      <td>0.910900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.519222</td>\n",
       "      <td>0.909100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.415389</td>\n",
       "      <td>0.929500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15640, training_loss=0.048249347503666225, metrics={'train_runtime': 5404.6192, 'train_samples_per_second': 185.027, 'train_steps_per_second': 2.894, 'total_flos': 2.020099608576e+18, 'train_loss': 0.048249347503666225, 'epoch': 20.0})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44ddb301-6a63-4959-9e90-80ed17e0ab76",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2ForImageClassification(\n",
       "  (mobilenet_v2): MobileNetV2Model(\n",
       "    (conv_stem): MobileNetV2Stem(\n",
       "      (first_conv): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (conv_3x3): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
       "        (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (reduce_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(16, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer): ModuleList(\n",
       "      (0): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3-4): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(64, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6-8): 3 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(64, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (9): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (10-11): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (12): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), groups=576, bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(160, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (13-14): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(160, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (15): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(320, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_1x1): MobileNetV2ConvLayer(\n",
       "      (convolution): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (normalization): BatchNorm2d(1280, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU6()\n",
       "    )\n",
       "    (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=True)\n",
       "  (classifier): Linear(in_features=1280, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pretrained_whole.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0bf2f4b5-4817-46f8-9ca9-a2c5d4fba61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='157' max='157' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [157/157 00:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4153886139392853,\n",
       " 'eval_accuracy': 0.9295,\n",
       " 'eval_runtime': 30.5178,\n",
       " 'eval_samples_per_second': 327.678,\n",
       " 'eval_steps_per_second': 5.145,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4944737",
   "metadata": {},
   "source": [
    "## Trénink s pomocí destilace znalostí inicializovaného MobileNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93c3905",
   "metadata": {},
   "source": [
    "### Trénink inicializovaného modelu - pouze klasifikační hlavy s pomocí destilace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4154ee53-cb97-49c7-bc7f-645c9a765aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f4d7225-8227-40bc-908f-7af60b6a1f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model_pretrained = get_mobilenet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "61b93d60-5fa5-4034-9c6d-6ebbdf88bad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_model(student_model_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c7b5dd3-6469-4d35-b873-ce7c91e8041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = get_training_args(output_dir=\"./results/cifar10-pretrained-head-KD\", logging_dir='./logs/cifar10-pretrained-head-KD', remove_unused_columns=False, temp=6, lambda_param=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c1b8fbf-547b-43cc-8b6d-350feccc72d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ImageDistilTrainer(\n",
    "    student_model=student_model_pretrained,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90a92fdf-bb9d-43d6-88f3-cedb4d944732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15640' max='15640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15640/15640 1:02:01, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.194200</td>\n",
       "      <td>1.295173</td>\n",
       "      <td>0.638000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.773000</td>\n",
       "      <td>1.352618</td>\n",
       "      <td>0.638800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.734400</td>\n",
       "      <td>1.305183</td>\n",
       "      <td>0.712900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.694700</td>\n",
       "      <td>1.334172</td>\n",
       "      <td>0.714900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.687300</td>\n",
       "      <td>1.368952</td>\n",
       "      <td>0.684700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.671700</td>\n",
       "      <td>1.329848</td>\n",
       "      <td>0.720300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.670400</td>\n",
       "      <td>1.372895</td>\n",
       "      <td>0.664700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.661400</td>\n",
       "      <td>1.381742</td>\n",
       "      <td>0.639500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.658500</td>\n",
       "      <td>1.350707</td>\n",
       "      <td>0.703500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.657100</td>\n",
       "      <td>1.364204</td>\n",
       "      <td>0.720200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.655800</td>\n",
       "      <td>1.340042</td>\n",
       "      <td>0.712400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.653600</td>\n",
       "      <td>1.335667</td>\n",
       "      <td>0.713000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.653300</td>\n",
       "      <td>1.325100</td>\n",
       "      <td>0.710100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.649900</td>\n",
       "      <td>1.380655</td>\n",
       "      <td>0.697700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.646900</td>\n",
       "      <td>1.329752</td>\n",
       "      <td>0.718400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.645300</td>\n",
       "      <td>1.353464</td>\n",
       "      <td>0.696700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.645400</td>\n",
       "      <td>1.321333</td>\n",
       "      <td>0.735600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.647500</td>\n",
       "      <td>1.335600</td>\n",
       "      <td>0.720100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.646300</td>\n",
       "      <td>1.350428</td>\n",
       "      <td>0.729700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.646100</td>\n",
       "      <td>1.384097</td>\n",
       "      <td>0.727300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15640, training_loss=0.688703476498499, metrics={'train_runtime': 3721.5092, 'train_samples_per_second': 268.708, 'train_steps_per_second': 4.203, 'total_flos': 2.020099608576e+18, 'train_loss': 0.688703476498499, 'epoch': 20.0})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "788d8270-cc38-4d48-ab8f-2ed964430346",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2ForImageClassification(\n",
       "  (mobilenet_v2): MobileNetV2Model(\n",
       "    (conv_stem): MobileNetV2Stem(\n",
       "      (first_conv): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (conv_3x3): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
       "        (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (reduce_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(16, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer): ModuleList(\n",
       "      (0): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3-4): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(64, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6-8): 3 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(64, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (9): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (10-11): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (12): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), groups=576, bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(160, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (13-14): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(160, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (15): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(320, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_1x1): MobileNetV2ConvLayer(\n",
       "      (convolution): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (normalization): BatchNorm2d(1280, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU6()\n",
       "    )\n",
       "    (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=True)\n",
       "  (classifier): Linear(in_features=1280, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model_pretrained.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b6d21fed-fe8f-4156-b3b9-abcc5cf205c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='157' max='157' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [157/157 00:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.321333408355713,\n",
       " 'eval_accuracy': 0.7356,\n",
       " 'eval_runtime': 30.0257,\n",
       " 'eval_samples_per_second': 333.048,\n",
       " 'eval_steps_per_second': 5.229,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f28223",
   "metadata": {},
   "source": [
    "### Trénink inicializovaného modelu s pomocí destilace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa3d2f00-dfdd-454c-96c5-3d3cfedc7d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6a5e7e30-dd5e-479f-adc6-01bef4688aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model_pretrained_whole = get_mobilenet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2a571082-8fa2-4111-b4d8-458f90eea863",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = get_training_args(output_dir=\"./results/cifar10-pretrained-KD\", logging_dir='./logs/cifar10-pretrained-KD', remove_unused_columns=False, temp=6, lambda_param=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dc174e6e-38d1-452b-bb23-6380434df6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ImageDistilTrainer(\n",
    "    student_model=student_model_pretrained_whole.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a9763c61-ebdb-4395-8664-bb463fcf7f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15640' max='15640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15640/15640 1:36:21, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.588200</td>\n",
       "      <td>1.113030</td>\n",
       "      <td>0.886800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.246500</td>\n",
       "      <td>1.138879</td>\n",
       "      <td>0.864400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.196800</td>\n",
       "      <td>1.028809</td>\n",
       "      <td>0.921600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.155900</td>\n",
       "      <td>0.991875</td>\n",
       "      <td>0.925200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.139800</td>\n",
       "      <td>1.172694</td>\n",
       "      <td>0.873700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.122300</td>\n",
       "      <td>1.053637</td>\n",
       "      <td>0.913400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>1.166352</td>\n",
       "      <td>0.882600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.109900</td>\n",
       "      <td>1.100621</td>\n",
       "      <td>0.878000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.105700</td>\n",
       "      <td>1.038172</td>\n",
       "      <td>0.919400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.104200</td>\n",
       "      <td>0.995655</td>\n",
       "      <td>0.932400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.100900</td>\n",
       "      <td>1.024308</td>\n",
       "      <td>0.922400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.099400</td>\n",
       "      <td>1.008546</td>\n",
       "      <td>0.932800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.098900</td>\n",
       "      <td>0.999333</td>\n",
       "      <td>0.927900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.098500</td>\n",
       "      <td>0.964980</td>\n",
       "      <td>0.932200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.096800</td>\n",
       "      <td>1.046759</td>\n",
       "      <td>0.926400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.096100</td>\n",
       "      <td>1.016068</td>\n",
       "      <td>0.916400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.095900</td>\n",
       "      <td>0.972261</td>\n",
       "      <td>0.935800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.095500</td>\n",
       "      <td>1.021252</td>\n",
       "      <td>0.922100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.095200</td>\n",
       "      <td>0.996774</td>\n",
       "      <td>0.920300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.094900</td>\n",
       "      <td>0.989577</td>\n",
       "      <td>0.936000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15640, training_loss=0.13773624153088426, metrics={'train_runtime': 5781.8021, 'train_samples_per_second': 172.956, 'train_steps_per_second': 2.705, 'total_flos': 2.020099608576e+18, 'train_loss': 0.13773624153088426, 'epoch': 20.0})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "37cfba84-768e-4461-bd44-e8e0924d7b6e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2ForImageClassification(\n",
       "  (mobilenet_v2): MobileNetV2Model(\n",
       "    (conv_stem): MobileNetV2Stem(\n",
       "      (first_conv): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (conv_3x3): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
       "        (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (reduce_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(16, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer): ModuleList(\n",
       "      (0): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
       "          (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3-4): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
       "          (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(64, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6-8): 3 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(64, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (9): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "          (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (10-11): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (12): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), groups=576, bias=False)\n",
       "          (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(160, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (13-14): 2 x MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(160, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (15): MobileNetV2InvertedResidual(\n",
       "        (expand_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (conv_3x3): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "          (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU6()\n",
       "        )\n",
       "        (reduce_1x1): MobileNetV2ConvLayer(\n",
       "          (convolution): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(320, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_1x1): MobileNetV2ConvLayer(\n",
       "      (convolution): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (normalization): BatchNorm2d(1280, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU6()\n",
       "    )\n",
       "    (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=True)\n",
       "  (classifier): Linear(in_features=1280, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model_pretrained.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ebcfba8e-655d-40dc-a557-fbadb912fd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='157' max='157' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [157/157 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9895767569541931,\n",
       " 'eval_accuracy': 0.936,\n",
       " 'eval_runtime': 27.2427,\n",
       " 'eval_samples_per_second': 367.071,\n",
       " 'eval_steps_per_second': 5.763,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
