{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b80e8fe1",
   "metadata": {},
   "source": [
    "# Notebook pro trénink s destilací nad datasetem CIFAR10\n",
    "V tomto notebooku je trénován MobileNetV2 nad datasetem CIFAR10, jako učitelsý model je využíván finetunued ViT nad stejným datasetem. \n",
    "\n",
    "MobileNetV2 je používán s náhodnou inicializací, tréninkem pouze klasifikační hlavy inicializovaného (předtrénovaného nad ImageNetem) MobileNetuV2 a trénink celého modelu, taktéž inicializovaného. Tyto tři úlohy jsou trénovány bězným způsobem a také s pomocí destilace výše zmíněného modelu.  \n",
    "\n",
    "Při destilaci je využíváno předpočítaných logitů ze sešitu precompute_logits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d1c726",
   "metadata": {},
   "source": [
    "## Import knihoven a definice metod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7e7a26f-aa1f-4645-b3b3-4643ca8be2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, EarlyStoppingCallback, AutoModelForImageClassification\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import torch\n",
    "import math\n",
    "import base\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce29a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_part = base.get_dataset_part()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf6897a",
   "metadata": {},
   "source": [
    "Resetování náhodného seedu pro replikovatelnost výsledků."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd53a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29b9ceef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and will be used: NVIDIA H100 PCIe\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and will be used:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eb90dc",
   "metadata": {},
   "source": [
    "Provedení transformací nad datasetem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec5b1934",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"cifar100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b74ce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = base.base_transforms()\n",
    "\n",
    "#Poslední train batch použijeme jako eval část...\n",
    "test = base.CustomCIFAR100L(root=f\"{os.path.expanduser('~')}/data/100-logits\", dataset_part=dataset_part.TEST, transform=transform)\n",
    "train = base.CustomCIFAR100L(root=f\"{os.path.expanduser('~')}/data/100-logits\", dataset_part=dataset_part.TRAIN, transform=transform)\n",
    "eval = base.CustomCIFAR100L(root=f\"{os.path.expanduser('~')}/data/100-logits\", dataset_part=dataset_part.EVAL, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5f20702",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_transform = base.aug_transforms()\n",
    "train_aug = base.CustomCIFAR100L(root=f\"{os.path.expanduser('~')}/data/100-logits\", dataset_part=dataset_part.TRAIN, transform=augment_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8892fc30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70fe6727ce7d4fdab6b769eadabb5bc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Removing entries from augmented dataset that are different from the base one - based on saved logits:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_aug = base.remove_diff_pred_class(train, train_aug, pytorch_dataset=True)\n",
    "train_combo = ConcatDataset([train, train_aug])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b36ab156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "0     100\n",
      "63    100\n",
      "73    100\n",
      "72    100\n",
      "71    100\n",
      "     ... \n",
      "30    100\n",
      "29    100\n",
      "28    100\n",
      "27    100\n",
      "99    100\n",
      "Name: count, Length: 100, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Test rozložení --> Good Enough\n",
    "df = pd.DataFrame(eval.labels)\n",
    "print(df.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a85914",
   "metadata": {},
   "source": [
    "### Standardní trénink náhodně inicializovaného modelu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa456108",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 7\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71481756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nápočet epoch na steps\n",
    "data_length = len(train)\n",
    "min_r = math.ceil(data_length/batch_size)*2\n",
    "max_r = math.ceil(data_length/batch_size)*num_epochs\n",
    "warm_up = math.ceil(data_length/batch_size/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b1cf201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_space(trial):\n",
    "    params =  {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 5e-5, 5e-3, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0, 1e-2, step=1e-3),\n",
    "        \"warmup_steps\" : trial.suggest_int(\"warmup_steps\", 0, warm_up)\n",
    "    }   \n",
    "    print(f\"Trial {trial.number} with params: {params}\")\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10b540bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pruner = optuna.pruners.HyperbandPruner(min_resource=min_r, max_resource=max_r, reduction_factor=2, bootstrap_count=2)\n",
    "sampler = optuna.samplers.TPESampler(seed=42, multivariate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfdd0c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15c07c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/_hp-search\", logging_dir=f\"~/logs/{DATASET}/_hp-search\", epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "035b3241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    return AutoModelForImageClassification.from_pretrained(\"timm/tiny_vit_5m_224.in1k\", num_labels=100, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cc2f65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of TimmWrapperForImageClassification were not initialized from the model checkpoint at timm/tiny_vit_5m_224.in1k and are newly initialized because the shapes did not match:\n",
      "- head.fc.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([100]) in the model instantiated\n",
      "- head.fc.weight: found shape torch.Size([1000, 320]) in the checkpoint and torch.Size([100, 320]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    model_init = lambda: get_model()\n",
    ")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9524e916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 23:22:16,562] A new study created in memory with name: Base\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 with params: {'learning_rate': 0.0002805758207667253, 'weight_decay': 0.01, 'warmup_steps': 24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of TimmWrapperForImageClassification were not initialized from the model checkpoint at timm/tiny_vit_5m_224.in1k and are newly initialized because the shapes did not match:\n",
      "- head.fc.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([100]) in the model instantiated\n",
      "- head.fc.weight: found shape torch.Size([1000, 320]) in the checkpoint and torch.Size([100, 320]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1252' max='2191' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1252/2191 03:28 < 02:36, 5.99 it/s, Epoch 4/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.779000</td>\n",
       "      <td>0.893963</td>\n",
       "      <td>0.740600</td>\n",
       "      <td>0.762904</td>\n",
       "      <td>0.740600</td>\n",
       "      <td>0.740171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.584700</td>\n",
       "      <td>0.686867</td>\n",
       "      <td>0.794800</td>\n",
       "      <td>0.806792</td>\n",
       "      <td>0.794800</td>\n",
       "      <td>0.794618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.336300</td>\n",
       "      <td>0.631952</td>\n",
       "      <td>0.815400</td>\n",
       "      <td>0.824960</td>\n",
       "      <td>0.815400</td>\n",
       "      <td>0.815350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.184800</td>\n",
       "      <td>0.601714</td>\n",
       "      <td>0.832700</td>\n",
       "      <td>0.840475</td>\n",
       "      <td>0.832700</td>\n",
       "      <td>0.832641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 23:25:51,435] Trial 0 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 with params: {'learning_rate': 0.0007875660249889869, 'weight_decay': 0.001, 'warmup_steps': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of TimmWrapperForImageClassification were not initialized from the model checkpoint at timm/tiny_vit_5m_224.in1k and are newly initialized because the shapes did not match:\n",
      "- head.fc.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([100]) in the model instantiated\n",
      "- head.fc.weight: found shape torch.Size([1000, 320]) in the checkpoint and torch.Size([100, 320]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='626' max='2191' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 626/2191 01:40 < 04:12, 6.19 it/s, Epoch 2/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.837700</td>\n",
       "      <td>1.323822</td>\n",
       "      <td>0.627000</td>\n",
       "      <td>0.676967</td>\n",
       "      <td>0.627000</td>\n",
       "      <td>0.624342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.914200</td>\n",
       "      <td>1.028047</td>\n",
       "      <td>0.697900</td>\n",
       "      <td>0.728427</td>\n",
       "      <td>0.697900</td>\n",
       "      <td>0.693776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 23:27:34,014] Trial 1 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 with params: {'learning_rate': 6.533369619026643e-05, 'weight_decay': 0.009000000000000001, 'warmup_steps': 19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of TimmWrapperForImageClassification were not initialized from the model checkpoint at timm/tiny_vit_5m_224.in1k and are newly initialized because the shapes did not match:\n",
      "- head.fc.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([100]) in the model instantiated\n",
      "- head.fc.weight: found shape torch.Size([1000, 320]) in the checkpoint and torch.Size([100, 320]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1252' max='2191' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1252/2191 04:07 < 03:06, 5.04 it/s, Epoch 4/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.847600</td>\n",
       "      <td>1.418506</td>\n",
       "      <td>0.692800</td>\n",
       "      <td>0.702749</td>\n",
       "      <td>0.692800</td>\n",
       "      <td>0.684777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.964500</td>\n",
       "      <td>0.804600</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.790334</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.785589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.535300</td>\n",
       "      <td>0.642450</td>\n",
       "      <td>0.819400</td>\n",
       "      <td>0.821925</td>\n",
       "      <td>0.819400</td>\n",
       "      <td>0.818424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.338900</td>\n",
       "      <td>0.594126</td>\n",
       "      <td>0.828900</td>\n",
       "      <td>0.831575</td>\n",
       "      <td>0.828900</td>\n",
       "      <td>0.828155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-30 23:31:43,543] Trial 2 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 with params: {'learning_rate': 0.0013035123791853842, 'weight_decay': 0.0, 'warmup_steps': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of TimmWrapperForImageClassification were not initialized from the model checkpoint at timm/tiny_vit_5m_224.in1k and are newly initialized because the shapes did not match:\n",
      "- head.fc.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([100]) in the model instantiated\n",
      "- head.fc.weight: found shape torch.Size([1000, 320]) in the checkpoint and torch.Size([100, 320]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='314' max='2191' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 314/2191 00:37 < 03:45, 8.34 it/s, Epoch 1/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.301500</td>\n",
       "      <td>1.986411</td>\n",
       "      <td>0.469400</td>\n",
       "      <td>0.565807</td>\n",
       "      <td>0.469400</td>\n",
       "      <td>0.464106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_base = trainer.hyperparameter_search(\n",
    "    direction=\"maximize\",\n",
    "    backend=\"optuna\",\n",
    "    hp_space=hp_space,\n",
    "    compute_objective=lambda metrics: metrics[\"eval_f1\"],\n",
    "    pruner=pruner,\n",
    "    sampler=sampler,\n",
    "    study_name=\"Base\",\n",
    "    n_trials=150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50f7744",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_base_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24f990e8-d259-44c7-b85b-cca2f4f97a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad7fa0f-f432-4e99-bb07-31951b7858f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/-KD_hp-search\", logging_dir=f\"~/logs/{DATASET}/-KD_hp-search\",  remove_unused_columns=False, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7285525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_space(trial):\n",
    "    params =  {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 5e-5, 5e-3, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0, 1e-2, step=1e-3),\n",
    "        \"warmup_steps\" : trial.suggest_int(\"warmup_steps\", 0, warm_up),\n",
    "        \"lambda_param\": trial.suggest_float(\"lambda_param\",0,1,step=.1),\n",
    "        \"temperature\": trial.suggest_float(\"temperature\", 2,7, step=.5)\n",
    "    }\n",
    "    print(f\"Trial {trial.number} with params: {params}\")\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "167bf222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pruner = optuna.pruners.HyperbandPruner(min_resource=min_r, max_resource=max_r, reduction_factor=2, bootstrap_count=2)\n",
    "sampler = optuna.samplers.TPESampler(seed=42, multivariate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9239ca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainer(\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    model_init = lambda: get_model()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2287f2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_distill = trainer.hyperparameter_search(\n",
    "    direction=\"maximize\",\n",
    "    backend=\"optuna\",\n",
    "    hp_space=hp_space,\n",
    "    compute_objective=lambda metrics: metrics[\"eval_f1\"],\n",
    "    pruner=pruner,\n",
    "    sampler=sampler,\n",
    "    study_name=\"Distill\",\n",
    "    n_trials=150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e740f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BestRun(run_id='35', objective=0.8607044045531035, hyperparameters={'learning_rate': 0.0006139968240256416, 'weight_decay': 0.007, 'warmup_steps': 4, 'lambda_param': 0.30000000000000004, 'temperature': 6.0}, run_summary=None)\n"
     ]
    }
   ],
   "source": [
    "print(best_distill_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0b010c5-c092-4b29-b948-4b2497639caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f087c232",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/-aug_hp-search\", logging_dir=f\"~/logs/{DATASET}/-aug_hp-search\", epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd6c88aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_space(trial):\n",
    "    params =  {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 5e-5, 5e-3, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0, 1e-2, step=1e-3),\n",
    "        \"warmup_steps\" : trial.suggest_int(\"warmup_steps\", 0, warm_up)\n",
    "    }   \n",
    "    print(f\"Trial {trial.number} with params: {params}\")\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c125351c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pruner = optuna.pruners.HyperbandPruner(min_resource=min_r, max_resource=max_r, reduction_factor=2, bootstrap_count=2)\n",
    "sampler = optuna.samplers.TPESampler(seed=42, multivariate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1bb8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4021edd7d4a5404a8ab8d2b9331af961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/69.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc958f9818e34d1b98cc48f27c4a9158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/14.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    args=training_args,\n",
    "    train_dataset=train_combo,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    model_init = lambda: get_model()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5717abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_base_aug = trainer.hyperparameter_search(\n",
    "    direction=\"maximize\",\n",
    "    backend=\"optuna\",\n",
    "    hp_space=hp_space,\n",
    "    compute_objective=lambda metrics: metrics[\"eval_f1\"],\n",
    "    pruner=pruner,\n",
    "    sampler=sampler,\n",
    "    study_name=\"Base-head\",\n",
    "    n_trials=150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22ab8463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BestRun(run_id='35', objective=0.7718702742260117, hyperparameters={'learning_rate': 0.0024870786738035154, 'weight_decay': 0.009000000000000001, 'warmup_steps': 20}, run_summary=None)\n"
     ]
    }
   ],
   "source": [
    "print(best_base_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "029dc1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "base.reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5964b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = base.get_training_args(output_dir=f\"~/results/{DATASET}/-aug-KD_hp-search\", logging_dir=f\"~/logs/{DATASET}/-aug-KD_hp-search\", remove_unused_columns=False, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e46a6f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_space(trial):\n",
    "    params =  {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 5e-5, 5e-3, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0, 1e-2, step=1e-3),\n",
    "        \"warmup_steps\" : trial.suggest_int(\"warmup_steps\", 0, warm_up),\n",
    "        \"lambda_param\": trial.suggest_float(\"lambda_param\",0,1,step=.1),\n",
    "        \"temperature\": trial.suggest_float(\"temperature\", 2,7, step=.5)\n",
    "    }\n",
    "    print(f\"Trial {trial.number} with params: {params}\")\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c281d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pruner = optuna.pruners.HyperbandPruner(min_resource=min_r, max_resource=max_r, reduction_factor=2, bootstrap_count=2)\n",
    "sampler = optuna.samplers.TPESampler(seed=42, multivariate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08588175",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = base.DistilTrainer(\n",
    "    args=training_args,\n",
    "    train_dataset=train_combo,\n",
    "    eval_dataset=eval,\n",
    "    compute_metrics=base.compute_metrics,\n",
    "    model_init = lambda: get_model()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2b7d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_distill_aug = trainer.hyperparameter_search(\n",
    "    direction=\"maximize\",\n",
    "    backend=\"optuna\",\n",
    "    hp_space=hp_space,\n",
    "    compute_objective=lambda metrics: metrics[\"eval_f1\"],\n",
    "    pruner=pruner,\n",
    "    sampler=sampler,\n",
    "    study_name=\"Distill\",\n",
    "    n_trials=150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e7cbbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BestRun(run_id='44', objective=0.7611287079618219, hyperparameters={'learning_rate': 0.00063155918393816, 'weight_decay': 0.009000000000000001, 'warmup_steps': 5, 'lambda_param': 0.6000000000000001, 'temperature': 4.0}, run_summary=None)\n"
     ]
    }
   ],
   "source": [
    "print(best_distill_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aace0a8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_base_random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest random init training score: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mbest_base_random\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest random init distilation trianing score: \u001b[39m\u001b[38;5;124m\"\u001b[39m, best_distill_random)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest pretrained (head only) training score: \u001b[39m\u001b[38;5;124m\"\u001b[39m, best_base_head)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_base_random' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Best random init training score: \", best_base)\n",
    "print(\"Best random init distilation trianing score: \", best_distill)\n",
    "print(\"Best pretrained (head only) training score: \", best_base_aug)\n",
    "print(\"Best pretrained distilation (head only) training score: \",best_distill_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ebe2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
